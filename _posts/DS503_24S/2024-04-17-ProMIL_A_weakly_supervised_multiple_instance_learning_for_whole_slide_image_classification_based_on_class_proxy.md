---
title:  "[ESWA 2023] ProMIL: A weakly supervised multiple instance learning for whole slide image classification based on class proxy"
permalink: ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy.html
tags: [reviews]
use_math: true
usemathjax: true
---


# Bag level label ì˜ˆì¸¡ì„ ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì— ëŒ€í•˜ì—¬

## 1. Problem Definition
&emsp;WSI(Whole Slide Image)ëŠ” ì§ˆë³‘ ì§„ë‹¨, ë³‘ë¦¬í•™ ì—°êµ¬ ë“±ì—ì„œ ì¡°ì§ì˜ ì‹œê°í™”ì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” giga pixel ë‹¨ìœ„ì˜ ì´ë¯¸ì§€ì´ë‹¤. í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì´ í•™ìŠµí•˜ì—¬ ë‹¤ì–‘í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” WSIë¥¼ ì‘ì€ patchë“¤ë¡œ ë‚˜ëˆ„ëŠ” patching ê³¼ì •ì´ í•„ìš”í•˜ë‹¤. ë˜í•œ, ë³‘ë¦¬í•™ìë“¤ì— ì˜í•œ localized annoationì´ í•„ìš”í•˜ë‚˜, ì´ëŠ” ë§ì€ ì‹œê°„ê³¼ ë¹„ìš©ì„ ì†Œëª¨í•œë‹¤. ë”°ë¼ì„œ, patch levelì—ì„œì˜ lable ì—†ì´ Slide(WSI) ë‹¨ìœ„ì˜ label ë§Œì„ í™œìš©í•˜ì—¬ WSIì˜ ë²”ì£¼ë¥¼ ë¶„ë¥˜í•˜ëŠ” weakly supervised learningì˜ í•„ìš”ì„±ì´ ë¶€ê°ëœë‹¤. ë³¸ ë…¼ë¬¸ì€ class proxyë¥¼ í™œìš©í•˜ì—¬ WSIì— ëŒ€í•œ weakly supervised learningì„ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ë°©ì•ˆì„ ì œì‹œí•œë‹¤.

## 2. Motivation
&emsp;Multiple Instance Learning(MIL)ì€ WSIì™€ ê°™ì€ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ”ë° íš¨ê³¼ì ì¸ ëª¨ë¸ì´ë‹¤. í•´ë‹¹ ëª¨ë¸ì€ feature extractor, aggregator, classifierë¡œ ì´ë£¨ì–´ì ¸ ì‘ì€ patchë“¤ë¡œë¶€í„° featureë¥¼ ì¶”ì¶œí•˜ì—¬ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ embeddingì„ ìˆ˜í–‰í•˜ê³ , WSIì˜ ë²”ì£¼ë¥¼ ë¶„ë¥˜í•  ìˆ˜ ìˆë‹¤. ê·¸ëŸ¬ë‚˜, ê¸°ì¡´ conventional MILì€ 1ì¥ì—ì„œ ì–¸ê¸‰í•œ ë°”ì™€ ê°™ì´ patch level labelì„ í•„ìš”ë¡œ í•˜ë©°, ë²”ì£¼ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ”ë° ì–´ë ¤ì›€ì„ ì§€ë‹Œë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œë„ê°€ ì´ë£¨ì–´ì¡Œìœ¼ë‚˜, ë‹¤ìŒê³¼ ê°™ì€ í•œê³„ì ì„ ì§€ë‹Œë‹¤.   

[DS-MIL(CVPR 2021)](https://arxiv.org/abs/2011.08939): Dual streamì„ ë„ì…í•˜ì—¬ ì¤‘ìš”í•œ patchë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ predictionì€ ìˆ˜í–‰í•œë‹¤. 1st streamì€ max-poolingì„ í™œìš©í•˜ì—¬ informative patchë¥¼ ì‹ë³„í•˜ë©°, 2nd streamì€ ê° patchì— ëŒ€í•œ attention scoreë¥¼ ê³„ì‚°í•˜ì—¬ predictionì„ ìˆ˜í–‰í•œë‹¤. ê·¸ëŸ¬ë‚˜, DS-MILì€ spatial featureë¥¼ ë°˜ì˜í•˜ì§€ ëª»í•œë‹¤ëŠ” í•œê³„ì ì„ ì§€ë‹Œë‹¤.   

[DTFD-MIL(CVPR 2022)](https://arxiv.org/abs/2203.12081): WSI levelì—ì„œì˜ ì •ë³´ë§Œ ì¡´ì¬í•  ë¿, patch levelì˜ ì •ë³´ëŠ” ì¡´ì¬í•˜ì§€ ì•Šê¸°ì—, pseudo-bagì„ ë„ì…í•˜ì—¬ # of bagë¥¼ ëŠ˜ë¦¬ê³ , ê²°ê³¼ì ìœ¼ë¡œ ë™ì¼í•œ ë°ì´í„°ë¡œë¶€í„° ë³´ë‹¤ ë§ì€ ì •ë³´ë¥¼ ì–»ê³ ì ì‹œë„í•œë‹¤. T1 ë‹¨ê³„ì—ì„œ ê° pseudo-bagì˜ representationì„ ì˜ˆì¸¡í•˜ê³ , T2 ë‹¨ê³„ì—ì„œëŠ” T1 ë‹¨ê³„ì—ì„œì˜ ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ WSI levelì˜ predictionì„ ìˆ˜í–‰í•œë‹¤. ê·¸ëŸ¬ë‚˜, DTFD-MILì€ pseudo-bagì˜ ìˆ˜ë¥¼ ì‹¤í—˜ì ìœ¼ë¡œ ê²°ì •í•´ì•¼ í•˜ë©°, label noiseì— ë¯¼ê°í•˜ë‹¤ëŠ” í•œê³„ì ì„ ì§€ë‹Œë‹¤.   


## 3. Method
&emsp;ê¸°ì¡´ì˜ conventional MILê³¼ DS-MIL, DTFD-MIL ë“±ì„ ë³´ì™„í•˜ì—¬ ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ëŠ” ProMILì€ patch levelì˜ annotation ì—†ì´ class proxyë¥¼ í†µí•´ ê° ë²”ì£¼ì˜ íŠ¹ì„±ì„ ê°€ì¥ ì˜ ë‚˜íƒ€ë‚´ëŠ” representativeí•œ vectorë¥¼ ì°¾ê³ , ì´ë¥¼ í™œìš©í•˜ì—¬ WSIì˜ class labelì„ ì˜ˆì¸¡í•˜ëŠ” weakly supervised learning + metric learning ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤. Fig.1ì€ ê¸°ì¡´ì˜ ë°©ë²•ë¡ ê³¼ ProMILì˜ êµ¬ì¡°ì ì¸ ì°¨ì´ë¥¼ ê°„ëµí•˜ê²Œ í‘œí˜„í•œë‹¤.   

<p align="center">
  <img src="../../images/DS503_24S/ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy/Fig1.jpg" alt="alt text"/>
  <br>
  <em>Fig.1. Illustration of the difference between ProMIL and conventional MIL models</em>
</p>

### 3.1 Metric Learning
&emsp;Weakly supervised learningê³¼ëŠ” ë‹¬ë¦¬ í•„ìì—ê²Œ metric learningì€ ë‹¤ì†Œ ìƒì†Œí•œ ê´€ê³„ë¡œ ë³¸ ë…¼ë¬¸ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œ metric learningì— ëŒ€í•´ ê°„ëµíˆ ë‹¤ë£¨ê³ ì í•œë‹¤. ê¸°ì¡´ì˜ featureë¡œëŠ” ë¶„ë¥˜ê°€ ì‰½ì§€ ì•Šì•˜ë˜ ë°ì´í„°ì— ëŒ€í•´ ë°ì´í„°ë¥¼ class label ë³„ë¡œ ì˜ êµ¬ë¶„í•  ìˆ˜ ìˆê²Œ ë§Œë“œëŠ” metricì„ í•™ìŠµí•˜ëŠ” ê³¼ì •ì„ ì˜ë¯¸í•œë‹¤. Fig.2ëŠ” ì´ëŸ¬í•œ ê´€ì ì—ì„œ metric learningì˜ ëª©ì ì„ ì‹œê°ì ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ë‹¤.   

<p align="center">
  <img src="../../images/DS503_24S/ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy/Fig2.png" alt="alt text"/>
  <br>
  <em>Fig.2. Illustration of purpose for metric learning</em>
</p>

&emsp;ê¸°ì¡´ì˜ classification taskì™€ëŠ” ë‹¤ë¥´ê²Œ metric learningì€ íŠ¹íˆ imbalance datasetì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤. ë¶„ë¥˜ ë¬¸ì œëŠ” "$x$ëŠ” $y$ì´ë‹¤."ë¼ëŠ” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìŠµì„ ìˆ˜í–‰í•˜ëŠ” ë°˜ë©´, metric learningì€ "$x_1$ì€ $x_2$ì™€ëŠ” ê°€ê¹ê³ , $x_3$ì™€ëŠ” ë©€ë‹¤."ë¼ëŠ” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ê¸°ì— ë³´ë‹¤ sparseí•œ labelì— ëŒ€í•´ì„œë„ ë‹¤ë¥¸ class labelë¡œë¶€í„° ë©€ë¦¬ ë–¨ì–´ì§€ê²Œë” í•™ìŠµì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ì¦‰, ê°™ì€ classë¼ë¦¬ëŠ” ê°€ê¹ê²Œ, ë‹¤ë¥¸ classë¼ë¦¬ëŠ” ë©€ê²Œë¼ëŠ” ì†Œê¸° ëª©ì ì˜ ì ˆë°˜ì€ ë‹¬ì„±í•œ ì…ˆì´ë‹¤.

&emsp;Metric learningì„ í†µí•´ í•™ìŠµëœ ìƒˆë¡œìš´ ê±°ë¦¬ í•¨ìˆ˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ embedding function $ğ‘“: â„^ğ‘Ÿâ†’â„^ğ‘š$ë¥¼ í†µí•´ ë³€í™˜ëœ ìƒˆë¡œìš´ ë°ì´í„° í‘œí˜„ì— ëŒ€í•œ Euclidean distanceë¡œ ì •ì˜ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, metric learningì„ í†µí•´ í•™ìŠµëœ ê±°ë¦¬ í•¨ìˆ˜ë¥¼ ğ‘“(ğ‘¥;ğœƒ)ë¼ê³  í•  ë•Œ, ë‘ ë°ì´í„° $ğ’™_ğŸ$ê³¼ $ğ’™_2$ì— ëŒ€í•œ ìƒˆë¡œìš´ ê±°ë¦¬ í•¨ìˆ˜ $d(ğ’™_ğŸ, ğ’™_2)$ëŠ” ì•„ë˜ì™€ ê°™ì´ ì •ì˜ëœë‹¤. ë”°ë¼ì„œ, metric learning ë¬¸ì œì˜ ëª©ì ì€ ë°ì´í„°ë¥¼ ê° ëª©í‘œê°’ì— ë”°ë¼ ì˜ êµ¬ë¶„ë˜ë„ë¡ ë³€í™˜í•˜ëŠ” embedding í•¨ìˆ˜ ğ‘“ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ ëœë‹¤. ì´ë–„, ğ‘“ê°€ ë‹¨ìˆœí•œ ì„ í˜• ë³€í™˜ì´ ì•„ë‹ˆë¼, deep neural networkì¼ ê²½ìš°ì— ì•ì— deepì„ ë¶™ì—¬ deep metric learningì´ë¼ê³  í•œë‹¤. 

$d(ğ’™_ğŸ, ğ’™_2)=\vert\vert f(ğ’™_ğŸ)-f(ğ’™_2)\vert\vert^2_2$

&emsp;Deep metric learningì—ëŠ” contrastive loss, triplet loss ë“± ë‹¤ì–‘í•œ loss functionì— ê¸°ë°˜í•œ ë°©ë²•ì´ ìˆì§€ë§Œ, ì´ëŠ” sampling, calculation issueë¥¼ ì§€ë‹ˆë¯€ë¡œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” class proxy, ì¦‰ ê° í´ë˜ìŠ¤ë¥¼ ê°€ì¥ ì˜ ëŒ€í‘œí•˜ëŠ” vectorë¥¼ ì°¾ê¸° ìœ„í•œ  NCA lossë¥¼ ì‚¬ìš©í•˜ì˜€ìŒì„ ë°íŒë‹¤. ì´ë•Œ, NCA lossëŠ” sample vectorì™€ proxy vectorë¥¼ ìµœëŒ€í•œ ê°€ê¹ê²Œ ë§Œë“œëŠ”ë° ëª©ì ì„ ë‘ë©°, ëª¨ë“  sample set $Z$ì™€ sample vector $x$, proxy vector $y$ì— ëŒ€í•´ì„œ ì•„ë˜ì™€ ê°™ì´ ì •ì˜ëœë‹¤.   

$L_{NCA}(x, y, Z) = -\log \left( \frac{\exp(-d(x, y))}{\sum_{z \in Z} \exp(-d(x, z))} \right)$

### 3.2 Overall Framework
&emsp;ProMIL ëª¨ë¸ì˜ overall frameworkëŠ” Fig.3.ì— ì œì‹œëœë‹¤. Patching(preprocessing) ê³¼ì •ì„ ê±°ì¹œ WSI ë°ì´í„°ì— ëŒ€í•˜ì—¬ í•´ë‹¹ ëª¨ë¸ì˜ ì£¼ìš” workflowëŠ” 2ê°œ ë¶„ê¸°ë¥¼ í¬í•¨í•œë‹¤. ìƒìœ„ ë¶„ê¸°ì—ì„œëŠ” ê° WSI embedding ê³¼ì •ì„, í•˜ìœ„ ë¶„ê¸°ì—ì„œëŠ” class proxy í•™ìŠµ ê³¼ì •ì„ ê±°ì¹˜ë©°, ê²°ê³¼ì ìœ¼ë¡œ, embedding vectorì™€ proxy vector ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ NCA loss functionì„ í™œìš©í•˜ì—¬ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì™€ class proxyê°€ ì—…ë°ì´íŠ¸ëœë‹¤.   

<p align="center">
  <img src="../../images/DS503_24S/ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy/Fig3.jpg" alt="alt text"/>
  <br>
  <em>Fig.3. Illustration of ProMIL's overall framework</em>
</p>

### 3.3 Preprocessing
&emsp;WSIì—ëŠ” trainingê³¼ inferenceì— ì˜ë¯¸ì—†ëŠ” background areaê°€ ì¡´ì¬í•œë‹¤. ë”°ë¼ì„œ, RGBë¡œë¶€í„° HSV color spaceë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€ì˜ í¬í™”ë„ ê°’ê³¼ ì„ê³„ê°’ì„ ë¹„êµí•˜ì—¬ ì¡°ì§ ì˜ì—­ì˜ binary maskë¥¼ ìƒì„±í•œë‹¤. ì´í›„, blurringê³¼ morphological closingì„ í†µí•´ tissue extractionì„ ìˆ˜í–‰í•œë‹¤. ê·¸ëŸ¬ë‚˜, ì¶”ì¶œëœ ì¡°ì§ ì˜ì—­ ë˜í•œ ì»´í“¨í„°ê°€ ì²˜ë¦¬í•˜ê¸°ì— ë§¤ìš° í¬ê¸°ì— ì§ì ‘ í›ˆë ¨ì— ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ patchë¡œ ë¶„í• í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” WSIë¥¼ 224x224 í¬ê¸°ì˜ ì¼ë ¨ì˜ íŒ¨ì¹˜ë¡œ ìë¥¸ë‹¤. ê·¸ ê²°ê³¼, Fig.4.ì˜ (c)ì™€ ê°™ì€ Patchingì„ ì™„ë£Œí•œ tissue regionì„ ì–»ì„ ìˆ˜ ìˆë‹¤.

<p align="center">
  <img src="../../images/DS503_24S/ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy/Fig4.jpg" alt="alt text"/>
  <br>
  <em>Fig.4. Illustration of preprocessing WSI</em>
</p>

### 3.4 WSI Embedding
&emsp;ì•ì„œ 3.3ì¥ì˜ preprocessingì„ ë§ˆì¹œ WSIëŠ” multi-scale feature generator (MSFG)ì— ì˜í•´ ê°œì²´ë³„ë¡œ representation matrix $R$ì´ ìƒì„±ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, $i$ë²ˆì§¸ WSIì˜ $j$ë²ˆì§¸ patch $x_{i,j}$ëŠ” pretrained ResNet101ì˜ stage3 ($S_3$) & stage4 ($S_4$)ë¥¼ ê±°ì³ ê°ì ë‹¤ë¥¸ í¬ê¸°ì˜ ì°¨ì› $l_3, l_4$ë¥¼ ì§€ë‹ˆëŠ” features $s_{i,j}^3, s_{i,j}^4$ê°€ ì¶”ì¶œëœë‹¤.   
$$
s_{i,j}^3=S_3(x_{i,j}), s_{i,j}^4=S_4(x_{i,j})
$$   
$$
s_{i,j}^3 \in \mathbb{R}^{1 \times l_3}, s_{i,j}^4 \in \mathbb{R}^{1 \times l_4}
$$

&emsp;$$s^3_{i,j},s^4_{i,j}$$ ëŠ” concatenateë˜ì–´ $i$th WSI's $j$th patch $x_{i,j}$ì— ëŒ€í•œ representation vector $r_{i,j}$ê°€ ìƒì„±ë˜ê³  $i$th WSIì— ëŒ€í•˜ì—¬ $n_i$ê°œì˜ patch representation vectorë¥¼ í† ëŒ€ë¡œ representation matrix $R_i$ ê°€ ìƒì„±ëœë‹¤. ì´ë•Œ $z$ëŠ” concat featureì˜ ì°¨ì›ì„ ì˜ë¯¸í•œë‹¤.
$$
r_{i,j}=concat([s^3_{i,j},s^4_{i,j}]), \quad r_{i,j} \in \mathbb{R}^{1 \times z}
$$   
$$
R_i = \{ r_{i,1}, r_{i,2}, \ldots, r_{i,n_i} \}, \quad R_i \in \mathbb{R}^{n_i \times z}
$$

&emsp;$i$th WSI's representation matrix $R_i$ì— ëŒ€í•˜ì—¬ batch normalization, projection, activation, regularizationì„ ê±°ì³ WSIë³„ë¡œ matrix $$H'_i$$ì™€ patchë³„ë¡œ vector $$h'_{i,j}$$ê°€ ìƒì„±ëœë‹¤. ì´ë•Œ, $$W_p$$ëŠ” projection matrixë¥¼ ì˜ë¯¸í•œë‹¤.
$$
R'_i=BatchNormald(R_i)
$$
$$
H^T_i=Relu(W_pR'^T_i), \quad W_p \in \mathbb{R}^{d \times z}
$$
$$
H'_i=L2-Norm(H_i), \quad H'_i \in \mathbb{R}^{n_i \times d}
$$
$$
H_i' = \{ h_{i,1}', \ldots, h_{i,n_i}' \}, \quad h_{i,j}' \in \mathbb{R}^{1 \times d}
$$

&emsp;patchë³„ vector $h'_{i,j}$ëŠ” [Gated-Attention (Ilse et al., 2018)](https://proceedings.mlr.press/v80/ilse18a.html?ref=https://githubhelp.com)ì„ í†µí•´ attention score ê³„ì‚°, dropout, weighted aggregationì„ ê±°ì³ $i$th WSI embedding $G_i$ë¥¼ outputìœ¼ë¡œ ë„ì¶œí•˜ê²Œ ëœë‹¤.

$$
a_{i,j} = \frac{\exp{ \left( W_a \left( \tanh \left( V_a h_{i,j}' \right)^T \right) \odot \sigma \left( U_a h_{i,j}' \right)^T \right) }}{\sum_{p=1}^{n_i} \exp{ \left( W_a \left( \tanh \left( V_a h_{i,p}' \right)^T \right) \odot \sigma \left( U_a h_{i,p}' \right)^T \right) }}
$$
$$
\{ a_{i,1}', \ldots, a_{i,n_i}' \} = \text{dropout}(a_{i,1}, \ldots, a_{i,n_i})
$$
$$
G_i = \sum_{j=1}^{n_i} a_{i,j}' h_{i,j}'
$$
Fig.5ëŠ” preprocessingë¶€í„° feature extraction, projection, gated attention ë“± WSI Embeddingì˜ ì „ì²´ì ì¸ ê³¼ì •ì„ ë³´ì—¬ì¤€ë‹¤.

<p align="center">
  <img src="../../images/DS503_24S/ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy/Fig5.jpg" alt="alt text"/>
  <br>
  <em>Fig.5. Illustration of WSI embedding overflow</em>
</p>

### 3.5 Class Proxy Construction
&emsp;ê° classë¥¼ ê°€ì¥ ì˜ ë‚˜íƒ€ë‚´ëŠ” vector, class proxyëŠ” randomí•˜ê²Œ initialized ë˜ì–´, 3.4ì¥ì—ì„œ ë„ì¶œí•œ WSI embedding $G_i$ì™€ì˜ ì°¨ì´ë¥¼ minimizeí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ $T$ epoch ë™ì•ˆ í•™ìŠµ ê³¼ì •ì—ì„œ update ëœë‹¤. ì´ë•Œ, cosine simliarity $\cos \theta_c$ë¥¼ ë°”íƒ•ìœ¼ë¡œ embedding vectorì™€ proxy vectorì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•œë‹¤. ì¦‰, ProMIL ëª¨ë¸ì€ $distance=-\cos \theta_c$ë¼ê³  ì •ì˜í•˜ë©° $\cos \theta_c$ëŠ” ì•„ë˜ì™€ ê°™ì´ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.

$$
p_c^1 \in \mathbb{R}^{1 \times d}, \quad c \in \{0, \ldots, C-1\}
$$
$$
\cos \theta_c = \left< \frac{G_i}{\| G_i \|_2}, \frac{p_c^t}{\| p_c^t \|_2} \right>, \quad t=1, \ldots, T
$$

### 3.6 Loss Function
&emsp;ì•ì„œ 3.1ì¥ì—ì„œ class proxyë¥¼ ì˜ í•™ìŠµí•˜ê¸° ìœ„í•œ NCA lossì— ëŒ€í•´ ê°„ëµíˆ ë‹¤ë£¨ì—ˆë‹¤. ë³¸ ë…¼ë¬¸, ProMILì˜ loss function $Loss'$ì€ NCA lossì— marginì„ ì¶”ê°€í•˜ì—¬ ë³´ë‹¤ informativeí•œ instances(pathces)ì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ì£¼ë„ë¡ í•˜ì˜€ë‹¤. ë˜í•œ, {ğ, ğ’, ğ’”} í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ê°ê° ëª¨ë¸ì˜ overfitting ë°©ì§€, cosine marginì˜ í¬ê¸° í†µì œ, ëª¨ë¸ ìˆ˜ë ´ ì†ë„ í–¥ìƒì˜ ëª©ì ì„ ë‹¬ì„±í•˜ê³ ì ì‹œë„í•˜ì˜€ë‹¤.
$$
Loss' = (1 - \alpha + \frac{\alpha}{C})Loss - \frac{\alpha}{C} \sum_{c=0, c \neq Y_i}^{C-1} \log \left( \frac{e^{s \cdot \cos \theta_c}}{e^{s \cdot (\cos \theta_{Y_i} - m)} + \sum_{c=0, c \neq Y_i}^{C-1} e^{s \cdot \cos \theta_c}} \right)
$$
$$
Loss = -\log \left( \frac{e^{s \cdot (\cos \theta_{Y_i} - m)}}{e^{s \cdot (\cos \theta_{Y_i} - m)} + \sum_{c=0, c \neq Y_i}^{C-1} e^{s \cdot \cos \theta_c}} \right), \quad \alpha (0 < \alpha < 1), m \geq 0, s \geq 0
$$


### 3.7 Algorithm
&emsp; Fig.6ëŠ” ProMIL ëª¨ë¸ì˜ pseudo codeë¥¼ ì œì‹œí•œë‹¤. í•´ë‹¹ ì½”ë“œëŠ” WSI embedding, simliarity measure, bag prediction, gradient calculation, parameter update ê³¼ì • ë“±ì„ í¬í•¨í•œë‹¤.

<p align="center">
  <img src="../../images/DS503_24S/ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy/Fig6.jpg" alt="alt text"/>
  <br>
  <em>Fig.6. Model Algorithm</em>
</p>

## 4. Experiment
&emsp;ë³¸ ì¥ì—ì„œëŠ” ProMIL ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ 6ê°œì˜ (CAMELYON16, TCGA-NSCLC, TCGA-RCC, HER2-Status, Trastuzumab response, Breakhis-2 (binary), Breakhis-8 (multi-class)) open-source datasetì— ëŒ€í•´ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ë‹¤. ê·¸ ê²°ê³¼, ProMIL ëª¨ë¸ì´ ê¸°ì¡´ ëª¨ë¸ DS-MIL, Trans-MIL, DTFD-MIL ë“±ì— ë¹„í•´ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” Table.1, Table.2, Table.3ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

|   Method   | CAMELYON16 Accuracy | CAMELYON16 AUC | TCGA-NSCLC Accuracy | TCGA-NSCLC AUC | TCGA-RCC Accuracy | TCGA-RCC AUC |
|:----------:|:-------------------:|:--------------:|:-------------------:|:--------------:|:-----------------:|:------------:|
|   ABMIL    |       0.845         |     0.854      |        0.869        |     0.941      |         /         |      /       |
|  MIL-RNN   |         /           |     0.930      |          /          |       /        |         /         |      /       |
|   DSMIL    |      0.8682         |     0.894      |       0.9190        |     0.9633     |         /         |      /       |
|    CLAM    |         /           |     0.936      |          /          |     0.963      |         /         |    0.991     |
|  TransMIL  |      0.8837         |     0.9309     |       0.8835        |     0.9603     |      0.9466       |    0.9882    |
| DTFD-MIL   |       0.908         |     0.946      |       0.894         |     0.961      |         /         |      /       |
|   ProMIL   |      0.9132         |     0.8991     |       0.9814        |     0.9942     |      0.9938       |    0.9968    |

Table.1. Experimental results on CAMELYON16, TCGA-NSCLC and TCGA-RCC

&nbsp;

| Status      | HER2-Status Accuracy | HER2-Status AUC | Trastuzumab response Accuracy | Trastuzumab response AUC |
|:-----------:|:--------------------:|:---------------:|:-----------------------------:|:-----------------------:|
| Unannotated |          /           |      0.82       |               /               |          0.68           |
| Annotated   |          /           |      0.90       |               /               |          0.80           |
| ProMIL      |       0.9489         |     0.9614      |           0.9176              |         0.9210          |

Table.2. Experimental results on HER2-Status and Trastuzumab response

&nbsp;


|   Model    | Binary Accuracy | Binary AUC | Multi-class Accuracy | Multi-class AUC |
|:----------:|:---------------:|:----------:|:--------------------:|:---------------:|
| CSDCNN-Raw |     0.9580      |      /     |        0.894         |        /        |
|  INV3-Raw  |     0.9684      |   0.9947   |        0.928         |        /        |
|  IRV2-Raw  |     0.9790      |   0.9957   |        0.9207        |        /        |
|  IRV2-Aug  |     0.9716      |      1     |        0.9763        |        /        |
| IRRCNN-Raw |     0.9795      |      /     |        0.9569        |        /        |
| IRRCNN-Aug |     0.9799      |      /     |        0.9709        |        /        |
|  Sharma et al.  |   0.974    |      /     |           /          |        /        |
|   C-Net    |     0.9933      |      /     |           /          |        /        |
|   ProMIL   |     0.9954      |   0.9993   |        0.9640        |      0.9771     |

Table.3. Experimental results on BreakHis

&emsp;ì¶”ê°€ì ìœ¼ë¡œ, ë³¸ ë…¼ë¬¸ì—ì„œ í™œìš©í•œ ë‹¤ì–‘í•œ techniqueì˜ ìœ ì˜ì„±ì„ í™•ì¸í•˜ê¸° ìœ„í•˜ì—¬ visualization ë˜í•œ ìˆ˜í–‰í•˜ì˜€ë‹¤. ê·¸ ê²°ê³¼ëŠ” ì•„ë˜ Fig.7, Fig.8, Fig.9ì™€ ê°™ë‹¤. ë³¸ ëª¨ë¸ì€ class proxyë¥¼ í™œìš©í•˜ì—¬ WSIì˜ class labelì„ ì˜ˆì¸¡í•œë‹¤. Fig.7ì„ í†µí•´ diagonal, ì¦‰ ê°™ì€ classë¼ë¦¬ëŠ” cosine ìœ ì‚¬ë„ê°€ ë†’ì€ ë°˜ë©´, ë‹¤ë¥¸ classë¼ë¦¬ëŠ” ìœ ì‚¬ë„ê°€ ë‚®ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” updateë¥¼ ë§ˆì¹œ class proxyê°€ ê° classì— ëŒ€í•´ representativeí•œ íŠ¹ì„±ì„ ì§€ë‹Œë‹¤ëŠ” ê²ƒì„ ë°˜ì˜í•œë‹¤.

<p align="center">
  <img src="../../images/DS503_24S/ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy/Fig7.jpg" alt="alt text"/>
  <br>
  <em>Fig.7. Illustration of cosine similarity between class proxies</em>
</p>

ë˜í•œ, ë³¸ ëª¨ë¸ì€ ê¸°ì¡´ conventional MILì—ì„œ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” cross entropy loss fucntion ëŒ€ì‹ , NCA-lossë¥¼ ì‚¬ìš©í•œë‹¤. Fig.8ì€ í•´ë‹¹ loss functionì˜ ìœ ì˜ì„±ì„ ê²€ì¦í•˜ëŠ” ì§€í‘œì´ë‹¤. ê·¸ë˜í”„ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ 6ê°œ open-source datasetì—ì„œ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<p align="center">
  <img src="../../images/DS503_24S/ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy/Fig8.jpg" alt="alt text"/>
  <br>
  <em>Fig. 8. Illustration of the effectiveness of our loss function</em>
</p>

Fig.9ì€ WSIì˜ ê° patchë“¤ì´ ë³¸ ëª¨ë¸ì˜ Gated-Attention ê³¼ì •ì„ ê±°ì³¤ì„ ë•Œ, attention scoreì˜ heatmapì„ ì‹œê°í™”í•œë‹¤. ì‹¤ì œ ë³‘ë¦¬í•™ìë“¤ì˜ patch annotationê³¼ attention heatmapì˜ ìœ ì‚¬í•œ ì–‘ìƒìœ¼ë¡œ ë³´ì•„ ProMIL ëª¨ë¸ì´ model interpretabilityë¥¼ ê°–ì¶˜ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<p align="center">
  <img src="../../images/DS503_24S/ProMIL_A_weakly_supervised_multiple_instance_learning_for_whole_slide_image_classification_based_on_class_proxy/Fig9.jpg" alt="alt text"/>
  <br>
  <em>Fig.9. Visualization of the attention scores on TCGA-NSCLC, TCGA-RCC and HER2-Status</em>
</p>

## 5. Conclusion
&emsp;4ì¥ì˜ ì‹¤í—˜ ê²°ê³¼ì— ë”°ë¥´ë©´, ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ëŠ” ëª¨ë¸ ProMILì€ ìµœì†Œí•œì˜ annotation (WSI level annotation)ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ë‚˜ì€ ì„±ëŠ¥ì„ ì´ëŒì–´ë‚¸ë‹¤. íŠ¹íˆ, balanced, imbalanced datasetì—ì„œ, binary, multi-class classificationê³¼ ê°™ì€ ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì ìš© ê°€ëŠ¥í•œ stabilityê°€ ëª¨ë¸ì˜ ì¥ì ìœ¼ë¡œ ë³´ì¸ë‹¤. ë³¸ ëª¨ë¸ì˜ í™œìš©ì´ ì‹¤ì œ ë³‘ë¦¬í•™ ë¶„ì•¼ì—ì„œì˜ workload ê°ì†Œì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆê¸°ë¥¼ í¬ë§í•œë‹¤.

## 6. Reference
[1] Ilse, Maximilian, Jakub Tomczak, and Max Welling. "Attention-based deep multiple instance learning." International conference on machine learning. PMLR, 2018.   
[2] Li, Bin, Yin Li, and Kevin W. Eliceiri. "Dual-stream multiple instance learning network for whole slide image classification with self-supervised contrastive learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.    
[3] Movshovitz-Attias, Yair, et al. "No fuss distance metric learning using proxies." Proceedings of the IEEE international conference on computer vision. 2017.   
[4] Zhang, Hongrun, et al. "Dtfd-mil: Double-tier feature distillation multiple instance learning for histopathology whole slide image classification." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.   

## Author
Name: ì†¡ ì°¬ì¬ (ChanJae Song)   
Affiliation: KAIST ISE   
Contact: chan4535@kaist.ac.kr   
Research Topic: Weakly Supervised Learning, Metric Learning   