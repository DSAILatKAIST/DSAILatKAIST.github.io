<!DOCTYPE html>
<html>
<head>
    <meta name="google-site-verification" content="1tAPTdgw0-t8G2Bya463OpBtYUbj9Um93gfnsowYKLw" />
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CV4PTXQSTW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-CV4PTXQSTW');
</script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="keywords" content="reviews,  ">
<title>[AAAI 2021] TabNet: Attentive Interpretable Tabular Learning | Awesome Reviews</title>
<link rel="stylesheet" href="css/syntax.css">

<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="css/modern-business.css">
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="css/customstyles.css">
<link rel="stylesheet" href="css/boxshadowproperties.css">
<!-- most color styles are extracted out to here -->
<link rel="stylesheet" href="css/theme-blue.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="js/jquery.navgoco.min.js"></script>


<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<!-- Anchor.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script>
<script src="js/toc.js"></script>
<script src="js/customscripts.js"></script>

<link rel="shortcut icon" href="images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="DSAILatKAIST.github.io" href="http://localhost:4000/feed.xml">


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>




    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    <script>
        $(document).ready(function() {
            $("#tg-sb-link").click(function() {
                $("#tg-sb-sidebar").toggle();
                $("#tg-sb-content").toggleClass('col-md-9');
                $("#tg-sb-content").toggleClass('col-md-12');
                $("#tg-sb-icon").toggleClass('fa-toggle-on');
                $("#tg-sb-icon").toggleClass('fa-toggle-off');
            });
        });
    </script>
    


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-static-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fa fa-home fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle"> Awesome Reviews</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- toggle sidebar button -->
                <li><a id="tg-sb-link" href="#"><i id="tg-sb-icon" class="fa fa-toggle-on"></i> Nav</a></li>
                <!-- entries without drop-downs appear here -->




                
                
                
                <li><a href="introduction">Introduction</a></li>
                
                
                
                <li><a href="https://statistics.kaist.ac.kr/" target="_blank" rel="noopener">KAIST ISysE</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Reviews<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="reviews_kse801_2022.html">KSE801 (2022)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2023.html">DS503 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS535_2023.html">DS535 (2023)</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
			<li>



  <a class="email" title="Submit feedback" href="#" onclick="javascript:window.location='mailto:swkim@kaist.ac.kr?subject=Question about reviews feedback&body=I have some feedback about the [AAAI 2021] TabNet: Attentive Interpretable Tabular Learning page: ' + window.location.href;"><i class="fa fa-envelope-o"></i> Feedback</a>

</li>



		
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">
                        <input type="text" id="search-input" placeholder="search...">
                        <ul id="results-container"></ul>
                    </div>
                    <script src="js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: 'search.json',
                                searchResultTemplate: '<li><a href="{url}" title="[AAAI 2021] TabNet: Attentive Interpretable Tabular Learning">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>



<!-- Page Content -->
<div class="container">
  <div id="main">
    <!-- Content Row -->
    <div class="row">
        
        
            <!-- Sidebar Column -->
            <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
  <li class="sidebarTitle"> </li>
  
  
  
  <li>
      <a title="How to contribute" href="#">How to contribute</a>
      <ul>
          
          
          
          <li><a title="How to contribute?" href="how_to_contribute.html">How to contribute?</a></li>
          
          
          
          
          
          
          <li><a title="Review template (Example)" href="template.html">Review template (Example)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Reviews" href="#">Reviews</a>
      <ul>
          
          
          
          <li><a title="KSE801 (2022F)" href="reviews_kse801_2022.html">KSE801 (2022F)</a></li>
          
          
          
          
          
          
          <li><a title="DS503 (2023S)" href="reviews_DS503_2023.html">DS503 (2023S)</a></li>
          
          
          
          
          
          
          <li><a title="DS535 (2023F)" href="reviews_DS535_2023.html">DS535 (2023F)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
      
      <!-- if you aren't using the accordion, uncomment this block:
         <p class="external">
             <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
         </p>
         -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>



            </div>
            
        

        <!-- Content Column -->
        <div class="col-md-9" id="tg-sb-content">
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/math...">
</script>
<article class="post" itemscope itemtype="https://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[AAAI 2021] TabNet: Attentive Interpretable Tabular Learning</h1>
        <p class="post-meta"><time datetime="2023-04-20T00:00:00+09:00" itemprop="datePublished">Apr 20, 2023</time> /
            
            
            
            
            

        </p>


    </header>

    <div class="post-content" itemprop="articleBody">

        

        <h1 id="tabnet-attentive-interpretable-tabular-learning">TabNet: Attentive Interpretable Tabular Learning</h1>

<p>본 논문의 저자는 <strong>트리 기반 앙상블 모델</strong>들이 딥러닝에 비해 <strong>정형 데이터</strong>에서 학습에 보다 논리적이고 합리적인 접근 방법이라고 소개합니다.   일반적으로 관측되는 정형 데이터는 대략적인 초평면(hyperplane) 경계를 지니고 있는 매니폴드(manifolds)를 가지고 있으며 이 공간에서는 트리 기반 앙상블 모델의 결정 방식이 이해(representation)하는데 더 강점을 지니고 있기 때문입니다.   <br />
 본 논문에서 제안한 TabNet은 <strong>decision tree-based gradient boosting</strong>의 장점을 살린 인공신경망 아키텍쳐이며, <strong>feature engineering</strong>과 <strong>selection</strong>까지 함께 활용할 수 있는 장점이 있습니다. 또한 <strong>해석가능한(interpretability)</strong>, 설명가능한 XAI(eXplainable Artificial Intelligence)라는 점에서 큰 장점이 있습니다.</p>

<blockquote>
  <ul>
    <li>두괄식으로 <strong>TabNet의 컨셉</strong>을 간략하게 설명하자면 다음과 같이 정의됩니다.<br />
 “입력된 정형데이터(tabular data)에서 Feature를 masking하며 여러 step을 거쳐서 학습”
      <ul>
        <li>각 step별 <strong>feature들의 importance</strong> 파악 (설명력 확보)</li>
        <li><strong>masking 으로 중요한 feature 들만 선출</strong>해서 학습하여 성능 향상 (모델 고도화)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>저희 분야에서는 정형데이터인 tabular data를 활용한 연구가 많이 진행되는 편이어서, 본 논문을 흥미롭게 읽었는데요. 정형데이터를 많이 활용하시는 분이라면 도움이 될 수 있을 것 같습니다.</p>

<hr />

<h2 id="1-problem-definition">1. Problem Definition</h2>
<p>과거 정형 데이터를 활용한 모델들의 성능비교를 했을 때, <strong><em>LightGBM</em></strong>의 성능이 가장 좋다고 알려져있고, 혹은 앙상블을 고려한 <strong><em>Extreme Gradient Boosting</em></strong> (<strong><em>XGBoost</em></strong>)나 <strong><em>Catboost</em></strong>을 떠올릴 수 있습니다. 더하여 <strong><em>Neural Network</em></strong>를 추가하는 방법이 있는데, 정형 데이터의 경우에 <em>Neural Network</em>는 복잡하거나 깊은 레이어로 구성되지 않는 편이며, 더 깊거나 복잡하다고 성능이 눈에 띄게 좋아지지 않았습니다.</p>
<blockquote>
  <p>여기서 잠깐!</p>
</blockquote>

<p>[<strong>LightGBM과 기존의 트리기반 알고리즘에 대한 추가 설명</strong>]</p>

<p><img src="https://user-images.githubusercontent.com/82039869/237000522-a78be61f-9848-4031-9ed2-b03c61bf6e00.jpg" alt="lightgbm" /></p>

<p>기존의 트리기반 알고리즘은 <strong><em>level wise</em></strong>(ex : XGBoost) 방식을 사용했고, 최대한 균형이 잡힌 트리를 유지하면서 분할하기 때문에 tree의 깊이가 최소화 될 수 있다는 장점이 있었지만, 균형을 맞추기 위한 시간이 필요했다. 
LightGBM의 <strong><em>leaf wise</em></strong> 방식은 tree의 균형을 고려하지 않고 최대 손실값을 가지는 leaf node를 지속적으로 분할하면서 비대칭적인 tree가 생성된다. 이러한 방식은 level wise tree 분할 방식보다 예측 오류 손실을 최소화 할 수 있다.</p>

<p><strong><em>PCA</em></strong>를 활용하여 <strong>차원축소</strong>를 하거나, <strong><em>autoencoder</em></strong>를 기반으로 <strong>노이즈를 제거</strong>하는 등의 방식에 활용이 되는 것이 주 였다고 볼 수 있습니다. <br />
또한, <strong><em>CNN, MLP</em></strong>와 같은 딥러닝 모델은 적절한 귀납적 편향(<em>inductive bias</em>)의 부족으로 지나치게 <strong><em>Overparametrized</em></strong> 되어 정형 데이터 내 매니폴드에서 일반화된 해결책을 찾는데 어려움을 발생시길 수 있습니다. 그럼에도 불구하고 이런 딥러닝 학습 방법론을 정형 데이터 학습에 사용하고자 하는 이유는 이미지나 다른 종류에 데이터와 정형데이터를 함께 학습(<em>Multi-Modal</em>)할 수 있으며 트리 기반 모델 성능의 핵심인 Feature Engineering과 같은 작업이 크게 필요하지 않습니다. 또한, 스트리밍 데이터 학습이 용이하고 종단간(<em>end-to-end</em>) 모델은 Domain adaptation, Generative modeling, Semi-supervised learning과 같은 가치있는 응용 모델과 같은 표현 학습(<em>representation learning</em>)이 가능합니다.</p>

<h2 id="2-motivation">2. Motivation</h2>
<p>본 논문에서는 새로운 고성능 및 해석 가능한 표준 심층 테이블 형식 데이터 학습 아키텍처 인 TabNet을 제안합니다. TabNet은 원자료의 다른 전처리 없이 입력할 수 있고 경사하강법 최적화 방법을 통해 유연한 통합(flexible integration)이 가능한 종단간(end-to-end) 학습이 가능합니다. 또한, 순차적인 어텐션(Sequential Attention)을 사용하여 각 의사 결정 단계에서 추론할 feature들을 선택합니다. 이로인해 더 나은 해석 능력과 학습이 가능하며 숨겨진 특징을 예측하기 위해 사전 비지도 학습을 사용하여 정형 데이터에 중요한 성능 향상을 보여줍니다(<em>Self-supervised learning</em>).</p>

<blockquote>
  <p>본 논문에서 제안한 TabNet의 차별화된 아이디어와 contribution은 다음과 같습니다.
 1) 전처리 과정을 거치치 않은 <strong>raw data로도 end-to-end 학습이 가능</strong>
 2) <strong>sequantial attention</strong> 과정에서 <strong>각 step마다 중요한 feature를 선별</strong>하면서 각 과정의 모델 해석과 성능 향상이 가능 
 3) <strong>다양한 도메인의 데이터</strong>에서 다른 테이블 학습 모델과 비교 했을 때 <strong>분류/회귀 문제에서 우수한 성능</strong>을 보임 
 4) <strong>masking 된 feature를 예측하는 tabnet decoder 비지도 학습을 통한 우수한 성능</strong>을 보임</p>
</blockquote>

<h2 id="3-method">3. Method</h2>
<p>본격적으로 TabNet architecture를 살펴보기 전에, TabNet의 feature selection 방법과, encoder, decoder에 대한 설명을 간략히 정리했습니다.</p>

<p><img src="https://user-images.githubusercontent.com/82039869/237002064-d235dd1b-7c9e-4566-8fb3-fce2beedc122.jpg" alt="image_revise1" /></p>

<p>기존의 Feature seletion은 Lasso Regularization, Instance-wise feature selection등의 방법을 사용합니다. 이러한 방식을 본 논문에서는 Hard feature selection으로 표현하고 있으며, TabNet은 Soft feature selection을 구현하여 사용합니다.
간단히 언급하면, <strong>TabNet은 masking</strong>을 이용하여, 좌측에서 우측으로 <strong>sequential하게 feature selection</strong>을 하며 피드백을 주고 학습해나가는 구조입니다 (<em>figure 1 그림 참조</em>).</p>

<p><img src="https://user-images.githubusercontent.com/82039869/237002151-316bc441-2b50-44fd-b71b-1bc8b4f5d7e2.jpg" alt="image_revise2" /></p>

<p>더하여 tabnet encoder를 통해서 <strong>feature engineering</strong>효과를 내고, decision making 부분을 통해 <strong>feature selection</strong>이 이루어집니다. encoder는 <em>fine-tuning</em>하면서 task에 맞게 성능을 향상시켜 맞춰갑니다. <br />
encoder에 decoder 구조 결합하면 autoencoder 같은 자기 학습 구조를 가지고 있고, decoder 에서는 ?(물음표) 로 된 <em>missing value</em> 를 채워넣는 구조입니다.</p>

<blockquote>
  <p><strong>TabNet encoder와 decoder의 architecture를 좀 더 자세히 살펴보면 아래 그림과 같습니다.</strong></p>
</blockquote>

<p><img src="https://user-images.githubusercontent.com/82039869/237002504-8ad61c75-433a-4376-b84d-a1de9464984d.jpg" alt="image_revise3" /></p>

<p>우선 <em>Encoder</em>와 <em>Decoder</em>를 거시적으로 설명하면 다음과 같습니다.</p>
<blockquote>
  <p><strong><em>Encoder</em></strong>  <br />
<em>Encoder</em>는 여러 Desicion Step으로 구성되며, Step 내의 두가지 블록이 존재합니다.</p>
  <ul>
    <li>Feature transformer 블록 : 임베딩 수행</li>
    <li>Attentive transformer 블록 : trainable Mask 생성</li>
    <li>Masked Feature는 다음 Step의 Input feature가 되며, 이전 step에서 사용되었던 Mask의 정보를 피드백하기에 Feature의 재사용 빈도를 제어할 수 있습니다.</li>
  </ul>

  <p><strong><em>Decoder</em></strong></p>
  <ul>
    <li><em>Decoder</em>의 각 step은 feature transformer 블록에서 FC layer로 이루어지고 각 step 합산해서 reconstructed feature 결과를 산출합니다. 디코더 구조를 통해 결측치 보간 효과가 가능합니다.</li>
  </ul>
</blockquote>

<p>추가적으로 <em>Encoder</em>와 <em>Decoder</em>에 대해 자세히 살펴보면 다음과 같이 정리할 수 있습니다.</p>

<blockquote>
  <ul>
    <li><strong>(a) : TabNet encoder</strong> 의 경우, 각 decision step에 대해서 <strong><em>1)feature transformer, 2)attentive transformer, 3)feature masking</em></strong>으로 구성되어 있습니다.  <br />
첫 의사결정 단계에서 부족한 부분을 다음 의사결정 단계에서 보완하는 방식이며, 트리기반 부스팅 모델들과 유사합니다.
모델의 용어를 좀 더 구체적을 설명하면, BN : 최초 Feature에 대해 배치 정규화를 적용
      <ul>
        <li><strong><em>Feature transformer</em></strong> : 이후에 아래의 단계 반복.</li>
        <li><strong><em>Attentive transformer</em></strong> : (d)에서 설명</li>
        <li><strong><em>Mask</em></strong> : Attentive transformer에서 나온 <strong><em>Mask</em></strong>(<strong><em>M[i]</em></strong>)에 대해 feature <strong><em>f</em></strong>를 곱하여 이후 step의 <em>Feature transformer</em>에 들어가는 input을 조절. Mask를 통해 변수를 soft selection 함.</li>
        <li><strong><em>Feature transformer</em></strong> : (c)에서 설명</li>
        <li><strong><em>Split</em></strong> : Feature transformer의 output을 두 개로 복제하여 하나는 <em>relu</em>로, 하나는 <em>Attentive transformer</em>로 보냄</li>
      </ul>
    </li>
    <li>
      <p><strong>(b) : TabNet decoder</strong>는 각 단계에서 feature transformer 블록으로 구성됩니다. 일반 학습에서는 Decoder를 사용하지 않고, self-supervised 학습을 진행할 때, 인코더 다음에 붙여져서 기존의 결측값을 보완하고 표현학습을 진행하게 됩니다.</p>
    </li>
    <li><strong>(c) Feature Transformer</strong>는 4개의 네트워크 묶음으로 구성됩니다.
      <ul>
        <li><strong><em>Fully Connected Layer</em></strong> (<strong>FC</strong>) - <strong><em>Batch Normalization</em></strong> (<strong>BN</strong>) - <strong><em>Gated Linear Unit Activation</em></strong> (<strong>GLU</strong>)로 구성된 블럭들을 순차적으로 통과하는 구조를 쌓고, 블럭간의 <em>residual skip connecion</em>을 적용했습니다.</li>
        <li>그리고 <em>residual output</em>의 <em>normalization</em>을 위해 <strong><em>sqrt</em></strong>(<strong><em>0.5</em></strong>)를 곱했습니다. 이때, 두 레이어는 모든 <em>decision</em> 단계에서 공유되며, 나머지 두 레이어는 <em>decision</em> 단계에 의존합니다. 따라서 앞 2개의 네트워크는 모든 파라미터를 공유하며 <strong>글로벌 성향</strong>을 학습하고, 뒤에 2개의 네트워크 그룹은 <strong>로컬 성향</strong>을 학습합니다. 
이어서 <strong>D</strong>개의 변수를 갖는 값들을 입력받은 <em>feature transformer</em>는 <strong><em>split</em></strong>할 값들을 내보냅니다. 총(<strong>B,N</strong>)의 <em>output</em>을 내보냈을 때, 논문에서는 <em>split</em> 과정을 통해 <em>d</em>[<em>i</em>]와 <em>a</em>[<em>i</em>]로 나누었습니다.</li>
      </ul>
    </li>
    <li><strong>(d) Attnetive transformer</strong> 블록으로, 현재 의사결정 단계에서 각 변수들이 얼마나 많은 영향을 미쳤는지 사전 정보량(<em>prior scale information</em>)을 통해 집계합니다. 다시말해, 현재 decision step 전에 각 feature가 얼마나 많이 사용되었는지를 집계한 정보를 나타냅니다. 이것은 단일 레이어에 맵핑하여 사용되며, 계수의 정규화는 각 decision step에서 가장 두드러진 특징을 <strong><em>sparse</em></strong>하게 선택하고, 계수값들을 일반화(<em>normalization</em>)하기 위해 <strong><em>sparsemax</em></strong>를 사용하여 학습되어집니다.</li>
  </ul>
</blockquote>

<h2 id="4-experiment">4. Experiment</h2>
<p>본 논문에서는 regression, classification task로 성능을 평가하였고, 데이터 셋의 모든 categorical value 들은 임베딩되었고, numerical value들은 전처리 없이 input으로 활용되었습니다. TabNet은 대부분의 <em>hyperparameter</em>에 대해 그리 예민하지 않다는 특징을 가집니다.</p>

<blockquote>
  <p><strong>Instance-wise feature selection</strong> (synthetic dataset - 임의로 생성한 데이터셋 활용)</p>
</blockquote>

<p><img src="https://user-images.githubusercontent.com/82039869/237002742-68b8810f-fd98-4077-81c3-799524d74314.jpg" alt="image_revise4" /></p>

<p>Table 1의 결과를 간략히 정리하면 다음과 같다.</p>
<ul>
  <li><strong>6개 임의로 생성된 데이터로 성능을 평가</strong> –&gt; syn1 ~ syn 6 데이터</li>
  <li><strong>syn 1~3 에서는 각 인스턴스(data row) 별로 중요한 피쳐가 같음</strong> –&gt; 따라서 syn 1~3 에서는 Tabnet 의 성능이 global feature selection 하는 다른 모델들과 성능이 비슷</li>
  <li><strong>syn 4~6 에서는 각 인스턴스(data row) 별로 중요한 피쳐가 다름</strong> –&gt; 따라서 불필요한 feature들을 instance wise로 제거해서 성능을 향상</li>
</ul>

<blockquote>
  <p><strong>Performance on real-world datasets</strong> (실제 데이터셋 활용)</p>
</blockquote>

<p><img src="https://user-images.githubusercontent.com/82039869/237004066-0d97d137-2837-47c2-8357-128642572409.jpg" alt="image_revise5" /></p>

<p><strong><em>Forest cover type dataset</em></strong>  : 나무 분류 문제 / <strong><em>Poker Hand</em></strong> : 카드 분류 문제 / <strong><em>Sarcos</em></strong> : 로봇 팔 관련 데이터 / <strong><em>Higgs Boson</em></strong> : 이진 분류 문제 /<strong><em>Rossman Store Sales</em></strong> : 상점 매출 예측</p>

<p>다양한 데이터셋을 활용하여 <em>XGBoost, LightGBM, Random forest, MLP</em> 등 다양한 모델과의 비교 결과, <strong>Test accuracy, MSE 등의 평가지표</strong>에서 TabNet이 다른 모델들에 비해 <strong>좋은 성능</strong>을 보이는 것을 확인할 수 있습니다.</p>

<p>또한 본 논문에서 제안한 그림(<em>Figure 5</em>)을 통해 알 수 있듯이, 각 스텝에서 활성화된 <strong>feature 를 시각화</strong>로 확인할 수 있다는 장점이 있고, <strong>instance 별 중요도</strong> 또한 확인이 가능합니다.</p>

<p><img src="https://user-images.githubusercontent.com/82039869/237004512-34c5c360-5f8f-423a-8de5-a5d2f700ae5c.jpg" alt="image_revise6" /></p>

<p>그림의 하얀색 부분이 모델 학습에 사용 feature라고 해석할 수 있습니다. <br />
간단히 설명해보자면, <em>Syn2 dataset</em>에서는 <strong><em>feature X3-X6</em></strong> 만 활용 되었으며 <strong><em>Magg</em></strong> 는 각 스텝의 <strong>feature importance를 결합</strong> 했을 때 나오는 결과를 <strong>시각화</strong> 한 것입니다.</p>

<h2 id="5-conclusion">5. Conclusion</h2>

<blockquote>
  <p>저자는 <em>tabular learning</em>을 위한 참신한 딥러닝 아키텍처인 <strong><em>TabNet</em></strong>을 제시했으며, TabNet은 각 결정 단계에서 처리할 의미 있는 변수의 subset을 선택하기 위해 <strong><em>sequential attention mechanism</em></strong>을 활용했습니다. 선택된 특징들은 <em>representation</em>으로 처리되어서 다음 결정 단계에서 정보를 보내고 기여하고 있습니다. <strong><em>Instance-wise feature selection</em></strong>은 <em>model capacity</em>로써 효율적인 학습을 가능하게 한다고 정리할 수 있을 것입니다.</p>
</blockquote>

<p>저의 개인적인 소견으로는, 논문에서 언급된 것과 같이 <strong>정형 데이터보다는 비정형 데이터에 많이 집중</strong>되어 개발되어 있는 상태라고 생각합니다. 따라서 비정형데이터에서 성능을 높인 모델을 정형데이터에 적용하기에는 이론이 맞지 않다고 생각했는데, 본 모델에서 대안으로 <strong><em>attention mechanism</em></strong>이라고 하는 방법이 제시되어 너무 좋았습니다. 또한 본 모델을 활용한다면 전처리의 필요성이 줄어들고, <strong><em>tree-based model</em></strong>처럼 활용할 수 있는 것이 또 하나의 장점이라고 생각합니다.  <br />
마지막으로 보통은 딥러닝을 해석하고 평가하기 위해 <em>surrogate model</em>로 대체하는데, 본 논문에서는 <strong>해석가능성 방식</strong>을 활용하여 구현한 것이 인상적이었습니다. 아주 작은 코멘트로는, 신경망모델 치고는 조절해야할 파라미터가 조금 많아 <em>parameter search</em>하는데 시간이 소요 될 것 같습니다. <br />
하지만 정형 데이터에 대한 모델 연구나 방법론이 한정적이라고 생각했었는데 끝없이 발전하고 있다는 생각이 드는 논문이었습니다. 특히 <strong><em>tabular data</em></strong>를 활용한 연구를 많이 진행하고 있는 입장으로 TabNet을 저희 연구분야에 적용하기 위해 코드 및 구조를 더욱더 꼼꼼히 배워야 겠다는 생각을 했습니다.
모두 한번 읽어보세요~! :)</p>

<h2 id="6-reference--additional-materials">6. Reference &amp; Additional materials</h2>
<ul>
  <li>TabNet 논문파일과, Github - tensorflow, torch로 구현된 코드 링크를 함께 첨부드립니다.
    <ul>
      <li><a href="https://arxiv.org/abs/1908.07442">TabNet 논문</a></li>
      <li><a href="https://github.com/google-research/google-research/tree/master/tabnet">TabNet tensorflow code</a></li>
      <li><a href="https://github.com/microsoft/qlib/blob/main/qlib/contrib/model/pytorch_tabnet.py">TabNet torch code</a></li>
    </ul>
  </li>
</ul>

    </div>



</article>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>







<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy;2024 Copyright 2021 Google LLC. All rights reserved. <br />
 Site last generated: Apr 17, 2024 <br />
<p><img src="images/company_logo.png" alt="Company logo"/></p>
                </div>
            </div>
</footer>






        </div>
    <!-- /.row -->
</div>
<!-- /.container -->
</div>
<!-- /#main -->
    </div>

</body>

<!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-66296557-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>





</html>


