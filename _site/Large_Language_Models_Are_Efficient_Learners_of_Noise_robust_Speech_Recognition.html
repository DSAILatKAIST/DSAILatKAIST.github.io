<!DOCTYPE html>
<html>
<head>
    <meta name="google-site-verification" content="1tAPTdgw0-t8G2Bya463OpBtYUbj9Um93gfnsowYKLw" />
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CV4PTXQSTW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-CV4PTXQSTW');
</script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="keywords" content="reviews,  ">
<title>[ICLR 2024] Large Language Models Are Efficient Learners of Noise-robust Speech Recognition | Awesome Reviews</title>
<link rel="stylesheet" href="css/syntax.css">

<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="css/modern-business.css">
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="css/customstyles.css">
<link rel="stylesheet" href="css/boxshadowproperties.css">
<!-- most color styles are extracted out to here -->
<link rel="stylesheet" href="css/theme-blue.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="js/jquery.navgoco.min.js"></script>


<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<!-- Anchor.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script>
<script src="js/toc.js"></script>
<script src="js/customscripts.js"></script>

<link rel="shortcut icon" href="images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="DSAILatKAIST.github.io" href="http://localhost:4000/feed.xml">


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>




    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    <script>
        $(document).ready(function() {
            $("#tg-sb-link").click(function() {
                $("#tg-sb-sidebar").toggle();
                $("#tg-sb-content").toggleClass('col-md-9');
                $("#tg-sb-content").toggleClass('col-md-12');
                $("#tg-sb-icon").toggleClass('fa-toggle-on');
                $("#tg-sb-icon").toggleClass('fa-toggle-off');
            });
        });
    </script>
    


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-static-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fa fa-home fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle"> Awesome Reviews</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- toggle sidebar button -->
                <li><a id="tg-sb-link" href="#"><i id="tg-sb-icon" class="fa fa-toggle-on"></i> Nav</a></li>
                <!-- entries without drop-downs appear here -->




                
                
                
                <li><a href="introduction">Introduction</a></li>
                
                
                
                <li><a href="https://statistics.kaist.ac.kr/" target="_blank" rel="noopener">KAIST ISysE</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Reviews<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="reviews_kse801_2022.html">KSE801 (2022)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2023.html">DS503 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS535_2023.html">DS535 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2024.html">DS503 (2024)</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
			<li>



  <a class="email" title="Submit feedback" href="#" onclick="javascript:window.location='mailto:swkim@kaist.ac.kr?subject=Question about reviews feedback&body=I have some feedback about the [ICLR 2024] Large Language Models Are Efficient Learners of Noise-robust Speech Recognition page: ' + window.location.href;"><i class="fa fa-envelope-o"></i> Feedback</a>

</li>



		
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">
                        <input type="text" id="search-input" placeholder="search...">
                        <ul id="results-container"></ul>
                    </div>
                    <script src="js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: 'search.json',
                                searchResultTemplate: '<li><a href="{url}" title="[ICLR 2024] Large Language Models Are Efficient Learners of Noise-robust Speech Recognition">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>



<!-- Page Content -->
<div class="container">
  <div id="main">
    <!-- Content Row -->
    <div class="row">
        
        
            <!-- Sidebar Column -->
            <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
  <li class="sidebarTitle"> </li>
  
  
  
  <li>
      <a title="How to contribute" href="#">How to contribute</a>
      <ul>
          
          
          
          <li><a title="How to contribute?" href="how_to_contribute.html">How to contribute?</a></li>
          
          
          
          
          
          
          <li><a title="Review template (Example)" href="template.html">Review template (Example)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Reviews" href="#">Reviews</a>
      <ul>
          
          
          
          <li><a title="KSE801 (2022F)" href="reviews_kse801_2022.html">KSE801 (2022F)</a></li>
          
          
          
          
          
          
          <li><a title="DS503 (2023S)" href="reviews_DS503_2023.html">DS503 (2023S)</a></li>
          
          
          
          
          
          
          <li><a title="DS535 (2023F)" href="reviews_DS535_2023.html">DS535 (2023F)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
      
      <!-- if you aren't using the accordion, uncomment this block:
         <p class="external">
             <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
         </p>
         -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>



            </div>
            
        

        <!-- Content Column -->
        <div class="col-md-9" id="tg-sb-content">
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/math...">
</script>
<article class="post" itemscope itemtype="https://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[ICLR 2024] Large Language Models Are Efficient Learners of Noise-robust Speech Recognition</h1>
        <p class="post-meta"><time datetime="2024-04-17T00:00:00+09:00" itemprop="datePublished">Apr 17, 2024</time> /
            
            
            
            
            

        </p>


    </header>

    <div class="post-content" itemprop="articleBody">

        

        <h2 id="사전-지식">사전 지식</h2>
<ul>
  <li>LM (Language Model, 언어 모델)
    <ul>
      <li>단어 sequence의 확률을 결정하기 위한 방법</li>
      <li>단어를 추론하고 생성</li>
    </ul>
  </li>
  <li>ASR (Automatic Speech Recognition, 자동 음성인식)
    <ul>
      <li>음성과 text를 활용하여 학습시킴</li>
      <li>context dependency가 부족할 수 있음</li>
      <li>LM을 연결할 경우 context 정보가 반영되어 성능이 올라감</li>
    </ul>
  </li>
  <li>Rescoring
    <ul>
      <li>단어가 나타날 확률을 구할 때 sparsity, long-term dependency 등의 문제가 발생</li>
      <li>모델에 global context 반영 위해 rescoring 제안</li>
      <li>여러 번 decoding 거치는 multi-pass 방법론</li>
      <li>이 논문에는 최상의 N개 결과를 이용하는 N-best list rescoring이 적용됨
        <ul>
          <li>(e.g.) (real) 북구청으로 가세요.</li>
          <li>(e.g.) (top1) 북구청으로 가세요.</li>
          <li>(e.g.) (top2) 북극청으로 가세요.</li>
          <li>(e.g.) (top3) 북구 처음으로 가세요.</li>
          <li>(e.g.) (top4) 부끄청으로 가세요.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>GER (Generative Error Correction)
    <ul>
      <li>noise-robust ASR 모델</li>
      <li>noise가 있는 audio로부터 text를 생성하기 위함</li>
    </ul>
  </li>
  <li>Beam Search Decoding
    <ul>
      <li>자연어 처리에서 sequence를 생성할 때 사용하는 기법 중 하나</li>
      <li>가장 높은 확률의 token 하나를 고르는 게 아니라, 가능도가 높은 여러 개의 token을 선택해 target sequence를 늘리는 방법</li>
      <li>성능은 좋으나, 속도가 느려질 수 있다는 한계</li>
    </ul>
  </li>
  <li>KD (Knowledge Distillation, 지식 증류)
    <ul>
      <li>연산량이 적은 network가 큰 network만큼의 성능을 낼 수 있도록 teacher network의 지식을 student network에 전달하는 학습법</li>
    </ul>
  </li>
</ul>

<h2 id="소개">소개</h2>
<ul>
  <li>최근 연구에서 LLM(Large Language Model)이 NLP(Natural Language Processing)에 자주 사용되고 있음.</li>
  <li>이 논문은 ASR의 연구 주제 중 하나인 GER에서 N-best list rescoring을 활용하여 성능을 높이고자 함.</li>
  <li>음성의 noise로 인한 부정적인 영향을 줄이고자 학습된 LLM을 fine-tuning함.</li>
  <li>저자는 해당 model을 noise에 강인한 RobustGER로 소개하고 있음.</li>
  <li>noise가 낀 audio를 바로 적용하면 corss modality gap으로 인한 성능 저하.
    <ul>
      <li>이 문제 해결을 위해 noise embedding 추출.</li>
      <li>N-best hypothesis list로부터 noise diversity 측정.</li>
      <li>worse noise condition, beam search decoding 등으로 N-best의 diversity를 높임.</li>
    </ul>
  </li>
  <li>noise embedding은 language-space denoising을 위한 기법.</li>
  <li>mutual information estimation(KL divergence)을 통한 KD를 사용하여 audio embedding에서 noise information을 제거함.</li>
  <li>WER(word error rate)을 기존 GER 모델보다 53.9% 가량 개선함.</li>
</ul>

<h2 id="benchmark-모델--데이터">Benchmark 모델 &amp; 데이터</h2>
<ul>
  <li>GER (Generative Error Correction)
    <ul>
      <li>noise에 robust한 ASR 모델</li>
      <li>noisy한 speech $X_n$으로부터 beam search decoding을 활용하여 N_best hypotheses $\mathcal{Y}_N={Y_1,Y_2,···,Y_N}$을 생성함</li>
      <li>
        <p>생성한 후보군을 text로 바꿔주는 hypotheses-to-transcription (H2T) 모델에 넣어줌  ${Y=\mathcal{M}_ {H2T}(\mathcal{Y}_N)}$</p>
      </li>
      <li>ground truth가 $Y^+$일 때, cross-entropy loss를 다음과 같이 계산하여 LLM을 fine-tuning 함. ($\theta$는 learnable parameter)  ${\mathcal{L}_ {H2T} = \sum_ {t=1}^{T}- \log \mathcal{P}_ {\theta}(y_ {t}^{+} \vert y_ {t-1}^{+}, ··· ,y_ {1}^{+},\mathcal{Y}_ {N})}$</li>
    </ul>
  </li>
  <li>데이터
    <ul>
      <li>noise한 speech audio 사용
        <ul>
          <li>CHiME-4, DEMAND, NOIZEUS, LibriSpeech-FreeSound, RATS, etc.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="방법론">방법론</h2>
<p><img src="../../images/DS503_24S/Large_Language_Models_Are_Efficient_Learners_of_Noise_robust_Speech_Recognition/framework1.png" alt="framework" /></p>
<ul>
  <li>전체 Framework
    <ul>
      <li>$\mathcal{Y}_ {N}$에서 $N=5$로 설정</li>
      <li>$\mathcal{Y}_ {N}$으로부터 추출한 language-space noise를 $E_ {LN}$으로 설정</li>
      <li>source speech $X_n$에서 KD를 통해 noise를 제거하기 위해 ASR audio embedding을 $\mathcal{E}_ {ASR}(X_ {n})$으로 설정</li>
      <li>noise 제거를 위해 denoising을 minus sign을 붙여 $-E_ {LN}$으로 표현</li>
      <li>다음 ${\mathcal{M}_ {H2T}}$는 LLM finetuning을 거친 H2T mapping: ${Y=\mathcal{M}_ {H2T}(\mathcal{Y}_ {N};-E_ {LN})}$</li>
    </ul>
  </li>
  <li>Language-space Noise Embedding
    <ul>
      <li>$E_ {LN}=[E_ {LN}^{utt};E_ {LN}^{tok}]$</li>
      <li>$E_ {LN}$은 N-best list 내부의 문장 전체 diversity에 영향 끼치는 1) utterance level $E_ {LN}^{utt}$와 단어 단위에서 distribution을 측정한 2) token level $E_ {LN}^{tok}$로 나누어짐</li>
      <li>한편, raw text로부터 audio embedding을 얻기 위해 sentence-BERT (SBERT)가 사용됨</li>
    </ul>
  </li>
  <li>Utterance-level Noise Embedding
    <ul>
      <li>
        <p>Utterance-level Noise Embedding은 음성 신호에서 발생하는 배경 소음이나 잡음을 표현하는 데 사용되는 특징 벡터</p>
      </li>
      <li>
        <p>$E_ {LN}^{utt}=Concat { [\mathcal{E}_ {sbert} (Y_ {i}) - \mathcal{E}_ {sbert}(Y_ {j}) ]_ {i,j=1,i&gt;j}^{N} } \in \mathbb{R}^{ {N(N-1)\over{2} } \times D_ {sbert} }$</p>
      </li>
      <li>이 때, $D_ {sbert}$는 SBERT embedding size</li>
      <li>$i,j$ 차이가 클 수록, worse noise가 생성됨</li>
    </ul>
  </li>
  <li>Token-level Noise Embedding
    <ul>
      <li>Token-level Noise Embedding은특정 단어나 음성 토큰에 대응되는 잡음이나 변형을 나타내는 임베딩 벡터</li>
      <li>zero-padding ($Ø$)한 $Y_ {i}$를 일정한 길이로 잘라 $T$개의 token을 만듦</li>
      <li>$Y_i^{ali}=[y_ {i_ {1}}^{ali},y_ {i_ {2}}^{ali},···,y_ {i_ {T}}^{ali}], \quad y_ {i_ {t}}^{ali}\in \mathcal{V} \cup  Ø$</li>
      <li>$E_ {edit}$을 통해 token-level difference를 측정</li>
      <li>$E_ {LN}^{tok} = Concat { [ E_ {edit}(Y_ {i}^{ali}, Y_ {j}^{ali}) ]_ {i,j=1,i&gt;j}^{N} } \in \mathbb{R}^{ {N(N-1)\over{2}} \times D_ {sbert} }$</li>
      <li>$E_ {edit}(Y_i^{ali},Y_j^{ali})=\sum_ {t=1}^T[\mathcal{E}_ {sbert}(y_ {i_t}^{ali})-\mathcal{E}_ {sbert}(y_ {j_t}^{ali})]$</li>
    </ul>
  </li>
  <li>Audio Noise Distillation
    <ul>
      <li>Mutual Information을 활용하여 clean speech와 noisy speech의 분포가 얼마나 차이 나는지 살핌</li>
      <li>$I(X;Z)=D_ {KL}(\mathbb{P}_ {XZ} \vert\vert\mathbb{P}_ {X} \mathbb{P}_ {Z})$</li>
    </ul>
  </li>
  <li>MINE (mutual information neural estimation)
    <ul>
      <li>MINE은 상호 정보(Mutual Information, MI)를 신경망을 통해 추정하는 방법론</li>
      <li>아래와 같은 MINE (mutual information neural estimation)을 활용하여 parameter $\theta \in \Theta$에 대해 계산</li>
      <li>$\psi_ { \mathbf{\theta} }는 \mathcal{X} \times \mathcal{Z} \rightarrow \mathbb{R}$ statistics network</li>
      <li>$I_ {\Theta}(X;Z) = \sup_ {\theta \in \Theta} \mathbb{E}_ {\mathbb{P}_ {XZ}}[ \psi_ { \mathbf{\theta} } ] - \log(\mathbb{E}_ {\mathbb{P}_ {X} \mathbb{P}_ {Z}}[e^{\psi_ { \mathbf{\theta} } } ])$</li>
    </ul>
  </li>
</ul>

<p><img src="../../images/DS503_24S/Large_Language_Models_Are_Efficient_Learners_of_Noise_robust_Speech_Recognition/mine1.png" alt="mine" /></p>

<ul>
  <li>학습 알고리즘은 아래와 같음</li>
  <li>이 알고리즘은 잡음이 섞인 음성 데이터를 효과적으로 처리하여 깨끗한 음성 데이터를 얻기 위해 여러 모델과 네트워크를 조정하는 과정을 반복</li>
</ul>

<ol>
  <li><strong>Require:</strong>
    <ul>
      <li>LLM $\mathcal{M}_ {\text{H2T}}$ 과 어댑터 $\mathcal{G}_ { \mathbf{\upsilon} }$</li>
      <li>정보 이론 기반의 MINE 통계 네트워크 $\psi$ (parameters: $\mathbf\theta$)</li>
      <li>언어 임베딩 조정 튜너 $\mathcal{T}$ (parameters: $\mathbf{\omega}$)</li>
      <li>N-best 음성 인식 가설 $\mathcal{Y}_N$</li>
      <li>병렬 잡음 음성 $\mathcal{X}_ {n}$ 및 깨끗한 음성 데이터 $\mathcal{X}_ {c}$</li>
      <li>배치 크기 $B$ 와 총 반복 횟수 $M$</li>
      <li>하이퍼 파라미터 가중치 $\lambda$ (손실 함수 가중치)
      -</li>
    </ul>
  </li>
  <li><strong>For</strong> $m=1$ <strong>to</strong> $M$:
    <ul>
      <li>N-best 가설 샘플링: ${ \mathcal{Y}_ {N}^{(1)}, \mathcal{Y}_ {N}^{(2)}, \cdots, \mathcal{Y}_ {N}^{(B)} }$;</li>
      <li>잡음 및 깨끗한 음성 샘플 추출: ${(X_n^{(1)}, X_c^{(1)}), (X_n^{(2)}, X_c^{(2)}), \cdots, (X_n^{(B)}, X_c^{(B)})}$;</li>
      <li>언어 공간 잡음 임베딩 추출: ${E_ {\text{LN}}^{(1)}, E_ {\text{LN}}^{(2)}, \cdots, E_ {\text{LN}}^{(B)}}$;</li>
      <li>상호 정보 계산: $\mathcal{I} = \frac{1}{B} \sum_ {b=1}^{B} \psi_ {\mathbf{\theta}} (E_ {\text{LN}}^{(b)}, \mathcal{E}_ {\text{ASR}}(X_ {n}^{(b)})) - \log( \frac{1}{B} \sum_ {b=1}^{B} e^{\psi_ { \mathbf{\theta} }(E_ {\text{LN}}^{(b)}, \mathcal{E}_ {\text{ASR}}(X_ {c}^{(b)}))})$;</li>
      <li>파라미터 업데이트:   $\mathbf{\theta} \leftarrow \mathbf{\theta} + {\mathbf{g}}_ {\mathbf{\theta}}$; (${\mathbf{g}}_ { \mathbf{\theta} } = \nabla_ { \mathbf{\theta} }(\mathcal{I})$)</li>
      <li>GER 손실 함수 계산: $\mathcal{L}_ {\text{H2T}}$ (with $\mathcal{T}_ {\mathbf{\omega}} (E_ {\text{LN}}^{(b)})$);</li>
      <li>상호 정보 재계산: $\mathcal{I}_ {1} = \frac{1}{B}\sum_ {b=1}^{B} \psi_ {\mathbf{\theta}}(\mathcal{T}_ {\mathbf{\omega}}(E_ {\text{LN}}^{(b)}), \mathcal{E}_ {\text{ASR}}(X_ {n}^{(b)}))$;</li>
      <li>파라미터 업데이트: $\mathbf{\upsilon} \leftarrow \mathbf{\upsilon} - \mathbf{g_ {\upsilon}}, \mathbf{\omega} \leftarrow \mathbf{\omega} - \mathbf{g_ {\omega}}$; ($\mathbf{g_ {\upsilon,\omega}} = \nabla_ {\mathbf{\upsilon,\omega}}(\mathcal{L}_ {\text{H2T}} - \lambda \mathcal{I}_ {1})$  )</li>
    </ul>
  </li>
</ol>

<h2 id="실험">실험</h2>
<ul>
  <li>다양한 noise 환경의 audio에 대해 실험을 진행함</li>
  <li>GER은 baseline에 비해 성능 진전이 있었지만 여러 잡음 조건에 대해 성능 향상 제한적</li>
  <li>RobustGER은 여러 소음에 대한 일관된 성능 향상 (Table 1)</li>
  <li>RobustGER은 소음 정도에 대해서도 일관된 성능 향상 (Table 2)</li>
  <li>
    <p>token-level noise가 성능 개선에 큰 기여 (Table 3)</p>

    <p><img src="../../images/DS503_24S/Large_Language_Models_Are_Efficient_Learners_of_Noise_robust_Speech_Recognition/table1.png" alt="table1" /></p>

    <p>$\quad$ <strong>Table 1: WER (%) results of RobustGER with LLaMA-2-7b finetuning</strong>
  <img src="../../images/DS503_24S/Large_Language_Models_Are_Efficient_Learners_of_Noise_robust_Speech_Recognition/table2.png" alt="table2" /></p>

    <p>$\quad$ <strong>Table 2: WER (%) results of RobustGER on different SNR-level testing conditions</strong>
  <img src="../../images/DS503_24S/Large_Language_Models_Are_Efficient_Learners_of_Noise_robust_Speech_Recognition/table3.png" alt="table3" /></p>

    <p>$\quad$ <strong>Table 3: Ablation study of the language-space noise embedding in terms of utterance and token levels</strong></p>
  </li>
  <li>noise embedding
    <ul>
      <li>KD 방식을 통해 최적의 noise embedding을 구함</li>
      <li>
        <p>다음과 같이 잡음의 대표성이 잘 나타남</p>

        <p><img src="../../images/DS503_24S/Large_Language_Models_Are_Efficient_Learners_of_Noise_robust_Speech_Recognition/embedding1.png" alt="embedding" /></p>
      </li>
    </ul>
  </li>
  <li>데이터 효율성
    <ul>
      <li>
        <p>LLM fine-tuning을 활용하여 점진적으로 훈련 데이터 크기를 줄여도 WER 유지</p>

        <p><img src="../../images/DS503_24S/Large_Language_Models_Are_Efficient_Learners_of_Noise_robust_Speech_Recognition/table4.png" alt="table4" /></p>

        <p>$\quad$ <strong>Table 4: Data efficiency of RobustGER on CHiME-4 test sets</strong></p>
      </li>
    </ul>
  </li>
  <li>error 수정 예시
    <ul>
      <li>
        <p>다음과 같이 RobustGER이 correction 성능이 가장 뛰어난 것을 볼 수 있음</p>

        <p><img src="../../images/DS503_24S/Large_Language_Models_Are_Efficient_Learners_of_Noise_robust_Speech_Recognition/table5.png" alt="table5" /></p>

        <p>$\quad$ <strong>Table 5:  Case study of RobustGER</strong></p>
      </li>
    </ul>
  </li>
</ul>

<h2 id="결론">결론</h2>
<ul>
  <li>language-space noise embedding을 추출하여 이를 denoising 해주었을 때, word correction 성능이 향상되는 것을 볼 수 있었음</li>
  <li>noise를 인식하고 noise embedding을 생성하는 복합적인 알고리즘을 활용하였음</li>
  <li>speech 분야에서 fine-tuning LLM의 우수한 성능을 보여줌</li>
</ul>

<h2 id="저자">저자</h2>
<ul>
  <li>Yuchen Hu (yuchen005@e.ntu.edu.sg)</li>
  <li>Chen Chen (hucky@nvidia.com)</li>
</ul>

<h2 id="참조">참조</h2>
<ul>
  <li>Github link (https://github.com/YUCHEN005/RobustGER)</li>
</ul>


    </div>



</article>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>







<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy;2024 Copyright 2021 Google LLC. All rights reserved. <br />
 Site last generated: May 27, 2024 <br />
<p><img src="images/company_logo.png" alt="Company logo"/></p>
                </div>
            </div>
</footer>






        </div>
    <!-- /.row -->
</div>
<!-- /.container -->
</div>
<!-- /#main -->
    </div>

</body>

<!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-66296557-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>





</html>


