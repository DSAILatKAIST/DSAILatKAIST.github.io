<!DOCTYPE html>
<html>
<head>
    <meta name="google-site-verification" content="1tAPTdgw0-t8G2Bya463OpBtYUbj9Um93gfnsowYKLw" />
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CV4PTXQSTW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-CV4PTXQSTW');
</script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="keywords" content="reviews,  ">
<title>[ICML 2022] Structure-Aware Transformer for Graph Representation Learning | Awesome Reviews</title>
<link rel="stylesheet" href="css/syntax.css">

<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="css/modern-business.css">
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="css/customstyles.css">
<link rel="stylesheet" href="css/boxshadowproperties.css">
<!-- most color styles are extracted out to here -->
<link rel="stylesheet" href="css/theme-blue.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="js/jquery.navgoco.min.js"></script>


<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<!-- Anchor.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script>
<script src="js/toc.js"></script>
<script src="js/customscripts.js"></script>

<link rel="shortcut icon" href="images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="DSAILatKAIST.github.io" href="http://localhost:4000/feed.xml">







    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    <script>
        $(document).ready(function() {
            $("#tg-sb-link").click(function() {
                $("#tg-sb-sidebar").toggle();
                $("#tg-sb-content").toggleClass('col-md-9');
                $("#tg-sb-content").toggleClass('col-md-12');
                $("#tg-sb-icon").toggleClass('fa-toggle-on');
                $("#tg-sb-icon").toggleClass('fa-toggle-off');
            });
        });
    </script>
    





</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-static-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fa fa-home fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle"> Awesome Reviews</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- toggle sidebar button -->
                <li><a id="tg-sb-link" href="#"><i id="tg-sb-icon" class="fa fa-toggle-on"></i> Nav</a></li>
                <!-- entries without drop-downs appear here -->




                
                
                
                <li><a href="introduction">Introduction</a></li>
                
                
                
                <li><a href="https://statistics.kaist.ac.kr/" target="_blank" rel="noopener">KAIST ISysE</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Reviews<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="reviews_DS503_2022.html">DS503 (2022)</a></li>
                        
                        
                        
                        <li><a href="reviews_kse801_2022.html">KSE801 (2022)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2023.html">DS503 (2023)</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
			<li>



  <a class="email" title="Submit feedback" href="#" onclick="javascript:window.location='mailto:swkim@kaist.ac.kr?subject=Question about reviews feedback&body=I have some feedback about the [ICML 2022] Structure-Aware Transformer for Graph Representation Learning page: ' + window.location.href;"><i class="fa fa-envelope-o"></i> Feedback</a>

</li>



		
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">
                        <input type="text" id="search-input" placeholder="search...">
                        <ul id="results-container"></ul>
                    </div>
                    <script src="js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: 'search.json',
                                searchResultTemplate: '<li><a href="{url}" title="[ICML 2022] Structure-Aware Transformer for Graph Representation Learning">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>



<!-- Page Content -->
<div class="container">
  <div id="main">
    <!-- Content Row -->
    <div class="row">
        
        
            <!-- Sidebar Column -->
            <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
  <li class="sidebarTitle"> </li>
  
  
  
  <li>
      <a title="How to contribute" href="#">How to contribute</a>
      <ul>
          
          
          
          <li><a title="How to contribute?" href="how_to_contribute.html">How to contribute?</a></li>
          
          
          
          
          
          
          <li><a title="Review template (Example)" href="template.html">Review template (Example)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Reviews" href="#">Reviews</a>
      <ul>
          
          
          
          <li><a title="DS503 (2022S)" href="reviews_DS503_2022.html">DS503 (2022S)</a></li>
          
          
          
          
          
          
          <li><a title="KSE801 (2022F)" href="reviews_kse801_2022.html">KSE801 (2022F)</a></li>
          
          
          
          
          
          
          <li><a title="DS503 (2023S)" href="reviews_DS503_2023.html">DS503 (2023S)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
      
      <!-- if you aren't using the accordion, uncomment this block:
         <p class="external">
             <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
         </p>
         -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>



            </div>
            
        

        <!-- Content Column -->
        <div class="col-md-9" id="tg-sb-content">
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/math...">
</script>
<article class="post" itemscope itemtype="https://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[ICML 2022] Structure-Aware Transformer for Graph Representation Learning</h1>
        <p class="post-meta"><time datetime="2023-04-20T00:00:00+09:00" itemprop="datePublished">Apr 20, 2023</time> /
            
            
            
            
            

        </p>


    </header>

    <div class="post-content" itemprop="articleBody">

        

        <h1 id="structure-aware-transformer-for-graph-representation-learning"><strong>**Structure-Aware Transformer for Graph Representation Learning</strong>**</h1>

<p><em><strong>Background before reading this review.</strong></em></p>

<p>*Notation</p>

<p>$G = (V, E, \mathbf X)$</p>

<ul>
  <li>node $u \in V$</li>
  <li>node attribute $x_u \in \mathcal X \subset \mathbb R^d$</li>
  <li>$\mathbf X \in \mathbb R^{n \times d}$</li>
</ul>

<ol>
  <li>
    <p>Transformers on Graph</p>

    <p>GNNì—ì„œëŠ” ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ explicití•˜ê²Œ í™œìš©í•˜ëŠ” ë°˜ë©´, transformerëŠ” ë…¸ë“œì˜ attributeë¥¼ í™œìš©í•˜ì—¬ ë…¸ë“œë“¤ ì‚¬ì´ relationì„ ë‚˜íƒ€ë‚´ëŠ”ë° í™œìš©</p>

    <p>Transformer êµ¬ì„± ìš”ì†Œ</p>

    <ol>
      <li>Self-attention module
        <ul>
          <li>input node feature $\mathbf X$ê°€ linear projectionì„ í†µí•´ Query($\mathbf Q$), Key($\mathbf K$), Value($\mathbf V$)ë¡œ íˆ¬ì˜ë˜ê³ , ì´ë¥¼ í™œìš©í•˜ì—¬ self-attentionì„ ê³„ì‚°í•  ìˆ˜ ìˆìŒ</li>
          <li>multi-head attention</li>
        </ul>
      </li>
      <li>feed-forward NN
        <ul>
          <li>self-attentionì˜ outputì´ skipconnectionì´ë‚˜ FFNë“±ì„ ê±°ì¹˜ë©´ í•˜ë‚˜ì˜ transforemer layerë¥¼ í†µê³¼í•˜ê²Œë¨</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>
    <p>Absolute encoding</p>

    <p>ê·¸ë˜í”„ì˜ ìœ„ì¹˜ì /êµ¬ì¡°ì ì¸ representationì„ input node featureì— ë”í•˜ê±°ë‚˜ concatenateí•˜ì—¬ Transformerì˜ inputìœ¼ë¡œ ì‚¬ìš© : Vanilla transformerì˜ PE</p>

    <p>Graph Transformerì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” Positional encoding methodë“¤</p>

    <ul>
      <li>Laplacian PE</li>
      <li>Random Walk PE</li>
    </ul>

    <p>(-) ë…¸ë“œì™€ ê·¸ ì´ì›ƒë“¤ ì‚¬ì´ì˜ structural similarityë¥¼ ë°˜ì˜í•˜ì§€ëŠ” ì•ŠìŒ</p>
  </li>
  <li>
    <p>Self-attention and kernel smoothing</p>

    <p>$\operatorname{Attn}\left(x_v\right)=\sum_ {u \in V} \frac{\kappa_ {\exp }\left(x_v, x_u\right)}{\sum_ {w \in V} \kappa_ {\exp }\left(x_v, x_w\right)} f\left(x_u\right), \forall v \in V$</p>

    <ul>
      <li>linear value function $f(x) = \mathbf W_ {\mathbf V}x$</li>
      <li>$\kappa_ {\exp }$ (non-symmetric) exponential kernel parameterized by $\mathbf W_ {\mathbf Q}, \mathbf W_ {\mathbf K}$</li>
    </ul>

    <p>$\kappa_ {\exp }\left(x, x^{\prime}\right):=\exp \left(\left\langle\mathbf{W}_ {\mathbf{Q}} x, \mathbf{W}_ {\mathbf{K}} x^{\prime}\right\rangle / \sqrt{d_ {\text {out }}}\right)$</p>

    <ul>
      <li>$\langle \cdot, \cdot\rangle$ : dotproduct</li>
      <li>í•™ìŠµê°€ëŠ¥í•œ exponential kernel</li>
      <li>(-) only position-aware, not structure-aware encoding</li>
    </ul>
  </li>
</ol>

<h1 id="1-problem-definition"><strong>1. Problem Definition</strong></h1>

<h2 id="limitations-of-gnn"><em><strong>Limitations of GNN</strong></em></h2>

<ol>
  <li>limited expressiveness : ìµœëŒ€ 1-WL testì˜ í‘œí˜„ë ¥ì„ ê°€ì§</li>
  <li>Over-smoothing problem : GNN layerì˜ ìˆ˜ê°€ ì¶©ë¶„íˆ ì»¤ì§€ë©´ ëª¨ë“  node representationì´ ìƒìˆ˜ë¡œ ìˆ˜ë ´í•˜ê²Œë¨</li>
  <li>Over-squashing problem : ê·¸ë˜í”„ì˜ ìˆ˜ë§ì€ ë©”ì„¸ì§€ë“¤ì´ ê³ ì •ëœ ê¸¸ì´ì˜ ë²¡í„° í•˜ë‚˜ë¡œ ì••ì¶•ë˜ì–´ ë°œìƒí•˜ëŠ” ê·¸ë˜í”„ â€œbottleneckâ€ìœ¼ë¡œ ì¸í•´ ë©€ë¦¬ ìœ„ì¹˜í•œ ë…¸ë“œì˜ ë©”ì„¸ì§€ê°€ íš¨ìœ¨ì ìœ¼ë¡œ ì „íŒŒë˜ì§€ ì•ŠëŠ” ë¬¸ì œ</li>
</ol>

<p>â‡’ Beyond neighborhood aggregation!</p>

<h2 id="transformer"><em><strong>Transformer</strong></em></h2>

<ul>
  <li>í•˜ë‚˜ì˜ self-attention layerë¥¼ í†µí•´ ê·¸ë˜í”„ë‚´ì˜ ì–´ë–¤ ë…¸ë“œìŒì´ë“ ì§€ ê·¸ ì‚¬ì´ì˜ ìƒí˜¸ì‘ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆìŒ</li>
  <li>GNNê³¼ ë‹¬ë¦¬ ì¤‘ê°„ ê³„ì¸µì—ì„œ structural inductive biasê°€ ë°œìƒí•˜ì§€ ì•Šì•„ GNNì˜ í‘œí˜„ë ¥ í•œê³„ë¥¼ í•´ê²°</li>
  <li>graph structure infoë¥¼ ì–¼ë§ˆë‚˜ í•™ìŠµí•˜ëŠ”ì§€ input node featureì—ë§Œ structural, positional infoë¥¼ encodingí•´ ë„£ìŒ</li>
  <li>ë…¸ë“œì— ëŒ€í•œ structural, positional infoë§Œ input node featureë¡œ encodingí•˜ì§€ë§Œ, ê·¸ë˜í”„ êµ¬ì¡° ìì²´ì—ì„œ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì •ë³´ì˜ ì–‘ì´ ì œí•œë¨</li>
</ul>

<blockquote>
  <p>ğŸ’¡ Goal : ê·¸ë˜í”„ ë°ì´í„°ì— Transformerë¥¼ ì ì ˆíˆ ë³€í˜•í•´ ì ìš©í•˜ì—¬ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì˜ ë°˜ì˜í•˜ê³  ë†’ì€ í‘œí˜„ë ¥ì„ ê°€ì§€ëŠ” Achitectureë¥¼ ë””ìì¸í•˜ëŠ” ê²ƒ</p>
</blockquote>

<h1 id="2-motivation"><strong>2. Motivation</strong></h1>

<h2 id="message-passing-graph-neural-networks"><em><strong>Message passing graph neural networks.</strong></em></h2>

<p>ìµœëŒ€ 1-WL testë¡œ ì œí•œëœ í‘œí˜„ë ¥, over-smoothing, over-quashing</p>

<h2 id="limitations-of-existing-approaches"><em><strong>Limitations of existing approaches</strong></em></h2>

<ul>
  <li>ë…¸ë“œë“¤ ì‚¬ì´ positional relationshipë§Œ encodingí•˜ê³ , strucutral relationshipì„ ì§ì ‘ encodingí•˜ì§€ì•ŠìŒ
    <ul>
      <li>ë…¸ë“œë“¤ ì‚¬ì´ structural similarityë¥¼ í™•ì¸í•˜ê¸°ê°€ ì–´ë µê³ , ë…¸ë“œë“¤ ì‚¬ì´ì˜ structural interactionì„ ëª¨ë¸ë§í•˜ëŠ”ë° ì‹¤íŒ¨í•˜ê²Œë¨</li>
    </ul>
  </li>
</ul>

<p>ex.</p>

<p><img src="https://user-images.githubusercontent.com/69068083/231114064-4063d3f0-f895-4d7c-a932-eddbeb77de34.png" alt="Untitled" /></p>

<p>G1ê³¼ G2ì—ì„œ ìµœë‹¨ê±°ë¦¬ë¥¼ í™œìš©í•œ positional encodingì„ í• ê²½ìš° node uì™€ vê°€ ë‹¤ë¥¸ ë…¸ë“œë“¤ì— ëŒ€í•´ ëª¨ë‘ ê°™ì€ representationì„ ê°€ì§€ê²Œë˜ì§€ë§Œ, ê·¸ë˜í”„ì˜ ì‹¤ì œ êµ¬ì¡°ëŠ” ë‹¤ë¦„ â†’ strucure awareì— ì‹¤íŒ¨</p>

<blockquote>
  <p>ğŸ’¡ Message-passing GNNê³¼ Transformer architecture ê°ê°ì˜ ì¥ì ì„ ì‚´ë ¤ local, global infoë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ëŠ” transformer architectureë¥¼ ì œì•ˆ</p>
</blockquote>

<h2 id="contribution-of-this-paper"><em><strong>Contribution of this paper</strong></em></h2>
<p>Q. Transformerêµ¬ì¡°ì— structural infoë¥¼ ì–´ë–»ê²Œ ì¸ì½”ë”©í• ê²ƒì¸ê°€?</p>

<p>A. Structure-aware self attentionë¥¼ ë„ì…í•œ Structre-Aware Transformer(SAT)</p>

<ol>
  <li>reformulate the self-attention mechanism
    <ul>
      <li>kernel smoother</li>
      <li>ì›ë˜ ë…¸ë“œ featureì— ì ìš©í•˜ëŠ” exponential ì»¤ë„ì„ í™•ì¥í•˜ì—¬ ê° ë…¸ë“œê°€ ì¤‘ì‹¬ì¸ subgraph representationì„ ì¶”ì¶œí•˜ì—¬ local structureì—ë„ ì ìš©</li>
    </ul>
  </li>
  <li>subgraph representationë“¤ì„ ìë™ì ìœ¼ë¡œ ë§Œë“¤ì–´ë‚´ëŠ” ë°©ë²•ë¡  ì œì•ˆ
    <ul>
      <li>ì´ë¥¼ í†µí•´ kernel smootherê°€ êµ¬ì¡°ì /íŠ¹ì„±ì  ìœ ì‚¬ì„±ì„ í¬ì°©í•  ìˆ˜ ìˆê²Œë¨</li>
    </ul>
  </li>
  <li>GNNìœ¼ë¡œ ê·¸ë˜í”„ì˜ subgraph infoë¥¼ í¬í•¨í•˜ëŠ” node representationì„ ë§Œë“¤ì–´ ê¸°ì¡´ GNNì— ì¶”ê°€ì ì¸ êµ¬ì¡° ê°œì„  ì—†ì´ë„ ë” ë†’ì€ ì„±ëŠ¥ì„ ëƒ„</li>
  <li>Transformerì˜ ì„±ëŠ¥í–¥ìƒì´ structure-awareí•œ ì¸¡ë©´ì—ì„œ ì¼ì–´ë‚œ ê²ƒì„ ì¦ëª…í•˜ê³  absolute encodingì´ ì¶”ê°€ëœ transfoemrë³´ë‹¤ SATê°€ ì–¼ë§ˆë‚˜ interpretableí•œì§€ë¥¼ ë³´ì—¬ì¤Œ</li>
</ol>

<h1 id="3-method"><strong>3. Method</strong></h1>

<h2 id="structure-aware-transformer"><em><strong>Structure-Aware Transformer</strong></em></h2>

<h3 id="1-structure-aware-self-attention"><em>1. <strong>Structure-Aware Self-attention</strong></em></h3>

<p>position-awareí•œ structural encodingì— ë…¸ë“œë“¤ ì‚¬ì´ structural similarityë¥¼ í¬í•¨í•˜ê¸° ìœ„í•´ ê° ë…¸ë“œì˜ local structureì— ê´€í•œ generalized kernelì„ ì¶”ê°€</p>

<p>ê° ë…¸ë“œê°€ ì¤‘ì‹¬ì´ë˜ëŠ” subgraph setì„ ì¶”ê°€í•¨ìœ¼ë¡œì¨ structure-aware attentionì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë  ìˆ˜ ìˆìŒ</p>

<p>$\operatorname{SA-Attn}\left(v\right):=\sum_ {u \in V} \frac{\kappa_ {\text{graph} }\left(S_G(v), S_G(u)\right)}{\sum_ {w \in V} \kappa_ {\text{graph}}\left(S_G(v), S_G(u)\right)} f\left(x_u\right)$</p>

<ul>
  <li>$S_G(v)$ : node feature $\mathbf X$ì™€ ì—°ê´€ëœ $v$ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œí•˜ëŠ” subgraph</li>
  <li>$\kappa_ {\text{graph} }$ : subgraphìŒì„ ë¹„êµí•˜ëŠ” kernel</li>
</ul>

<p>â‡’ attribute &amp; structural similarity ëª¨ë‘ í‘œí˜„ ê°€ëŠ¥í•œ expressive node representation ìƒì„± â†’ table 1</p>

<p>â‡’ ë™ì¼í•œ subgraph êµ¬ì¡°ë¥¼ ê°€ì§€ëŠ” ê²½ìš°ì—ë§Œ permutation equivariantí•œ ì„±ì§ˆì„ ê°–ê²Œë¨</p>

<p>$\kappa_ {\text {graph }}\left(S_G(v), S_G(u)\right)=\kappa_ {\exp }(\varphi(v, G), \varphi(u, G))$</p>

<ul>
  <li>$\varphi(v, G)$ : feature $\mathbf X$ë¥¼ ê°€ì§€ëŠ” node $v$ê°€ ì¤‘ì‹¬ì— ìˆëŠ” subgraphì˜ vector representationì„ ë§Œë“¤ì–´ë‚´ëŠ” structure extractor
    <ul>
      <li>GNNì´ë‚˜ differentiable Graph kernelë“± subgraphì˜ representationì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì–´ëŠ ëª¨ë¸ì´ë“  ë  ìˆ˜ ìˆìŒ</li>
      <li>Task/data íŠ¹ì„±ì— ë”°ë¼ Edge attributeì„ í™œìš©í•  í•„ìš”ê°€ ìˆëŠ” ê²½ìš° ê·¸ì— ë§ëŠ”GNNì„ ì„ íƒí•˜ë©´ ë¨. ë”°ë¡œ edge attributeì„ í™œìš©í•˜ì§€ëŠ” ì•Šê³  subgraph extractorì—ì„œ í™œìš©</li>
    </ul>
  </li>
</ul>

<p><em><strong>k-subtree GNN extractor.</strong></em></p>

<p>$\varphi(u, G) = \operatorname{GNN}_G^{(k)}(u)$</p>

<ul>
  <li>node uì—ì„œ ì‹œì‘í•˜ëŠ” k-subtree structureì˜ representationìƒì„±</li>
  <li>at most 1-WL test</li>
  <li>ì‘ì€ k ê°’ì´ë”ë¼ë„ over-smoothing, over-squashing issueì—†ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ”ê²ƒì„ í™•ì¸</li>
</ul>

<p><em><strong>k-subgraph GNN extractor.</strong></em></p>

<p>$\varphi(u, G) = \sum_ {v \in \mathcal N_k(u)} \operatorname{GNN}_G^{(k)}(v)$</p>

<ul>
  <li>node uì˜ representationë§Œì„ ì‚¬ìš©í•˜ëŠ”ë°ì„œ ë‚˜ì•„ê°€ node uê°€ ì¤‘ì‹¬ì´ ë˜ëŠ” k-hop subgraphì „ì²´ì˜ representationì„ ìƒì„±í•˜ê³  í™œìš©</li>
  <li>node u ì˜ k-hopì´ì›ƒ $\mathcal N_k(u)$ì— ëŒ€í•´ ê° ë…¸ë“œì— GNNì„ ì ìš©í•œ node representationì„ pooling(ë…¼ë¬¸ì—ì„œëŠ” summation)</li>
  <li>More powerful than 1-WL test</li>
  <li>original node representationê³¼ì˜ concatenationì„ í†µã… structural similarityë¿ë§Œ ì•„ë‹ˆë¼ attributed similarityë„ ë°˜ì˜</li>
</ul>

<p><em><strong>Other structure extractors.</strong></em></p>

<ul>
  <li>directly learn a number of â€œhidden graphsâ€ as the â€œanchor subgraphsâ€ to represent subgraphs</li>
  <li>domain-specific GNNs</li>
  <li>non-parametric graph-kernel</li>
</ul>

<h3 id="2-structure-aware-transformer"><em>2. Structure-Aware Transformer</em></h3>

<p><img src="https://user-images.githubusercontent.com/69068083/231114106-a71006e8-a9e5-44cb-b353-578ec4e09a80.png" alt="Untitled" /></p>

<p>self-attentionâ†’ skipconnection â†’ normalization layer â†’ FFN â†’ normalization layer</p>

<p><em><strong>Augmentation on skip connection.</strong></em></p>

<p>$xâ€™_v = x_c +1/ \sqrt {d_v} \operatorname{SA-Attn}\left(v\right)$</p>

<ul>
  <li>$d_v$ : node $v$ì˜ degree</li>
  <li>degree factorë¥¼ í¬í•¨í•˜ì—¬ ì—°ê²°ì´ ë§ì€ graph componentë“¤ì´ ì••ë„ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šë„ë¡í•¨</li>
</ul>

<p>*graph-level taskë¥¼ ì§„í–‰í•´ì•¼ í•  ê²½ìš° input graphì— ë‹¤ë¥¸ ë…¸ë“œì™€ì˜ connectivityì—†ì´ virtual <code class="language-plaintext highlighter-rouge">[cls] </code>nodeë¥¼ ì¶”ê°€í•˜ê±°ë‚˜, node-level representationì„ sum/average ë“±ìœ¼ë¡œ aggregation</p>

<h3 id="3-combination-with-absolute-encoding"><em>3. Combination with Absolute Encoding</em></h3>

<p>ìœ„ì˜ structure aware self-attentionì— ì¶”ê°€ë¡œ absolute encodingì„ ì¶”ê°€í•˜ê²Œ ë˜ë©´ postion-awareí•œ íŠ¹ì„±ì´ ì¶”ê°€ë˜ì–´ ê¸°ì¡´ì˜ ì •ë³´ë¥¼ ë³´ì™„í•˜ëŠ” ì—­í• ì„ í•˜ê²Œëœë‹¤. ì´ëŸ¬í•œ ì¡°í•©ì„ í†µí•´ ì„±ëŠ¥í–¥ìƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.</p>

<p>RandomWalk PE</p>

<p>Absolute PEë§Œ ì‚¬ìš©í•  ê²½ìš° structural biasê°€ ê³¼ë„í•˜ê²Œ ë°œìƒí•˜ì§€ ì•Šì•„ì„œ ëˆ„ê°œì˜ ë…¸ë“œê°€ ìœ ì‚¬í•œ local structureë¥¼ ê°–ê³  ìˆë”ë¼ë„ ë¹„ìŠ·í•œ node representationì´ ìƒì„±ë˜ëŠ”ê²ƒì„ ë³´ì¥í•˜ê¸° ì–´ë µë‹¤!</p>

<p>â†’ Structural, positional signìœ¼ë¡œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” distanceë‚˜ Laplacian-based positional representationì´ ë…¸ë“œë“¤ ì‚¬ì´ì˜ structural simialrityë¥¼ í¬í•¨í•˜ì§€ ì•Šê¸°ë•Œë¬¸</p>

<blockquote>
  <p>ğŸ“Œ Structural aware attenrionì€ inductive biasê°€ ë” ê°•í•˜ë”ë¼ë„ ë…¸ë“œì˜ strucutral similarityë¥¼ ì¸¡ì •í•˜ëŠ”ë° ì í•©í•˜ì—¬ ìœ ì‚¬í•œ subgraphêµ¬ì¡°ë¥¼ ê°€ì§„ ë…¸ë“œë“¤ì´ ë¹„ìŠ·í•œ embeddingì„ ê°–ê²Œí•˜ê³ , expressivityê°€ í–¥ìƒë˜ì–´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„</p>
</blockquote>

<h3 id="4-expressivity-analysis"><em>4. Expressivity Analysis</em></h3>

<p>SATì—ì„œëŠ” ê°ë…¸ë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œí•˜ëŠ” k-subgraph GNN extractorê°€ ë„ì…ë˜ì–´ ì ì–´ë„ subgraph representationë§Œí¼ì€ expressiveí•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì¥</p>

<h1 id="4-experiment"><strong>4. Experiment</strong></h1>

<h3 id="experiment-setup"><em><strong>Experiment setup</strong></em></h3>

<p><em><strong>Dataset</strong></em></p>

<ul>
  <li>ZINC</li>
  <li>CLUSTER</li>
  <li>PATTERN</li>
  <li>OGBG-PPA</li>
  <li>OGBG-CODE2</li>
</ul>

<p><em><strong>Baseline</strong></em></p>

<ul>
  <li><em><strong>GNNs</strong></em>
    <ul>
      <li>GCN</li>
      <li>GraphSAGE</li>
      <li>GAT</li>
      <li>GIN</li>
      <li>PNA</li>
      <li>Deeper GCN</li>
      <li>ExpC</li>
    </ul>
  </li>
  <li><em><strong>Transformers</strong></em>
    <ul>
      <li>Original Transformer with RWPE</li>
      <li>Graph Transformer</li>
      <li>SAN</li>
      <li>Graphormer</li>
      <li>GraphTrans</li>
    </ul>
  </li>
</ul>

<h3 id="results"><em><strong>Results</strong></em></h3>
<p><strong>Table1.</strong> SATì™€ graph regression, classification taskì˜ sotaëª¨ë¸ê³¼ ë¹„êµ</p>

<ul>
  <li>ZINC datasetì˜ ê²½ìš° ì‘ì„ìˆ˜ë¡ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸í•˜ëŠ” MAE(Mean Absolute Error), CLUSTERì™€ PATTERNì˜ ê²½ìš° ë†’ì„ìˆ˜ë¡ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸í•˜ëŠ” Acurracyê°€ í‰ê°€ì§€í‘œë¡œ ì‚¬ìš©ë˜ì—ˆìŒ.</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/69068083/231114155-056893f6-8d16-4a59-b43b-62c76fd482a3.png" alt="Untitled" /></p>

<p><strong>Table2.</strong> SATì™€ OGBë°ì´í„°ì…‹ì—ì„œì˜ sotaëª¨ë¸ ë¹„êµ</p>
<ul>
  <li>OGB datasetì˜ ê²½ìš° ë†’ì„ìˆ˜ë¡ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸í•˜ëŠ” Acurracy, F1 scoreê°€ í‰ê°€ì§€í‘œë¡œ ì‚¬ìš©ë˜ì—ˆìŒ.</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/69068083/231114185-23daa0d6-bc32-4838-93e8-0a6d09a17f7e.png" alt="Untitled" /></p>

<p><strong>Table3.</strong> structure extractorë¡œ ì‚¬ìš©í•œ GNNê³¼ì˜ ì„±ëŠ¥ë¹„êµ. Sparse GNNì„ ëª¨ë“  ê²½ìš°ì—ì„œ outperformí•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ</p>

<p><img src="https://user-images.githubusercontent.com/69068083/231114223-e6e32dfd-039b-4caa-b123-14e72e9fc867.png" alt="Untitled" /></p>

<p><strong>Fig3.</strong> ZINCë°ì´í„°ì…‹ì— SATì˜ ë‹¤ì–‘í•œ variantì‹¤í—˜</p>

<ul>
  <li>í‰ê°€ì§€í‘œ : MAE(ë” ì‘ì€ ì§€í‘œê°€ ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸)</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/69068083/231114263-2ea26465-c8b3-4df8-b7d4-4d329d41d97b.png" alt="Untitled" /></p>

<ol>
  <li>structure extractorì—ì„œì˜ kì˜ ì˜í–¥ ë¹„êµ
    <ul>
      <li>k=0ì¼ë•Œ, Absolute encodingë§Œì„ í™œìš©í•˜ëŠ” vanilla transformerë‘ ê°™ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŒ</li>
      <li>k=3ì¼ë•Œ, optimal performanceë¥¼ ë³´ì„ì„ í™•ì¸</li>
      <li>k=4ë¥¼ ë„˜ì–´ì„œë©´ ì„±ëŠ¥ì´ ì•…í™”ë˜ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆëŠ”ë°, ì´ëŠ” GNNì—ì„œì˜ ì•Œë ¤ì§„ ì‚¬ì‹¤ì¸ ë” ì ì€ ìˆ˜ì˜ layerë¥¼ ê°€ì§€ëŠ” networkê°€ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒê³¼ ë§ˆì°¬ê°€ì§€ë¼ê³  í•  ìˆ˜ ìˆìŒ</li>
    </ul>
  </li>
  <li>Absolute encodingì˜ ì˜í–¥ ë¹„êµ
    <ul>
      <li>RWPE vs. Laplacian PE</li>
      <li>Structure-aware attentionì˜ ë„ì…ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥í–¥ìƒë³´ë‹¤ëŠ” ê·¸ ì •ë„ê°€ ë‚®ì•˜ì§€ë§Œ, RWPEë¥¼ ë„ì…í•  ê²½ìš° ì„±ëŠ¥ì´ ë” ì¢‹ì€ê²ƒìœ¼ë¡œ ë³´ì•˜ì„ ë•Œ, ë‘ê°€ì§€ encodingì´ ìƒí˜¸ë³´ì™„ì ì¸ ì—­í• ì„ í•œë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆìŒ</li>
    </ul>
  </li>
  <li>Readout methodì˜ ì˜í–¥ ë¹„êµ
    <ul>
      <li>node-level representationì„ aggregateí•  ë•Œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ readoutdìœ¼ë¡œ meanê³¼ sumì„ ë¹„êµí•˜ì˜€ìŒ</li>
      <li>ì¶”ê°€ë¡œ <code class="language-plaintext highlighter-rouge">[CLS]</code> í† í°ì„ í†µí•´ graph-level ì •ë³´ë¥¼ poolingí•˜ëŠ” ë°©ë²•ë„ ê°™ì´ ë¹„êµí•˜ì—¬ë³´ì•˜ìŒ</li>
      <li>GNNì—ì„œëŠ” readout methodì˜ ì˜í–¥ì´ ë§¤ìš° ì»¸ì§€ë§Œ SATì—ì„œëŠ” ë§¤ìš° ì•½í•œ ì˜í–¥ë§Œì„ í™•ì¸í•¨.</li>
    </ul>
  </li>
</ol>

<h1 id="5-conclusion"><strong>5. Conclusion</strong></h1>

<p><em><strong>Strong Points.</strong></em></p>

<p>structural infoë¥¼ graphormerì—ì„œì²˜ëŸ¼ íœ´ë¦¬ìŠ¤í‹±í•˜ê²Œ shortest path distance(SPD)ë¥¼ í™œìš©í•˜ì§€ ì•Šê³ , ê·¸ëŸ¬í•œ local infoë¥¼ ì˜ ë°°ìš°ëŠ” GNNìœ¼ë¡œ ëŒ€ì²´í•œ ì ì´ novelí•˜ë‹¤ê³  í•  ìˆ˜ ìˆìŒ</p>

<p>Transformerì˜ global receptive field íŠ¹ì„±ê³¼ GNNì˜ local structureíŠ¹ì„±ì´ ìƒí˜¸ë³´ì™„ì </p>

<p>encodingì— ìˆì–´ì„œë„</p>

<ol>
  <li>RWPEë¥¼ í†µí•œ positional encoding</li>
  <li>k-subtree/subgraph GNNì„ í†µí•œ structure-aware attention</li>
</ol>

<p>ë‘ê°€ì§€ê°€ ìƒí˜¸ë³´ì™„ì ì¸ ì—­í• ì„ í•¨</p>

<p>â†’ ê°ìê°€ ì˜ ë°°ìš°ëŠ” íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ìƒí˜¸ë³´ì™„ì ì¸ ë‘ê°€ì§€ ë°©ë²•ë¡ ì„ ì˜ ì„ì–´ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ì—ˆê³ , ê·¸ ì´ìœ ê°€ ë‚©ë“í•˜ê¸° ì‰¬ì›€</p>

<p><em><strong>Weak Points.</strong></em></p>

<p>ê·¸ë˜í”„ë°ì´í„°ì— Transformerë¥¼ ì ìš©í•œ ë‹¤ë¥¸ ë…¼ë¬¸ì˜ architectureì¸ Graphormerì—ì„œ ì‚¬ìš©í•œ SPDë§Œì˜ ì¥ì  : ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ìˆì§€ ì•Šì€, ì•„ì£¼ ë©€ë¦¬ì— ìœ„ì¹˜í•œ ë…¸ë“œìŒì´ë”ë¼ë„ shortest pathìƒì˜ weighted edge aggregationì„ í•˜ëŠ” ë§Œí¼ ê·¸ëŸ¬í•œ íŠ¹ì„± ë°˜ì˜ë˜ë©´ ì¢‹ì€ ê·¸ë˜í”„ êµ¬ì¡°/ ë°ì´í„°ì…‹ì—ì„œëŠ” SATê°€ captureí•˜ì§€ ëª»í•˜ëŠ” ë¶€ë¶„ì´ ìˆì„ ê²ƒ</p>

<hr />
<h1 id="author-information"><strong>Author Information</strong></h1>

<ul>
  <li>
    <p>Dexiong Chen</p>

    <ul>
      <li>Department of Biosystems Science and Engineering, ETH Zurich, Switzerland.</li>
      <li>SIB Swiss Institute of Bioinformatics, Switzerland.</li>
    </ul>
  </li>
  <li>
    <p>Leslie Oâ€™Bray</p>

    <ul>
      <li>Department of Biosystems Science and Engineering, ETH Zurich, Switzerland.</li>
      <li>SIB Swiss Institute of Bioinformatics, Switzerland.</li>
    </ul>
  </li>
  <li>
    <p>Karsten Borgwardt</p>

    <ul>
      <li>Department of Biosystems Science and Engineering, ETH Zurich, Switzerland.</li>
      <li>SIB Swiss Institute of Bioinformatics, Switzerland.</li>
    </ul>
  </li>
</ul>

<h1 id="6-reference--additional-materials"><strong>6. Reference &amp; Additional materials</strong></h1>

<ul>
  <li>Github Implementation : <a href="https://github.com/BorgwardtLab/SAT"></a><a href="https://github.com/BorgwardtLab/SAT">https://github.com/BorgwardtLab/SAT</a></li>
  <li>Reference : <a href="https://arxiv.org/abs/2202.03036">Structure-Aware Transformer for Graph Representation Learning</a></li>
</ul>

    </div>



</article>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>







<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy;2023 Copyright 2021 Google LLC. All rights reserved. <br />
 Site last generated: Apr 25, 2023 <br />
<p><img src="images/company_logo.png" alt="Company logo"/></p>
                </div>
            </div>
</footer>






        </div>
    <!-- /.row -->
</div>
<!-- /.container -->
</div>
<!-- /#main -->
    </div>

</body>

<!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-66296557-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>





</html>


