<!DOCTYPE html>
<html>
<head>
    <meta name="google-site-verification" content="1tAPTdgw0-t8G2Bya463OpBtYUbj9Um93gfnsowYKLw" />
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CV4PTXQSTW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-CV4PTXQSTW');
</script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="keywords" content="reviews,  ">
<title>[CVPR 2022] End-to-end Generative Pretraining for Multimodal Video Captioning | Awesome Reviews</title>
<link rel="stylesheet" href="css/syntax.css">

<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="css/modern-business.css">
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="css/customstyles.css">
<link rel="stylesheet" href="css/boxshadowproperties.css">
<!-- most color styles are extracted out to here -->
<link rel="stylesheet" href="css/theme-blue.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="js/jquery.navgoco.min.js"></script>


<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<!-- Anchor.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script>
<script src="js/toc.js"></script>
<script src="js/customscripts.js"></script>

<link rel="shortcut icon" href="images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="DSAILatKAIST.github.io" href="http://localhost:4000/feed.xml">


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>




    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    <script>
        $(document).ready(function() {
            $("#tg-sb-link").click(function() {
                $("#tg-sb-sidebar").toggle();
                $("#tg-sb-content").toggleClass('col-md-9');
                $("#tg-sb-content").toggleClass('col-md-12');
                $("#tg-sb-icon").toggleClass('fa-toggle-on');
                $("#tg-sb-icon").toggleClass('fa-toggle-off');
            });
        });
    </script>
    


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-static-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fa fa-home fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle"> Awesome Reviews</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- toggle sidebar button -->
                <li><a id="tg-sb-link" href="#"><i id="tg-sb-icon" class="fa fa-toggle-on"></i> Nav</a></li>
                <!-- entries without drop-downs appear here -->




                
                
                
                <li><a href="introduction">Introduction</a></li>
                
                
                
                <li><a href="https://statistics.kaist.ac.kr/" target="_blank" rel="noopener">KAIST ISysE</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Reviews<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="reviews_kse801_2022.html">KSE801 (2022)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2023.html">DS503 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS535_2023.html">DS535 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2024.html">DS503 (2024)</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
			<li>



  <a class="email" title="Submit feedback" href="#" onclick="javascript:window.location='mailto:swkim@kaist.ac.kr?subject=Question about reviews feedback&body=I have some feedback about the [CVPR 2022] End-to-end Generative Pretraining for Multimodal Video Captioning page: ' + window.location.href;"><i class="fa fa-envelope-o"></i> Feedback</a>

</li>



		
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">
                        <input type="text" id="search-input" placeholder="search...">
                        <ul id="results-container"></ul>
                    </div>
                    <script src="js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: 'search.json',
                                searchResultTemplate: '<li><a href="{url}" title="[CVPR 2022] End-to-end Generative Pretraining for Multimodal Video Captioning">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>



<!-- Page Content -->
<div class="container">
  <div id="main">
    <!-- Content Row -->
    <div class="row">
        
        
            <!-- Sidebar Column -->
            <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
  <li class="sidebarTitle"> </li>
  
  
  
  <li>
      <a title="How to contribute" href="#">How to contribute</a>
      <ul>
          
          
          
          <li><a title="How to contribute?" href="how_to_contribute.html">How to contribute?</a></li>
          
          
          
          
          
          
          <li><a title="Review template (Example)" href="template.html">Review template (Example)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Reviews" href="#">Reviews</a>
      <ul>
          
          
          
          <li><a title="KSE801 (2022F)" href="reviews_kse801_2022.html">KSE801 (2022F)</a></li>
          
          
          
          
          
          
          <li><a title="DS503 (2023S)" href="reviews_DS503_2023.html">DS503 (2023S)</a></li>
          
          
          
          
          
          
          <li><a title="DS535 (2023F)" href="reviews_DS535_2023.html">DS535 (2023F)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
      
      <!-- if you aren't using the accordion, uncomment this block:
         <p class="external">
             <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
         </p>
         -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>



            </div>
            
        

        <!-- Content Column -->
        <div class="col-md-9" id="tg-sb-content">
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/math...">
</script>
<article class="post" itemscope itemtype="https://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[CVPR 2022] End-to-end Generative Pretraining for Multimodal Video Captioning</h1>
        <p class="post-meta"><time datetime="2024-04-17T00:00:00+09:00" itemprop="datePublished">Apr 17, 2024</time> /
            
            
            
            
            

        </p>


    </header>

    <div class="post-content" itemprop="articleBody">

        

        <h1 id="end-to-end-generative-pretraining-for-multimodal-video-captioning">End-to-end Generative Pretraining for Multimodal Video Captioning</h1>

<h2 id="1-problem-definition">1. Problem Definition</h2>
<p>The paper tackles the challenge of multimodal video captioning, learning from unlabelled videos and aiming to generate accurate and coherent captions for videos.</p>

<h2 id="2-motivation">2. Motivation</h2>
<p>The task of multimodal video captioning is an emerging benchmark of progress in AI fields. A successful model must not only understand multimodal streams of input video but also generate coherent descriptions of the content. However, there are two major limitations or challenges in this area. First, recent video and language pretraining frameworks lack the ability to generate sentences due to often lacking decoder. Secondly, the datasets often lack annotated captions in unlabelled videos. 
To tackle the first obstacle, the authors propose integrating a decoder into the framework, enabling models to generate previously unseen sentences. Moreover, departing from prior approaches that solely pretrain the encoder, they advocate for joint end-to-end training of the entire encoder-decoder model. They also want to overcome the limitation of lacking annotated videos by introducing a novel pretraining objective that requires no annotated captions and instead uses utterances sampled at various times within the same video. Finally, apart from two mentioned challenges, they want to make the encoder trainable from raw pixels and words directly, in contrast with existing methods that rely on pre-extracted visual features limiting transfer to new domains.</p>

<h2 id="3-method">3. Method</h2>
<p>The proposed framework is called Multimodal Video Generative Pretraining (MV-GPT) as illustrated in the figure below.</p>

<p><img src="../../images/DS503_24S/End-to-end_Generative_Pretraining_for_Multimodal_Video_Captioning/MV-GPT_framework.png" alt="" />
<!-- ![MV-GPT Framework](images/MV-GPT%20framework.png) --></p>

<p>Recall that the objective is to pretrain a model that can effectively encode multimodal videos (visual frames and transcribed speech) as well as decode natural language sentences.</p>

<h3 id="pretraining-objectives-and-losses">Pretraining Objectives and Losses</h3>
<p>The framework leverages unlabelled instructional video data containing video frames and associated utterances. Since unlabelled videos lack captioning targets, the model is trained to generate a future utterance (as a caption target) in the video based on the current video context and utterances (forward generation). To enable the generation of text aligned with the current video context, they add an extra backward generation loss. This involves the model generating the current utterance based on the current video frames and a future utterance (backward generation). With this bidirectional approach, the generated sentences are encouraged to be temporally aligned with the visual inputs. 
Note that the employed loss functions are minimizing the negative log-likelihood of the true future and present utterances.</p>

<h3 id="model">Model</h3>
<p>The model entirely uses transformer blocks and is trained directly from pixels and word tokens. At the beginning, there are two specific encoders: one for text using BERT-base architecture, and another for visuals using ViViT architecture. Then, they are fused using a co-attentional transformer by the multimodal encoder, where each layer is a stack of transformer blocks particular for each textual and visual stream. Lastly, the output is generated autoregressively conditioned on multimodal video features using a GPT-2 decoder with masked language modeling and special tokens, BOS and EOS. 
The model is pretrained end-to-end using Adam optimizer with the batch size of 2048.</p>

<h2 id="4-experiment">4. Experiment</h2>
<h3 id="experiment-setup">Experiment Setup</h3>
<ul>
  <li>The authors utilize HowTo100M as the pretraining dataset and then evaluate on these four downstream captioning benchmarks through finetuning: YouCook2, Video Timeline Tags (ViTT), MSR-VTT, and ActivityNet-Captions</li>
  <li>The results are reported using the following metrics: BLEU-4 (B-4), CIDEr (C ), METEOR (M), and ROUGE-L (R-L). For ViTT, BLEU-1 (B-1) is measured instead of BLEU-4.
    <h3 id="result">Result</h3>
    <p>The comparisons of the proposed MV-GPT to existing methods on all four datasets are shown below. It can be seen that the MV-GPT outperforms all prior works with a margin in all datasets and all metrics.</p>
  </li>
</ul>

<p><img src="../../images/DS503_24S/End-to-end_Generative_Pretraining_for_Multimodal_Video_Captioning/compare_youcook2.png" alt="" />
<!-- ![compare youcook2](images/compare%20youcook2.png) --></p>

<p><img src="../../images/DS503_24S/End-to-end_Generative_Pretraining_for_Multimodal_Video_Captioning/compare_vitt.png" alt="" />
<!-- ![compare ViTT](images/compare%20vitt.png) --></p>

<p><img src="../../images/DS503_24S/End-to-end_Generative_Pretraining_for_Multimodal_Video_Captioning/compare_msr-vtt.png" alt="" />
<!-- ![compare MSR-VTT](images/compare%20msr-vtt.png) --></p>

<p><img src="../../images/DS503_24S/End-to-end_Generative_Pretraining_for_Multimodal_Video_Captioning/compare_act.png" alt="" />
<!-- ![compare Act](images/compare%20act.png) --></p>

<p>Besides, the authors also show results on non-generative video understanding tasks (including VideoQA, video retrieval and action classification) to emphasize the capability other than just being a generative model.</p>

<p>By the end, they illustrate qualitative examples on YouCook2 (first row) and MSR-VTT (last two rows) as follows.
<img src="../../images/DS503_24S/End-to-end_Generative_Pretraining_for_Multimodal_Video_Captioning/qualitative_example.png" alt="" />
<!-- ![qualitative example](images/qualitative%20example.png) --></p>

<h2 id="5-conclusion">5. Conclusion</h2>
<p>The authors introduce a new framework for multimodal video captioning called MV-GPT, where both the encoder for multimodal inputs and the decoder for generating captions are trained together using a bidirectional generative objective. This involves sampling utterances from unlabeled videos at various time points instead of caption target. The model undergoes end-to-end training during both pretraining and finetuning stages. It achieves top performance on various video captioning benchmarks and other tasks such as video understanding.
In my opinion, this seems like a cutting-edge framework that will allow us to have an automated video captioning system (still being challenging nowadays) for any platforms in the near future.</p>

<h3 id="author-information">Author Information</h3>
<ul>
  <li>Author name: Paul Hongsuck Seo
    <ul>
      <li>Affiliation: Korea University</li>
      <li>Research Topic: Multimodal Interactive Intelligence, Vision, Speech and Language Understanding</li>
    </ul>
  </li>
  <li>Author name: Arsha Nagrani
    <ul>
      <li>Affiliation: Google Inc.</li>
      <li>Research Topic: Machine learning, Computer Vision, Speech Technology, Deep Learning</li>
    </ul>
  </li>
  <li>Author name: Anurag Arnab
    <ul>
      <li>Affiliation: University of Oxford</li>
      <li>Research Topic: Computer Vision, Machine Learning, Deep Learning</li>
    </ul>
  </li>
  <li>Author name: Cordelia Schmid
    <ul>
      <li>Affiliation: Institut national de recherche en informatique et en automatique</li>
      <li>Research Topic: Computer vision, Object Recognition, Video Recognition, Learning</li>
    </ul>
  </li>
</ul>

<h2 id="6-reference--additional-materials">6. Reference &amp; Additional Materials</h2>
<ul>
  <li><a href="https://arxiv.org/abs/2201.08264">[CVPR 2022] End-to-end Generative Pretraining for Multimodal Video Captioning</a></li>
</ul>

    </div>



</article>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>







<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy;2024 Copyright 2021 Google LLC. All rights reserved. <br />
 Site last generated: Apr 23, 2024 <br />
<p><img src="images/company_logo.png" alt="Company logo"/></p>
                </div>
            </div>
</footer>






        </div>
    <!-- /.row -->
</div>
<!-- /.container -->
</div>
<!-- /#main -->
    </div>

</body>

<!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-66296557-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>





</html>


