<!DOCTYPE html>
<html>
<head>
    <meta name="google-site-verification" content="1tAPTdgw0-t8G2Bya463OpBtYUbj9Um93gfnsowYKLw" />
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CV4PTXQSTW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-CV4PTXQSTW');
</script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="keywords" content="reviews,  ">
<title>[ICLR 2023] LEARNING MLPS ON GRAPHS: A UNIFIED VIEW OF EFFECTIVENESS, ROBUSTNESS, AND EFFICIENCY | Awesome Reviews</title>
<link rel="stylesheet" href="css/syntax.css">

<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="css/modern-business.css">
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="css/customstyles.css">
<link rel="stylesheet" href="css/boxshadowproperties.css">
<!-- most color styles are extracted out to here -->
<link rel="stylesheet" href="css/theme-blue.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="js/jquery.navgoco.min.js"></script>


<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<!-- Anchor.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script>
<script src="js/toc.js"></script>
<script src="js/customscripts.js"></script>

<link rel="shortcut icon" href="images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="DSAILatKAIST.github.io" href="http://dsailatkaist.github.io/feed.xml">


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>




    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    <script>
        $(document).ready(function() {
            $("#tg-sb-link").click(function() {
                $("#tg-sb-sidebar").toggle();
                $("#tg-sb-content").toggleClass('col-md-9');
                $("#tg-sb-content").toggleClass('col-md-12');
                $("#tg-sb-icon").toggleClass('fa-toggle-on');
                $("#tg-sb-icon").toggleClass('fa-toggle-off');
            });
        });
    </script>
    


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-static-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fa fa-home fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle"> Awesome Reviews</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- toggle sidebar button -->
                <li><a id="tg-sb-link" href="#"><i id="tg-sb-icon" class="fa fa-toggle-on"></i> Nav</a></li>
                <!-- entries without drop-downs appear here -->




                
                
                
                <li><a href="introduction">Introduction</a></li>
                
                
                
                <li><a href="https://statistics.kaist.ac.kr/" target="_blank" rel="noopener">KAIST ISysE</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Reviews<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="reviews_kse801_2022.html">KSE801 (2022)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2023.html">DS503 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS535_2023.html">DS535 (2023)</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
			<li>



  <a class="email" title="Submit feedback" href="#" onclick="javascript:window.location='mailto:swkim@kaist.ac.kr?subject=Question about reviews feedback&body=I have some feedback about the [ICLR 2023] LEARNING MLPS ON GRAPHS: A UNIFIED VIEW OF EFFECTIVENESS, ROBUSTNESS, AND EFFICIENCY page: ' + window.location.href;"><i class="fa fa-envelope-o"></i> Feedback</a>

</li>



		
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">
                        <input type="text" id="search-input" placeholder="search...">
                        <ul id="results-container"></ul>
                    </div>
                    <script src="js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: 'search.json',
                                searchResultTemplate: '<li><a href="{url}" title="[ICLR 2023] LEARNING MLPS ON GRAPHS: A UNIFIED VIEW OF EFFECTIVENESS, ROBUSTNESS, AND EFFICIENCY">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>



<!-- Page Content -->
<div class="container">
  <div id="main">
    <!-- Content Row -->
    <div class="row">
        
        
            <!-- Sidebar Column -->
            <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
  <li class="sidebarTitle"> </li>
  
  
  
  <li>
      <a title="How to contribute" href="#">How to contribute</a>
      <ul>
          
          
          
          <li><a title="How to contribute?" href="how_to_contribute.html">How to contribute?</a></li>
          
          
          
          
          
          
          <li><a title="Review template (Example)" href="template.html">Review template (Example)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Reviews" href="#">Reviews</a>
      <ul>
          
          
          
          <li><a title="KSE801 (2022F)" href="reviews_kse801_2022.html">KSE801 (2022F)</a></li>
          
          
          
          
          
          
          <li><a title="DS503 (2023S)" href="reviews_DS503_2023.html">DS503 (2023S)</a></li>
          
          
          
          
          
          
          <li><a title="DS535 (2023F)" href="reviews_DS535_2023.html">DS535 (2023F)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
      
      <!-- if you aren't using the accordion, uncomment this block:
         <p class="external">
             <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
         </p>
         -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>



            </div>
            
        

        <!-- Content Column -->
        <div class="col-md-9" id="tg-sb-content">
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/math...">
</script>
<article class="post" itemscope itemtype="https://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[ICLR 2023] LEARNING MLPS ON GRAPHS: A UNIFIED VIEW OF EFFECTIVENESS, ROBUSTNESS, AND EFFICIENCY</h1>
        <p class="post-meta"><time datetime="2023-04-20T00:00:00+09:00" itemprop="datePublished">Apr 20, 2023</time> /
            
            
            
            
            

        </p>


    </header>

    <div class="post-content" itemprop="articleBody">

        

        <h3 id="title">Title</h3>
<p>LEARNING MLPS ON GRAPHS: A UNIFIED VIEW OF EFFECTIVENESS, ROBUSTNESS, AND EFFICIENCY</p>

<h3 id="1-motivation">1. Motivation</h3>
<p>Graph Machine Learning 은 non-Euclidea nsctructural data 인 graph 를 다루는 연구분야이다.<br />
기존 Machine Learning 과 달리, node 와 edge 로 이루어진 graph 를 학습하면서, node 들의 연결성과 관계에 대한 다양한 properties 를 발굴해내면서, Recommendation System, Social Netowrk, Traffic forcast 등 여러 분야에서 높은 Performance 를 보인다.<br />
하지만, structure data 를 사용하는데 발생하는 scalability 문제와 message passing 기법으로 인한 multi-hop data dependency 때문에, Graph Machine Learning 은 아직 현실세계에 적용하기에 많은 문제점들이 존재한다.<br />
Graph Machine Learning 의 scalability 문제를 해결하기 위하여, 최근에는 Graph based model 이 아닌 MLP 를 Graph Machine Learning 의 성능까지 끌어올리려는 연구가 진행되고 있다.<br />
주로 pretrain 된 GNN (Graph Neural Network) 를 MLP 로 knowledge distillation 하는 방식으로 진행되는 위 연구는, MLP 자체가 가지는 문제점 때문에 아직 효과적이지도, robust 하지도 못한 성과를 보이고 있다.<br />
그 이유로는 다음과 같다.<br /></p>
<ul>
  <li>MLP 는 기본적으로 Euclidean space 의 data 를 다루는 것에 특화된 model 이다. 따라서, Graph 의 non-Euclidean 한 structure 특성을 MLP 에 반영할 수가 없다.</li>
  <li>만약에, node label 이 graph structure 와 밀접한 연관이 있다면, MLP 의 embedding vector 와 label 의 space 가 다를 수도 있다.</li>
  <li>GNN based teacher network 에 MLP 를 매칭시키기 어렵다.</li>
  <li>Node feature 의 noise 에 대하여 너무 sensitive 하다.
따라서 본 연구에서는 다음과 같은 질문을 던진다.<br />
Can we learn MLPs that are graph structure-aware in both the feature and representation spaces, insentive to node feature noises, and have superior performance as well as fast inference speed ?<br />
MLP 가 GNN 을 따라갈 수 없는 이유와 본 연구에서 던지는 질문에서 확인할 수 있듯이, 가장 중요한 것은 MLP 가 structure 정보를 포착할 수 있게 만드는 것이다.<br />
본 연구는 이를 해결방안을 다음과 같이 제시한다.<br /></li>
  <li>Structure 정보를 포착하기 위하여, Graph 에서 node 의 position featurers 를 추출해 낸후, node feature 와 조합하여 MLP 의 input 으로 사용한다.</li>
  <li>GNN 에서 얻은 node similarity 정보를 MLP 로 전달한다.</li>
  <li>마지막으로, MLP 의 robustness 를 증가시키기 위하여, adversarial feature augmentation 을 진행한다.
위와 같은 해결방안을 제시한 model 은 논문에서 NOise-robust Structure-aware MLPs On Graphs (NOSMOG) 로 부르게 된다.</li>
</ul>

<h3 id="2-preliminary">2. Preliminary</h3>
<h4 id="--notation-">- Notation <br /></h4>
<p>Graph 는 다음과 같이 표기한다.<br />
$\mathcal{G} = (\mathcal{V}, \mathcal{E}, \boldsymbol{\mathcal{C}})$<br />
여기서, $\mathcal{V}$ 는 node set 을, $\mathcal{E}$ 는 edge set 을, $\boldsymbol{\mathcal{C}} \in \mathbb{R}^{d _c}$ 는 node content attributes (i.e., node featuers)를 나타낸다.<br />
Node classification task 의 경우, 각 node $v \in \mathcal{V}$ 의 category (i.e., label) probability 를 예측하는 것으로, ground truth node label 은 $\boldsymbol{Y} \in \mathbb{R}^{K}$ 로 표기한다.<br />
여기서 $K$ 는 category 의 개수를 의미한다.<br />
또한, ground truth label 을 가지고 있는 node set 을 $\mathcal{V}^{L}$ 로 표기하며, ground truth label 이 없는 node set 은 $\mathcal{V}^{U}$ 로 표기한다.</p>

<h4 id="--graph-neural-network-">- Graph Neural Network <br /></h4>
<p>node $v \in \mathcal{V}$ 가 주어졌을 때, GNN 은 node $v$ 의 neighbor 인 $\mathcal{N}(v)$ 에서 message 를 aggregate 하여, node $v$ 의 embedding $\pmb{h} \in \mathbb{R}^{d_ {n}}$ 를 업데이트한다. <br />
$l$-th layer 의 node embedding 을 $\boldsymbol{h}^{(l-1)}_ {v}$ 라고 할 때, neighbor 의 embedding 을 aggregate (denote AGG) 하고, 이전 layer 에서 얻은 node 의 embedding 과 combine (denote COM) 을 진행한다.<br />
이는 $\boldsymbol{h}^{(l)}_ {v} = COM(\boldsymbol{h}^{(l-1)}_ {v}, AGG(\left\lbrace \boldsymbol{h}^{(l-1)}_ {u} where u \in \mathcal{N}(v) \right\rbrace))$<br />
로 작성할 수 있다.</p>

<h4 id="--knowledge-distillation-">- Knowledge Distillation <br /></h4>
<p>복잡하거나 (e.g, ensemble model) 거대한 model 은 feature extraction 이나 generalize 를 잘 수행할 수 있다.<br />
하지만, 이 거대한 model 은 보편적으로 사용하기에는 computing resource, energy, memory 측면에서 효율적이지 않으며, 원하는 task 나 service 에 맞춰 학습하기도 어려울 수 있다.<br />
이를 해결하기 위하여 제안된 방법론이다.<br />
거대한 model 을 원하는 task 에 fine-tuning 시키는 것이 아니라, model 이 학습한 generalize 된 knowledge 를 우리가 원하는 task 에 맞춰진 간단한 model 에 전달하는 것이 Knowledge distillation 의 main idea 이다.<br />
여기서, 복합하거나 거대한 model 을 teacher network 라고 부르며, 간단한 model 을 student model 이라고 부른다.<br /></p>

<p>동일한 input 에 대하여, student model 은 input 의 true label 을 학습하면서, teacher network 에서 생성된 output 과의 distance 를 minimize 하는 방식으로 학습이 진행된다.<br />
<img src="https://github.com/Sein-Kim/Recommender_Systems/assets/76777494/95e72f40-1872-4fa3-88c0-3daa9062de8b" alt="knowledge_distillation" /><br />
간략하게 표현하면, 위의 그림 (<a href="https://intellabs.github.io/distiller/knowledge_distillation.html">출처</a>) 과 같은 방식으로 knowledge distillation 이 작동되게 된다.<br /></p>

<h3 id="3-proposed-model-">3. Proposed Model <br /></h3>
<p>NOSMOG 는 GNN 을 MLP 로 distillation 하는 것을 기본으로 하여, 세개의 key components 가 존재한다.<br />
우선 NOSMOG 의 overview 는 다음 그림과 같다.<br />
<img src="https://user-images.githubusercontent.com/76777494/231966040-1986ce5e-aad7-4b43-8bab-b1cdd84045d8.png" alt="Figure1" />
<br />
Distillation 은 figure 에서 $(a)$ 에 기술되어 있으며, 세가지 key components 는 figure 에서 $(b)$, $(c)$, $(d)$ 로 나타내져 있다.<br /></p>
<ul>
  <li>$(b)$ 는 graph 의 position feature 를 얻어내는 과정을 나타낸다.</li>
  <li>$(c)$ 는 representational similarity distillation 를 나타낸다.</li>
  <li>$(d)$ 는 adversarial feature augmentation 을 나타낸다.</li>
</ul>

<h4 id="--training-mlps-with-gnns-distillation-">- Training MLPs with GNNs Distillation <br /></h4>
<p>우선 figure 의 $(a)$ 에 해당하는 부분에 대하여 살펴보도록하겠다.<br />
GNN 을 MLP 로 knowledge distillation 하는 과정은 매우 간단하다. 우선적으로 GNN 을 pretrain 시킨다. 이 pretrain 된 GNN 을 teacher GNN 이라고 부른다.<br />
teacher GNN 으로부터 생성된 node 의 embedding vector 를 soft labels 이라고 부르며 $\boldsymbol{z} _{v}$ 로 표기한다.<br />
따라서, Knowledge distillation 은 다음과 같이 정의할 수 있다.<br />
$\mathcal{L} = \sum _{v \in \mathcal{V}^{L}} \mathcal{L} _{GT}(\hat{\boldsymbol{y}} _{v}, \boldsymbol{y} _{v}) + \lambda \sum _{v \in \mathcal{V}} \mathcal{L} _{SL}(\hat{\boldsymbol{y}} _{v}, \boldsymbol{z} _{v}) \left[Eq1\right]$<br />
$\boldsymbol{y} _{v}$ 는 node $v$ 의 ground truth label 이며, $\hat{\boldsymbol{y}} _{v}$ 는 student 인 MLP 의 prediction 이다 (즉 node $v$ 에 대한 MLP 의 output).<br />
$\mathcal{L} _{GT}$ 는 cross-entropy loss, $\mathcal{L} _{SL}$ 은 KL-divergence loss, $\lambda$ 는 두 loss term 의 균형을 맞추기 위한 coefficient (hyper-parameter) 이다.</p>

<h3 id="--incorporating-node-position-features-">- Incorporating Node Position Features <br /></h3>
<p>이 부분에서는 figure 의 $(b)$ 에 해당하는 부분에 관하여 설명한다.<br />
Eq 1. 만을 사용하여, MLP 가 GNN 을 따라할 수 있도록 유도할 수는 있다.<br />
하지만, message passing 기법을 사용하여, graph structure 정보를 사용할 수 있는 GNN 과는 달리, MLP 는 graph structure 를 다룰 수 없다.<br />
이는 node content feature 와 label space 가 다를 경우 (e.g., node label 이 graph structure 와 큰 연관성이 있는 경우) 학습 결과에 큰 영향을 미칠 수 있다.<br /><br />
이를 해결하기 위하여, MLP 가 node position 정보를 학습하게 만들어, graph structure 에서부터 나오는 information 을 다룰 수 있도록 만든다.<br />
간단하게, given graph $\mathcal{G}$ 에서 node $v \in \mathcal{V}$ 에 대하여 DeepWalk 를 진행하여, node $v$ 의 positional feature $\boldsymbol{P} _{v}$ 를 얻는다.<br />
이 positional feature 는 graph 의 structure 정보를 내포하고 있는 data 로써, node content feature 를 사용하지 않고 DeepWalk 를 진행하였기에, graph structure 정보만을 가지고있는 positional information 이라고 볼 수 있다.<br />
모든 node 에 관하여, positional feature 를 얻어주고, 이를 node 의 기존 content feature 에 concatnate 하여, MLP 의 input 으로 사용한다.<br />
즉, Eq 1. 에서 사용된 $\hat{\boldsymbol{y}} _{v}$ 는 다음과 같이 표기할 수 있다.<br />
$\boldsymbol{X} _{v} = CONCAT(\boldsymbol{\mathcal{C}} _{v}, \boldsymbol{P} _{v}), \hat{\boldsymbol{y}} _{v} = MLP(\boldsymbol{X} _{v}) \left[Eq2\right]$<br /></p>

<h4 id="--representational-similarity-distillation-">- Representational Similarity Distillation <br /></h4>
<p>이 부분은 figure 의 $(c)$ 에 해당되는 부분이다. <br />
Representational Similarity Distillation (denote RSD) 는 MLP 의 output 이 teacher GNN 의 output 에 strict 하게 matching 하는 것을 조금 완화시키고, MLP 가 soft structural node similarity 를 포착할 수 있도록 도와주는 loss 이다.<br />
RSD 는 node embedding 의 similarity 에 대한 정보를 담고 있기 때문에, MLP 가 GNN 의 representation space 를 학습할 수 있도록 도와주게 된다.<br />
Pretrain 되어있는 GNN (i.e., teacher GNN) 에서 생성한 모든 node 에 대한 representation 을 $\boldsymbol{H} _{G} \in \mathbb{R}^{N \times d _{G}}$ 라고 하고, MLP (i.e., student) 에서 생성한 모든 node 에 대한 representation 을 $\boldsymbol{H} _{M} \in \mathbb{R}^{N \times d _{M}}$ 이라고 표기하면, 다음 식을 통하여, RSD 를 계산하기 위한 GNN, MLP 각각의 node similarity matrix 를 구할 수 있다.<br />
$S _{GNN} = \boldsymbol{H} _{G} \cdot (\boldsymbol{H} _{G})^{T} \text{ and } S _{MLP} = \boldsymbol{H’} _{M} \cdot (\boldsymbol{H’} _{M})^{T} \text{ , } \boldsymbol{H’} _{M} = \sigma (W _{M}\cdot \boldsymbol{H} _{M}) \left[Eq3\right]$<br />
Eq 3. 에서, $W _{M} \in \mathbb{R}^{d _M \times d _M}$ 은 transformation matrix 이며, $\sigma$ 는 activation function (본 논문에서는 ReLu 를 사용하였다.), $\boldsymbol{H’} _{M}$ 은 MLP 의 representation 을 transformation 시킨 결과이다.<br />
Eq 3. 에서 얻은 $S _{GNN}, S _{MLP}$ 를 사용하여, RSD loss (denote $\mathcal{L} _{RSD}$) 를 다음 식과 같이 나타낼 수 있다. 본 논문에서는 RSD loss 에 Frobenius norm $\vert\vert\cdot\vert\vert _{F}$ 를 사용하였다.<br />
$\mathcal{L} _{RSD}(S _{GNN}, S _{MLP}) = \vert\vert S _{GNN} - S _{MLP} \vert\vert _{F}^2 \left[Eq4\right]$<br /></p>

<h4 id="--adversarial-feature-augmentation-">- Adversarial Feature Augmentation <br /></h4>
<p>MLP 은 feature noise 에 대하여 굉장히 민감하다는 문제점을 가지고 있다.<br />
따라서, noise 에 대한 MLP 의 robustness 를 증가시키기 위해서, 본 논문에서는 adversarial feature augmentation 방법을 도입하였다.<br />
Adversarial feature augmentation 은 MLP input 에 대한, 작은 fluctuations 에도 invariant 하고, 기타 다른 sample 들에 대하여 generalize 가 잘 될 수 있도록 한다.<br />
Node $v \in \mathcal{V}$ 에 대한 adversarial feature augmentation 과 해당 loss $\mathcal{L} _{ADV}$ 는 다음과 같이 정의한다.<br />
$\boldsymbol{X’} _{v} = \boldsymbol{X} _{v} + \delta, \hat{\boldsymbol{y’}} _{v} = MLP(\boldsymbol{X’} _{v})$<br />
$\mathcal{L} _{ADV} = \text{max} _{\delta \in \varepsilon} \left[- \sum _{v\in \mathcal{V}^{L}}\boldsymbol{y} _v \text{log}(\hat{\boldsymbol{y’}} _{v}) - \sum _{v\in \mathcal{V}}\boldsymbol{z} _{v} \text{log}(\hat{\boldsymbol{y’}} _{v})\right] \left[Eq5\right]$<br />
Eq 5. 에서 확인 할 수 있듯이, $\mathcal{L} _{ADV}$ 는, label 이 존재하는 node ($v \in \mathcal{V}^{L}$) 의 ground truth ($\boldsymbol{y} _v$) 와, graph 내 모든 node 들의 soft label ($\boldsymbol{z} _{v}$)를 사용하여, adversarial 를 학습하게 된다.<br />
또한 $\text{max} _{\delta \in \varepsilon}$ 에서 확인 할 수 있듯이, 가능한 noise set 에서 가장 worst-case noise 를 선정하여 학습을 진행하게 된다. 이는 MLP 가 noise 에 대하여 더욱 robust 할 수 있도록 도와주게 된다.<br />
또한, 학습 과정에 있어서, 각 time step (epoch) 마다 worst-case noise 를 제공하기 위하여, noise $\delta$ 를 아래 식과 같이 학습하게 된다.<br />
$\delta _{t+1} = \prod _{\vert\vert\delta\vert\vert _{\infty} \leq \varepsilon} \left[ \delta _{t} + \boldsymbol{s}\cdot\text{sign}(\nabla _{\delta}(-\boldsymbol{Y}\text{log}(MLP(\boldsymbol{X} + \delta _t))))\right] \left[Eq 6\right]$<br />
여기서 $\boldsymbol{s}$ 는 noise 의 step size 이며, $\nabla _{\delta}$ 는 $\delta$ 에 대하여 계산된 gradient 이다.</p>

<h4 id="--overall-loss-">- Overall Loss <br /></h4>
<p>Final objective function $\mathcal{L}$ 은 Knowledge distillation ($\mathcal{L} _{GT}, \mathcal{L} _{SL}$), representational similarity distillation ($\mathcal{L} _{RSD}$), adversarial feature augmentation ($\mathcal{L} _{ADV}$) 의 합으로 아래 식과 같이 표현할 수 있다.<br />
$\mathcal{L} = \mathcal{L} _{GT} + \lambda \mathcal{L} _{SL} + \mu \mathcal{L} _{RSD} + \eta \mathcal{L} _ {ADV}$<br />
여기서, $\lambda, \mu, \eta$ 는 hyper-parameter 이다.</p>

<h3 id="4-experiments">4. Experiments</h3>
<p>NOSMOG 에 대한 평가는 graph machine learning 에서 주로 사용하는 public benchmark dataset (Cora, Citeseer, Pubmed, A-computer, A-photo) 를 사용하였다.<br />
실험은 크게, <strong>NOSMOG 에 대한 성능 평가</strong>, <strong>Inductive/Transductive setting 에서의 성능평가</strong>, <strong>Inference 속도에 대한 평가</strong> 등으로 이루어져있다.<br /></p>

<h4 id="--baselines-">- Baselines <br /></h4>
<p>NOSMOG 를 비교하기 위한 baseline 으로는 SAGE (graph deep learning model), MLP, GLNN (graph-mlp) 이 사용되었다.<br />
<strong>SAGE</strong><br />
저자들은 범용적으로 사용되는 GraphSage 를 baseline 으로 설정하였다.<br />
GraphSage 는 새로운 node 들이 추가되는 (evolving or inductive) 한 환경을 잘 다룰 수 있는 framework 로써, 현재 많은 연구에서 backbone network or baseline 을 담당하고 있다.<br />
인접한 모든 node 들의 정보를 sum 으로 aggregate 하는 기타 graph model 과는 다르게, GraphSage 의 경우 neighbor embedding 과 현재 node embedding 을 concatenate 하는 방식으로 aggregation 을 진행한다.<br />
GraphSage 의 논문은 다음 <a href="https://arxiv.org/abs/1706.02216">링크</a> 에서 확인할 수 있다.</p>

<p><strong>MLP</strong><br />
Graph 를 MLP 에 distillation 한 것이, node feature 만을 사용하여 MLP 를 학습한 것보다 얼마나 성능을 향상 시켰는지 확인하기 위하여, MLP 와 비교를 진행하였다. <br />
본 논문 Experiments 에서 사용된 MLP 는, node feature 를 MLP 의 input 으로 사용하였다.<br />
따라서, Graph model 과는 달리, MLP 는 graph 의 structure 정보를 사용하지 않았다. <br />
<strong>GLNN</strong><br />
GLNN 은 graph teacher 를 사용하여, MLP 에 knowledge distillation 을 진행하는 논문으로, ICLR 2022 에 발표되었다.<br />
NOSMOG 에서 Eq1 만을 사용한 것이 GLNN 이다.<br />
또한, GLNN 은 NOSMOG 의 Incorporating Node Postiion Features 와 같은 부분이 없기에, MLP 의 input 으로 node feature (node content feature) 만이 사용된다.<br />
GLNN 의 논문은 다음 <a href="https://arxiv.org/abs/2110.08727">링크</a> 에서 확인할 수 있다.</p>

<p><img src="https://user-images.githubusercontent.com/76777494/232275417-98531f1c-abe0-4645-abb0-5ab9d6604ea2.png" alt="Figure2" />
<img src="https://user-images.githubusercontent.com/76777494/232275443-f7a11c5c-b275-45e6-92db-db04bf6d5981.png" alt="Figure3" />
Table 1, 2 에서 확인 할 수 있듯이, NOSMOG 는 GNN, MLP 와 비교하였을 때 전반적인 performance 뿐만 아니라, transductive, inductive setting 각각에서도 outperform 함을 확인할 수 있다.<br />
이는, graph 의 정보들을 적절한 방식으로 MLP 에 transfer 할 수 있다면, graph structure 정보를 explicit 하게 사용하는 graph based model 보다, graph structure 정보를 더 잘 포착할 수 있음을 보여준다. 또한, NOSMOG 와 같이 GNN-MLP 방식의 model 인 GLNN 은 large graph dataset 에서는 낮은 성능을 보이지만, NOSMOG 는 knowledge distillation 기반으로 GLNN 은 포착할 수 없는 추가적인 정보들을 사용하여, GLNN 보다 높은 성능을 보였다.</p>

<p><img src="https://user-images.githubusercontent.com/76777494/232276249-fb56129b-fda3-463a-a948-48a98368df7e.png" alt="Figure4" />
또한, Graph 의 가장 큰 단점인 inference 과정에서의 memory, time consuming issue 를 해결하였는지를 확인하기 위하여, 저자들은 accracy 와 inference time 에 관한 실험을 진행하였다. 위의 그림에서 확인 할 수 있듯이, NOSMOG 는 graph based model 보다 훨씬 빠른 inference time 을 보이면서도 높은 성능을 기록하는 모습을 보여주었다. 즉 NOSMOG 와 GLNN 에서 볼 수 있듯이, GNN-MLP model 은 graph based model 의 큰 한계점인 memory, time consuming issue 를 해결 할 수 있는 방법임을 증명하였다.</p>

<p><img src="https://user-images.githubusercontent.com/76777494/232276741-77925b73-f928-454e-b62b-af5d79985f91.png" alt="Figure5" />
마지막으로 실험으로, ablation study 에 대한 분석을 진행하겠다. Ablation study 에서 확인 할 수 있듯이 NOSMOG 의 많은 component 들이 model performance 에 큰 기여할 하고 있음을 확인할 수 있다. 특히, graph 의 positional 정보들을 처리하는 <strong>w/o POS</strong> (i.e., Incorporating Node Position Features) 가 NOSMOG 의 performance 에 가장 큰 영향을 미치는 것을 확인할 수 있었다. 이는 결국 structure 구조로 이루어진 graph data 를 학습할 때에는, graph structure 정보를 포착하는 것이 그 무엇보다 중요함을 시사하는 바이다.
<br />
<br /></p>

<p>저자는 논문의 마지막에, NOSMOG 가 어떻게 GLNN 을 능가하는 성능을 가지고, GNN 계열 모델과 비슷한 성능을 가질 수 있는지를 information theory 를 사용하여 해석한다.<br />
Graph 를 학습하는 것은, mutual information $I(\mathcal{G}^{v};\boldsymbol{y} _v)$ 를 최대화하는 것과 같다.<br />
Graph 는 node 정보와 edge 정보를 가지고 있기 때문에, 위의 mutual information 은 다음과 같이 표현할 수 있다.<br /></p>

<p>$I(\mathcal{G}^{v};\boldsymbol{y} _v) = I(\boldsymbol{X}^{v},\mathcal{E}^{v};\boldsymbol{y} _v) = I(\mathcal{E}^{v};\boldsymbol{y} _v) + I(\boldsymbol{X}^{v};\boldsymbol{y} _v \vert \mathcal{E}^{v})$.<br /></p>

<p><strong>Graph</strong> 계열 모델의 경우, node 의 neighbor 의 정보를 aggregate 하면서 학습을 진행한다.<br />
Aggregate 에서 사용되는 multihop neighbourhood 는 subgraph $S^{v}$ 로 표현할 수 있으며, embedding 과정을 $\boldsymbol{z}^{v} = f _{GNN}(\boldsymbol{X}^{v},S^{v})$ 로 나타낼 수 있다.<br />
Embedding 으로 graph 를 학습하는 과정은, $P(\boldsymbol{y} _v \vert \boldsymbol{z}^{v})$ 라는 likelihood 를 maximize 하는 것과 동일하며, 이는 $\mathcal{L} _{1}(f _{GNN}(\boldsymbol{X}^{v},S^{v}),\boldsymbol{y} _v)$ 를 minimize 하는 것과 동일하다.<br />
$\mathcal{L}$ loss 를 바탕으로 node representation 와 structure information 을 update 하기 때문에, 이는 $I(\mathcal{E}^{v};\boldsymbol{y} _v) + I(\boldsymbol{X}^{v}; \boldsymbol{y} _v \vert \mathcal{E}^{v})$ 라는 mutual information 을 maximize 하는 것과 동일하다.<br />
<br /></p>

<p><strong>GLNN</strong> 에서는 teacher GNN 을 바탕으로 implicit 하게 얻은 structure 정보를 사용한다. 따라서, GLNN 의 classifier model (i.e. MLP) 에서는 label 과 structure 간의 관계를 사용하지 못한다.<br />
이는, GLNN 이 $I(\mathcal{E}^{v};\boldsymbol{y} _v)$ 를 무시한 상태로, $I(\boldsymbol{X}^{v};\boldsymbol{y} _{v} \vert \mathcal{E}^{v})$ 의 mutual information 만을 maximize 하는 것을 의미한다.<br />
따라서, graph 의 온전한 information 을 update 하지 못하기 때문에, GLNN 은 GNN 이나 NOSMOG 에 비하여 expressive power 가 떨어지게 된다.<br />
<br /></p>

<p><strong>NOSMOG</strong> 에서는 node position feature 를 바탕으로, structure 정보와 label 간의 관계를 파악할 수 있게 된다. (즉 MLP 에서 structure 정보가 label 을 맞추는데 사용된다.)<br />
따라서, NOSMOG 는 teacher GNN 의 knowledge distillation 으로부터, $I(\boldsymbol{X}^{v};\boldsymbol{y} _{v} \vert \mathcal{E}^{v})$ 를 maximize 하게 되고, node feature 에 사용된 position feature 덕분에 $I(\mathcal{E}^{v};\boldsymbol{y} _v)$ 를 maximize 할 수 있다.<br />
따라서, NOSMOG 는 graph 의 온전한 information 을 학습할 수 있고, 그렇기 때문에 GNN 과 비슷한 expressive power 를 가질 수 있게 된다.<br /></p>

<h3 id="5-conclusion">5. Conclusion</h3>
<p>본 논문에서는 MLP 를 사용하여, Graph data 를 학습하는 GNN-MLP 관련 연구에서 현재까지 한계점이었던, effectiveness, robustness, efficiency 문제를 해결하였다.<br />
특히, node position features 를 결합하여 graph structure 정보를 MLP 로 전달하고, representation similarity 에 대한 knowledge 를 distillation 함으로 structure-aware 를 성공적으로 이루었다. 또한, noise 에 취약한 MLP 를 adversarial feature augmentation method 로 noise 에 robust 한 model 을 성공적으로 구현하였다.</p>

    </div>



</article>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>







<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy;2023 Copyright 2021 Google LLC. All rights reserved. <br />
 Site last generated: Oct 17, 2023 <br />
<p><img src="images/company_logo.png" alt="Company logo"/></p>
                </div>
            </div>
</footer>






        </div>
    <!-- /.row -->
</div>
<!-- /.container -->
</div>
<!-- /#main -->
    </div>

</body>

<!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-66296557-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>





</html>


