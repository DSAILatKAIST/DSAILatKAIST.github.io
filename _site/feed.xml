<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>DSAILatKAIST.github.io</title>
        <description>Intended as a documentation theme based on Jekyll for technical writers documenting software and other technical products, this theme has all the elements you would need to handle multiple products with both multi-level sidebar navigation, tags, and other documentation features.</description>
        <link>http://localhost:4000/</link>
        <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Wed, 17 Apr 2024 23:53:33 +0900</pubDate>
        <lastBuildDate>Wed, 17 Apr 2024 23:53:33 +0900</lastBuildDate>
        <generator>Jekyll v3.9.2</generator>
        
        <item>
            <title>[ICLR 2024] Training Diffusion Models With Reinforcement Learning</title>
            <description>&lt;h1 id=&quot;ddpotraining-diffusion-models-with-reinforcement-learning&quot;&gt;&lt;strong&gt;[DDPO]Training Diffusion Models with Reinforcement Learning&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;1-problem-definition--motivation&quot;&gt;&lt;strong&gt;1. Problem Definition &amp;amp; Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Diffusion probabilistic models, 일반적으로 Diffusion model라 칭하는 모델이 최근 Image, Video, Audio, Drug/Material Design, Continuous Control 등 다양한 분야에서 두각을 보이고 있다.&lt;/p&gt;

&lt;p&gt;Diffusion model은 노이즈를 점진적으로 추가하는 forward process 와 이를 역으로 되돌리는 reverse process, 즉 sequential denoising process를 적용함으로서, 간단한 prior distribution을 target distribution으로 변환시킨다.
이를 학습하는 데에는, Maximum likelihood estimation에 기반해 Evidence Lower Bound(ELBO*)등의 Trick을 이용해 Variational Lower Bound를 Maximize하는 방식을 사용한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ELBO*:&lt;br /&gt;
$\log p_ \theta(\mathbf{x}) \geq  \mathbb{E}_ {q_\phi}  \left[\frac{\log p_ \theta(\mathbf{z},\mathbf{x})}{\log q_ \phi(\mathbf{z}|\mathbf{x})}\right]$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Limitations:&lt;/strong&gt;
하지만 이러한 Likelihood 기반의 학습 방식이 가지고 있는 여러 한계가 존재했다. 
먼저, Likelihood를 직접 최적화 하는 것이 생성된 샘플의 품질 향상과는 직결되지 않는다는 단점이 존재했고(Nichol &amp;amp; Dhariwal, 2021; Kingma et al., 2021), 이를 계산하기 위해 많은 양의 sampling과 복잡한 계산이 필요했다. 이에, 하기 논문 (Ho et al., 2020; Denoising Diffusion Probabilistic Models[DDPM])의 등장으로 부터, 대부분의 Diffusion-based 모델들은 직접적으로 likelihood를 maximize하는 것이 아닌 아래와 같은 Approximation(Denoising Objective)을 minimize하는 방식으로 학습하였다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Modified Objective Function of Diffusion Models[DDPM]&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$L_ {\text {simple }}(\theta):=\mathbb{E}_ {t, \mathbf{x}_ 0, \boldsymbol{\epsilon}}\left[\left\vert\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_ \theta\left(\sqrt{\bar{\alpha}_ t} \mathbf{x}_ 0+\sqrt{1-\bar{\alpha}_ t} \boldsymbol{\epsilon}, t\right)\right\vert^2\right]$&lt;/p&gt;

&lt;p&gt;직접적으로 Diffusion model구조의 data distribution matching에서 Likelihood 연산을 진행하는 것은 계산량이 너무 크기 때문에 (Intractable), 이 논문에서는 denoising process를 &lt;strong&gt;multi-step decision-making task&lt;/strong&gt;로 바라보고, 강화학습의  &lt;strong&gt;Policy gradient&lt;/strong&gt; 방법을 적용하는 방식 DDPO(Denoising Diffusion Policy Optimization)을 제안한다. 이 모델은  &lt;strong&gt;black-box reward function&lt;/strong&gt;과 함께, &lt;strong&gt;Downstream task&lt;/strong&gt;에 대한 Likelihood 최적화가 가능함을 보였다.&lt;/p&gt;

&lt;p&gt;정리하자면, RL algorithm으로 Diffusion Network를 학습시키는 방식을 제안한 것이다.&lt;/p&gt;

&lt;h2 id=&quot;2-preliminaries&quot;&gt;&lt;strong&gt;2. Preliminaries&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;21-diffusion-models&quot;&gt;2.1 Diffusion Models&lt;/h3&gt;
&lt;p&gt;(Ho et al., 2020)등의 이전 논문에서, conditional diffusion probabilistic model 은 아래와 같이 정의되며,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$p(x_ {0}\vert c)$: sample $x_ 0$의 분포, corresponding context $c$&lt;/li&gt;
  &lt;li&gt;$q(x_ t\vert x_ {t-1})$: Markovian forward process (점진적 노이즈 추가)&lt;/li&gt;
  &lt;li&gt;$\mu_ \theta(x_ t, c, t)$: Reversing forward process (노이즈 제거)에 사용되는 neural net&lt;/li&gt;
  &lt;li&gt;$\tilde {\mu}$: Posterial mean of forward process. $x_ 0, x_ t$의 가중평균.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Training은 Log-likelihood 의 Variational lower bound를 maximize함으로서 유도된, 아래 목적식을 최적화 함으로써 진행된다.&lt;/p&gt;

&lt;p&gt;$\mathcal{L}_ {\mathrm{DDPM}}(\theta)=\mathbb{E}_ {\left(\mathbf{x}_ 0, \mathbf{c}\right) \sim p\left(\mathbf{x}_ 0, \mathbf{c}\right), t \sim  \mathcal{U}{0, T}, \mathbf{x}_ t \sim q\left(\mathbf{x}_ t \mid  \mathbf{x}_ 0\right)}\left[\left\vert\tilde{\boldsymbol{\mu}}\left(\mathbf{x}_ 0, t\right)-\boldsymbol{\mu}_ \theta\left(\mathbf{x}_ t, \mathbf{c}, t\right)\right\vert^2\right]$&lt;/p&gt;

&lt;p&gt;Sampling은 random $x_ T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ 로 부터, Reverse process $p_ \theta(x_ {t-1} \vert x_ t, c)$를 거쳐 sample $x_ 0$를 얻어내는 방식으로 진행된다.&lt;/p&gt;

&lt;h3 id=&quot;22-markov-decision-process-and-reinforcement-learning&quot;&gt;2.2 Markov Decision Process and Reinforcement Learning&lt;/h3&gt;

&lt;p&gt;마르코프 결정 과정(Markov Decision Process, MDP)은 순차적 의사 결정 문제(sequential decision-making problem)를 수학적으로 정형화한 모델로,  다음과 같은 요소들로 정의된다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\mathcal{S}:$ 상태 공간(state space)&lt;/li&gt;
  &lt;li&gt;$\mathcal{A}:$ 행동 공간(action space)&lt;/li&gt;
  &lt;li&gt;$\mathcal{\rho_ 0}:$ 초기 상태 분포(initial state distribution)&lt;/li&gt;
  &lt;li&gt;$\mathcal{P}:$ 전이 커널(transition kernel)&lt;/li&gt;
  &lt;li&gt;$\mathcal{R}:$ 보상 함수(reward function)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;MDP에서 에이전트(agent)는 각 타임스텝(timestep) $t$ 마다 현재 상태(state) $s_ t \in \mathcal{S}$를 관측하고, 정책(policy) $\pi(a\vert s)$에 따라 행동(action) $a_ t \in \mathcal{A}$를 선택한다.&lt;/p&gt;

&lt;p&gt;그 후 환경으로부터 보상(reward) $R(s_ t, a_ t)$을 받고, 전이 커널 $P(s_ {t+1}\vert s_ t, a_ t)$에 따라 다음 상태 $s_{t+1}$로 전이한다. 이런 식으로 에이전트가 환경과 상호작용하며 생성되는 상태-행동의 시퀀스 $\tau = (s_ 0, a_ 0, s_ 1, a_ 1, …, s_ T, a_ T)$를 트래젝토리(trajectory)라고 한다.&lt;/p&gt;

&lt;p&gt;강화학습(Reinforcement Learning, RL)의 목표는 에이전트가 정책 $\pi$를 따라 행동할 때 얻게 되는 기대 누적 보상(expected cumulative reward)을 최대화 하는 것이다. 이는 아래와 같은 수식을 Maximize 함으로서 이루어진다.&lt;/p&gt;

\[J_ {RL}(\pi) = \mathbb{E}_ {\tau \sim p(\tau\vert\pi)}\left[\sum_ {t=0}^T R(s_ t, a_ t)\right]\]

&lt;h2 id=&quot;3-methods&quot;&gt;&lt;strong&gt;3. Methods&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;denoising-diffusion-policy-optimization&quot;&gt;Denoising Diffusion Policy Optimization&lt;/h3&gt;

&lt;p&gt;먼저, pre-trained or random initialize된 Diffusion model이 존재한다고 가정하자. Diffusion model은 sample distribution $p_ \theta (x_ 0 \vert c)$ (context-conditional distribution)을 유도하며, Denoising diffusion RL의 목적식은 아래와 같은 reward signal $r$을 정의된 sample과 context 하에서 maximize하는 것이다.&lt;/p&gt;

&lt;p&gt;$\mathcal{J}_ {\text  {DDRL }}(\theta)=\mathbb{E}_ {\mathbf{c}  \sim p(\mathbf{c}), \mathbf{x}_ 0 \sim p_ \theta\left(\mathbf{x}_ 0 \mid  \mathbf{c}\right)}\left[r\left(\mathbf{x}_ 0, \mathbf{c}\right)\right]$&lt;/p&gt;

&lt;p&gt;기본적인 diffusion training에서 크게 벗어나지 않으면서, $\mathcal{J}_ {\text {DDRL}}$을 maximize 하는 방법론으로는 online RL 방식에서 sampling과 training을 반복하는 One-step MDP인 reward-weighted regression (Peters &amp;amp; Schaal, 2007)이라는 방법론이 존재하나, $\pi$에 대한 KL Divergence term이 존재해서, 명확히 말하자면 이는 Optimality에 도달하지 못한다.&lt;/p&gt;

&lt;p&gt;DDPO에서는 DPOK(Diffusion policy optimiation with KL regularization, 유사한 다른 논문)와 같은 Multi-step MDP formulation을 적용한다.&lt;/p&gt;

&lt;p&gt;$\begin{array}{lrr}\mathbf{s}_ t \triangleq\left(\mathbf{c}, t, \mathbf{x}_ t\right) &amp;amp;  \pi\left(\mathbf{a}_ t \mid  \mathbf{s}_ t\right) \triangleq p_ \theta\left(\mathbf{x}_ {t-1}  \mid  \mathbf{x}_ t, \mathbf{c}\right) &amp;amp; P\left(\mathbf{s}_ {t+1}  \mid  \mathbf{s}_ t, \mathbf{a}_ t\right) \triangleq\left(\delta_ {\mathbf{c}}, \delta_ {t-1}, \delta_ {\mathbf{x}_ {t-1}}\right) \\mathbf{a}_ t \triangleq  \mathbf{x}_ {t-1}  &amp;amp;  \rho_ 0\left(\mathbf{s}_ 0\right) \triangleq\left(p(\mathbf{c}), \delta_ T, \mathcal{N}(\mathbf{0}, \mathbf{I})\right) &amp;amp; R\left(\mathbf{s}_ t, \mathbf{a}_ t\right) \triangleq  \begin{cases}r\left(\mathbf{x}_ 0, \mathbf{c}\right) &amp;amp;  \text  { if } t=0 \0 &amp;amp;  \text  { otherwise }\end{cases}\end{array}$&lt;/p&gt;

&lt;p&gt;식에 대해 차례로 설명하자면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;context $c$, diffusion index $t$, $t$ 번째 step의 noised sample $x_ t$의 tuple -&amp;gt; state $s_ t$ ; Denoising Network가 받게되는 현재 상태.&lt;/li&gt;
  &lt;li&gt;denoising 을 진행하는 context conditioned reverse process를 -&amp;gt; policy $\pi(a_ t \vert s_ t)$ ; Denoising을 하는 주체(reverse process)이자, 학습 대상이므로 이를 Policy로 설정한다.&lt;/li&gt;
  &lt;li&gt;Dirac Delta distribution $\delta_ c, \delta_ {t-1}, \delta_ {x_ {t-1}}$의 튜플 -&amp;gt; Transition probability ; 여기서 Dirac Delta는 MDP transition을 Deterministic 하게 (동일한 state, action이 주어질 시 다음 state가 동일하게 정해지게) 유도하기 위한 트릭이라고 이해하면 된다. (이를 통해 최종 state에서 termination 되게 된다.)&lt;/li&gt;
  &lt;li&gt;$x_ {t-1}$ -&amp;gt; action $a_ t$ ; Policy인 reverse process에서 뽑아내는 $x_ {t-1}$이 action과 같은 역할이 된다.&lt;/li&gt;
  &lt;li&gt;context probability $p(c)$, $\delta_T$, Multivariate standard normal distribution 의 tuple -&amp;gt; initial state distribution; 이는 시작지점에 대한 확률분포로 Diffusion Process 시작지점으로서 생각할 수 있다.&lt;/li&gt;
  &lt;li&gt;보상함수 $R(s_ t, a_ t)$는 denoised 된 step $t$에 도달하는 경우에만 주는 것으로 정의한다. 원본 데이터에 얼마나 가까운지로 보상을 준다고 생각하면 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;복잡해 보이나, 핵심은 Diffusion model에서 사용되는 component들을 Multi-step MDP의 형태로 formulate 했다는 점이다. 즉 Diffusion Model 의 큰 틀은 변하지 않지만 보는 방식을 다르게 했다는 것이다.&lt;/p&gt;

&lt;p&gt;이런 방식으로 Diffusion component들을 MDP로 변환하면, log-likelihood (여기서는 Policy)를 구할 수 있음과 더불어, diffusion model 파라미터에 대한 gradient(여기서는 Policy Gradient)도 구할 수 있게 된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Policy gradient estimation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Likelihood, 그리고 likelihood의 gradient에 대해 직접적으로 access가 가능하게 되면서, $\nabla_ \theta \mathcal{J}_ {\text{DDRL}}$에 대한 Monte Carlo estimation을 진행할 수 있다.&lt;/p&gt;

&lt;p&gt;Sampling과 parameter update를 통해 trajectories ${x_ T, x_ {T-1}, … , x_ 0}$ 를 수집하고 Policy gradient 의 대표적인 알고리즘 REINFORCE(Williams, 1992; Mohamed et al., 2020)을 사용함으로서 아래와 같은 estimation을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;$\nabla_ \theta  \mathcal{J}_ {\mathrm{DDRL}}=\mathbb{E}\left[\sum_ {t=0}^T \nabla_ \theta  \log p_ \theta\left(\mathbf{x}_ {t-1}  \mid  \mathbf{x}_ t, \mathbf{c}\right) r\left(\mathbf{x}_ 0, \mathbf{c}\right)\right]$&lt;/p&gt;

&lt;p&gt;위 식은 REINFORCE algorithm에서 context condition이 추가된 형태다. 논문에서는 이를 DDPO-SF로 명시한다. (Score function Policy gradient estimator)&lt;/p&gt;

&lt;p&gt;하지만 MC approach의 특성상 data collection마다 한 step의 optimization만 가능하기 때문에, 여러번의 optimization을 사용하기 위해서는 importance sampling estimator를 적용할 수 있다.&lt;/p&gt;

&lt;p&gt;$\nabla_ \theta  \mathcal{J}_ {\mathrm{DDRL}}=\mathbb{E}\left[\sum_ {t=0}^T \frac{p_ \theta\left(\mathbf{x}_ {t-1}  \mid  \mathbf{x}_ t, \mathbf{c}\right)}{p_ {\theta_ {\text  {old }}}\left(\mathbf{x}_ {t-1}  \mid  \mathbf{x}_ t, \mathbf{c}\right)}  \nabla_ \theta  \log p_ \theta\left(\mathbf{x}_ {t-1}  \mid  \mathbf{x}_ t, \mathbf{c}\right) r\left(\mathbf{x}_ 0, \mathbf{c}\right)\right]$&lt;/p&gt;

&lt;p&gt;이를 논문에서는 DDPO-IS (Importance sampling Policy gradient estimator) 라고 명시한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Importance sampling 방식은, offline policy  혹은 offline-RL등에서 주로 사용하는 방법으로, update시에 변화하는 policy에 대해, 다른 policy에서 얻은 정보를 사용하면서도 optimality를 유지하기 위한 방법이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다만 이 방법을 사용했을 때, policy 가 너무 많이 Update 되어 버리면(old policy와 current policy의 차이가 많이 나면) estimation에 문제가 생길 수 있기 때문에 (Importance sampling weight가 explode 혹은 vanish), Implementation에서는 TRPO에서의 Trust region이나 PPO의 clipping등의 방식을 적용해야 한다. 논문에서는 clipping method를 사용하였다.&lt;/p&gt;

&lt;h3 id=&quot;reward-functions-for-text-to-image-diffusion&quot;&gt;Reward functions for text-to-image diffusion&lt;/h3&gt;
&lt;p&gt;DDPO Equation을 살펴보면, 대부분의 component들은 Diffusion component들에서 명시되어 있으나, 구체적으로 어떤 방식으로 Reward를 줄 지에 대해서는 결정이 필요하다. 논문에서는 세 가지 방식의 reward를 사용했다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Compressibility and Incompressibility&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Text-to-image diffusion model은 학습시, text-image의 co-occurence로 학습을 진행하기 때문에, prompt를 이용해 file size를 명시하는 것이 어렵다. 주로 image에 대한 caption에 file size(kb, mb, gb)를 명시하지 않으므로 (EX: “고양이가 생선을 먹고있는 사진” 으로 파일 사이즈 없이 captioning이 달리므로)모델이 파일크기에 대한 정보를 수급하지 못한다. 이에 논문에서는 diffusion model의 sample들을 512x512로 고정하고, Reward로 file-size를 조정함으로서 얼마나 원본이미지의 중요한 성질을 유지하며 잘 압축시켰는지(compressibility)혹은 그 반대로 얼마나 원본 이미지 보다 더 세밀하게 구현했는지(Incompressibility)등을 하나의 지표로 사용하였다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Aesthetic Quality&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;두 번째로 사용한 방식은, LAION aesthetics predictor를 reward function으로 사용해, 모델에서 생성해낸 이미지의 예술성 척도를 Reward로 사용해, 더 aesthetic 한 이미지를 생성하는 objective로 적용하였다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Automated Prompt Alignment with Vision-Language Models&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;마지막으로, 인간이 직접 reward를 labeling하는 방식을 적용하면 RLHF(Reinforcement Learning with human feedback)방식이 되나, 논문에서는 이러한 Labeling 과정을 vision-language model(VLM)에서의 feedback으로 대체하였다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/DS501_24S/Training_Diffusion_Models_With_Reinforcement_Learning/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 figure가 논문에서 사용한 VLM의 예시인데, 먼저 prompt(“a monkey washing dishes”)를 Diffusion model에 입력해 이미지를 생성한다. 그 다음 LLaVA(Liu et al., 2023)모델에 이미지와  이미지에 대한 짧은 설명을 달라는 prompt를 함께 제공함으로서, short description을 얻는다. 처음에 입력했던 prompt와 요약된 설명의 bert similarity를 계산해 이를 reward로 사용한다.&lt;/p&gt;

&lt;p&gt;직관적으로 생각해 보면, prompt를 통해 생성한 이미지가 과연 그 prompt 에 맞춰 제대로 이미지를 생성해 냈는지를 확인할 수 있는 지표가 된다.&lt;/p&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;논문에서 Experiment 의 목적은, User-specified objective들 (reward 세팅으로 정해짐) 에 대해서 RL algorithm으로 Diffusion model을 fine-tuning 하는 방식이 과연 효과적인가를 판단함에 있다. 특히 아래 세 가지 질문들에 답할 수 있는가에 집중하였다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;DDPO와, 기존 방식 RWR(Reward-weighted Regression) 간의 비교&lt;/li&gt;
  &lt;li&gt;VLM 방식이 인간이 수동으로 Labeling하기 힘든 부분들에 대한 대안책이 될 수 있는가?&lt;/li&gt;
  &lt;li&gt;RL fine-tuning이 fine-tuning 과정에서 보지 못했던 prompt 들에 대해서도 generalization이 가능한가? (overfit이 일어나지 않는가?)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Experiment Settings&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;모든 Experiments들에 대한 Base model로는 Stable Diffusion v1.4(Rombach et al., 2022)를 사용하였다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;학습에 사용된 이미지들은 ImageNet-1000 category의 398개의 동물이미지를 Uniform하게 sampling한 이미지로, Compressibility, Incompressibility에서는 이를 모두 이용해 Fine-tuning을 진행했다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Aesthetic quality prompt의 경우에만 조금 더 작은 45 categories의 동물이미지를 사용하였다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;각 실험별 상세한 Setting들은 내용 설명과 함께 진행하겠다.&lt;/p&gt;

&lt;h3 id=&quot;algorithm-comparisons&quot;&gt;Algorithm Comparisons&lt;/h3&gt;
&lt;p&gt;논문에서는 먼저 전반적 성능 확인을 위해 Reward Setting 1, 2번에 대한 결과를 이전 알고리즘(RWR)과 대비해 분석한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/DS501_24S/Training_Diffusion_Models_With_Reinforcement_Learning/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 서로 다른 reward function에 대한 RL Fine-tuned Result이다. 정성적 관점에서, Aesthetic Quality에서는 기본 pre-trained 이미지에 비해 훨씬 예술적인(빛의 구도 등) 이미지를 연출하며, compressibility에서는 이미지 내에서 가장 중요한 부분들을 살리고 나머지는 간소화 한 것을 확인 할 수 있다. 반대로 Incompressibility에서는 file 크기를 늘리기 위해 이미지 내의 세세한 부분들을 선명하게 구현하였음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/DS501_24S/Training_Diffusion_Models_With_Reinforcement_Learning/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reward 지표를 바탕으로한 정량적 분석에서는 DDPO 방식이 기존의 방법론 RWR에 비해 훨씬 지표상으로 많은 Reward를 얻었음을 확인할 수 있다. 또한 Importance sampling 기법을 사용한 것이 Monte Carlo based approach(REINFORCE)에 비해 약간 더 나은 성능을 보였다.&lt;/p&gt;

&lt;h3 id=&quot;automated-prompt-alignment&quot;&gt;Automated Prompt Alignment&lt;/h3&gt;
&lt;p&gt;다음으로, VLM 방식의 효과성을 확인하기 위해, 이전 task들에서 가장 성능이 좋았던 DDPO-IS를 바탕으로, 실험을 진행했다.&lt;/p&gt;

&lt;p&gt;Prompt Setting은 “a(n) [animal] [activity]”를 베이스로, animal의 경우 Aesthetic에서 사용된 45개의 동물 카테고리를 사용였고, activity의 경우 “riding a bike”, “playing chess”, 그리고 “washing dishes” 세 가지만 사용하였다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/DS501_24S/Training_Diffusion_Models_With_Reinforcement_Learning/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 pretrained 된 stable diffusion으로부터, fine-tuning이 진행될수록 변하는 이미지를 나타내고 있다. 가장 위 “a dolphin riding a bike”를 먼저 살펴보면, pretrained된 상태에서는 이와 유사한 이미지를 생성하지도 못하지만, fine-tuning을 진행하면서 점점 faithful한 이미지를 생성해 냄을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;그림 우측의 Prompt Alignment Score 에서도 역시 Training Sequence들이 진행되면서 Bert Score 향상의 유의미한 지표를 보여주고 있다.&lt;/p&gt;

&lt;p&gt;논문에서 Fine-tuning이 이루어지며 점점 Cartoon 풍의 이미지로 변한다는 사실을 짚었는데, 이에 대한 해석으로 저자들은 “동물이 사람이 하는 행동을 하는 Image들 자체가 주로 만화에서 등장해서” 라고 이를 분석하였다.&lt;/p&gt;

&lt;h3 id=&quot;generalization&quot;&gt;Generalization&lt;/h3&gt;
&lt;p&gt;RL Finetuning이 Generalization Property를 띈다는 다른 논문 (English instruction이 다른 언어에 대한 capability  역시 상승시켰다는 내용; Ouyang et al., 2022) 의 결과와 마찬가지로, 동물 이미지로 학습한 DDPO에 대해 보지 못했던 새로운 동물, 동물이 아닌 사물, 그리고 새로운 시나리오(앞서 언급한 3가지 행동 prompt가 아닌)에 대해서도 일반적으로 좋은 성능을 냄을 확인할 수 있었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/DS501_24S/Training_Diffusion_Models_With_Reinforcement_Learning/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서는 학습 때 사용하지 않았던 홍학, 불가사리, 그리고 사물인 자전거와 냉장고 이미지에서도 Aesthetic fine-tuned 상황에서 이러한 특징을 잘 살리고 있음을 확인할 수 있다. 또한, “a capybara washing dishes” 나 “a duck taking an exam”과 같은 새로운 동물 + 시나리오에 대해서도 그럴듯한 이미지를 생성해 냄을 확인할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이 논문에서는 DDPO(Denoising Diffusion Policy Optimization)를 제시해, 기존의 Diffusion model components들을 Multi-step MDP로 재정의하고, 이전 방법론(RWR)의 Suboptimality 한계를 강화학습의 Policy gradient update를 적용함으로서 극복해 Downstream task fine-tuning 성능을 향상시켰다.&lt;/p&gt;

&lt;p&gt;더 나아가 논문은 Stable Diffusion과 같은 text-to-image 모델에 대해, Policy gradient 에 필요한 Reward function을 다양하게 설정하는 방식으로 User-specific objective를 정의하는 방법을 제시하였다. 실제 실험 결과를 통해 이러한 RL-based fine-tuning이 미리 설정된 Reward function 에 따라 효과적으로 목적을 달성함을 확인하였으며, Data-specific 하지 않고 generalization이 가능함을 증명해 보였다. 특히 LLM등에서 사용되어 파장을 일으켰던 RLHF 방법론을  VLM(Vision Language Model)등을 이용해 유저 라벨링 없이도 이용이 가능하게 설계했다는 점에서 상당한 의의가 있다.&lt;/p&gt;

&lt;p&gt;논문에서는 Text-to-image에 한정하여 실험을 진행하였으나, Diffusion 기반 모델들의 Fine-tuning에 RL방법론을 사용할 수 있다는 점은 이 논문이 훨씬 다양한 분야로 확장이 가능함을 의미한다.&lt;/p&gt;

&lt;p&gt;또한, Likelihood Maximization 에 대해, Policy gradient 방법론을 적용함으로서, 조금 더 Optimality에 다다르게 밀어넣을 수 있다는 점은, MDP formulation이 가능한 MLE base의 다양한 모델에 적용해 볼 만하다는 점에서 여러 색다른 접근이 가능하다고 해석할 수 있겠다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Kiyoung Om
    &lt;ul&gt;
      &lt;li&gt;Affiliation: &lt;a href=&quot;http://silab.kaist.ac.kr/&quot;&gt;SILAB@Kaist&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Research Topic: Offline-RL, Reinforcement Learning&lt;/li&gt;
      &lt;li&gt;Contact: se99an@kaist.ac.kr&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Github Implementation
    &lt;ul&gt;
      &lt;li&gt;Official codes : &lt;a href=&quot;https://github.com/jannerm/ddpo&quot;&gt;DDPO&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Website: &lt;a href=&quot;https://rl-diffusion.github.io/&quot;&gt;DDPO official explanation&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reference
    &lt;ul&gt;
      &lt;li&gt;Paper: &lt;a href=&quot;https://arxiv.org/abs/2305.13301&quot;&gt;Training Diffusion Models with Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Other References
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.11239&quot;&gt;Denoising Diffusion Probabilistic Models&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2305.16381&quot;&gt;DPOK: Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf&quot;&gt;Policy Gradient Methods for Reinforcement Learning with Function Approximation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://is.mpg.de/fileadmin/user_upload/files/publications/ICML2007-Peters_4493%5B0%5D.pdf&quot;&gt;Reinforcement Learning by Reward-weighted Regression for Operational Space Control&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Wed, 17 Apr 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Training_Diffusion_Models_With_Reinforcement_Learning.html</link>
            <guid isPermaLink="true">http://localhost:4000/Training_Diffusion_Models_With_Reinforcement_Learning.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICLR 2024] Time-LLM: Time Series Forecasting by Reprogramming Large Language Models</title>
            <description>&lt;p&gt;Hello Worlds&lt;/p&gt;
</description>
            <pubDate>Wed, 17 Apr 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Time-LLM_Time_Series_Forecasting_by_Reprogramming_Large_Language_Models.html</link>
            <guid isPermaLink="true">http://localhost:4000/Time-LLM_Time_Series_Forecasting_by_Reprogramming_Large_Language_Models.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICLR 2024] Large Language Models Are Not Robust Multiple Choice Selectors</title>
            <description>&lt;!-- &lt;div markdown=&quot;span&quot; class=&quot;alert alert-info&quot; role=&quot;alert&quot;&gt;&lt;i class=&quot;fa fa-info-circle&quot;&gt;&lt;/i&gt; &lt;b&gt;Note:&lt;/b&gt; This template is an example, so you don&apos;t have to follow this templates!&lt;/div&gt;


 --&gt;

&lt;h1 id=&quot;large-language-models-are-not-robust-multiple-choice-selectors&quot;&gt;&lt;strong&gt;Large Language Models Are Not Robust Multiple Choice Selectors&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;1-preliminary&quot;&gt;&lt;strong&gt;1. Preliminary&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;The paper investigates a performance issue in large language models (LLMs) when answering multiple-choice questions (MCQs). While MCQs are a common way to test LLMs, the models are susceptible to the order of the answer choices. The authors call this bias towards specific answer positions “&lt;strong&gt;selection bias&lt;/strong&gt;”.&lt;/p&gt;

&lt;h3 id=&quot;11-measurement-of-selection-bias&quot;&gt;1.1 Measurement of Selection Bias&lt;/h3&gt;

&lt;p&gt;To measure selection bias in LLMs answering multiple-choice questions, a simple way is to count how often the model picks each answer choice. However, this can be misleading if some answer choices are much more common than others, i.e., label imbalance.&lt;/p&gt;

&lt;p&gt;Alternatively, the proposed way is to&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;first, calculate &lt;strong&gt;the balance of recalls&lt;/strong&gt; for each answer choice. This measures how often the model picks each choice when it is the correct answer, and&lt;/li&gt;
  &lt;li&gt;next, compute &lt;strong&gt;the standard deviation of those recalls (RStd)&lt;/strong&gt; as a quantitative metric. A higher standard deviation of recalls, implying more variation, indicates a stronger bias towards certain answer IDs. Formally, the mathematical expression of this metric is $\textrm{RStd} = \textrm{Std} { \textrm{Recall}(d_i)_ {i=1}^ {n} } = \sqrt{\frac{\sum_ {i=1}^ {n} (\textrm{Recall}(d_ i) - \mu)^ 2}{n}}$, where $\mu = \frac{1}{n} \sum_ {i=1}^ {n} \textrm{Recall}(d_ i)$&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- and the recall of an option ID $d_ i$ is defined as $\textrm{Recall}(d_i) = \frac{\(d_i)}{1}$ --&gt;

&lt;p&gt;and the recall of an option ID $d_ i$ is defined as $\textrm{Recall}(d_ i) = \frac{\textrm{#}(\textrm{correct answer is }d_ i \, \&amp;amp; \, \textrm{prediction is }d_ i)}{\textrm{#}(\textrm{correct answer is }d_ i)} \times 100\%$&lt;/p&gt;

&lt;!-- and the recall of an option ID $d_ i$ is defined as $\textrm{Recall}(d_ i) = \frac{\#(\textrm{correct answer is }d_ i \, \&amp; \, \textrm{prediction is }d_ i)}{\#(\textrm{correct answer is }d_ i)} \times 100\%$ --&gt;

&lt;p&gt;This method is more reliable because it is not affected by how common each answer choice is overall. Also, this method reflects how well the model will perform when the order of the answer choice is changed, because it focuses on how likely the model is to pick each option regardless of its position.&lt;/p&gt;

&lt;h3 id=&quot;12-observations&quot;&gt;1.2 Observations&lt;/h3&gt;

&lt;p&gt;The paper studied how selection bias affects different LLM models. The major insights are as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Selection bias is common but inconsistent&lt;/strong&gt;: While most models show bias, it varies between models and sizes. Interestingly, even models trained on the same data (e.g., llama family) can exhibit different biases. This suggests a complex interrelation between training data, model capacity, and other factors.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Selection bias shows some consistency within a model&lt;/strong&gt;: While not perfect, a model might favor certain answer choices (like A or B) across different MCQ tests. This suggests bias leans more towards inherent model behavior than the specific task or domain.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;In-context examples can be a double-edged sword&lt;/strong&gt;: Providing additional context (like a few examples) can reduce the original bias, but it might also introduce new ones. These new biases seem unpredictable even within the same model family, making selection bias even more intricate.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are two main hypotheses of selection bias in LLMs when dealing with MCQs:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Token Bias&lt;/strong&gt;: This hypothesis suggests that in the standard MCQ prompt, LLMs might inherently favor certain option IDs (e.g., A or C) when selecting answers, assigning them higher probabilities.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Position Bias&lt;/strong&gt;: Alternatively, models may exhibit a bias towards options presented at specific ordering positions, such as favoring options presented first or last.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To differentiate between two potential causes, two ablation experiments are conducted:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Shuffling option IDs: This experiment involves randomly shuffling the default ID ordering, effectively eliminating the impact of position bias and focusing solely on token bias. However, this approach may affect the naturalness and quality of the MCQ prompt, potentially leading to degraded model performance.&lt;/li&gt;
  &lt;li&gt;Removing option IDs: The option IDs are removed, and the model is asked to directly select option contents. This experiment helps gauge the impact of token bias, as any change in selection bias indicates the influence of token bias, while the remaining bias corresponds to position bias.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The results indicate that the removal of option IDs notably reduces selection bias, &lt;strong&gt;primarily indicating the influence of token bias&lt;/strong&gt;. However, the remaining selection bias, corresponding to position bias, varies across models and tasks, suggesting its presence but irregularity. Some models exhibit marginal remaining bias, while others still demonstrate pronounced bias even after reducing it significantly. This variability suggests that &lt;strong&gt;position bias exists but is highly model- and task-dependent&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Further, removing option IDs is evidently not a promising solution to selection bias in LLMs for MCQs. The first reason is regarding performance drop. While removing IDs reduces bias, it generally hurts how well the model answers the questions. This is because we have to estimate the answer by comparing the likelihood of each option, which is less effective than using the original option IDs. The second reason is due to implementation difficulty. Using likelihood is cumbersome compared to the simpler method of having the model predict the answer ID directly. In conclusion, removing option IDs is not a practical solution for mitigating selection bias.&lt;/p&gt;

&lt;p&gt;Besides, the paper explores two ways to potentially reduce selection bias in LLMs with MCQs. One attempt is to involve explicit debiasing instruction. Adding a message telling the model to consider all options fairly shows no improvement. Another trial is to apply chain-of-thought (CoT) prompting. This technique involves prompting the LLM to explain its though process before giving the answer. Even with this prompt, the bias remains, thus the CoT prompting is inefficient. The two results suggest that selection bias is a deep-rooted issue within the LLM itself and cannot be easily fixed with basic changes to how the question is presented.&lt;/p&gt;

&lt;h2 id=&quot;2-method&quot;&gt;&lt;strong&gt;2. Method&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;To address the problem of selection bias, a new method called &lt;strong&gt;PriDe&lt;/strong&gt; is proposed. It can remove this bias without needing any additional training data by estimating the bias based on a small number of samples and then corrects for it during the normal operation of the LLM.&lt;/p&gt;

&lt;h3 id=&quot;21-permutation-based-debiasing-baseline-and-formulation&quot;&gt;2.1 Permutation-based Debiasing Baseline and Formulation&lt;/h3&gt;

&lt;p&gt;First, we need to define a baseline to compared with the newly proposed debiasing method. Here, the baseline averages the model’s prediction distribution across various permutations of options, countervailing both the model’s token bias and position bias.&lt;/p&gt;

&lt;p&gt;Formally, let $q$ denote the MCQ question. Suppose the $n$ default-ordered option IDs (e.g., A/B/C/D) are $d_ i$ and the default-ordered option contents are $o_ i$, $i\in {1,2,…,n}$. Denote $I$ a permutation of ${1,2,…,n}$, $\mathcal{I}$ a set of possible permutations, $g_ I (i)$ the index of $i$ in $I$, and $x^ I$ the concatenation of the default-ordered option IDs and the $I$-permuted option contents, so that $o_ i$ is tied with $d_ {g_ I (i)}$ in $x^ I$. The permutation-based debiasing baseline can be formulated as&lt;/p&gt;

&lt;p&gt;$\begin{equation} 
    \tilde{P}_ {\textrm{debiased}} (o_ i \vert q, x) = \frac{1}{\vert \mathcal{I} \vert} \sum_ {I \in \mathcal{I}} P_ {\textrm{observed}} (d_ {g_ I (i)} \vert q, x^ I), \quad i \in {1,2,…,n},
\end{equation}$&lt;/p&gt;

&lt;p&gt;where $x$ is the default input of option IDs and option contents, $P_ {\textrm{observed}} (d_ {g_ I (i)} \vert q, x^ I)$ is the observed prediction probability for the option ID $d_ {g_ I (i)}$ (meaning $o_ i$ being correct) under the option permutation $I$, and $\tilde{P}_ {\textrm{debiased}} (o_ i \vert q, x)$ denotes the debiased prediction probability for the option content $o_ i$. However, due to expensive computation, &lt;em&gt;cyclic permutation&lt;/em&gt;, where $\mathcal{I} = { (i, i+1, …, n, 1, …, i-1) }_ {i=1}^ n$, is alternatively considered to reduce the computational cost. In the case of the baseline, the overhead of Cyclic Permutation is still somewhat high, hence required more efficient debiasing methods.&lt;/p&gt;

&lt;h3 id=&quot;22-prediction-probability-decomposition&quot;&gt;2.2 Prediction Probability Decomposition&lt;/h3&gt;

&lt;p&gt;The core idea is to obtain a debiased prediction distribution by separating the model’s prior bias for option IDs from the overall prediction distribution. In other words, the observed prediction distribution $P_ {\textrm{observed}}$ over $d_ i$ can be decomposed as a prior distribution $P_ {\textrm{prior}}$ over $d_ i$ and a debiased distribution $P_ {\textrm{debiased}}$ over $d_ i$:&lt;/p&gt;

&lt;p&gt;$\begin{equation}
    P_ {\textrm{observed}} (d_ i \vert q, x^ I) = Z_ {q, x^ I}^ {-1} P_ {\textrm{prior}} (d_ i \vert q, x^ I) P_ {\textrm{debiased}} (o_ {f_ I (i)} \vert q, x^ I), \forall I \in \mathcal{I}, \quad i \in {1, 2, …, n},
\end{equation}$&lt;/p&gt;

&lt;p&gt;where $f_ I (i)$ denotes $i$-th element in $I$. Note that the form of $P_ {\textrm{observed}}$ can be rewritten as a joint probability $P(d_ i , o_ j \vert q, x^ I)$ for $d_ i$ and $o_ j$, which equals to $P_ {\textrm{observed}} (d_ i \vert q, x^ I)$ if $j = f_ I (i)$ and $0$ otherwise. Thus, the above prediction probability decomposition can be interpreted as the conditional independent assumption (ignore the normalization $Z_ {q, x^ I}^ {-1}$), where the model holds independent beliefs about $d_ i$ and $o_ j$. Specifically, $P_ {\textrm{debiased}} (o_ j \vert q, x^ I)$ reflects the model’s &lt;strong&gt;true belief about the option content&lt;/strong&gt; $o_ j$, which is not influenced by the option ID $d_ i$. In constrast, $P_ {\textrm{prior}} (d_ i \vert q, x^ I)$ indicates the model’s &lt;strong&gt;prior bias for the option ID&lt;/strong&gt; $d_ i$, which actually involves not only the model’s token bias but also position bias, due to the natural binding between option IDs and options’ ordering positions. Thus, instead of strictly distinguishing the two biases, we can address them together by eliminating $P_ {\textrm{prior}}$.&lt;/p&gt;

&lt;p&gt;For tractable derivation, assuming that $P_ {\textrm{debiased}}$ is not affected by option ordering, implying its invariance to option permutation $I$, allows $x_ I$ to be replaced with the default input $x$. Moreover, we assume $P_ {\textrm{prior}}$ to be independent of $x_ I$, meaning that the prior for option IDs depends on only the question $q$. Then, $(2)$ can be simplified to&lt;/p&gt;

&lt;p&gt;$\begin{equation}
    P_ {\textrm{observed}} (d_ i \vert q, x^ I) = Z_ {q, x^ I}^ {-1} P_ {\textrm{prior}} (d_ i \vert q) P_ {\textrm{debiased}} (o_ {f_ I (i)} \vert q, x), \quad \forall I \in \mathcal{I}, i \in {1, 2, …, n}.
\end{equation}$&lt;/p&gt;

&lt;h3 id=&quot;23-debiasing-with-prior-estimation&quot;&gt;2.3 Debiasing With Prior Estimation&lt;/h3&gt;

&lt;p&gt;Taking the logarithm of both sides of $(3)$ and summing over all $I \in \mathcal{I}$ gives&lt;/p&gt;

&lt;p&gt;$\begin{equation}
    \sum_ {I \in \mathcal{I}} \log P_ {\textrm{observed}} (d_ i \vert q, x^ I) = \vert \mathcal{I} \vert \log P_ {\textrm{prior}} (d_ i \vert q) + \left( \sum_ {I \in \mathcal{I}} \log P_ {\textrm{debiased}} (o_ {f_ I (i)} \vert q, x) \right) + C
\end{equation}$
$\begin{equation}
    = \vert \mathcal{I} \vert \log P_ {\textrm{prior}} (d_ i \vert q) + \left( \frac{\vert \mathcal{I} \vert}{n} \sum_ {j = 1}^ {n} \log P_ {\textrm{debiased}} (o_ {f_ I (i)} \vert q, x) \right) + C
\end{equation}$
$\begin{equation}
    = \vert \mathcal{I} \vert \log P_ {\textrm{prior}} (d_ i \vert q) + C’, \quad i \in {1, 2, …, n}.
\end{equation}$&lt;/p&gt;

&lt;p&gt;Without any sample labels, we get&lt;/p&gt;

&lt;p&gt;$\begin{equation}
    P_ {\textrm{prior}} (d_ i \vert q) = \textrm{softmax} \left( \frac{1}{\vert \mathcal{I} \vert} \sum_ {I \in \mathcal{I}} \log P_ {\textrm{observed}} (d_ i \vert q, x^ I) \right), \quad i \in {1, 2, … , n}.
\end{equation}$&lt;/p&gt;

&lt;p&gt;According to the observation that selection bias within the same model shows a moderate cross-domain similarity, it infers that the prior for option IDs is likely to transfer across different samples and domains, suggesting the computation for the priors of partial test samples and utilize them as an approximation for the remaining samples. This can tremendously enhance debiasing efficiency since no more computational overhead is required for the remaining samples upon the estimated prior.&lt;/p&gt;

&lt;p&gt;Based on the mentioned motivation, PriDe at the beginning takes $K$ test samples $\mathcal{D}_ {\textrm{e}}$ from the test set $\mathcal{D}$, where $K$ can be adjusted depending on the esimation budget. Each sample in $\mathcal{D}_ {\textrm{e}}$ undergoes the standard permutation-based debiasing in $(1)$, during which we estimate each sample-specific prior $P_ {\textrm{prior}} (d_ i \vert q)$ using $(7)$. For the remaining samples $\mathcal{D}_ {\textrm{r}} = \mathcal{D} \setminus \mathcal{D}_ {\textrm{e}}$, the “global prior” $\tilde{P}_ {\textrm{prior}} (d_ i)$ is computed by averaging the previously computed priors as an approximation to the new sample’s $P_ {\textrm{prior}} (d_ i \vert q)$ in $(3)$. Thus, the approximated $\tilde{P}_ {\textrm{debiased}} (o_ i \vert q, x)$ can be computed, resulting in the debiased prediction as follows:&lt;/p&gt;

&lt;p&gt;$\begin{equation}
    \tilde{P}_ {\textrm{debiased}} (o_ i \vert q, x) \propto P_ {\textrm{observed}} (d_ i \vert q, x) / \tilde{P}_ {\textrm{prior}} (d_ i), \quad i \in {1, 2, …, n}.
\end{equation}$&lt;/p&gt;

&lt;p&gt;When $K \ll \vert \mathcal{D} \vert$, the overhead for prior estimation will become negligible compared to the whole inference cost. Figure 1 summarizes PriDe:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/DS501_24S/Large_Language_Models_Are_Not_Robust_Multiple_Choice_Selectors/algo_pride.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 1: PriDe Algorithm&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-experiment&quot;&gt;&lt;strong&gt;3. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;31-experiment-setup&quot;&gt;&lt;strong&gt;3.1 Experiment setup&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Models:
    &lt;ul&gt;
      &lt;li&gt;Causal, decoder-only LLMs are used due to prevalent uses of this kind of architecture.&lt;/li&gt;
      &lt;li&gt;20 LLMs from various families and sizes are included:
        &lt;ul&gt;
          &lt;li&gt;llama-7/13/65B (Touvron et al., 2023a)&lt;/li&gt;
          &lt;li&gt;llama-2(-chat)-7/13/70B (Touvron et al., 2023b)&lt;/li&gt;
          &lt;li&gt;vicuna-v1.3-7/13/33B, vicuna-v1.5-7/13B (Chiang et al., 2023)&lt;/li&gt;
          &lt;li&gt;falcon(-inst)-7/40B (Almazrouei et al., 2023)&lt;/li&gt;
          &lt;li&gt;gpt-3.5-turbo-0613 (OpenAI, 2022)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;All models except gpt-3.5-turbo are open-source on HuggingFace and allow access to output probabilities.&lt;/li&gt;
      &lt;li&gt;gpt-3.5-turbo is a commercial API that only provides generated text, not output probabilities.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Benchmarks:
    &lt;ul&gt;
      &lt;li&gt;3 MCQ benchmarks are utilized:
        &lt;ul&gt;
          &lt;li&gt;MMLU (Hendrycks et al., 2020): 4-option MCQs; domains across 57 subjects&lt;/li&gt;
          &lt;li&gt;ARC-Challenge (Clark et al., 2018): 4-option MCQs&lt;/li&gt;
          &lt;li&gt;CommonsenseQA (CSQA) (Talmor et al., 2019): 5-option MCQs&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Evaluation:
    &lt;ul&gt;
      &lt;li&gt;The evaluation follows established LLM evaluation frameworks:
        &lt;ul&gt;
          &lt;li&gt;HuggingFace LLM Leaderboard&lt;/li&gt;
          &lt;li&gt;EleutherAI lm-harness&lt;/li&gt;
          &lt;li&gt;Original MMLU implementation&lt;/li&gt;
          &lt;li&gt;OpenAI Evals&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Open-source models: output probabilities of option IDs (A/B/C/D/E) are used, with the highest probability indicating the prediction.&lt;/li&gt;
      &lt;li&gt;gpt-3.5-turbo: the first generated token is compared to the golder answer (decoding temperature set to 0).&lt;/li&gt;
      &lt;li&gt;The primary evaluation focuses on the 0-shot setting to avoid bias from additional information.&lt;/li&gt;
      &lt;li&gt;5-shot experiments are also conducted, where in-context examples are provided from development sets and shared across all test samples within the same task.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;32-results&quot;&gt;&lt;strong&gt;3.2 Results&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;By comparing a new debiasing method called PriDe with two existing methods (Cyclic Permutation and Full Permutation) for reducing selection bias in LLMs answering MCQs, some key findings are, according to Figure 2, that&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;PriDe achieves better debiasing and improves performance compared to the other two methods, especially when considering the computational cost. This holds true even when additional context (in-context examples) is provided to the LLM.&lt;/li&gt;
  &lt;li&gt;The estimated bias using PriDe correlates well with the actual selection bias observed in the model, suggesting PriDe effectively identifies the underlying cause of the bias.&lt;/li&gt;
  &lt;li&gt;PriDe can achieve reliable bias estimation even with a limited amount of data (by sampling $K=\alpha \vert \mathcal{D} \vert$ test samples), indicating that the model’s bias for answer choices is consistent across different samples.&lt;/li&gt;
  &lt;li&gt;PriDe can be combined with simpler debiasing methods (using fewer random permutations) to further improve efficiency while maintaining effectiveness.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../images/DS501_24S/Large_Language_Models_Are_Not_Robust_Multiple_Choice_Selectors/result_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 2: Debiasing results&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Nonetheless, there are some limitations:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Full Permutation was not evaluated on the 5-option MCQ benchmark due to its high computational cost.&lt;/li&gt;
  &lt;li&gt;For gpt-3.5-turbo, the debiasing process relies on an approximation because it does not provide the necessary output probabilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Furthermore, an analysis on transferability across different domains is performed. In reality, questions might come from various domains, so it is crucial to ensure that the debiasing method works even if it was not trained on that specific domain. The result, according to Figure 3, shows that the bias estimated from one domain with a small number of samples can be used to debias questions from other domains as well. Also, there might be a slight performance drop for LLMs when the domain shift is significant (e.g., STEM to NON-STEM). While PriDe aims to reduce bias, not boost performance, the authors suggest updating the estimated bias with a few new samples from the new domain if a large domain shift is expected. This update would have negligible extra cost compared to the overall process.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/DS501_24S/Large_Language_Models_Are_Not_Robust_Multiple_Choice_Selectors/result_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 3: Cross-domain debiasing results&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In addition, the consequence of model predictions by debiasing methods is also taken into consideration. While the main goal was to reduce bias, the debiasing often leads to improved performance as well. There are 3 insights from the experiment:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Both methods (PriDe and Cyclic Permutation) improve more predictions than they worsen. This means debiasing generally helps the model make better choices.&lt;/li&gt;
  &lt;li&gt;PriDe seems to mostly affect predictions where the model itself was not very confident at first. The new, debiased predictions tend to be among the top two choices the model considered before debiasing, especially for larger models. This suggests PriDe corrects the model’s bias for certain answer IDs when it is unsure and pushes the model towards a more likely answer.&lt;/li&gt;
  &lt;li&gt;Cyclic Permutation changes even high-confidence predictions more frequently and can lead to more dramatic shifts in the answer choice. Also, it is inclined to pick the originally lowest-ranked option more often as the debiased answer. Additionally, it flattens the model’s confidence distribution across all answer choices. This is due to the nature of the permutation-based debiasing which is a sort of mixture of experts, where each expert considers the options in a different order. This leads to more neutral, i.e., less certain, predictions yet requires more computation compared to PriDe.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-conclusion&quot;&gt;&lt;strong&gt;4. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;!-- Please summarize the paper.  
It is free to write all you want. e.g, your opinion, take home message(오늘의 교훈), key idea, and etc. --&gt;

&lt;p&gt;The study investigates a common issue in LLMs where their answers to MCQs can be influenced by the way the answer choices are presented. This presence is called selection bias, encompassing two main reasons: token bias and position bias. A new method called PriDe is then proposed to fix this bias. The mechanism of this approach is to estimate the model’s preference for certain answer IDs and corrects for it without needing any additional information about the questions themselves. This method is efficient, interpretable, and applicable for different domains, leading to the enhancement in the overall reliability of LLMs in answering MCQs.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Author name: Rawat Padungkiettiwong
    &lt;ul&gt;
      &lt;li&gt;Affiliation: KAIST School of Computing&lt;/li&gt;
      &lt;li&gt;Research Topic: Natural Language Processing, Trustworthy LLMs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/chujiezheng/LLM-MCQ-Bias&quot;&gt;Github Implementation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;References&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Zheng, Chujie, Hao Zhou, Fandong Meng, Jie Zhou, and Minlie Huang. “Large language models are not robust multiple choice selectors.” In The Twelfth International Conference on Learning Representations. 2023.&lt;/p&gt;

&lt;p&gt;Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothe ́e Lacroix, Baptiste Rozie`re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023a.&lt;/p&gt;

&lt;p&gt;Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko- lay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open founda- tion and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023b.&lt;/p&gt;

&lt;p&gt;Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https: //lmsys.org/blog/2023-03-30-vicuna/.&lt;/p&gt;

&lt;p&gt;Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Co- jocaru, Merouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. Falcon-40B: an open large lan- guage model with state-of-the-art performance, 2023.&lt;/p&gt;

&lt;p&gt;OpenAI. https://chat.openai.com.chat, 2022.&lt;/p&gt;

&lt;p&gt;Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. In International Conference on Learning Representations, 2020.&lt;/p&gt;

&lt;p&gt;Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457, 2018.&lt;/p&gt;

&lt;p&gt;Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. CommonsenseQA: A ques- tion answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Con- ference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4149–4158, Minneapolis, Min- nesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1421. URL https://aclanthology.org/N19-1421.&lt;/p&gt;
</description>
            <pubDate>Wed, 17 Apr 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Large_Language_Models_Are_Not_Robust_Multiple_Choice_Selectors.html</link>
            <guid isPermaLink="true">http://localhost:4000/Large_Language_Models_Are_Not_Robust_Multiple_Choice_Selectors.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[SIGIR 2022] User-controllable Recommendation Against Filter Bubbles</title>
            <description>&lt;h1 id=&quot;sigir-22user-controllable_recommendation_against_filter_bubbles&quot;&gt;[SIGIR-22]User-controllable_Recommendation_Against_Filter_Bubbles&lt;/h1&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#1-problem-definition&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;과거 몇 년 동안 추천시스템은 ‘개인화된 정보 필터링’이라는 명목으로 정보의 과잉을 감당하기 어려운 사용자들에게 불필요한 정보를 필터링 해주어 빠른 발전을 거두었지만, ‘필터버블(Filter Bubble)’에 대한 논의는 항상 이어져 왔었다.&lt;/p&gt;

&lt;p&gt;필터버블이란, 추천시스템이 사용자-아이템 간 상호작용을 기반으로 기존 사용자의 선호도에 일치하는 아이템만 계속해서 노출시키는 현상을 가리킨다.  이런 현상이 반복되면, 유사한 아이템만 노출되는 확률이 계속해서 커지게 되고, 사용자가 다양한 카테고리의 콘텐츠를 접할 수 있는 기회가 점점 줄어지게 된다.&lt;/p&gt;

&lt;p&gt;즉, 장기적인 관점에서 필터버블은 아이템 혹은 콘텐츠의 다양성과 오리지널리티를 추천시스템에서 배제시키게 되고, 이는 필연적으로 정보의 편식으로 인해 사용자로 하여금 왜곡 효과를 낳게 된다.&lt;/p&gt;

&lt;p&gt;따라서, 필터버블을 완화하는 것 또한 추천시스템에서 중요한 과제로 자리매김하게 되었다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#2-motivation&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;필터버블을 완화하는 방안으로 기존 연구에서는 ‘다양성(Diversity)’과 공정성(Fairness)’을 높이는 방법을 제안했었다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;다양성&lt;/strong&gt;:
다양성은 추천 목록에서 유사성이 다른 아이템을 생성하도록 장려하는 방안이다. 이는 후처리 및 엔드-투-엔드 방법으로 나눌 수 있다. 전자는 몇몇 모델에 의해 생성된 추천 목록을 다시 순위 지정을 통해 다양화시키며, 후자는 모델 훈련 및 예측 과정에서 정확도와 다양성의 균형을 맞추는 방향으로 진행된다. 그러나 이러한 방식들 역시 단순히 사용자에게 다양한 아이템을 추천한 후 사용자의 피드백을 통해 새로운 아이템 카테고리를 발굴해가는 것으로 많은 시간이 필요하다. 심지어 다양한 아이템을 추천하는 단계에서 사용자 선호도와 관련 없는 아이템을 많이 가져올 수 있다는 단점이 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;공정성&lt;/strong&gt;:
추천시스템에서 공정성을 달성하기 위해서는 다양한 사용자 그룹 또는 아이템 카테고리 간에 균형을 맞추어야 한다. 이것은 특정 그룹에게 더 많은 추천을 하도록 조절하거나 특정 카테고리의 아이템을 다른 것보다 자주 포함시키는 것을 의미하여 필터버블을 어느 정도 완화할 수 있다. 그러나 이렇게 균형을 맞추는 과정에서, 일부 사용자 또는 아이템 그룹에 대한 추천 정확성을 희생시킬 수 있다. 예를 들어, 만약 특정 사용자 그룹에게 더 많은 공정성을 부여하려면 그 그룹에 대한 추천 목록에서 다른 사용자 그룹의 선호를 무시하고 그 그룹에 맞춰야 할 수 있기 때문에 그 그룹에 대한 정확한 추천이 희생되고 사용자 경험이 저하될 수 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇듯 기존 접근 방식은 다양성, 공정성을 고려하여 필터버블을 완화하지만 정확성과 사용자 경험을 희생해야 한다는 단점이 있다.&lt;/p&gt;

&lt;p&gt;또한, 사용자의 피드백을 통해 추천시스템이 모델 훈련-예측의 무한 루프를 도는 과정에서, 사용자는 추천 결과를 수동적으로만 받아들이게 때문에 진정한 ‘개별맞춤’ 결과를 생성하기까진 많은 시간과 비용을 필요로 한다. 즉, 비록 추천시스템이 사용자의 선호도를 기반으로 결과를 생성하긴 하지만, 다양성과 공정성 향상 과정에서 다시 불필요한 정보까지 포함시킬 수 있기 때문에 사용자가 자신에게 필요한 정보만을 얻기 위해선 생성된 추천 결과에 대해 ‘like’ 혹은 ‘dislike’ 등 지속적인 피드백을 제공하고 학습을 시켜야 한다.&lt;/p&gt;

&lt;p&gt;따라서, 저자는 사용자가 직접 컨트롤을 통해 자신이 원하는 추천 결과를 생성할 수 있게끔 ‘User-Controllable Recommendation System(UCRS)’ 방안을 제시했다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/9wXYx34/rsloop.png&quot; alt=&quot;rsloop&quot; /&gt;&lt;/p&gt;

&lt;p&gt;사용자가 제어할 수 있는 추천시스템인 UCRS는 기존 추천시스템 외에 아래 3가지 기능을 추가시켰다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;필터버블의 탐지하여 사용자에게 알려주는 필터버블 경고 기능&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;4가지 수준의 제어 명령 기능&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;사용자 제어에 따라 추천결과를 조정하는 응답 메커니즘&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이로써, 저자는 사용자가 추천시스템의 동작을 제어할 수 있는 방법을 제공하여 사용자의 참여를 촉진하고, 사용자가 더 많은 표현력과 제어권을 가지게 함으로써 사용자 경험을 향상시키는 것을 목적으로 삼았다.&lt;/p&gt;

&lt;p&gt;이와 더불어, 저자는 앞서 말한 응답 메커니즘 단계에서 사용자 A가 1년 전에는 액션 영화를 많이 시청했지만 현재는 코미디 영화에 더 관심이 있을 수 있는 것처럼 시간이 지남에 따라 사용자의 선호도가 변할 수 있다는 점까지 인식하였다. 이에 따라, 사용자 표현의 오래된 정보가 추천에 미치는 영향을 완화하는 데 중점을 둔 ‘User-Controllable Inference(UCI)’ 프레임 워크가 제안되었다.&lt;/p&gt;

&lt;p&gt;UCI는 사용자가 제어 명령을 제공하면,  반 사실(counterfactual)인 대조적 추론을 사용하여 과거에 나온 사용자 표현의 영향을 줄이는 방안이다. 예를 들어, 여성인 사용자 B는 여성 사용자 그룹이 선호하는 영화 리스트에 질려 남성 사용자 그룹이 선호하는 영화 리스트를 추천시키는 제어 명령을 내렸다고 가정하자. 이 때, 반 사실인 대조적 추론은 ‘사용자 B가 남성이라면 추천 리스트는 어떻게 변할까?’라는 질문의 대한 예측이라고 생각할 수 있다. 즉, UCI는 오래된 사용자 표현이 폐기되는 반 사실 세계를 가정하고 이런 조건에 맞는 새로운 추천 결과를 생성한다. 이로써 과거 사용자-아이템 간 상호작용 패턴에 극한되지 않고 사용자가 원하는 추천을 얻을 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;3-preliminary&quot;&gt;3. Preliminary&lt;/h2&gt;
&lt;h3 id=&quot;31-experimental-settings&quot;&gt;3.1 Experimental settings&lt;/h3&gt;
&lt;p&gt;저자는 Method를 확립하기에 앞서 추천시스템에서 필터버블이 어떠한 유형으로 발생되는지 알아보는 사전 실험을 수행했다:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;대표적인 추천 모델인 Factorization Machine (FM)을 DIGIX-Video, Amazon-Book 및 ML-1M과 같은 세 개의 공개 데이터셋에 훈련시킴.&lt;/li&gt;
  &lt;li&gt;각 사용자에 대해 상위 10개의 추천 아이템을 수집함.&lt;/li&gt;
  &lt;li&gt;사용자 그룹을 ID, 성별 및 연령을 고려한 사용자 특성(User Features)과 아이템 카테고리에 대한 관심도 등을 고려한 사용자 상호작용(User Interactions) 두 가지 요인으로 분류함.&lt;/li&gt;
  &lt;li&gt;FM이 생성한 추천결과와 사용자 그룹에 따른 사용자의 과거 상호작용 패턴을 비교함.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;32-analysis&quot;&gt;3.2 Analysis&lt;/h3&gt;
&lt;p&gt;분석 결과로는, 사용자 특성과 아이템 특성(Item Features) 2가지 측면에서 필터버블이 존재한다는 사실이 발견되었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/0c9Qt8R/fbresult.png&quot; alt=&quot;fbresult&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이미지 2(a)는 DIGIX-Video의 남성 및 여성 사용자별 상위 3개 아이템 카테고리에 대한 과거 분포를 시각화한 결과이다. 여성 사용자 그룹은 로맨스 영화를 더 선호한 반면, 남성 사용자 그룹은 액션 영화를 더 선호했다. 그 결과, 이미지 2(b)와 2(c)에서 알 수 있듯이, 추천 결과에서도 편향된 분포를 유지하게 되었다.&lt;/p&gt;

&lt;p&gt;이러하듯이, 사용자는 계속해서 유사한 아이템을 추천 받게 된다. 추천 모델은 이러한 편향을 강화하고 상위 특정 카테고리를 더 노출시키는 경향으로 이어져 결국 남성과 여성 사용자 그룹 간의 심각한 분리를 야기시키게 된다.&lt;/p&gt;

&lt;p&gt;또한, 이미지 2(d) 및 2(e)는 Amazon-Book 및 ML-1M 데이터셋에 대해 사용자 상호작용에 따라 나눈 결과이다. 동 결과에서도 과거 사용자 상호작용 패턴에 따른 카테고리 편향 증폭이 발견되었다. 즉, 사용자으로부터 가장 큰 관심을 받은 카테고리가 이후 추천 목록에서도 증가된 것이다. 이는 필터버블의 강화를 초래하고 사용자의 관심을 좁혀 사용자 그룹 분리로 이어지게 된다.&lt;/p&gt;

&lt;p&gt;따라서, 저자는 사용자 특성과 아이템 특성 2가지 측면에서 필터버블을 완화하는 UCRS 체계를 제안했다.&lt;/p&gt;

&lt;h2 id=&quot;4-method&quot;&gt;&lt;strong&gt;4. Method&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#3-method&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;전반적으로 저자는 커버리지(Coverage), 격리지수(Isolation Index), 최다 카테고리 지배도(Majority Category Domination, MCD) 등 지표를 통해 필터버블의 수준을 실시간으로 감지하고 사용자에게 알람을 보내는 경고 기능을 구현했다.&lt;/p&gt;

&lt;p&gt;또한, 제어 명령 기능과 관련해서는 앞서 사전 실험 결과에 따라, 사용자 특성과 아이템 특성 2가지 방면에서 UCRS 제어시스템을 구현했다.&lt;/p&gt;

&lt;p&gt;마지막으로, 사용자 제어에 따라 추천결과를 조정하는 반 사실 추론 응답 메커니즘을 통해 필터버블을 완화하는 동시에 추천 정확성은 유지하고 사용자가 원하는 결과를 얻을 수 있는 추천시스템을 구현했다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/7Nrkm21/ucrs.png&quot; alt=&quot;ucrs&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;41-필터버블-감지-지표&quot;&gt;4.1 필터버블 감지 지표&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Coverage&lt;/strong&gt;:
필터버블은 추천 항목의 다양성을 감소시키는 경우가 많으므로 추천 목록의 카테고리 수를 계산하는 Coverage를 다양성 척도로 사용했다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Isolation Index&lt;/strong&gt;: 
다양성 척도 외에도 저자는 서로 다른 사용자 그룹 간의 분리수준을 측정하기 위해 Isolation Index를 제안했다. 두 사용자 그룹 a와 b가 주어졌을 때 권장 격리 지수는 다음과 같이 계산할 수 있다:
&lt;img src=&quot;https://i.ibb.co/vDmB3Dx/isolation.png&quot; alt=&quot;isolation&quot; /&gt;
여기서 $I$는 아이템 집합을 의미하며,  $a_ {i}$와 $b_{i}$는 그룹 $a$와 그룹 $b$에서 추천 아이템 $i$를 받은 사용자 수를 나타낸다. $a_ {n} = ∑_ {i ∈ I} a_ {i}$는 그룹 $a$에서 해당 아이템의 총 노출 빈도이며, $b_{n}$도 같은 방법으로 계산된다.  마지막으로, $s$는 그룹 a의 아이템 노출 빈도 가중 평균 값에서 그룹 b의 가중 평균 값을 뺀 값과 같으며, $\frac{a_ i}{a_ i+b_ i}$가 가중치가 된다. 즉, s는 0~1 사이의 값을 가지며,  두 그룹 간의 권장 분리 수준을 나타내고, 값이 클수록 더 심한 분리를 의미하게 된다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;MCD&lt;/strong&gt;:
MCD는 아이템 특성과 관련된 필터버블을 감지하는 용도로 사용되어 가장 자주 추천되는 아이템 카테고리의 비율을 확인할 수 있다. 시간이 지남에 따라 MCD가 증가하면 아이템 카테고리와 관련된 필터 버블의 심각성이 커지고 있음을 나타낸다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;결론적으로 이러한 지표들을 통해 사용자에게 실시간으로 필터버블 경고를 보내고 이를 제어할지 여부를 결정하게 도울 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;42-제어-명령-기능&quot;&gt;4.2 제어 명령 기능&lt;/h3&gt;
&lt;p&gt;사용자의 과거 상호작용 데이터인 𝐷가 주어졌을 때, 기존의 추천 모델은 추천 𝑅을 예측하기 위해 𝑃(𝑅|𝐷)를 사용한다. 그러나 UCRS는 추가로 사용자 제어인 𝐶를 고려하며 사용자 개입(𝑑𝑜(𝐶))을 통해 𝑃(𝑅|𝐷, 𝑑𝑜(𝐶))를 추정할 것을 제시했다. 이때, 사용자 및 아이템 제어 각각 ‘Fine-grained controls’와 ‘Coarse-grained controls’ 2가지 세부 수준으로 또 나눠져 총 4가지 유형의 사용자 제어가 제시됐다.&lt;/p&gt;

&lt;h4 id=&quot;421-사용자-특성-제어user-feature-controls&quot;&gt;4.2.1 사용자 특성 제어(User-feature Controls)&lt;/h4&gt;
&lt;p&gt;N가지 사용자 특성과 사용자 𝑢가 있을 때, 사용자 𝑢는 $x_ u = [ x^1_ {u}, \ldots, x^n_ {u}, \ldots,  x^N_ {u} ], \text{ where }  x^n_ {u} \in {0,1 }$ 로 표현되며, 여기서 $x^n_ {u} \in {0,1 }$는 사용자 𝑢가 사용자 특성 $x^n$을 가지고 있는지 여부를 나타낸다. 예를 들어,  [$x^{1}$과 $x^{2}$]가 남성과 여성을 나타낸다면, $x_ {u}$ = [0, 1]은 사용자 𝑢가 여성임을 뜻한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fine-grained controls&lt;/strong&gt;
사용자 특성 측면에서 발생되는 필터버블(예: 성별 및 연령)을 완화하기 위해 저자는 UCRS가 다른 사용자 그룹이 좋아하는 항목을 더 많이 추천하도록 하는 세분화된 사용자 특성 컨트롤을 설계했다.&lt;/p&gt;

&lt;p&gt;예를 들어, 30대의 중년 사용자는 10대가 좋아하는 영화에 관심이 있을 수 있다. 이 때, 사용자 $u$에 대한 $𝑃(𝑅 \vert 𝐷, 𝑑𝑜(𝐶))$를 계산할 때, 제어령은 $do(C=c_ u(+ \hat{x},\alpha))$와 같이 쓸 수 있다. 여기서 $c_u(+\hat{x},\alpha)$는 다른 사용자 그룹$\hat{x}$에서 많이 추천되는 아이템을 더 많이 노출시키는 제어령이다. 참고로 $\hat{x}$는 사용자 $u$가 기존에 가지고 있지 않았던 feature이어야 한다. $α ∈ [0,1]$는 사용자 제어의 강도를 조정하는 계수이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Coarse-grained controls&lt;/strong&gt;
하지만, 사용자는 단순히 필터버블을 제거하길 원하지 다른 사용자 그룹이 좋아하는 아이템은 추천 받고 싶지 않을 수 있다. 혹은 어떤 사용자 그룹이 더 좋은 추천 결과를 가지는지 모르는 사용자도 있을 것이다. 따라서 저자는 사용자가 자신이 속한 그룹의 필터버블을 벗어날 수 있도록 coarse-grained 수준의 제어령도 설계했다.&lt;/p&gt;

&lt;p&gt;예를 들어, 중년 사용자는 추천리스트가 ‘연령=30세’로 제한되는 것을 원하지 않는다고 가정하자. $𝑃(𝑅 \vert 𝐷, 𝑑𝑜(𝐶))$에서 제어령은 $do(C = c_ u(-\overline{x},\alpha))$로 표현된다. 이로써 기존에 자신의 사용자 그룹에 제시되었던 feature $\overline{x}$을 줄임으로써 필터버블을 완화할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;422-아이템-특성-제어item-feature-controls&quot;&gt;4.2.2 아이템 특성 제어(Item-feature Controls)&lt;/h4&gt;
&lt;p&gt;사용자 기능 제어는 사용자 특성과 관련된 필터버블을 해결하지만 사용자 상호 작용의 영향은 고려하지 않는다. 사용자 특성 제어를 보완하기 위해 아이템 특성 제어를 도입시키면서 추천 목록을 조정할 수 있다. 이러한 제어령을 사용하면 카테고리(예: 액션 영화, 로맨스 영화) 등 아이템 특성을 고려하여 추천시스템을 설정할 수 있게 된다.&lt;/p&gt;

&lt;p&gt;M개의 아이템 특성과 아이템$i$는 $h _{i} = [ h^1 _{i}, \ldots, h^m _{i}, \ldots,  h^M _{i} ], \text{ where }  h^m _{i} \in {0,1 }$ 로 나타내며, 여기서 $h^m _{i} \in {0,1 }$ 는 아이템$i$가 아이템 특성 $h^m$ 을 가지고 있는지를 나타낸다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fine-grained controls&lt;/strong&gt;
Fine-grained controls에서는 사용자가 특정 아이템 카테고리의 추천을 늘리도록 허용할 수 있다. 예를 들어 로맨스 영화와 같은 특정 카테고리의 아이템을 더 많이 받을 수 있게끔 구체적인 제어령을 내릴 수 있다. $do(C=c_i(+\hat{h},\beta))$로 표현되며, $\hat{h}$는 타겟 아이템 카테고리이며, $β ∈ [ 0 , 1 ]$는 사용자 제어 강도를 조정하는 계수이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Coarse-grained controls&lt;/strong&gt;
 Coarse-grained controls는 사용자가 타겟 카테고리를 지정해야 하는 부담을 줄이기 위해 제안됐다. 이는 사용자의 과거 상호작용에서 가장 큰 비중을 차지했던 아이템 카테고리의 추천을 줄이도록 진행된다. 제어령은 $do(C=c_i(-\overline{h},\beta))$처럼 표현된다.&lt;/p&gt;

&lt;p&gt;종합적으로 보면,  UCRS의 Fine-grained controls는 사용자가 세분화된 사용자 혹은 아이템 특성을 활용하여 구체적인 제어 명령을 통해 특정 추천 목표를 달성하는 방안이고,  Coarse-grained controls는 세분화된 특성에 대해서 사용자가 구체적인 제어 명령을 지시할 필요 없이 간단하게 필터버블을 완화하는 방법이다.&lt;/p&gt;

&lt;h3 id=&quot;43-반-사실적counterfactual-응답-메커니즘&quot;&gt;4.3 반 사실적(Counterfactual) 응답 메커니즘&lt;/h3&gt;
&lt;p&gt;Fine-grained controls나 Coarse-grained controls에서는 연령 혹은 카테고리 등 변경된 features를 기반으로 추천리스트를 새롭게 생성하게 된다. 여기서 기존 features에 대해 사실과 다른 질문에 답하는 추론 과정이 포함된다. 이게 무슨 뜻인지 아래 내용에서 더 자세히 설명하겠다.&lt;/p&gt;

&lt;h4 id=&quot;431-response-to-user-feature-controls&quot;&gt;4.3.1 Response to User-feature Controls&lt;/h4&gt;
&lt;p&gt;앞서 User-feature Controls의 Fine-grained controls에서 $do(C=c_ u(+\hat{x},\alpha))$ 제어령을 사용하는 것을 확인했다. 이에 따라, UCRS는 변경된 $\hat{x}$를 기반으로 추천을 생성해야 한다. 예를 들어, 30대 중년이 10대가 좋아하는 영화 리스트를 보고 싶은 경우, 인과적 관점에서 볼 때, 제어령의 목표는 반 사실적인 질문에 답하는 것이다. 즉, “사용자가 $\hat{x}$에 속한다면 사용자의 추천은 어떻게 될 것인가?”라는 질문에 답하는 것이라고 생각하면 된다. 마찬가지로, Coarse-grained controls는 “사용자가 실제 그룹 $\overline{x}$에 속하지 않는 경우 사용자의 추천은 어떻게 될 것인가?”라는 질문에 답하는 것이다. 이런 반 사실적 질문에 답하기 위해 UCI 프레임워크는 사용자 features과 추천 간의 인과적 연관성을 식별하고 반 사실적 추론을 수행해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/Sx0GdrJ/causal-graph.png&quot; alt=&quot;causal_graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Causal view of generating recommendations&lt;/strong&gt;
Figure 4는 추천 생성 과정을 나타낸다. 대부분의 모델에서 추천시스템은 사용자 ID, 나이, 성별 등 상호작용을 통해 사용자 표현을 학습한다. 즉, 사용자 $u$와 항목 $i$에 대한 표현은 사용자가 한 아이템을 선호할 확률$Y_{u,i}\in [0,1]$를 예측하는 데 사용된다.  $Y_{u,i}$는 각 features와 상응하는 그룹들의 선호도를 반영한다.&lt;/p&gt;

&lt;p&gt;반 사실적 추론에 답하려면 Fine-grained controls에서는 특정 $\hat{x}$를 변경하고, Coarse-grained controls에서는 특정 $\overline{x}$를 제거하는 게 직관적인 판단일 것이다. 그러나 Figure 4에서 볼 수 있듯이 추천시스템 학습 과정에는 features 간 상호작용 또한 이루어진다. 예를 들어, 나이를 30세에서 18세로 변경하거나 아예 제거하더라도, ‘User ID’는 여전히 과거 features 간의 상호작용을 인코딩하므로 사용자가 새로 원하는 추천을 방해하게 된다.&lt;/p&gt;

&lt;p&gt;이런 방해를 제거하기 위해 기존 연구에서는 confounder balancing, back-door/front-door adjustments이 널리 사용됐다. confounder balancing과 back-door adjustments를 사용하려면 방해 요소가 표현에 미치는 인과적 효과를 추정해야 하는데 이런 추정은 거의 불가능하다. 왜냐하면 (1) 사용자 상호작용은 시간 지남에 따라 새로운 상호작용이 지속적으로 추가되는 동적인 고차원 공간에서 이뤄지며, (2) 사용자 상호작용이 표현에 미치는 영향은 추천시스템의 학습 과정에 따라 결정되고, 학습 접근 방식에 따라 결과도 달라지기 때문이다. 또한 front-door adjustments 조정을 위해서는 모든 back-door 경로를 차단하는 매개체를 밝혀내야 하는데, 이는 Figure 4의 인과 그래프에는 적용할 수 없다. 이러한 문제를 해결하기 위해 저자는 추론 과정에서 ‘User ID’ 표현이 예측 결과 $Y_{u,i}$에 미치는 영향을 직접적으로 줄이는 방법을 제안했으며, 이를 통해 학습 과정을 알지 못해도 features가 가지고 있는 과거 정보의 영향을 효과적으로 줄일 수 있게 됐다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Implementation of counterfactual inference&lt;/strong&gt;
UCI 프레임워크는 먼저 사실과 반대되는 추론을 사용하여 ‘User ID’ 표현의 효과를 추정하고, 원래 예측 $Y_{u,i}$에서 해당 효과를 뺀 다음 추정을 재개한다. 즉, 사용자 $u$가 ID 표현이 없는 경우를 가정한 $Y_{\hat{u},i}$를 예측하는 것이다. $Y_{u,i}-Y_{\hat{u},i}$를 사용하여 ‘User ID’의 효과를 측정할 수 있으며 $α$ 계수를 사용하여 강도를 조절할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/QFJSc4J/uci.png&quot; alt=&quot;uci&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;432-response-to-item-feature-control&quot;&gt;4.3.2 Response to Item-feature Control&lt;/h4&gt;
&lt;p&gt;Item-feature Control에서 Fine-grained controls는 아이템 카테고리$\hat{h}$의 수를 늘리는 것을 목표로 하고, Coarse-grained controls는 최다 카테고리 $\overline{h}$를 줄이는 것을 목표로 한다. 사실 이러한 과정 중에는 이하 2가지 질문이 내포되어 있다: (1) 사용자가 더 많은 특정 카테고리 $\hat{h}$를 원한다면 어떻게 될 것인가? (2) 사용자가 최다 카테고리 $\overline{h}$를 원하지 않으면 어떻게 될 것인가? 이러한 질문에 답하기 위해 UCI 프레임워크는 사용자가 추천 순서(ranking)을 제어할 수 있도록 아래와 같이 설계했다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/0XZhPPg/ranking.png&quot; alt=&quot;ranking&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 $Y_{u,i}$는 수정된 순서 점수이고 $β ∈ [ 0 , 1 ]$는 제어 강도를 조정하는 계수이다. $r(i)$는 아이템 $i$의 정규화 항을 나타낸다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/94WHy7y/r.png&quot; alt=&quot;r(i)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Fine-grained controls에서 $r(i)$는 더 많은 타겟 카테고리 $\hat{h}$를 추천하도록 권장하고, Coarse-grained controls를 적용하는 경우 최다 카테고리 $\overline{h}$를 줄이도록 조정이 된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Target category prediction&lt;/strong&gt;
현실에서는 아이템 카테고리의 수가 많기 때문에 Fine-grained controls에서 타겟 카테고리를 선별하는 것은 사용자에게 시간적 부담이 될 수 있다. Coarse-grained controls를 통해 이러한 부담을 일부 해소할 수 있지만, 만약 Fine-grained controls에서 사용자가 선호할 수 있는 타겟 카테고리를 예측할 수만 있다면 사용자 부담도 줄고 더욱 정확한 결과를 생성할 수 있다. 사용자가 추천리스트에서 최대 카테고리를 줄이려는 경우, 해당 사용자가 선호할 가능성이 높은 아이템 카테고리를 예측한 다음, Fine-grained controls를 통해 제어를 개선할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/Vmp4KgW/target.png&quot; alt=&quot;target&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 5에서 볼 수 있듯이, 사용자의 상호작용 아이템을 시간에 따라 분류한 다음, 상호작용 시퀀스를 두 부분으로 나누어 아이템 카테고리의 분포를 별도로 구할 수 있다. 그런 다음 다층 퍼셉트론(MLP)을 사용하여 첫 번째 부분을 기반으로 두 번째 부분의 분포를 예측한다. 훈련 중에 MLP는 모든 사용자의 카테고리 분포를 사용하여 (1) 시간적 관심사 변화(예: 일부 카테고리에 대한 선호도가 점차 증가)와 (2) 아이템 카테고리 간의 관계(예: 액션 영화를 좋아하는 사용자는 범죄 영화도 좋아할 수 있음)를 포착할 수 있다. 추론 단계에서는 분포의 두 번째 부분을 사용하여 상위 K개의 타겟 카테고리를 예측하게 된다. 또한, $do(\overline{h}=0)$를 사용하여 카테고리 $\overline{h}$를 축소시킨다. 이로써, 상위 K개의 아이템 카테고리는 Fine-grained controls의 최종 추천리스트로 간주되게 된다. 궁극적으로 UCI는 타켓 카테고리 예측을 사용하여 Fine-grained controls를 더욱 향상시킬 수 있게 된다.&lt;/p&gt;

&lt;h2 id=&quot;5-experiment&quot;&gt;&lt;strong&gt;5. Experiment&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#4-experiment&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&quot;research-question&quot;&gt;&lt;strong&gt;Research question&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;RQ1. UCI는 4가지 수준의 사용자 제어를 통해 어떻게 필터버블을 제거하고 추천을 조정하는가?&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RQ2. 사용자가 추천을 제어할 때 계수(예: α 및 β)는 결과에 어떻게 영향을 미치는가?&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RQ3. 제안된 사실과 반대되는 추론이 추천에 어떤 영향을 미치는?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experiment-setup&quot;&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#experiment-setup&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;DIGIX-Video&lt;/li&gt;
  &lt;li&gt;ML-1M&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Amazon-Book
 &lt;img src=&quot;https://i.ibb.co/VQ7cnkc/data.png&quot; alt=&quot;data&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;DIGIX-Video2&lt;/li&gt;
  &lt;li&gt;는 2021 DIGIX AI Challenge에서 공개된 비디오 추천 데이터셋이다. 이 데이터셋에는 사용자와 아이템의 다양한 특성이 포함되어 있으며, 연령, 성별, 아이템 카테고리 등이 포함되어 있다.&lt;/li&gt;
  &lt;li&gt;ML-1M은 널리 사용되는 영화 데이터셋으로, 각 영화에는 여러 장르 카테고리가 포함되어 있다.&lt;/li&gt;
  &lt;li&gt;Amazon-Book은 책 추천을 위해 만들어진 데이터셋으로, 사용자는 ID feature만 가지고 있으며 각 책 카테고리에 대한 레이블은 계층적인 topology로 이루어져 있다. 따라서 저자는 데이터 분석에서는 최상위 카테고리만 유지함으로써 각 책은 하나의 카테고리에만 할당되게 지정하였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;또한 저자는 각 데이터셋에 대해 10-core 설정을 사용하며, 점수가 4 이상인 데이터들만 양성 샘플로 처리했다. 타임스탬프로 상호작용을 정렬한 후 상호작용의 80%, 10%, 10%를 각각 훈련, 검증 및 테스트 세트로 사용했다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Baseline&lt;/strong&gt;
모든 baseline과 제안된 UCI는 모델에 독립적이며, Factorization Machine(FM)과  Neural Factorization Machine(NFM) 2가지 추천 모델를 기준으로 비교되었다.&lt;/p&gt;

&lt;h5 id=&quot;evaluation-of-user-feature-controls&quot;&gt;&lt;strong&gt;Evaluation of user-feature controls&lt;/strong&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;woUF는 user feature 없이 모델을 학습하므로 추천 학습 중에 서로 다른 사용자 그룹 간의 분리를 완화함&lt;/li&gt;
  &lt;li&gt;changeUF는 훈련된 추천 모델을 활용하고 user feature만을 변경하여 추론 대상 $\hat{x}$에 적용한다. changeUF는 fine-grained user-feature controls에서 사용됨&lt;/li&gt;
  &lt;li&gt;maskUF는 추론 시 기존 사용자 특성 $\overline{x}$ (예: 나이=30)을 제거하여 coarse-grained user-feature controls에서 사용됨&lt;/li&gt;
  &lt;li&gt;Fairco는 공정한 노출 기회를 구현하는 랭킹 알고리즘&lt;/li&gt;
  &lt;li&gt;Diversity는 추천리스트를 다양화하기 위해 목록 내 유사성을 최소화하는 재랭킹 알고리즘&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;evaluation-of-item-feature-controls&quot;&gt;&lt;strong&gt;Evaluation of item-feature controls&lt;/strong&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;woIF는 item feature 없이 모델을 학습함&lt;/li&gt;
  &lt;li&gt;Fairco(상동)&lt;/li&gt;
  &lt;li&gt;Diversity(상동)&lt;/li&gt;
  &lt;li&gt;Reranking은 UCI의 한 가지 변형으로, 𝑌′𝑢,𝑖 = 𝑌𝑢,𝑖 + 𝛽 · 𝑟(𝑖)에서 랭킹 알고리즘만 사용하며 반 사실 추론과 타켓 카테고리 예측은 사용되지 않음&lt;/li&gt;
  &lt;li&gt;C-UCI: ‘Coarse-grained controls’ UCI 포로토타입&lt;/li&gt;
  &lt;li&gt;F-UCI: ‘Fined-grained controls’ UCI 포로토타입&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Evaluation Metric&lt;/strong&gt;&lt;/p&gt;
&lt;h5 id=&quot;evaluation-of-user-feature-controls-1&quot;&gt;&lt;strong&gt;Evaluation of user-feature controls&lt;/strong&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Recall: 정확도 척도&lt;/li&gt;
  &lt;li&gt;NDCG: 정확도 척도&lt;/li&gt;
  &lt;li&gt;Coverage: 다양성 척도&lt;/li&gt;
  &lt;li&gt;Isolation Index: 격리지수 척도&lt;/li&gt;
  &lt;li&gt;DIS-EUC: 사용자와 그룹의 추천리스트 간의 거리 비교 척도
$\overline{x}$와 $\hat{x}$ 은 각각 사용자 $u$의 기존 그룹과 타겟 그룹을 나타냄; $d_{u} \in R^{M}$은 사용자 $𝑢$의 추천 아이템 카테고리에 대한 분포임; $\overline{g_u} ∈ R^{M}$는 원본 그룹 $\overline{x}$(예: 30세 사용자)의 사용자들의 평균 카테고리 분포를 나타내며;$\hat{g_u} ∈ R^{M}$은 대상 그룹 𝑥ˆ의 동일한 분포를 나타냅니다. 이후, 우리는 사용자 𝑢에 대해 $DIS-EUC = dis(𝑑_𝑢, \hat{g_𝑢}) - dis(𝑑_𝑢, \overline{𝑔_u})$를 계산합니다. 여기서 dis(·)는 유클리드 거리를 사용함. DIS-EUC는 사용자가 두 그룹 사이의 거리 차이를 측정하는데, 더 큰 거리는 더 심각한 그룹 분리와 필터버블을 나타냄.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;evaluation-of-item-feature-controls-1&quot;&gt;&lt;strong&gt;Evaluation of item-feature controls&lt;/strong&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Recall: 정확도 척도&lt;/li&gt;
  &lt;li&gt;NDCG: 정확도 척도&lt;/li&gt;
  &lt;li&gt;Coverage: 다양성 척도&lt;/li&gt;
  &lt;li&gt;MCD: 최다 카테고리 비율 척도&lt;/li&gt;
  &lt;li&gt;Weighted-NDCG: 카테고리 선호도 우선순위 척도&lt;/li&gt;
  &lt;li&gt;TCD(Target Category Domination): 목표 카테고리 비율 척도&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;result&quot;&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#result&quot;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/DGLCcZ2/rs1.png&quot; alt=&quot;rs1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/kD7nSjt/rs2.png&quot; alt=&quot;rs2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/WpSs466/rs3.png&quot; alt=&quot;rs3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Table 2와 Table 3는각각 Fine-grained controls과 Coarse-grained controls 결과이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;baseline (즉, woUF, changeUF 및 maskUF)은 추천 정확도를 약간 감소시키고 격리 지수 및 DIS-EUC 측면에서 그룹 분리를 완화시켰다. 한편, 대부분의 경우 다양성이 약간 상승했다. 그러나 전반적인 성능은 FM 또는 NFM과 매우 유사했다. 즉, 사용자 특성이 훈련에서 제거되거나 추론을 위해 변경/제거되더라도, 사용자 ID 표현은 여전히 과거 상호 작용을 인코딩하며 이는 사용자의 원래 특성에 영향을 받아 FM 및 NFM과 유사한 추천을 이끌어낸다.&lt;/li&gt;
  &lt;li&gt;공정성 및 다양성 방법은 필터버블 문제를 효과적으로 완화하고 추천 목록을 다양화할 수 있다. 그러나 이들은 성능을 급격히 감소시켰다. 예를 들어, Table 3의 NDCG에 따른 FM의 Fairco의 정확도는 15.38% 감소했다. 이는 공정성 및 다양성의 목표를 추구함에 따라 필연적으로 관련 없는 항목을 많이 추천하게 되어 긍정적인 항목의 기회를 차지하기 때문이다.&lt;/li&gt;
  &lt;li&gt;UCI는 필터 버블에서 그룹 분리를 유의미하게 완화시키면서 뛰어난 정확도를 달성했다. 또한, 다양성도 FM 및 NFM과 비교하여 증가하는데, 이는 정확성과 다양성 사이의 딜레마를 완화했다. 저자는 이러한 개선을 반 사실추론의 효과적인 작용에 기인한다고 보고 있다. 이는 오래된 사용자 ID 표현의 영향을 줄이는 데 효과적이며, 이로 인해 추천 모델이 과거 상호 작용과 유사한 항목을 덜 추천하고 추천을 더 다양하게 만들었다. 동시에, 우수한 정확도는 사용자 제어 𝑐𝑢 (·, 𝛼)의 𝛼가 사용자 ID 및 다른 그룹 특성 (예: 연령 및 성별)의 표현에 대한 영향을 조절하여 개인 선호도와 그룹 선호도 사이의 균형을 더 잘 조정하기 때문입니다. Figure 4에 나와 있는 것과 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-conclusion&quot;&gt;&lt;strong&gt;6. Conclusion&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#5-conclusion&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;저자는 사용자가 필터버블 완화를 능동적으로 제어할 수 있도록 하는 UCRS (User-Controllable Recommender System) 를 제안하여 사용자 특성 및 과거 상호작용을 기반으로 유사한 항목을 과도하게 추천하는 문제를 해결하는 시도를 보였다.&lt;/li&gt;
  &lt;li&gt;UCRS 프로토타입은 필터버블의 심각도를 감지하고 사용자에게 4가지 제어 명령을 제공하여 사용자로 하여금 추천시스템의 제어권을 능동적으로 실시할 수 있도록 추천시스템 생태계에 방향을 제시했다.&lt;/li&gt;
  &lt;li&gt;세 가지 데이터셋을 대상으로 한 실험을 통해 UCRS 프로토타입과 UCI 프레임워크는 정확성과 다양성 측면에서 유망한 성과를 보였으며 사용자 만족도와 추천 생태계에 대한 참여도를 높일 수 있을 것으로 기대된다.&lt;/li&gt;
  &lt;li&gt;단, 동 연구는 UCRS 프로토타입과 UCI 프레임워크를 평가할 때 온라인 실시간 데이터 대신 오프라인 데이터셋을 사용했고, 일부 사용자가 필터버블을 완화하고 제어 기능을 제공할 의향이 있다고 가정을 했기 때문에 현실 데이터와 비교하면 strong assumption일 것으로 판단된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#author-information&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Minkyung Choi
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Affiliation:
 &lt;a href=&quot;http://hfel.kaist.ac.kr/&quot;&gt;Human Factors and Ergonomics Lab – Human Factors and Ergonomics Lab (HFEL) (kaist.ac.kr)&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Research Topic:
Data Science, Computer Vision, VR&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference--additional-materials&quot;&gt;&lt;strong&gt;Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#6-reference--additional-materials&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Github Implementation:
https://github.com/WenjieWWJ/UCR&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reference:
Wang, W., Feng, F., Nie, L., &amp;amp; Chua, T. S. (2022, July). User-controllable recommendation against filter bubbles. In &lt;em&gt;Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval&lt;/em&gt; (pp. 1251-1261).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 20 Nov 2023 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2023-11-20-User-controllable_Recommendation_Against_Filter_Bubbles.html</link>
            <guid isPermaLink="true">http://localhost:4000/2023-11-20-User-controllable_Recommendation_Against_Filter_Bubbles.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[SIGIR 2023] Uncertainty-aware Consistency Learning for Cold-Start Item Recommendation</title>
            <description>&lt;h1 id=&quot;uncertainty-aware-consistency-learning-for-cold-start-item-recommendation&quot;&gt;&lt;strong&gt;Uncertainty-aware Consistency Learning for Cold-Start Item Recommendation&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;1-problem-definition-and-motivation&quot;&gt;&lt;strong&gt;1. Problem Definition and Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;In this paper, the central problem at hand is the Cold-Start problem in GNN-based recommendation systems, particularly when new items with limited interaction data are introduced to a user-item graph. The cold-start problem especially becomes tricky when the user-item graph constantly changing. This problem arises due to the scarcity of information on these “cold” items, which hinders accurate recommendations. To tackle this issue, existing models primarily rely on auxiliary user and item features which underutilize actual user-item interactions. Cold items have different embeddings due to fewer interactions comparing to warm items. This difference leads to a challenge of improving recommendations for both simultaneously which is called seesaw phenomenon. (i.e. Improveing the recommender system for cold-item, can potationally weaken recommender system for warm-items and vice versa)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For instance,&lt;/strong&gt; Suppose movie recommender system is using a vector of length 100 for movie embeddings:&lt;/p&gt;

&lt;p&gt;The embedding for “Spider-Man” might encompass values such as [0.2, 0.1, -0.3, 0.5, …], capturing its distinct characteristics and traits.&lt;/p&gt;

&lt;p&gt;However, when a new movie, “Kaist-Man,” is introduced, its embedding might initiate with values like [?, ?, ?, …], primarily due to the lack of interaction data.&lt;/p&gt;

&lt;p&gt;in this case, because “Spider-Man” is more likely to be recommended to users who are interested in superhero action movies than “Kaist-Man”. because the system has more information about it. The huge gap between their embeddings makes it challenging to improve recommendations for both simultaneously.&lt;/p&gt;

&lt;p&gt;To bridge this gap, in this paper, an Uncertainty-aware Consistency learning framework for Cold-start item recommendation (UCC) was introduced which relies exclusively on user-item interactions. This framework has two key designs: a) Uncertainty-aware Interaction Generation, and b) Graph-based Teacher-Student Consistency Learning.&lt;/p&gt;

&lt;h2 id=&quot;2-problem-formulation&quot;&gt;&lt;strong&gt;2. Problem formulation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Notations.&lt;/strong&gt; In this paper $U = {u}$ is the set of users and $I = {i}$ is set of items and $O ={ (u, i^+) \vert u ∈ U, i^+ ∈ I }$ is user-item interactions, where each pair represents each observed feedback.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt; a bipartite graph, where $V = U∪I$ is node set and $G = (V, O^+)$ is the edge set. if $M$:= number of users, $N$:=number of items, $D$:= dimension size of embedding&lt;/p&gt;

&lt;p&gt;Then in the training process of graph representation learning, $E_ {u} = [e_ {u_ {1}} , … , e_ {u_ {M}} ]∈ R^{M\times D}$ is user embedding and $E_ {i} = [e_ {i_ {1}} , … , e_ {i_ {N}}] ∈R^{N\times D}$ is item embedding.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt; Recommender models assessing the relationships between unobserved user-item pairs using the dot products of their embeddings. For given user $m$ and given item $n$ the score ${s_ {mn}}$ is calculated as: $s_ {mn} = e_ {u_ {m}} {e_ {i_ {n}} }^T$.&lt;/p&gt;

&lt;p&gt;A larger value of ${s_ {mn}}$ indicates a stronger preference by the user for the item. The top-k items from the ranking list are recommended to the user.&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;In this paper, they tackle the distribution gap between cold and warm items by employing an uncertainty-aware approach to generate interactions. Then they kept both item-level and model-level similarity with consistency.&lt;/p&gt;

&lt;h3 id=&quot;31-uncertainty-aware-interaction-generation&quot;&gt;3.1. Uncertainty-aware Interaction Generation&lt;/h3&gt;

&lt;p&gt;To determine whether generated interactions are accurate and unbiased enough they introduce the uncertainty degree of each user-item interaction which is calculated by cosine distance.&lt;/p&gt;

&lt;p&gt;for user $u_ {m}$ and item $i_ {n}$ cosine distance is&lt;/p&gt;

&lt;p&gt;$d_ {mn}= {\vert e_ {u_ {m}} {e_ {i_ {n}} }^T\vert  \over  \vert  \vert e_ {u_ {m}}\vert\vert \ \vert  \vert e_ {i_ {n}}\vert  \vert }$&lt;/p&gt;

&lt;p&gt;${s_ {mn}}_ {n=1}^N$ is ranking scores of item $i_ {n}$ for all users calculated with the pre-trained recommender, then overall interaction uncertainty of the item $i_ {n}$ can be estimated by the average of all rankings scores:&lt;/p&gt;

&lt;p&gt;$\bar{s_n}= {{1\over M}}\sum_ {k=1}^M s_ {mn}$&lt;/p&gt;

&lt;p&gt;So, high $\bar{s_n}$ suggests low item uncertainty, indicating widespread user acceptance, and whole low $\bar{s_n}$ indicates higher uncertainty.&lt;/p&gt;

&lt;p&gt;In order to bridge the gap between cold and warm items’ distribution and popularity bias all interactions with $d_ {mn}&amp;lt;\alpha  \bar{s_n}$ will be regarded as uncertain interactions and filtered in the generation stage. So the selection would be as follow:&lt;/p&gt;

&lt;p&gt;$\hat{O_ {n}}={I(d_ {mn}&amp;gt;\alpha  \bar{s_n})}$,&lt;/p&gt;

&lt;p&gt;where $\alpha$ is a pre-defined parameter and $I$ is the indicator function.&lt;/p&gt;

&lt;p&gt;In other words, they find the average ranking score for an item for all users ($\bar{s_n}$) and then for each user if item-user similarity ($d_ {mn}$) is smaller than $\alpha  \bar{s_n}$ they regard that interaction as uncertain.&lt;/p&gt;

&lt;h3 id=&quot;32-teacher-student-consistency-learning&quot;&gt;3.2. Teacher-student Consistency learning&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/2qjj3J0/figure1.png&quot; alt=&quot;figure1&quot; /&gt;
To address seesaw phenomena, and to achieve better recommendations for both warm and cold items at the same time, cold-item with generated low-uncertainty interactions should have a similar distribution with the warm items, so in this paper, they trained the teacher model (generator) and student model (recommender) with consistency learning&lt;/p&gt;

&lt;p&gt;trained the teacher model (generator) and student model (recommender) with consistency learning&lt;/p&gt;

&lt;p&gt;we train the teacher model (generator) and student model (recommender) with consistency learning, to ensure the cold items with additionally generated low-uncertainty interactions can have similar distribution with the warm items.&lt;/p&gt;

&lt;h4 id=&quot;321-item-level-consistency-learning&quot;&gt;3.2.1 Item-level consistency learning&lt;/h4&gt;

&lt;p&gt;This technique employs a contrastive loss to compare item embeddings before and after a generation process.&lt;/p&gt;

&lt;p&gt;Two types of augmentations are used:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Weak Augmentation:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this, edges in a graph are dropped out based on a dropout ratio $\rho$ to make the model more robust and less sensitive to specific data points. It can be formulated as follows:&lt;/p&gt;

&lt;p&gt;${\mathcal G}^{w}=({\mathcal V},{\mathcal M}\cdot{\mathcal O}^{+})$ where $\mathcal{M}\in{0,1}^{\vert O^{+}}$ is a masking vector.&lt;/p&gt;

&lt;p&gt;For example, in the movie recommendation system, if you always include the same user’s connection to a particular movie, the model might become too biased towards that user’s preferences. By using dropout, you randomly exclude some user-movie connections in each training iteration, making the model more balanced and better at recommending movies for a variety of users.&lt;/p&gt;

&lt;p&gt;Where M is a masking vector containing binary values {0, 1} for each element in O+.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Strong Augmentation:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This type involves adding more edges to the graph based on generated labels and can be formulated as follows:&lt;/p&gt;

&lt;p&gt;${\mathcal G}^{s}=({\mathcal V},{\mathcal O}^{+} +{\widehat O})$&lt;/p&gt;

&lt;p&gt;For example, if two movies share many common actors or are often rated similarly by users, strong augmentation would introduce more connections between those movies in the recommendation graph. This enriches the information available to the model, allowing it to make more accurate and diverse movie recommendations.&lt;/p&gt;

&lt;p&gt;These two augmentation operations create two different views for each node, denoted as $z_i^{\prime},z_i^{\prime\prime}$ 𝑖 (for weak and strong graphs, respectively).&lt;/p&gt;

&lt;p&gt;Consistency Regularization: To encourage the similarity between the different views of the same node, a consistency regularization is implemented. This involves the use of a contrastive loss:&lt;/p&gt;

&lt;p&gt;$\mathcal{L}_ {cr, item}=\sum_ {i\in I}-\log\frac{\exp(sim(z_i’,z_i’’)/\tau)}{\sum_ {j\in I}\exp(sim(z_i’,z_j’’)/\tau)}$,&lt;/p&gt;

&lt;p&gt;where $\mathcal{L}_ {cr, item}$ represents the item-side consistency regularization loss for both the teacher and the student model, $sim()$ is cosine similarity function and $\tau$ is a predefined hyper-parameter.Similarly, $\mathcal{L}_ {cr, user}$ can be computed. $\mathcal{L}_ {cr}=\mathcal{L}_ {cr, item}+\mathcal{L}_ {cr, user}$ represents the ultimate consistency loss used for consistency regularization.&lt;/p&gt;

&lt;p&gt;Recommendation loss can be calculated as follow:&lt;/p&gt;

&lt;p&gt;$\mathcal{L}_ {\mathbf{rec}}=\sum_ {(u,i^+,i^-)\in O}-\ln\sigma(\hat{y}_ {ui^+}-\hat{y}_ {ui^-})+\lambda\vert  \vert  \Theta\vert  \vert _2^2,$ is L2-regularization of model’s parameters.&lt;/p&gt;

&lt;p&gt;And Finally, our total loss is $\mathcal{L}_ {total}=\mathcal{L}_ {rec}+\mu\mathcal{L}_ {cr}$ where $\mu$ is a hyper-parameter.&lt;/p&gt;

&lt;h4 id=&quot;322-model-level-consistency-learning&quot;&gt;3.2.2 Model-level consistency learning&lt;/h4&gt;

&lt;p&gt;To keep the consistency between the teacher model and student, they suggested collecting the teacher embedding into the student embedding:&lt;/p&gt;

&lt;p&gt;$\mathbf{E}^s\leftarrow\gamma\mathbf{E}^s+(1-\gamma)\mathbf{E}^t$&lt;/p&gt;

&lt;p&gt;where $E^s$ and $E^t$ are the embeddings of the student and student model’s embedding respectively.&lt;/p&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;experiment-setup&quot;&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Datasets:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Experiments on Yelp and Amazon-Book benchmark datasets.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Follow a 10-core setting as in previous studies (Lightgcn and Neural collaborative filtering)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Split user-item interactions into training, validation, and testing sets (ratio 7:1:2).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Baselines:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The foundation for our GNN-based model is LightGCN 
&lt;em&gt;- Quick review on LightGCN:&lt;/em&gt; 
&lt;em&gt;LightGCN is a simplified and highly efficient approach to recommendation systems, acting as a streamlined version of Graph Convolutional Networks (GCN). It centers its operation on the connections within a recommendation graph, mainly between users and items. In this graph, users and items are represented as nodes, while interactions are depicted as edges. LightGCN starts by initializing embeddings for both users and items, encapsulating their latent characteristics. This algorithm then performs multiple layers of message passing within the graph. During each layer, user embeddings are updated based on the embeddings of the connected items, and vice versa. The simplicity of LightGCN’s update rule is striking; it merely aggregates neighbor embeddings, eschewing complex transformations, often taking the straightforward approach of averaging the embeddings of connected items in a single layer. By repeatedly executing these message-passing iterations, LightGCN ultimately generates user and item embeddings that capture the collaborative filtering signals, facilitating enhanced recommendations. The elegance of LightGCN lies in its computational efficiency, making it particularly advantageous for large-scale recommendation tasks, all the while focusing on the fundamental relationships between users and items within the recommendation graph.&lt;/em&gt;&lt;a href=&quot;https://doi.org/10.48550/arXiv.2002.02126&quot;&gt;read more here&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Focused on modelling user-item interactions, not item features.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;They used two types of recommendation models, the Generative model and Denoising models for user-item interactions: IRBPR, ADT, and SGL.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Evaluation Metric&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Following previous studies, they evaluate performance using Recall@K and NDCG@K where K = 20&lt;/p&gt;

&lt;h3 id=&quot;result&quot;&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;The overall results are shown in Table 1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/5F54hKF/table1.png&quot; alt=&quot;Table1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This table shows how UCC outperforms previous models.&lt;/p&gt;

&lt;p&gt;The paper conducts a comparative analysis between the proposed method and LightGCN in the context of cold-start recommendation. Items are categorized into ten groups based on popularity, ensuring equal interaction numbers for each group. The last two groups represent cold-start items, with higher GroupID values indicating warmer items. The following figures show how UCC has better performance in all groups&lt;/p&gt;

&lt;p&gt;Unlike other methods that often sacrifice warm item accuracy to improve cold items, the proposed method notably enhances the recall of LightGCN, especially for cold items. For instance, on the Yelp dataset, the proposed method achieves nearly a 7-fold increase in recall compared to LightGCN. The most significant improvement is observed for group-id 1 items in Amazon-Book, with recall improving by 400%, underscoring the method’s effectiveness in addressing cold-start recommendation challenges and highlighting the “seesaw phenomenon” problem.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/j87vzrD/figure2.png&quot; alt=&quot;figure2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In their ablation study, the result shows that the number of generated interactions is adaptive for different item groups. It notes that low-uncertainty interactions, which are more abundant for cold items, help alleviate the distribution difference between warm and cold items. Using item-side-generated interactions significantly improves performance, while user-side-generated interactions exacerbate the distribution gap. This underscores the effectiveness of the uncertainty-aware interaction generation component. Also, as shown in the following figure teacher-student learning outperforms other methods.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/HhYyCx0/figure3.png&quot; alt=&quot;figure3&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;This paper tackles the Cold-Start problem in recommendation systems by introducing the Uncertainty-aware Consistency Learning framework (UCC). UCC’s Uncertainty-aware Interaction Generation effectively bridges the gap between cold and warm items, resulting in notable improvements in recommendation performance.&lt;/p&gt;

&lt;p&gt;The Teacher-Student Consistency Learning component further enhances recommendation quality, addressing the seesaw phenomenon. Extensive ablation studies and experiments on benchmark datasets showcase the effectiveness of the UCC model, consistently outperforming existing approaches, especially in improving recall for cold items. This paper offers a promising solution to enhance recommendation systems, particularly in dynamic settings.&lt;/p&gt;

&lt;p&gt;However, it may face challenges related to complexity, scalability, and generalizability, and a broader evaluation with diverse datasets and consideration of interpretability is needed to establish its practical applicability. Additionally, a more in-depth analysis of its performance compared to a wider range of state-of-the-art approaches would provide a more comprehensive understanding of its competitiveness.&lt;/p&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Mahsa Aghazadeh&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Affiliation: &lt;a href=&quot;http://hfel.kaist.ac.kr/&quot;&gt;Human Factors and Ergonomics Lab&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Research Topic: Human Computer Interaction (HCI), Ergonomics, VR/AR&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Contact: mahsa_agz@kaist.ac.kr&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 20 Nov 2023 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2023-11-20-Uncertainty-aware_Consistency_Learning_for_Cold-Start_Item_Recommendation.html</link>
            <guid isPermaLink="true">http://localhost:4000/2023-11-20-Uncertainty-aware_Consistency_Learning_for_Cold-Start_Item_Recommendation.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[RecSys 2023] Trending Now: Modeling Trend Recommendations</title>
            <description>&lt;p&gt;&lt;strong&gt;[Recsys 2023] Trending Now: Modeling Trend Recommendations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Info&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;▢   &lt;strong&gt;Authors&lt;/strong&gt; : AWS AI Labs, Amazon USA&lt;/p&gt;

&lt;p&gt;▢   &lt;strong&gt;Research topic&lt;/strong&gt; : Trending now (현재 인기있는 상품을 추천하는 추천시스템)&lt;/p&gt;

&lt;p&gt;▢   &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3604915.3608810&quot;&gt;paper links&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Research Motivation &amp;amp; 논문 선정 이유&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;최근 추천시스템에서는 일반적으로 “현재 인기있는 상품 (trending now)” 과 같은 별도의 추천 항목을 제시해주어 해당 상품의 인기를 높여 활성유저를 유치하고 있습니다. 그러나 일반적으로 “시간 간격 내 interaction 수” 와 같은 단순한 휴리스틱 방법을 기반으로 추천해주기 때문에 rich-get-richer (인기있는 상품만 더 노출되어 더 많은 인기를 얻는) 문제 등 개선의 여지가 많이 남아있으며, 추천시스템에서 trend 를 모델링하는 연구는 제한적으로 이루어져 있습니다. 따라서 해당 논문은 &lt;strong&gt;시계열 예측&lt;/strong&gt; 이라는 새로운 관점에서 &lt;strong&gt;trend 를 반영한 추천시스템 모델을 제안&lt;/strong&gt;합니다. item trendiness 에 대한 정의를 통해 trend recommendation task 를 &lt;strong&gt;one-step time series forecasting&lt;/strong&gt; 문제로 공식화합니다. item 의 미래 trend 를 예측하고 추천 리스트를 생성하는 deep latent variable 모델인 &lt;strong&gt;TrendRec&lt;/strong&gt; 을 제안합니다.
현재 시점에서의 trend 를 파악하고 유저에게 관련 item 을 추천하는 것을 시계열 예측으로 접근한 관점이 신선했고, “acceleration” 이라는 개념을 정의하여 인기가 “빠르게 상승” 하고 있고 가까운 미래에 인기를 얻을 가능성이 있는 item 을 추천한다는 아이디어가 참신한 것 같아 해당 논문을 선정하게 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-introudction&quot;&gt;1. Introudction&lt;/h3&gt;

&lt;h4 id=&quot;1--definition&quot;&gt;1-①. Definition&lt;/h4&gt;

&lt;h5 id=&quot;-용어정의&quot;&gt;▶ 용어정의&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;용어&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Popularity&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;특정 시간 간격 내에 발생한 interaction 수&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;trend in the recommendation context&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;인기도 (popularity) 또는 가속도 (acceleration)의 &lt;strong&gt;변화율&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;trending now&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;현재 시점에서 점점 더 많은 interaction 이 발생하는 item list 이지만, 해당 item 들은 반드시 가장 인기있는 item 을 뜻하진 않는다. 아직 인기가 높지 않은 유망한 trending up item 에 대한 탐색이 가능하므로 popularity bias 없이 효과적으로 item 을 추천한다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;-trending-now-의-target-item-예시&quot;&gt;▶ trending now 의 target item 예시&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Example&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;•  최근 출시된 좋은 품질의 cold items (ex. 왕좌의 게임 새로운 에피소드) = Recently released cold items of good quality&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;•  갑작스러운 변화가 발생하는 항목 (ex. 영화가 오스카상을 수상하여 갑자기 유행하는 경우) = Items experiencing sudden changes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;•  주기적으로 유행하는 오래 지속되는 품목 (ex. 겨울의류와 같이 계절적인 영향을 받는 품목) = Long lasting items with periodic up-trend&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1--challenge&quot;&gt;1-②. Challenge&lt;/h4&gt;

&lt;p&gt;▢  &lt;strong&gt;Problem&lt;/strong&gt;: 현재 trend 를 안정적이고 신뢰성 있게 파악하기 위해서는 충분한 interaction 을 수집하는 데 일정 시간이 필요하나, trend 는 정의 특성상 역동적으로 변화하고 데이터 수집 기간 동안 변동이 있을 수 있다.&lt;/p&gt;

&lt;p&gt;▢  &lt;strong&gt;Solution&lt;/strong&gt; : trend recommendation 을 one-step forecasting problem 으로 공식화한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1--problem-setting--one-step-forecasting-problem&quot;&gt;1-③. Problem setting : One-step forecasting problem&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/N6sr5Wx/fig1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;▢ (왼쪽 그래프) 과거 item 의 trend 변화가 주어지면, &lt;strong&gt;다음 시간 단계에 어떤 item 이 유행할지 예측 (→ One-step forecasting)&lt;/strong&gt; 하는 것을 목표로 한다. 모델이 다음 시간 단계에서 유행하는 item 을 예측하면, 백엔드에서 데이터를 버퍼링하면서 다음 시간 단계 내 user 에게 해당 item 을 표시한다. 다음 시간 단계가 끝나면 모델은 새로 축적된 데이터를 기반으로 바로 다음 시간 단계에 대한 새로운 예측을 수행한다. 또 다른 데이터 수집의 주기를 시작하는 것으로 추천을 반복한다.&lt;/p&gt;

&lt;p&gt;▢ (오른쪽 그래프) 특정 use case 에 대한 최적화된 트렌드 추천을 설계하려면 기존의 시계열 예측 모델을 기반으로 구축할 수 있다. 더불어 시계열 예측 모델 외에도 추천 상황의 고유한 속성이 활용될 수 있다. 시계열에서 각 item 에 대한 대략적인 누적 interaction 수 외에도 더 세분화된 user-item 간 interaction 이 존재한다. 특정 item 에 대해 얼마나 많은 user 가 해당 item 과 상호작용 했는지 알 수 있을 뿐 아니라 이러한 user 가 정확히 누구인지도 알 수 있다. 이는 item 간 근본적인 상관관계를 파악하는 데 도움이 되는 추가적인 정보를 제공하며 &lt;strong&gt;user 가 많이 겹치는 item 은 공통 trend 패턴을 공유 할 수 있으므로 trend 예측의 정확도를 높일&lt;/strong&gt; 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-preliminaries&quot;&gt;2. Preliminaries&lt;/h3&gt;

&lt;h4 id=&quot;2--term-definition&quot;&gt;2-①. Term Definition&lt;/h4&gt;

&lt;h5 id=&quot;-용어정의-1&quot;&gt;▶ 용어정의&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;용어&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
      &lt;th&gt;표기&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Time Step&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;미리 정의한 시간 간격 (ex. 한시간)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Δ𝑡&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Velocity&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;item j 에 대해서, time step t 동안 수집된 interaction 수를 time step t 에서의 velocity 로 정의 (unit time Δ𝑡 당 item j 의 popularity)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;W𝑗𝑡&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Acceleration&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;time step t 에서의 item j 에 대한 acceleration. item j 의 velocity 가 단위 시간 Δ𝑡당 ΔW𝑗𝑡씩 &lt;strong&gt;변화&lt;/strong&gt;하고 있음을 나타낸다 (&lt;strong&gt;변화량&lt;/strong&gt;).&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;A𝑗𝑡&lt;/strong&gt; = &lt;strong&gt;ΔW𝑗𝑡&lt;/strong&gt; = W𝑗(𝑡) - W𝑗(𝑡-1)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;-acceleration--trend&quot;&gt;▶ &lt;strong&gt;Acceleration = Trend&lt;/strong&gt;&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;item 𝑗 의 시간 단계 𝑡 에서의  acceleration A𝑗𝑡 가 &lt;strong&gt;모든 item 의 acceleration 중 가장 높으면&lt;/strong&gt; 해당 item 은 시간 단계 𝑡에서 &lt;strong&gt;trendy 한 것으로 간주&lt;/strong&gt;한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;2--problem-definition&quot;&gt;2-②. Problem Definition&lt;/h4&gt;

&lt;h5 id=&quot;-적절한-time-interval-ex-향후-1시간-trend-item-향후-하루동안-trend-item-이-관건이다&quot;&gt;▶ 적절한 Time interval (ex. 향후 1시간 trend item, 향후 하루동안 trend item) 이 관건이다.&lt;/h5&gt;

&lt;p&gt;현재 trend 를 빠르게 감지하고 실시간으로 인기 있는 item 을 추천하는 것이 이상적이다. 이를 위해선 충분한 interaction 을 축적하는데 일정 시간이 필요하면서도, trend 는 동적으로 변화하면서 (dynamic variations) 데이터 수집 과정에서 시간적 변동 (temporal drift) 있는 것이 특징이기 때문에 적절한 time interval Δt 를 설정하는 것이 중요하다. Δt 가 너무 작다면 수집된 데이터가 불충분하여 noisy 가 발생할 수 있고, 너무 크다면 시간적 변동성이 발생해 예측 성능이 낮아질 수 있다. 따라서 데이터에 맞는 feasible 하고 short 한 적절한 time interval 을 찾는 것이 중요하다.&lt;/p&gt;

&lt;h5 id=&quot;-시간-단계-길이-time-step-length-와-작업-실행-가능성-task-feasibility-간의-상관-관계에-대한-가설&quot;&gt;▶ 시간 단계 길이 (time step length) 와 작업 실행 가능성 (task feasibility) 간의 상관 관계에 대한 가설&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;bias-variance tradeoff&lt;/strong&gt; : 시간 단계 길이가 짧으면(예: 1시간) 데이터 희소성 (data sparsity) 으로 인해 variance 가 발생하고, 시간 단계 길이가 길면(예: 하루) 시간적 드리프트 (temporal drift 시간에 따른 변동) 로 인해 편향이 발생한다. 따라서 둘 사이의 균형을 잘 맞출 수 있는 sweet spot 을 찾아야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/8613tW1/fig3.png&quot; alt=&quot;fig3&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;-one-step-time-series-forecasting-task&quot;&gt;▶ one-step time series forecasting task&lt;/h5&gt;

&lt;p&gt;trend recommendation task 를 one-step time series forecasting 문제로 정의한다. 각 item 대해 주어진 &lt;strong&gt;historical acceleration&lt;/strong&gt; [A𝑗0, A𝑗1, . . . , A𝑗𝑡] := &lt;strong&gt;A𝑗,0:𝑡&lt;/strong&gt; 과, covariates 와 같은 추가적인 &lt;strong&gt;contextual information&lt;/strong&gt; [C𝑗0, C𝑗1, . . . , C𝑗𝑡] := &lt;strong&gt;C𝑗,0:t&lt;/strong&gt; 가 주어졌을 때, 다음 step 인 (t+1) 에서의 acceleration 을 예측하기를 원한다. 그리고 trend prediction 을 기반으로 상위 k 개의 아이템을 추천한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/gVBST8w/fig2.png&quot; alt=&quot;fig2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;2--baseline-model&quot;&gt;2-③. Baseline model&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;널리 채택된 두 가지 휴리스틱 모델을 설명한 다음 일반적인 형태의 딥러닝 기반 확률론적 시계열 예측 모델을 baseline model 로 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-1-markov-heuristic-model&quot;&gt;▶ (1) Markov Heuristic Model&lt;/h5&gt;

&lt;p&gt;임의의 item j 의 next time step 의 acceleration A𝑗 (𝑡+1) 는 “오직” 현재 time step 의 acceleration A𝑗t 에 의존한다고 가정한다. 실제로 acceleration 는  짧은 시간 동안 동일하게 유지되는 경향이 있으므로 마르코프 휴리스틱 모델을 다음과 같이 정의한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/FXrwj30/fig4.png&quot; alt=&quot;fig4&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Aˆ𝑗 (𝑡+1) = next time step 에서 예측된 acceleration&lt;/li&gt;
  &lt;li&gt;Auto regressive model (AR) 의 special case 로도 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-2-exponential-moving-average-ema-heuristic-model&quot;&gt;▶ (2) Exponential Moving Average (EMA) Heuristic Model&lt;/h5&gt;

&lt;p&gt;마르코프 휴리스틱 모델의 가장 큰 단점은 다음 시간 단계의 item acceleration 이 현재 시간 단계의 영향을 받기 때문에 데이터 희소성 등의 문제로 인해 노이즈가 발생할 수 있다는 것이다. 따라서 여러 개의 최신 시간 단계를 고려하여 더 최근의 시간 단계에 더 많은 가중치를 할당하는 지수이동평균 휴리스틱 모델을 정의할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/7yZxLch/fig5.png&quot; alt=&quot;fig5&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Aˆ𝑗 (𝑡+1) = next time step 에서 예측된 acceleration&lt;/li&gt;
  &lt;li&gt;T : 모델이 고려하고 있는 최근 시간 단계 수&lt;/li&gt;
  &lt;li&gt;wk : 현재 시간 step 에서 멀어질수록 기하급수적으로 감소하는 미리 정의된 가중치&lt;/li&gt;
  &lt;li&gt;ARIMA model 의 special case 로 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-3-deep-learning-based-time-series-forecasting-model&quot;&gt;▶ (3) Deep Learning based Time Series Forecasting Model&lt;/h5&gt;

&lt;p&gt;휴리스틱 모델은 일반적으로 다양한 시나리오에 적응할 수 있는 유연성이 부족한 일반적인 가정 (general assumptions) 을 인코딩한다. 그러나 &lt;strong&gt;acceleration 패턴은 도메인(리테일, 미디어, 뉴스 등)에 따라 다르다&lt;/strong&gt;. 예를 들어, 매주 수요일마다 TV 시리즈의 새 에피소드가 공개되는 것과 같이 리테일과 미디어 영역 모두에서 다양한 주기(일별, 주별, 계절별 등)의 주기적 acceleration  패턴이 풍부하게 존재한다. 반대로 뉴스는 시간에 민감하고 사람들은 가장 최근 뉴스를 팔로우하는 경향이 있기 때문에 뉴스 영역에서는 이러한 규칙적인 acceleration  패턴이 거의 관찰되지 않는다. 또한 같은 도메인 내에서도 다양한 acceleration  패턴이 공존할 수 있다. 예를 들어, 특정 영화 플랫폼에서 새로 개봉한 액션 영화의 acceleration 곡선은 해당 플랫폼 사용자 커뮤니티의 선호도에 따라 새로 개봉한 다큐멘터리 영화의 acceleration 곡선에 비해 지속적으로 가파른 증가세를 보일 수 있다. 따라서 &lt;strong&gt;트렌드 추천을 위한 보다 일반적인 솔루션은 다양한 시나리오에 적응할 수 있는 학습 가능한 딥러닝 기반 시계열 예측 모델을 설계&lt;/strong&gt;하는 것이다. 모델을 공식화하면 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/vc5k5JC/fig6.png&quot; alt=&quot;fig6&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;𝑓seq (·) : 과거 acceleration  를 집계하고 다음 시간 단계에서 acceleration  의 확률적 분포를 예측하는 순차적 모델로 DeepAR, RNN, MQCNN, TFT 등이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-model--collaborative-time-series-forecasting-model-with-user-item-interactions-trendrec&quot;&gt;3. Model : collaborative time series forecasting model with user-item interactions (TRENDREC)&lt;/h3&gt;

&lt;h4 id=&quot;3--two-phase-framework&quot;&gt;3-①. Two-phase framework&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;phase&lt;/th&gt;
      &lt;th&gt;objective&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;1. 다음 item 추천&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;보조적인 목표로 하여, TrendRec은 user-item 간 interactive signal 을 활용하여 item 간의 기본 상관관계를 감지하고 이러한 지식을 item embedding 으로 인코딩한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;2. 다음 time step 의 trend (=acceleration) 예측&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;학습된 item embedding 을 사용하여 시계열 예측 목표를 위해 각 시계열에 대한 추가 context 를 제공한다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3--model-overview&quot;&gt;3-②. Model overview&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;TrendRec : RecSys + Time series forecasting&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;추천 모델은 user-item interaction 을 통해 다음 아이템 추천 objective 를 학습한다.
    &lt;ul&gt;
      &lt;li&gt;item feature 에 대한 representation learning 을 통해 dense latent item embedding 을 생성한다. 이를 통해 item 간 correlation 을 파악하여 시계열 예측에 대한 추가적인 context 를 제공한다. Item correlation 을 인코딩하는 shared latent item embeddings 을 통해 두 objectives 가 연결된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;시계열 예측 모델은 item의 accelerations 를 사용하여 다음 단계 acceleration 예측 objective 에 대해 학습한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;probabilistic graphical model (PGM)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/yVDd9qx/fig7.png&quot; alt=&quot;fig7&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;-노드&quot;&gt;▸ &lt;strong&gt;노드&lt;/strong&gt;&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;표기&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;V𝑗t ∈ R(D)&lt;/td&gt;
      &lt;td&gt;∘  &lt;strong&gt;item 𝑗&lt;/strong&gt; 의 속성은 시간 단계 t 까지의 정적속성과 동적속성을 모두 포함한다. &lt;br /&gt; ∘  𝐷 는 embedding 의 hidden dimension &lt;br /&gt; ∘ &lt;strong&gt;latent item embedding&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;𝜆v&lt;/td&gt;
      &lt;td&gt;∘ latent item embedding 의 분산 분포와 관련된 &lt;strong&gt;hyperparameter&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;A𝑗,0:t ∈ R(𝑁𝑗t)&lt;/td&gt;
      &lt;td&gt;∘ t 시점까지 item 𝑗 의 과거 acceleration : [A𝑗0, A𝑗1, . . . ,A𝑗𝑡]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;A𝑗(𝑡+1) ∈ R&lt;/td&gt;
      &lt;td&gt;∘  다음 시간 단계 t+1 에서의 item j 의 acceleration&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;𝑁𝑗t&lt;/td&gt;
      &lt;td&gt;∘  time step t 까지 item  𝑗 의 과거 time step 의 개수&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;U𝑖t ∈ R(D)&lt;/td&gt;
      &lt;td&gt;∘ time step t 까지 &lt;strong&gt;user 𝑖’s interests&lt;/strong&gt;  &lt;br /&gt; ∘  &lt;strong&gt;latent user embedding&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;𝜆u&lt;/td&gt;
      &lt;td&gt;∘  latent user embedding 의 분산 분포와 관련된 &lt;strong&gt;hyperparameter&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;S𝑖t ∈ R(N𝑖t x D)&lt;/td&gt;
      &lt;td&gt;∘ t 시점까지의 유저 𝑖의 과거 interaction sequence&lt;br /&gt; ∘  임베딩 행렬의 각 행은 item 임베딩을 나타낸다&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;𝑁𝑖t&lt;/td&gt;
      &lt;td&gt;∘  t 시점까지 user 𝑖 로부터 발생하는 interaction 개수&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;R𝑖𝑗t ∈ {0, 1}&lt;/td&gt;
      &lt;td&gt;∘ t 시점에서 item 𝑗 와 user 𝑖 사이에 interaction 이 발생했는지 여부를 나타낸   &lt;strong&gt;interaction label&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;-엣지&quot;&gt;▸ &lt;strong&gt;엣지&lt;/strong&gt;&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;표기&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Edge S𝑖𝑡 → U𝑖t&lt;/td&gt;
      &lt;td&gt;∘  user 의 이전 interactions 는 user 의 interest 를 표현하며, 이는 user의 다음 행동에 영향을 미친다. &lt;br /&gt; ∘  ex. 휴대폰을 구매한 사용자가 다음에 휴대폰 액세서리를 구매할 수 있다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edge {U𝑖𝑡, V𝑗𝑡} → R𝑖𝑗𝑡&lt;/td&gt;
      &lt;td&gt;∘  Interaction 은 user interests U𝑖𝑡 와 item properties V𝑗t 에 따라 달라진다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edge {V𝑗𝑡, A𝑗,0:𝑡 } → A𝑗 (𝑡+1)&lt;/td&gt;
      &lt;td&gt;∘ 다음 시간 단계 𝑡 +1에서 아이템 𝑖의 acceleration 는 item feature 와 item 의 과거 acceleration 에 영향을 받는다. &lt;br /&gt; ∘ ex. 액션 영화는 특정 웹사이트의 사용자 커뮤니티에서 트렌드가 될 가능성이 높다. &lt;br /&gt; ∘ ex. 주간 trend 패턴이 주기적으로 나타나는 item&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;-generative-process&quot;&gt;▸ &lt;strong&gt;Generative process&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;평균이 𝝁 그리고 분산이 diagonal covariance λ&lt;sup&gt;-1&lt;/sup&gt;ⅠD 인 가우시안 분포에서 latent offset vector 를 설정하여 latent item embedding 과 latent user embedding 을 계산한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/xsMpXM4/fig8.png&quot; alt=&quot;fig8&quot; /&gt;&lt;/p&gt;

&lt;p&gt;자세한 도출 과정은 아래와 같다.&lt;/p&gt;

&lt;p&gt;For each time step 𝑡 ∈ [𝑇]&lt;/p&gt;

&lt;p&gt;∘  For each item j ∈ [𝐽] ⇨ latent item offset vector ϵjt ~ N(0, λ&lt;sup&gt;-1&lt;/sup&gt;ⅠD) 를 설정하고, latent item offset vector 를 latent item embedding 으로 채택한다 ⇨ V𝑗𝑡 = ϵ𝑗𝑡&lt;/p&gt;

&lt;p&gt;∘  For each user i ∈ [𝐼] ⇨ latent user offset vector ϵit ~ N(0, λ&lt;sup&gt;-1&lt;/sup&gt;ⅠD) 를 설정하고, GRU4Rec 을 통해 얻은 user embedding n𝑖𝑡 = 𝑓seq (S𝑖𝑡) 을 더해 latent user embedding 을 계산한다 ⇨ U𝑖𝑡 = ϵ𝑖𝑡 + n𝑖𝑡&lt;/p&gt;

&lt;p&gt;R𝑖𝑗t 를 구하기 위해서 softmax function 을 latent user embedding 와 latent item embedding 을 내적한 값에 적용하여 recommendation score (Y𝑖𝑗𝑡) 를 계산한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Y𝑖𝑗𝑡 = 𝑓softmax(U’𝑖𝑡•V𝑗𝑡)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;user i 에 대해 모든 아이템에 대한 recommendation score (R𝑖∗𝑡) 를 계산한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;R𝑖∗𝑡 ~ 𝐶𝑎𝑡([Y𝑖𝑗𝑡]), j: 1,,..,J , 𝐶𝑎𝑡 is categorical distribution.&lt;/li&gt;
  &lt;li&gt;∗ 는 특정 차원에 있는 모든 요소의 집합을 나타낸다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3--training&quot;&gt;3-③. Training&lt;/h4&gt;

&lt;h5 id=&quot;-maximum-a-posteriori-map-estimation&quot;&gt;▸ &lt;strong&gt;Maximum a Posteriori (MAP) Estimation&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;maximum a posteriori (MAP) estimation&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/r2YHhD7/fig11.png&quot; alt=&quot;fig11&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다음 item 을 추천하는 것에 있어서 interaction R𝑖𝑗t 에 대한 조건부 확률을 다음과 같이 정의한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/djW18N7/fig9.png&quot; alt=&quot;fig9&quot; /&gt;&lt;/p&gt;

&lt;p&gt;item accelerations A𝑗(𝑡+1) 에 대한 조건부 확률을 다음과 같이 정의한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/cgTNhX0/fig10.png&quot; alt=&quot;fig10&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;𝑓𝑡𝑠 (·) : 다음 시간 단계 𝑡에서 acceleration 의 확률적 분포를 예측하기 위해 item 의 과거 acceleration 와 latent item embedding 을 모두 사용하는 모든 유형의 확률론적 시계열 예측 모델&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-negative-log-likelihood-nll&quot;&gt;▸ &lt;strong&gt;Negative Log Likelihood (NLL)&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;posterior probability 를 최대화 하는 것은 negative log likelihood 를 최소화하는 것과 같다. NLL 은 다음과 같이 계산할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/d5z24HJ/fig12.png&quot; alt=&quot;fig12&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(10) : Next Item Recommendation Loss → 이를 최소화하면 학습 세트에서 다음 항목 추천 성능이 향상된다.&lt;/li&gt;
  &lt;li&gt;(11) : Time Series Forecasting Loss → 이 term 을 최소화하면 훈련 세트에서 acceleration 예측이 향상된다.&lt;/li&gt;
  &lt;li&gt;(12) : Regularizing Latent Item Embedding V𝑗t and Latent User Embedding U𝑖t  →  V𝑗t 를 zero-mean Gaussian prior 에 근접하게 정규화하고 U𝑖𝑡 를 유저의 과거이력이 유저의 흥미를 나타낸다고 가정하고, 계산된  𝑓seq (S𝑖𝑡) likelihood function adopted by the probabilistic time series forecasting model에 근접하게 정규화한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3--inference&quot;&gt;3-④. Inference&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/K24SvyK/fig13.png&quot; alt=&quot;fig13&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;V*jt : the posterior of item j’s latent item embedding&lt;/li&gt;
  &lt;li&gt;𝑓∗ts (·) : the trained sequential time series forecasting model&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3--model-architecture&quot;&gt;3-⑤. Model architecture&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/YkTR6LN/fig14.png&quot; alt=&quot;fig14&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;왼쪽그림 : overview network structure&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;오른쪽그림 : figure visualizes the full details of the TrendRec implementation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;the model contains two principal components
    &lt;ul&gt;
      &lt;li&gt;(1) a sequential recommender :   &lt;strong&gt;R𝑖𝑗t&lt;/strong&gt; ⇨  recommendation score 는 latent user embedding U𝑖t 과 latent item embedding V𝑗t 사이의 내적 곱을 기반으로 계산된다.&lt;/li&gt;
      &lt;li&gt;(2) collaborative time series forecasting model :   &lt;strong&gt;A𝑗(𝑡+1)&lt;/strong&gt; ⇨  다음 item 추천 (1) 과정에서 pre-trained 된 latent item embedding 을 가져와 item historical acceleration 와 함께 활용하여 다음 시간 단계에서의 acceleration 를 예측한다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;→ 2가지 요소는 학습가능한 latent item embedding 을 통해 join 된다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-experiments&quot;&gt;4. Experiments&lt;/h3&gt;

&lt;p&gt;▢ &lt;strong&gt;Research question&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Research question&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Q1&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;task feasibility 와 time step length 의 correlations 에 대해 제안한 가설 (적절한 Δ𝑡 의 존재) 이 적용되는지, 각 dataset 의 time step length 는 어떻게 선택해야 하는지&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Q2&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;TrendRec이 휴리스틱 모델과 기본적인 딥러닝 기반 시계열 예측 모델을 포함한 모든 기준 모델보다 성능이 우수한지&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4--datasets&quot;&gt;4-①. Datasets&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/sVpgrZ4/fig15.png&quot; alt=&quot;fig15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;리테일 (TaoBao), 미디어(Netflix), 뉴스(MIND)를 포함한 다양한 도메인의 데이터를 이용
    &lt;ul&gt;
      &lt;li&gt;TaoBao 의 경우  아이템 카테고리가 크기 때문에 , 3개의 구분된 데이터셋을 구조화하기 위해 인터랙션 수를 기반으로 상위 3개의 아이템 카테고리를 선택한다 → TaoBao Cat1, TaoBao Cat2, TaoBao Cat3&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;다음 item 추천 objective 와 시계열 예측 objective 사이에 시간적 누수 (temporal leakage) 가 발생하지 않도록 엄격한 실험설정을 적용 : 모든 training interactions 이 모든 testing interactions 보다 먼저 발생하도록 데이터를 시간적으로 분할하고, training 단계에서 두 objective 에 대해 정확하게 동일한 훈련 데이터셋을 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4--evaluated-methods&quot;&gt;4-②. Evaluated methods&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Methods&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Oracle&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  다음시간 단계에서 실제 정답 (ground truth) 미래 acceleration 에 접근할 수 있다. &lt;br /&gt; ∘  항상 acceleration 을 정확하게 예측하고 상위 k 개의 트렌드 아이템을 추천한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Random&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  전체 아이템 카탈로그에서 replacement 없이 전체 아이템으로부터 random selection 을 하여 아이템을 추천해준다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Exponential moving average (EMA)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  지수이동평균은 최근 m 시간 단계 (latest 𝑚 time steps) 의 acceleration 의 가중치 합을 기반으로 다음 시간 단계의 acceleration 을 예측하는 규칙기반 모델이다. (m=8) &lt;br /&gt;  ∘  가중치는 현재 시간 단계로부터 멀어지는 시간 단계수가 증가함에 따라 0.75의 계수로 기하급수적으로 감소한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;DeepAR&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  auto-regressive RNN 에 기반한 SOTA 시계열 모델 중 하나이다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;TrendRec&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  본 연구에서 제안한 모델로 two-phase 로 이루어져있다. &lt;br /&gt; ∘ 다음 아이템 추천을 위해 GRU4Rec 을 채택해 latent item embedding 을 학습한다. &lt;br /&gt; ∘ 시계열 예측을 위해선 DeepAR 모델을 사용한다. 최신 시계열 예측 모델 중 하나이고, 널리 채택되고 있기 때문이다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4--evaluation-metrics&quot;&gt;4-③. Evaluation metrics&lt;/h4&gt;

&lt;p&gt;시계열 예측 설정에서 RMSE와 같은 평가 지표를 채택하는 대신, 다음 시간 단계에서 트렌드 아이템을 추천하는 트렌드 추천 집합의 목표에 밀접하게 부합하는 평가 지표를 설계한다.&lt;/p&gt;

&lt;h5 id=&quot;-1-acceleration-metric&quot;&gt;▸ (1) Acceleration metric&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/YhrfP9c/fig16.png&quot; alt=&quot;fig16&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델이 예측한 다음 단계 시간 t 의accelerations 에 기반하여 상위 k 개 item 을 선택&lt;/li&gt;
  &lt;li&gt;그런 다음 선택한 𝑘 아이템을 다음 시간 단계 𝑡에서 해당 ground truth acceleration 에 다음과 같이 맵핑&lt;/li&gt;
  &lt;li&gt;acceleration 이 trend 의 정량적인 측정 (quantitative measurement) 이기 때문에 item 의 다음 시간 단계의 예측한 acceleration 의 총합 (sum) 으로 계산하고 모델의 trendiness score 로 사용
    &lt;ul&gt;
      &lt;li&gt;값이 높을수록 모델은 다음 시간 단계에서의 트렌드한 아이템에 대한 예측을 더 잘한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;[0,1] 사이의 값으로 스케일링을 하기 위해 trendiness score 의 top 에 대해 min-max normalization 을 적용한다. trendiness score 의 upper bound 는 Oracle 모델에서, lower bound 는 Random 모델에서 온다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/WxJDZVJ/fig18.png&quot; alt=&quot;fig18&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;-2-tndcg-metric&quot;&gt;▸ (2) TNDCG Metric&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/n1cqYQh/fig17.png&quot; alt=&quot;fig17&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trendiness-Normalized-DCG (TNDCG) metric : 아이템의 rank position 을 logarithmic reduction factor 로 고려한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/7QFyjGs/fig19.png&quot; alt=&quot;fig19&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;r : index the rank position&lt;/li&gt;
  &lt;li&gt;A&lt;sup&gt;p&lt;/sup&gt;&lt;sub&gt;r&lt;/sub&gt; : acceleration of item ranked at position r based on order from &lt;strong&gt;model prediction (표기 p)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;A&lt;sup&gt;O&lt;/sup&gt;&lt;sub&gt;r&lt;/sub&gt; : acceleration of item ranked at position r based on order from &lt;strong&gt;ground truth (표기 O)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-3-evaluation-protocol&quot;&gt;▸ (3) Evaluation protocol&lt;/h5&gt;

&lt;p&gt;timestamp 를 기준으로 training 과 test step 을 나눈다. 그리고 testing 을 위해 가장 최근의 20% time span 을 남긴다. (예. eight hour training window, two-hour testing window)&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4---hypothesis-validation-q1--적절한-δt-선택하기&quot;&gt;4-④.  Hypothesis validation Q1 : 적절한 Δt 선택하기&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/HhkxtsJ/fig20.png&quot; alt=&quot;fig20&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Markov heuristic model 을 활용해 성능을 평가한다. 간단하지만 generic 한 가정에 기반한 기초적인 모델이고, 따라서 해당 모델의 성능은 task feasibility 를 반영한다. 
결과를 보면, TaoBao 와 MIND 데이터 세트의 곡선은 데이터 희소성 완화로 인해 시간 간격이 길어질수록 acc 지표가 먼저 개선된 다음 temporal drift 로 인해 감소하는 Q1 가설과 일치하는 결과를 보인다. 반면 Netflix 데이터셋의 경우 곡선이 계속 감소하고 있는데, 이는 time stamp 단위가 하루로, 충분한 데이터를 수집할 수 있을 만큼 길지만 temporal drift 가 발생하기 때문이다. 전반적으로 위의 결과는 가설을 입증하고 있다. 각 데이터셋의 시간 간격 &lt;strong&gt;Δ𝑡을 각 곡선의 peak 에 따라 선택&lt;/strong&gt;한다. 일관성을 위해 3개의 TaoBao dataset 은 모두 3시간, Netflix 는 하루, MIND 는 30분 시간간격으로 설정한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4---experimental-results-q2--trendrec-모델의-우수함-증명&quot;&gt;4-⑤.  Experimental results Q2 : TrendRec 모델의 우수함 증명&lt;/h4&gt;

&lt;p&gt;TrendRec 모델을 3개 도메인의 데이터에 대한 다양한 베이스라인모델에 대해 평가한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/ZxSJ9Np/fig21.png&quot; alt=&quot;fig21&quot; /&gt;&lt;/p&gt;

&lt;p&gt;TrendRec 이 가장 좋은 performance 를 보인다. TrendRec 의 시계열 예측 부분이 DeepAR 로 구성되어 있는데, DeepAR 대비 TrendRec 의 성능 향상은, 다음 item 추천 파트에서 얻은 pre-trained 된 latent item embedding 을 활용한 것이 효과적이었음을 보여준다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4---findings&quot;&gt;4-⑥.  Findings&lt;/h4&gt;

&lt;h5 id=&quot;-deep-learning-based-models-significantly-outperform-heuristic-models&quot;&gt;▸ Deep learning based models significantly outperform heuristic models&lt;/h5&gt;

&lt;p&gt;딥러닝 기반의 모델은 휴리스틱 모델보다 성능이 높다. 특히 TaoBao 과 Netflix 데이터셋에 대해 DeepAR 과 TrendRec 과 같은 딥러닝 기반의 모델은 휴리스틱 모델을 큰 차이로 더 성능이 높게 나온다. 해당 결과는 trend 추천을 위해 학습가능한 모델을 채택하는 것의 중요성을 강조한다.&lt;/p&gt;

&lt;h5 id=&quot;-the-ema-model-is-worse-than-the-markov-model-in-most-cases&quot;&gt;▸ The EMA model is worse than the Markov model in most cases&lt;/h5&gt;

&lt;p&gt;EMA 모델은 대부분의 경우에서 마르코프 모델보다 성능이 더 저하되는 결과를 보였다. 이는 trend 가 동적으로 변하고  이러한 결과는, recency bias 를 가진 간단한 가중치합 (weighted sum) 보다, 다음 시간 단계에서의 트렌드와 과거 트렌드 (historical trends) 사이에 의존적인 관계가 보다 더 복잡하다는 것을 의미한다.&lt;/p&gt;

&lt;h5 id=&quot;-performance-gain-from-deep-learning-based-models-is-relatively-small-in-the-news-domain&quot;&gt;▸ Performance gain from deep learning based models is relatively small in the News domain&lt;/h5&gt;

&lt;p&gt;뉴스도메인이 리테일이나 미디어 도메인과 비교했을 때, 딥러닝 기반의 모델과 휴리스틱 모델 사이의 성능 차이는 상대적으로 미미하다. (relatively marginal) 뉴스 도메인의 item 시계열을 분석해 보면 일반적으로 아이템이 출시되면 단기간에 최대 acceleration 에 도달한 후 급격히 하락하는 것으로 나타난다.  이는 주로 시간에 민감한 뉴스의 특성 때문이며, 딥러닝 기반 모델에 큰 도전 과제이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h3&gt;

&lt;h4 id=&quot;5--summary&quot;&gt;5-①. Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;이 연구에서는 추천 시스템에서 잘 다루어지지 않은 주제인 trend recommender 를 연구한다. 선행 연구가 제한적으로 이루어져 있기 때문에 trend 라는 개념을 공식적으로 정의하는 것으로 시작한다 (cf. 1-①. Definition 에서 acceleration 개념을 도입하고 2-①. Term Definition 에서 A𝑗𝑡 로 수식을 통해 구체화 함). 이후 적시에 안정적으로 trend 를 식별하는데 문제가 되는 bias-variance tradeoff 현상을 관찰하여 이를 바탕으로 trend recommendation 을 one-step time series forecasting 로 공식화한다.&lt;/li&gt;
  &lt;li&gt;방법론 측면에서 user-item interactive signal 을 활용하여 item 간 correlation 을 파악하고 이를 바탕으로 trend 예측을 용이하게 하는 TrendRec 이라는 two phase model 을 개발하였다.&lt;/li&gt;
  &lt;li&gt;Recommendation context 에서 trend 의 개념을 공식적으로 정의하고 그에 맞는 평가지표와 평가 프로세스를 수립했다.&lt;/li&gt;
  &lt;li&gt;리테일, 미디어, 뉴스 등 다양한 영역의 데이터셋에 대한 실험으로 통해 TrendRec 모델의 효과를 입증했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;5--opinion&quot;&gt;5-②. Opinion&lt;/h4&gt;

&lt;p&gt;해당 논문은 시계열 예측 모델을 적용하여 trend 한 item set 을 추천해주는 방법론을 제안하고 있습니다. user-item 간 interaction 정보를 바탕으로 item 정보를 embedding 하여, 더 효과적으로 시계열 예측이 가능하도록 모델 구조를 구성하였으며 특히 trend 라는 맥락에서 발생할 수 있는 적절한 time interval 을 설정하는 데 있어 bias-variance tradeoff 문제를 명시하고 관련된 해결책을 제시하고 있습니다. interaction 수의 변화율 (acceleration) 을 기준으로 trend 를 감지하려고 한 시도가 신선하게 다가왔으며, 수업에서 배웠던 sequence 한 정보를 기반으로 추천해주는 추천시스템 모델들과는 또 다른 맥락의 추천 방법론인 것 같아 전반적으로 인상깊었던 논문이었습니다. 또한 dataset 마다 trend 가 발생하는 상이한 특징에 따라 optimal 한 time interval 을 설정하는 접근 방식이 논문에서 뉴스나 영화 예시를 들었던 것 처럼 domain-based 한 부분이라, 추천 메커니즘에 대한 해석이 더 흥미롭게 다가왔던 것 같습니다. 그러나 TrendRec 에서 시계열 예측 모델로 DeepAR 을 선택한 것, 다음 아이템 예측 모델에 임베딩 방식으로 GRU4Rec을 채택한 것 대한 근거가 조금 부족하다고 느꼈습니다. 추가적인 다른 모델 채택 구성방식의 실험결과도 비교해주었으면 좋을 것 같다는 생각이 들었습니다. 하지만 trend recommendation 이라는 분야에서 해당 논문이 가지고 있는 가치는 매우 크다고 생각하며 앞으로 해당 분야가 발전함에 있어서 중요한 연구가 될 것이라 생각합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;-review-writer-information&quot;&gt;👩🏻 Review writer information&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;이다현 (Lee Dahyeon)
    &lt;ul&gt;
      &lt;li&gt;Master student, Department of Data science, KAIST&lt;/li&gt;
      &lt;li&gt;contact : isdawell@kaist.ac.kr&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 20 Nov 2023 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2023-11-20-Trending_Now_Modeling_Trend_Recommendations.html</link>
            <guid isPermaLink="true">http://localhost:4000/2023-11-20-Trending_Now_Modeling_Trend_Recommendations.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[AAAI 2023] Simple and Efficient Heterogeneous Graph Neural Network</title>
            <description>&lt;h1 id=&quot;simple-and-efficient-heterogeneous-graph-neural-network&quot;&gt;Simple and Efficient Heterogeneous Graph Neural Network&lt;/h1&gt;

&lt;h2 id=&quot;problem-definition&quot;&gt;Problem Definition&lt;/h2&gt;

&lt;p&gt;Heterogeneous Graph Neural Networks(HGNN)은 기존 Graph Neural Network(GNN)에서 사용하는 attention이나 multi-layer 구조 등의 매커니즘을 그대로 사용해왔다. 하지만 homogeneous graph를 위해 디자인된 GNN에서 사용하는 매커니즘을 Heterogeneous graph에 적용했을 때, 정말 효과가 있는지에 대한 분석은 이루어지지 않았다. 본 논문에서는 이러한 매커니즘들의 효과성에 대한 분석을 바탕으로, Heterogeneous graph를 효율적으로 모델링할 수 있는 Simple and Efficient Heterogeneous Graph Neural Networks(SeHGNN)을 제안한다.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;이전의 Heterogeneous Graph Neural Network(HGNN)은 GNN에서 사용하는 메커니즘이 heterogeneous 그래프에 효과가 있는지에 대한 분석은 거의 하지 않은 채, 이를 그대로 사용하면서 heterogeneous 그래프의 representation learning을 수행해왔다. 본 논문에서는 attention이나 multi-layer 구조가 heterogeneous 그래프를 모델링하는데 효과적인지에 대해 분석하는 과정에서 중요한 두 가지 발견을 하였고, 이를 바탕으로 SeHGNN 아키텍처를 설계하였다. Heterogeneous 그래프에 대한 기존 매커니즘의 효과성에 대한 분석 과정과 그에 따른 발견은 아래와 같다.&lt;/p&gt;

&lt;li&gt; attention에 대한 연구 &lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/MDVHbCW/figure1.png&quot; alt=&quot;figure1&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;HGNN은 Figure 1에 나타난 것처럼 서로 다른 모듈이나 파라미터들을 사용하여 계산되는 여러 attention을 사용한다. 이러한 attention들은 두 가지 유형으로 분류할 수 있는데, 첫 번째는 같은 relation의 neighbor들 사이에서 계산되는 neighbor attention이고, 두 번째는 서로 다른 relation 사이에서 계산되는 semantic attention이다. 본 논문에서는 attention의 효과성을 살펴보기 위해 attention을 사용한 경우와 사용하지 않은 경우에 대한 비교를 수행하였다.&lt;br /&gt;
이때, attention의 사용 양상은 Heterogeneous graph를 모델링하는 유형에 따라 나뉘어 지는데, HAN과 같이 metapath 기반 방법은 neighbor aggregation 단계와 semantic fusion 단계 각각에서 두 가지 attention을 뚜렷하게 구분하여 사용한다. 반면, HGB와 같이 metapath를 사용하지 않는 방법은 relation-specific한 임베딩을 사용하여 1-hop neighbor의 attention을 계산해서, 두 가지 attention 유형을 구분하는 것이 어려울 수 있기 때문에, attention의 영향을 제거하기 위해 추가 계산을 수행해야 한다. 구체적으로 각 노드의 이웃의 attention 값을 relation별로 평균화하여 neighbor attention을 제거하거나, 각 relation 내에서 정규화하여 각 relation이 최종 결과에 동일하게 기여하도록 조정할 수 있는데 이것은 semantic attention을 제거하는 것과 같다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/Ns6wjmB/table1.png&quot; alt=&quot;table1&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이를 바탕으로 HAN과 HGB에 대해 각 요소를 제거하면서 DBLP 데이터와 ACM 데이터에 대해 node classification을 수행해 실험하였고 그 결과를 Table 1에 정리하였다. 여기서 ‘*‘는 neighbor attention를 제거하는 것을 의미하고 ‘†’는 semantic attention를 제거하는 것을 의미한다. Table 1의 결과에서, semantic attention이 없는 모델은 성능이 감소하는 것을 나타내는 반면, neighbor attention이 없는 모델은 그렇지 않음을 보여준다. 이를 통해 semantic attention은 HGNN에서도 필수적이며, neighbor attention은 필요하지 않다는 것을 발견했고, 추가적으로 neighbor attention의 경우 다양한 SGC(Stochastic Gradient Community)기반의 연구에서 단순 mean aggregtion이 attention 모듈을 사용한 aggregation과 동일한 효과를 가질 수 있다는 것을 확인하였다고 하면서, mean aggregation으로 대체할 수 있음을 언급한다.&lt;/p&gt;

&lt;li&gt; multi-layer 구조에 대한 연구 &lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;neighbor attention이 없는, metapath를 사용하지 않는 방법은 각 relation 내에서 neighbor의 feature를 먼저 평균화한 다음, 다른 relation의 결과를 fusion하는 형태를 지닌다. 따라서 이들은 multi-layer 구조를 가지고 있으며, 각 레이어에서 1-hop metapath만 사용하는 metapath 기반 방법으로 변환할 수 있다. 따라서 본 논문에서는 metapath 기반 방법에서의 레이어 수와 metapath 수의 영향에 중점을 두고 실험을 수행하였다. metapath 기반 방법인 HAN에 대한 실험을 수행하면서 각 variant의 구조를 나타내는 숫자 list를 사용하였는데, 예를 들어 ACM 데이터셋에서 (1,1,1,1)은 각 레이어에서 1-hop metapath “PA” 및 “PS”를 사용하는 네 개의 레이어 네트워크를 나타내며, (4)는 4-hop 이상의 metapath가 없는 single-layer 네트워크를 나타낸다. 이러한 list는 receptive field의 크기도 보여준다. 예를 들어 (1,1,1,1), (2,2), (4)는 동일한 receptive field의 크기를 가지며 4-hop neighbor를 포함한다. 본 논문에서는 마찬가지로 DBLP 데이터와 ACM 데이터에 대해 실험을 수행하여 Table 2에 정리하였고 이 결과를 기반으로 두 번째 발견을 도출했다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/ZJp6f07/table2.png&quot; alt=&quot;table2&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Table 2에 나타난 것처럼 single-layer 구조와 긴 metapath를 사용한 모델이, multi-layer 구조와 짧은 metapath를 사용한 모델보다 우수한 성능을 보이는 것을 볼 수 있다. single-layer와 긴 metapath를 사용한 모델은 동일한 receptive field 크기에서 더 나은 성능을 달성하는데, 이는 multi-layer 네트워크가 각 레이어마다 semantic들을 fusion하기 때문에 고수준 의미를 구별하기 어렵게 만든다는 사실로 설명할 수 있다. 예를 들어, ACM 데이터에서 network 구조로 (4)와 같은 형태를 가진 모델에서 multi-hop metapath를 사용하면, 동일한 저자로부터 쓰여진 (PAP) 또는 익숙한 저자 (PAPAP)와 같은 고수준 의미를 구별할 수 있지만, 모든 중간 벡터가 서로 다른 semantic의 혼합을 나타내므로 4개 layer 네트워크 (1,1,1,1)에서는 이러한 차이를 구분할 수 없다. 더 나아가, 최대 metapath 길이를 증가시킴으로써 모델의 성능을 향상시키는데 도움이 되며, 다양한 의미를 갖는 더 많은 metapath를 도입할 수 있다고 설명한다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위의 두 가지 발견을 바탕으로 제안된 SeHGNN에서는 각 metapath 범위에서 mean aggregation을 사용하여 모델의 성능을 희생시키지 않으면서 중복되는 neighbor attention를 피할 수 있고, single-layer 네트워크 구조를 사용하면서 단순하지만 더 긴 metapath를 사용하여 receptive field를 확장함으로써 더 나은 성능을 얻는 것을 보여준다. 더불어 attention 모듈이 없는 neighbor aggregation 부분은 linear 연산만 포함하고 학습 가능한 파라미터가 없으므로, neighbor aggregation을 매 트레이닝 에폭마다 수행하는 것이 아니라 전처리 단계에서 한 번만 실행할 수 있도록 하여 훈련 시간을 크게 줄일 수 있다. 즉, 이러한 최적화를 통해 네트워크 구조를 간소화하고 효율적으로 만드는 것이 SeHGNN의 핵심 포인트이다.&lt;/p&gt;

&lt;h2 id=&quot;methodology&quot;&gt;Methodology&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://ibb.co/cYBCPdK&quot;&gt;&lt;img src=&quot;https://i.ibb.co/PDL9R8s/figure2.png&quot; alt=&quot;figure2&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://usefulwebtool.com/&quot;&gt;writing keyboard&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;SeHGNN의 아키텍처는 Simplified Neighbor Aggregation과 Multi-layer Feature Projection, 그리고 Transformer-based Semantic Fusion의 세 가지 주요 요소로 구성된다. Figure 2에서 SeHGNN과 다른 metapath 기반 HGNN 간의 차이를 볼 수 있는데, SeHGNN은 &lt;b&gt;neighbor aggregation을 전처리 단계에서 사전 계산&lt;/b&gt;하므로, 매 트레이닝 에폭에서 반복적인 neighbor aggregation의 과도한 복잡성을 피할 수 있다는 점이 주요한 특징이다. 각 구성 요소를 세부적으로 살펴보면 다음과 같다.&lt;/p&gt;

&lt;li&gt;Simplified Neighbor Aggregation&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;간소화된 neighbor aggregation은 전처리 단계에서 단 한 번 수행되는데, 주어진 모든 metapath의 집합 $\Phi_X$에 대한 다른 semantic의 feature matrix들의 list를 아래와 같이 생성한다.&lt;/p&gt;

&lt;p&gt;$M = {X_P : P \in \Phi_X}$&lt;/p&gt;

&lt;p&gt;일반적으로 각 노드 $v_i$에 대해, 각 주어진 metapath로부터 metapath 기반 이웃의 feature를 aggregate하기 위해 mean aggregation을 사용하며 semantic feature vector들의 list를 다음과 같이 출력하는데,&lt;/p&gt;

&lt;p&gt;$m_i = {z_i^P = \frac{1}{\vert\vert S^P \vert\vert} \sum_{p(i,j)\in S_P} x_j : P \in \Phi_X}$&lt;/p&gt;

&lt;p&gt;여기서 $S^P$는 메타패스 $P$에 상응하는 모든 메타패스 인스턴스들의 집합을 나타내고,
$p(i,j)$는 target 노드 $i$와 source 노드 $j$를 갖는 하나의 매타패스 인스턴스를 나타낸다.&lt;/p&gt;

&lt;p&gt;본 논문에서는 이러한 metapath 기반 neighbor collection을 간소화하기 위해 새로운 방법을 제안한다. HAN과 같은 기존의 metapath 기반 방법은 각 metapath에 대해 모든 metapath 기반 이웃을 enumerate하는 metapath neighbor 그래프를 구축하며, 이는 metapath의 길이에 따라 metapath 인스턴스의 수가 기하급수적으로 증가하므로 높은 부하를 초래했다. 본 논문에서는 GCN의 레이어별 전파에서 영감을 얻어 각 노드의 최종 기여 가중치를 인접 행렬의 곱셈을 사용하여 계산한다.&lt;/p&gt;

&lt;p&gt;$X_c = {x_0^{cT}; x_1^{cT}; \ldots; x_{\vert\vert V_c \vert\vert-1}^{cT}} \in \mathbb{R}^{\vert\vert V_c \vert\vert \times d_c}$&lt;/p&gt;

&lt;p&gt;여기서 $d_c$는 feature dimension이고, $X_c$는 $c$ 유형에 속하는 모든 노드의 초기 feature matrix를 나타낸다. 그런 다음 간소화된 neighbor aggregation 과정은 다음과 같이 표현될 수 있다.&lt;/p&gt;

&lt;p&gt;$XP = \hat{A}_ {c,c1}\hat{A}_ {c1,c2}\ldots \hat{A}_ {cl-1,cl}X^{cl}$&lt;/p&gt;

&lt;p&gt;여기서 $P = c1c2 … cl$은 $l$-hop metapath이며, $\hat{A}_ {ci,ci+1}$은 노드 유형 $c_i$와 $c_ {i+1}$ 간의 인접 행렬 $A_ {ci,ci+1}$의 row-normalized된 형태이다.&lt;/p&gt;

&lt;p&gt;여기에 레이블을 추가 입력으로 통합하면 모델 성능을 향상시킬 수 있다는 것을 입증한 이전 연구(Wang and Leskovec 2020; Wang et al. 2021b; Shi et al. 2021)를 활용하기 위해, raw feature들을 aggregation하는 것과 유사하게, 레이블을 one-hot 형식으로 표현하고 다양한 metapath를 통해 전파한다. 이 과정은 일련의 행렬 ${Y_P : P \in \Phi_Y}$ 을 생성하며, 이러한 행렬은 해당 metapath neighbor 그래프의 레이블 분포를 반영한다. metapath $P \in \Phi_Y$ 의 두 끝점은 노드 분류 작업에서 대상 노드 유형 $c$여야 한다. metapath $P = cc_1c_2 \ldots c_{l-1}c \in \Phi_Y$ 가 주어지면, 레이블 전파 과정은 다음과 같이 표현될 수 있다.&lt;/p&gt;

&lt;p&gt;$Y^P = rm _ diag(\hat{A}^P)Y^c, \, \hat{A}^P = \hat{A}_ {c,c1} \hat{A}_ {c1,c2}\ldots \hat{A}_ {cl-1,c}\,$&lt;/p&gt;

&lt;p&gt;여기서 $Y^c$는 raw label matrix이다. $Y^c$에서 training set에 속하는 노드에 해당하는 행은 one-hot 형태의 label 값을 가지며, 다른 행은 0으로 채워진다. 레이블 유출을 방지하기 위해 각 노드가 자신의 실제 레이블 정보를 받지 않도록 하기 위해 인접 행렬의 곱셈 결과에서 대각선에 있는 값을 제거한다. 레이블 전파는 neighbor aggregation 단계에서 실행되며 나중에 학습을 위한 추가 입력으로 semantic 행렬을 생성한다.&lt;/p&gt;

&lt;li&gt;Multi-layer Feature Projection&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;feature projection 단계는 서로 다른 metapath의 semantic 벡터가 다른 차원을 가지거나 다양한 데이터 공간에 위치할 수 있기 때문에, 이러한 semantic 벡터를 동일한 데이터 공간으로 projection하는 과정이다. 일반적으로, 각 metapath $P$에 대한 semantic-specific한 transformation matrix $W^P$를 정의하고 ${H^′P = W^PX^P}$ 를 계산한다. 더 나은 representation을 위해, 각 metapath $P$에 대해 multi-layer perception 블록 $MLP_P$를 사용하며, 이 블록은 두 개의 연속적인 linear layer 사이에 normalization layer, non-linear layer 및 dropout layer를 포함한다. 이 과정을 다음과 같이 나타낸다.&lt;/p&gt;

&lt;p&gt;$H’_P = \text{MLP}_P(X_P)$&lt;/p&gt;

&lt;li&gt;Transformer-based Semantic Fusion&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;semantic fusion 단계는 semantic feature 벡터를 융합하고 각 노드에 대한 최종 임베딩 벡터를 생성한다. 단순한 weighted sum 형식 대신, 본 논문에서는 각 semantic 쌍 간의 상호 관계를 더 탐색하기 위해 트랜스포머 기반의 semantic fusion 모듈을 제안하였다. 트랜스포머 기반의 semantic fusion 모듈은 미리 정의된 metapath list $\Phi = {P_1, \ldots, P_K}$ 와 각 노드에 대한 projected된 semantic 벡터 ${h’_ {P1}, \ldots, h’_ {PK}}$ 을 고려하여 semantic 벡터 쌍 간의 상호 attention를 학습하도록 설계되었다. 각 semantic 벡터 
$h^{‘Pi}$ 에 대해 이 모듈은 이 벡터를 query 벡터 $q^{Pi}$, key 벡터 $k^{Pi}$ 및 value 벡터 $v^{Pi}$로 매핑한다. 상호 attention 가중치 $\alpha(P_i, P_j)$ 는 소프트맥스 normalization 후의 query 벡터 $q^{Pi}$와 key 벡터 $k^{Pi}$의 dot product 결과이다. current semantic $P_i$의 출력 벡터 $h^{Pi}$는 모든 value 벡터 $v^{Pj}$의 weighted sum과 residual connection을 포함한다. semantic fusion 과정은 다음과 같이 표현될 수 있다.&lt;/p&gt;

&lt;p&gt;$q^{Pi} = W_Q h’^{Pi}$ , $k^{Pi} = W_K h’^{Pi}$ , $v^{Pi} = W_V h’^{Pi}$ , $P_i \in \Phi$ &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$\alpha(Pi,Pj) = \frac{exp(q^{Pi} \cdot k^{{Pj}^T})}{\sum_{Pt\in\Phi} exp(q^{Pi} \cdot k^{{Pt}^T})}$ &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$h^{Pi} = \beta \sum_{P_j\in\Phi} \alpha(P_i,P_j) v^{P_j} + h’^{P_i}$ &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;여기서 $W_Q$, $W_K$, $W_V$, β는 모든 metapath 간에 공유되는 학습 가능한 파라미터이다.&lt;/p&gt;

&lt;p&gt;각 노드의 최종 임베딩 벡터는 모든 출력 벡터의 연결로 이루어지는데, node classification과 같은 downstream 작업을 위해 또 다른 MLP가 사용되어 예측 결과를 생성하며, 이는 다음과 같이 표현될 수 있다.&lt;/p&gt;

&lt;p&gt;$Pred = \text{MLP}([h^{P1} \vert\vert h^{P2} \vert\vert \ldots \vert\vert h^{P \vert \Phi \vert}])$&lt;/p&gt;

&lt;h2 id=&quot;experiment&quot;&gt;Experiment&lt;/h2&gt;

&lt;p&gt;본 논문에서는 DBLP, ACM, IMDB 및 Freebase와 같은 널리 사용되는 heterogeneous 그래프 4개와 OGB 챌린지에서 가져온 큰 규모의 ogbn-mag 데이터셋을 사용하여 실험을 진행했고, node classification의 성능 비교를 통해 제안한 방법의 효과성을 검증했다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ibb.co/dpyvcbK&quot;&gt;&lt;img src=&quot;https://i.ibb.co/fN7WS80/table3.png&quot; alt=&quot;table3&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;li&gt;Results on HGB Benchmark&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;
Table 3은 네 가지 데이터셋에서 SeHGNN의 성능을 HGB 벤치마크의 여러 baseline들과 비교한 결과를 제시하며, 1st 행은 네 가지 metapath 기반 방법, 2nd 행은 metapath를 사용하지 않는 네 가지 방법을 나타낸다. SeHGNN이 Freebase 데이터셋의 micro-f1을 제외하고 모든 baseline 대비 최상의 성능을 달성하였다.&lt;/p&gt;

&lt;p&gt;추가적으로 Motivation 파트에서 언급한 두 가지 발견을 검증하고, 다른 모듈의 중요성을 결정하기 위해 ablation study도 수행하였는데, Table 3의 4th 행은 SeHGNN에 네 가지 변형을 가한 각각의 경우에 대한 결과를 나타낸다. Variant#1은 neighbor aggregation 단계에서 HAN과 같이 각 metapath에 대해 GAT를 사용한 경우이다. Variant#2는 각 레이어가 독립적인 neighbor aggregation 및 semantic fusion 단계를 갖는 두 개의 레이어 구조를 사용하며, 각 레이어의 metapath의 최대 hop이 SeHGNN의 절반으로 놓고 SeHGNN과 Variant#2가 동일한 수용 영역 크기를 갖도록 한 경우이다. SeHGNN과 Variant#1과 Variant#2 사이의 성능 차이를 통해 Motivation에서 언급한 두 가지 발견에 대한 내용이 SeHGNN에도 적용된다는 것을 확인할 수 있다. Variant#3는 추가 입력으로 레이블을 포함하지 않는 경우이고, Variant#4는 HAN과 같이 weighted sum fusion으로 트랜스포머 기반의 semantic fusion을 대체한 경우이다. 특히, SeHGNN에 뒤쳐지지만, Variant#3은 Freebase 데이터셋의 micro-f1을 제외한 대부분의 baseline들보다 우수한 성능을 보여준다. 이러한 결과는 레이블 전파와 트랜스포머 기반 fusion의 활용이 모델 성능을 향상시킨다는 것을 입증하는 증거로 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/TmM0Ldh/table4.png&quot; alt=&quot;table4&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;li&gt;Results on  Ogbn-mag&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;본 논문에서는 다섯 번째 데이터셋으로 ogbn-mag을 사용하여 성능을 비교하였다. ogbn-mag 데이터셋은 일부 유형의 노드의 초기 feature가 부족하고, target type 노드가 연도에 따라 분할되어 training 노드와 test 노드가 다른 데이터 분포를 갖게 된다는 문제점을 갖고 있다. 기존의 다른 방법들은 일반적으로 이러한 어려움을 다루기 위해 ComplEx (Trouillon et al. 2016)와 같은 비지도 표현 학습 알고리즘을 사용하여 추가 임베딩을 생성하고, multi-stage learning을 활용하여 마지막 학습 단계에서 확신 있는 예측을 가진 test 노드를 선택하고 이러한 노드를 training set에 추가하여 새로운 단계에서 모델을 다시 훈련한다고 한다(Li, Han, and Wu 2018; Sun, Lin, and Zhu 2020; Yang et al. 2021). 본 논문의 저자는 이러한 방법들을 사용하거나 사용하지 않는 결과를 이용하여 비교하였다. 추가 임베딩이 없는 방법의 경우 무작위로 초기화된 초기 feature 벡터를 사용했다고 한다.&lt;/p&gt;

&lt;p&gt;Table 4는 대규모 데이터셋 ogbn-mag에 대해 baseline과 비교한 결과를 보여준다. 결과는 SeHGNN이 동일한 조건에서 다른 방법을 능가한다. 무작위로 초기화된 특징을 가진 SeHGNN이 추가 표현 학습 알고리즘에서 잘 훈련된 임베딩을 가진 다른 방법보다 우수한 성능을 보이는데, 이는 SeHGNN이 그래프 구조로부터 더 많은 정보를 학습한다는 것을 보여주는 증거이다.&lt;/p&gt;

&lt;li&gt;Time Analysis&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;
본 논문에서는 또한 실행 시간에 대한 비교 분석도 수행하였다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/f8wwp0k/table5.png&quot; alt=&quot;table5&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;먼저, Table 5에서 보여지듯이 SeHGNN의 시간 복잡도를 HAN과 HGB와 비교하는 이론적 분석을 수행한다. SeHGNN과 HAN은 k개의 metapath와 single-layer 구조를 가정하고, HGB는 $l$개의 레이어 구조를 갖는 것으로 가정하여 분석한다. metapath의 최대 hop도 $l$로 설정하여 receptive field의 크기를 동일하게 유지한다. 대상 유형 노드의 수는 n이며 입력 및 hidden 벡터의 차원은 $d$이다. HAN에서 metapath neighbor 그래프의 평균 neighbor 수는 $e_1$이고, HGB에서 multi-layer aggregation 중에 관련된 neighbor 수는 $e_2$ 이다. $e_1$ 과 $e_2$는 metapath의 길이와 레이어 수인 $l$과 함께 지수적으로 증가한다. 위 다섯 개의 데이터셋에서 본 논문은 최대 metapath 수십 개를 사용하지만, 레이어 $l$ ≥ 3에 대해 각 노드는 평균 수천 개의 neighbor들로부터 정보를 aggregation한다. 일반적으로 $e_1$ ≫ $k^2$, $e_2$ ≫ $k^2$이다. 따라서 SeHGNN의 이론적 복잡성은 HAN과 HGB보다 훨씬 낮은 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/9GcRN9c/figure3.png&quot; alt=&quot;figure3&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://imgbb.com/&quot;&gt;image hosting without registration&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이론적 분석을 검증하기 위해 SeHGNN의 시간을 이전에 나온 HGNN들과 비교하는 실험을 수행하였고, Figure 3은 각 모델의 평균 시간 단위로 학습 시간에 따른 micro-f1 점수 달성 정도를 보여준다. 이는 SeHGNN이 학습 속도와 모델 성능 모두에서 우수함을 나타낸다.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;본 논문은 heterogeneouos 그래프 representation learning을 위한 SeHGNN이라는 새로운 방법을 제안한다. 이 방법은 attention 사용 여부와 네트워크 구조에 따른 효과성에 대한 두 가지 주요 발견을 기반으로 제안되었다. 본 논문에서는 light mean aggregation을 사용하여 neighbor aggregation을 사전에 계산함으로써 구조 정보를 효과적으로 포착하면서, neighbor attention이 과도하게 사용되는 것을 방지하고 반복적인 neighbor aggregation도 피할 수 있도록 하였다. 이와 함께 receptive field를 확장하고 semantic 정보를 더 잘 활용하기 위해 긴 metapath를 사용하는 single-layer 구조와, 트랜스포머 기반의 semantic fusion 모듈을 사용하여 모델의 효과성을 향상시켰다.&lt;/p&gt;

&lt;h2 id=&quot;author-information&quot;&gt;Author Information&lt;/h2&gt;
&lt;li&gt; 정민규 &lt;/li&gt;
&lt;p&gt;Contact: minkyujeong@kaist.ac.kr&lt;/p&gt;

</description>
            <pubDate>Mon, 20 Nov 2023 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2023-11-20-Simple_and_Efficient_Heterogeneous_Graph_Neural_Network.html</link>
            <guid isPermaLink="true">http://localhost:4000/2023-11-20-Simple_and_Efficient_Heterogeneous_Graph_Neural_Network.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[RecSys 2023] STRec: Sparse Transformer for Sequential Recommendations</title>
            <description>&lt;h1 id=&quot;title&quot;&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;STRec: Sparse Transformer  for  Sequential Recommendations&lt;/p&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Transformer 구조가 급속도로 발전함에 따라 researcher들은 SRS(sequential recommender systems)에서 Transformer 구조를 적용하고 이전 SRS model들에 비해 SRS task에 대하여 발전된 성능을 나타내는 model을 제시하고 있다. &lt;br /&gt;
이 논문에서 user-item interaction history는 다음과 같이 정의된다. &lt;br /&gt;
 $\begin{align}S = {(v_ 1, t_ 1), \ldots, (v_ n, t_ n ), \ldots, (v_ N, t_ N )} \end{align}$&lt;/p&gt;

&lt;p&gt;여기서 $v_ n \in V$는 timestamp $t_ n$에서 sequence $S$의 $n$번째 interacted item이고 $N$은 sequence의 최대 길이이다. 
 단순화를 위해 user 및 실제 길이에 대한 표기는 생략되었고 interacted timestamp $t_ n$을 고려한다. &lt;br /&gt;
SRS는 제공된 길이가 $N$인 interaction sequence ${(v_ 1, t_ 1), \ldots, (v_ N, t_ N )}$를 활용해서 다음 interacted item $v_ {N+1}$을 예측해야 하는 문제이다. &lt;br /&gt;
그러나 대부분의 기존 transformer 기반 SRS model들은 모든 item-item pair 간의 attention score를 계산하는 vanilla attention mechanism을 사용하고 있다.
이 경우 중복되는 item interaction으로 인해 model 성능이 저하되고 많은 계산 시간과 메모리를 필요로 할 수 있다는 문제점이 발생한다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;vanilla self-attention을 transformer 기반 SRS model에 활용하면 모든 item interaction을 scan할 수 있지만 모든 interaction을 scan할 경우 막대한 계산 시간과 메모리 비용이 발생하여 SRS 모델의 inference 효율성이 저하된다.
게다가 최적이 아닌 item interaction을 고려할 수 있어 추천 성능이 저하될 수 있다.&lt;br /&gt;
따라서 inference 효율성과 추천 성능을 높이기 위해 필요한 item interaction을 구별할 수 있는 효율적인 transformer 구조를 설계하는 것이 필요하다. &lt;br /&gt;
효율적인 Transformer 구조를 설계하기 위해 다음과 같은 노력이 이루어졌다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2004.05150&quot;&gt;Longformer&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2007.14062&quot;&gt;Big Bird&lt;/a&gt; : sparce attention 전략을 사용하여 필수적인 token pair에 대해서만 attention score를 계산&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.04768&quot;&gt;Linformer&lt;/a&gt; : low-rank approximation 방법을 사용하여 attention score 계산&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2106.13008&quot;&gt;Autoformer&lt;/a&gt; : 시계열 예측을 위해 sequence를 분해&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2202.10447&quot;&gt;FLASH&lt;/a&gt; : vanilla attention을 gated attention unit으로 대체&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2001.04451&quot;&gt;Reformer&lt;/a&gt; : locality-sensitive hashing(lsh) module 적용&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;하지만 위의 방법들은 SR(Sequential recommendation)을 위한 목적으로 설계되지 않았기 때문에(NLP나 시계열 예측을 위한 목적으로 설계됨) SR task에 직접 적용하면 추천 성능이 저하될 수 있다. &lt;br /&gt;
새로운 transformer 구조 설계가 필요한 이유를 아래 Figure 1을 통해 설명하고 있다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/da1298ed-6331-42bf-89b6-527befee79d0/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 1의 Attention weight matrix를 통해 SRS task에서의 transformer 기반 model이 높은 sparsity를 보이는 것을 알 수 있다.
논문에서는 해당 sparse attention에서 보이는 low-rank phenomenon을 두 가지 측면에서 설명하고 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;극히 일부의 interaction이 output에 차이를 만든다. (heatmap column level)&lt;/li&gt;
  &lt;li&gt;attention weight vector가 유사하고 이것이 low-rank phenomenon을 가중시킨다. (heatmap row level)&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/c910d64c-6c51-4c47-bbfc-0a11b206a0db/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;low-rank phenomenon은 attention weight matrix의 행에 대한 SVD 분해를 통해 명확히 드러난다. Figure 2를 통해 eigenvalue의 분포를 확인할 수 있다. &lt;br /&gt;
x축은 eigenvalue, y축은 value의 비율이다.
대부분의 eigenvalue는 상대적으로 작다. 이를 통해 low-rank matrix를 사용하여 original attention weight matrix를 근사화 할 수 있음을 알 수 있다. &lt;br /&gt;
이러한 현상을 바탕으로 이 논문에서는 효율성을 위해 일부 interaction 쌍만 transformer layer에서 계산하는 sparse transformer 모델(&lt;strong&gt;STRec&lt;/strong&gt;)을 제안하였다.&lt;br /&gt;
&lt;strong&gt;S&lt;/strong&gt;parse &lt;strong&gt;T&lt;/strong&gt;ransformer model for sequenctial &lt;strong&gt;Rec&lt;/strong&gt;ommendation tasks(&lt;strong&gt;STRec&lt;/strong&gt;)는 cross-attention와 학습 가능한 parameter를 활용한 sampling 전략을 기반으로 한다.&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;STRec&lt;/strong&gt;은 transformer 기반 backbone model을 기반으로 구성되었다. Figure 3를 통해 &lt;strong&gt;STRec&lt;/strong&gt; 모델 구조를 확인할 수 있다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/18dfd67a-8704-4238-b825-762bff970ac5/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Model은 Embedding layer, 여러 Transformer layer, Prediction layer로 구성되어 있다. &lt;br /&gt;
Backbone model과 비교했을 때 TransformerLayer에서 차이가 있는데, 논문에서는 cross-attention과 학습 가능한 parameter를 활용한 효율적인 sampling 전략을 기반으로 하는 sparse transformer를 활용한다. &lt;br /&gt;
Model의 각 layer를 설명하되 이 논문의 핵심인 Cross Attention Transformer Layer와 Sampling 전략 부분을 좀 더 자세히 설명할 예정이다.&lt;/p&gt;

&lt;h3 id=&quot;31-embedding-layer&quot;&gt;3.1 Embedding Layer&lt;/h3&gt;
&lt;p&gt;ID embedding과 positional embedding을 통합한 input item의 초기 표현을 식으로 나타내면 다음과 같다.&lt;/p&gt;

&lt;p&gt;$ \begin{align}h_ {n}^{0} = e_ n + p_ n \end{align}$&lt;/p&gt;

&lt;p&gt;여기서 $e_ n$은 item $v_ n$에 대한 ID embedding이고, $p_ n$은 sequence의 item index $n$에 대한 positional embedding이다. $h_ {n}^{0}$의 위 첨자 index 0는 embedding layer임을 나타낸다.&lt;/p&gt;

&lt;h3 id=&quot;32-sparse-transformer-in-strec&quot;&gt;3.2 Sparse Transformer in STRec&lt;/h3&gt;

&lt;h4 id=&quot;321-cross-attention-transformer-layer&quot;&gt;3.2.1 Cross Attention Transformer Layer&lt;/h4&gt;
&lt;p&gt;Attention layer의 계산 비용을 줄이기 위해 vanilla self-attention을 cross-attention으로 대체하였다. &lt;br /&gt;
cross-attention은 input sequence를 key, value로 샘플링된 item sequence를 query로 사용한다.
sampling된 query matrix는 기존 query matrix에 비해 크게 축소되기 때문에 계산이 더 효율적이다. &lt;br /&gt;
$H^ {l-1}$에 대해서 cross-attention은 다음과 같은 식으로 나타낼 수 있다. &lt;br /&gt;
$ \begin{align} \tilde{H}^ {l-1} = Add\&amp;amp;Norm\left(Attention\left(H_{I}^ {l-1}, H^ {l-1}, H^ {l-1}\right) \right)  \end{align}$
$\tilde{H}^ {l-1}$은 사전 정의된 $k_l$의 길이를 갖으며 sampling index $I_l$에 의해 $H_ {l-1}$에 있는 item representation이 sampling된 부분집합이다.
$\tilde{H}^ {l-1}$은 $H_{I}^ {l-1}$과 똑같은 shape를 갖는다.&lt;br /&gt;
FFN layer는 짧아진 $\tilde{H}^ {l-1}$를 input으로 하여 output hidden state를 만들어 낸다. &lt;br /&gt;
$ \begin{align} {H}^ {l} = Add\&amp;amp;Norm\left(FFN\left(\tilde{H}^ {l-1} \right)\right) \end{align}$
output hidden state $H^ {l}$의 길이는 여전히 $k_l$이며, $H_{I}^ {l-1}$, $\tilde{H}^ {l-1}$과 똑같은 shape를 갖는다.&lt;br /&gt;
vanila self-attention transformer layer와 비교했을 때 cross-attention layer는 attention과 feed-forward network 모두에서 sampled item에 대해서만 계산한다.&lt;br /&gt;
시간 복잡도와 공간 복잡도 모두 $O(n^ 2)$에서 $O(nk_ l)$로 감소한다.&lt;/p&gt;

&lt;h4 id=&quot;322-sampling-strategy&quot;&gt;3.2.2 Sampling strategy&lt;/h4&gt;
&lt;p&gt;Figure 1을 통해 후방 item이 SR task에서 중요할 가능성이 높음을 알 수 있다.
따라서 논문에서는 마지막 item과의 time interval을 바탕으로 학습 가능한 parameter를 사용해서 sampling 전략을 수행한다. time interval은 $T = {\tilde{t}_ i}_ {1 \le i \le N}$로 표현한다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} \tilde{t}_ {i} = t_ i - t_ N  \end{align}$
$t_ i, 1 \le i \le N$은 interaction $v_ i$에 대해 기록된 timestamp이다.&lt;br /&gt;
첫번째 layer의 경우 MLP(Multi-layer Perceptron)을 활용해서 time interval $T$를 sampling density로 mapping한다. 무작위 샘플링을 위해 uniform distribution을 갖는 random matrix $R$ 을 추가한다. sampling index $I$는 다음과 같이 생성된다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} I_ {1} = Top_k\left(MLP(T) + R, k_ 1\right)  \end{align}$
$ \begin{gather} r_ {i} \sim Uniform\left(0, 1\right) \nonumber \end{gather}$&lt;/p&gt;

&lt;p&gt;$Top_k\left(\cdot \right)$는 내림차순으로 정렬된 index들의 set을 생성한다.
$k_ 1$은 hyperparameter로서 첫번째 layer의 pre-define된 sample size이다.&lt;/p&gt;

&lt;p&gt;이후 layer들에 대해서 sampling index를 layer별로 생성하는데는 많은 시간이 걸린다. 따라서 $MLP\left(T \right) + R$ 부분은 모든 layer에 대해 fine-tuning 및 inference 과정에서 동일하게 유지된다. &lt;br /&gt;
논문에서는 정렬된 index $I_ 1$를 입력하고 첫 $k_ l$개의 index를 $I_ l$로 사용한다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} I_ {l} = I_ 1\left[1: k_ l\right]  \end{align}$
$ \begin{align} {H}_ {I}^ {l-1} = \left[{h}_ {I_ l \left[1\right]}^ {l-1}, \ldots, {h}_ {I_ l \left[k_ l\right]}^ {l-1} \right]
 ∀ 2 \le l \le L  \end{align}$
$I$는 미분 가능한 방식으로 근사된(하지만 미분 가능한 방식으로 처리하기 어려운) hard decision을 생성하는 random process를 요구하는 $Top_k$ 연산 으로 인해 미분 불가능하다. &lt;br /&gt;
이러한 문제를 해결하기 위해 pre-train 과정에서 &lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;Gumbel-Softmax&lt;/a&gt;를 적용하여 sampling 과정을 attention mask $M$으로 대체한다.
여기서 $m_ {ij} \approx 0$은 $i$번째 query와 $j$번째 key 간의 attention weight가 계산되지 않았음을 의미하고 그 반대의 경우(계산된 경우)는 $m_ {ij} \approx 1$이다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} S_ {l} = Sigmoid\left(MLP\left(T\right) + R + \alpha _ l\right)  ∀ 1 \le l \le L  \end{align}$
$ \begin{align} S_ {0} = \left[ 1, 1, \ldots, 1\right] \end{align}$
$ \begin{align} M_ {l} = S_ {l-1} \otimes S_ {l}  ∀ 1 \le l \le L  \end{align}$&lt;/p&gt;

&lt;p&gt;$\begin{gather}
 r_ {i} \sim Uniform\left(0, 1\right) \nonumber 
\end{gather}$&lt;/p&gt;

&lt;p&gt;$MLP\left(\cdot\right)$는 normalization이 포함된 multi-layer perceptron이다. &lt;br /&gt;
$\alpha$는 sampling될 interaction 수(mask matrix $S_l$의 1 개수)를 제어하는데 사용된다.
$\alpha_ {l}$이 커지면 해당 layer에서 더 많은 sample이 생성된다. &lt;br /&gt;
layer $S_ {l}$과 그 이전 layer $S_ {l-1}$을 활용하여 attention mask matrix는 outer product $\otimes$로 계산된다. 
이때 query-key pair를 뽑으면 query는 $S_ {l}$에서 나오고 key는 $S_ {l-1}$에서 나온다&lt;/p&gt;

&lt;p&gt;attention mask $M$이 있는 미분 가능한 attention layer는 다음과 같이 표현된다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} \tilde{H}^ {l-1} = Add\&amp;amp;Norm\left(\sigma \left(H_{I}^ {l-1}H^ {l-1^ {T}} + \left(M - 1\right) * \infty \right)H^ {l-1} \right)  \end{align}$&lt;/p&gt;

&lt;h3 id=&quot;33-prediction-layer&quot;&gt;3.3 Prediction layer&lt;/h3&gt;
&lt;p&gt;논문에서는 마지막 item embedding에 대한 최종 output prediction score를 계산하기 위해 &lt;a href=&quot;https://ieeexplore.ieee.org/document/5197422&quot;&gt;Matrix Factorization(MF)&lt;/a&gt;를 수행한다.&lt;/p&gt;

&lt;p&gt;$\begin{align} \hat{y} = \sigma\left(h_ {N}^ {L}E^ {T} \right)  \end{align}$&lt;/p&gt;

&lt;p&gt;위 식에 나온 기호 정리를 하면 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$h_ {N}^ {L} \in R^ d$: 마지막 transformer layer에서 나온 마지막 item representation&lt;/li&gt;
  &lt;li&gt;$E \in R^ {\vert V \vert \times d}$: candidate item $V$에 대한 embedding matrix&lt;/li&gt;
  &lt;li&gt;$\sigma\left(\cdot\right)$: softmax&lt;/li&gt;
  &lt;li&gt;$d$: embedding 차원&lt;/li&gt;
  &lt;li&gt;$\hat{y} \in R^ {\vert V \vert}$: prediction 결과로서 item set $V$에 대한 다음 item의 probability distribution&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;34-optimization&quot;&gt;3.4 Optimization&lt;/h3&gt;
&lt;p&gt;논문에서는 &lt;strong&gt;STRec&lt;/strong&gt;을 pre-train과 fine-tuning의 두 단계로 나누어서 train한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;pre-train 단계에서는 식 $(9)-(12)$를 활용해 sampling을 구현하고 모든 parameter를 최적화한다.&lt;/li&gt;
  &lt;li&gt;fine-tuning 단계에서는 MLP의 fix된 근사 hash 함수를 사용하고 다른 parameter를 fine-tuning하면서 추가로 최적화를 진행하는 대신 식 $(6)$을 활용하여 sampling index $I$를 직접 생성한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;최적화 할 parameter에는 다음과 같은 2가지 종류가 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$W$: backbone model parameter&lt;/li&gt;
  &lt;li&gt;$A$: 식$(9) -(12)$에 포함된 sampling 전략 parameter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;최적화 문제를 식으로 나타내면 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pre-training stage
  $\begin{align} \min _{\boldsymbol{W}, \mathcal{A}} \mathcal{L}(\hat{\boldsymbol{y}}, \boldsymbol{y}) \nonumber \end{align}$&lt;/li&gt;
  &lt;li&gt;Fine-tuning Stage
  $\begin{align} \min _{\boldsymbol{W}} \mathcal{L}(\hat{\boldsymbol{y}}, \boldsymbol{y}) \nonumber \end{align}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;candidate item은 모든 item이고 &lt;br /&gt;
$\hat{y}$는 다음 방문하는 item에 대한 예측 확률, $y$는 ground truth인 다음 item을 의미한다. &lt;br /&gt;
item embedding과 마지막 transformer layer의 output vector 사이의 내적을 수행하여 다음 방문 item에 대한 확률을 얻는다.&lt;/p&gt;

&lt;p&gt;$\mathcal{L}(\hat{\boldsymbol{y}}, \boldsymbol{y})$ loss function은 SRS 작업에서 활용되는 binary Cross-Entropy loss이다.
 $\begin{align} \mathcal{L}(\hat{\boldsymbol{y}}, \boldsymbol{y})  = \boldsymbol{y}log(\hat{\boldsymbol{y}}) + (1 - \boldsymbol{y})log(1 - \hat{\boldsymbol{y}})  \end{align}$&lt;/p&gt;

&lt;p&gt;상세 최적화 과정은 아래 Algorithm 1에 설명되어 있다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/b18318d2-596a-48c1-ae56-ef5195ee8095/image.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(line 3) flag c 초기화, c를 활용해 train epoch 계산&lt;/li&gt;
  &lt;li&gt;(line 4-9) pretrain 단계에서 모든 parameter를 동시에 train&lt;/li&gt;
  &lt;li&gt;(line 10-14) parameter $A$를 고정하고 $W$를 train 단계에서 수렴하도록 계속 train&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;35-model-inference&quot;&gt;3.5 Model Inference&lt;/h3&gt;
&lt;p&gt;inference 과정을 순서대로 작성하였다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;식 $(2)$ 활용 각 interaction의 초기 representation을 만들고 $H^ 0$과 연결&lt;/li&gt;
  &lt;li&gt;식 $(5)$ 활용 visiting time interval $T$ 계산&lt;/li&gt;
  &lt;li&gt;식 $(6)$ 활용 첫 layer에 대한 index $I_ 1$ 생성&lt;/li&gt;
  &lt;li&gt;$H^ 0$가 $L$개의 transformer layer에 의해 식 $(3)$, $(4)$와 같이 변환됨&lt;/li&gt;
  &lt;li&gt;식 $(7)$ 활용 각 layer $l$의 index $I_ l$이 포함된 sampling query 직접 생성&lt;/li&gt;
  &lt;li&gt;모든 candidate item과 sparse transformer의 output을 내적&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모든 candidate item similarity 점수 $\hat{y}$을 통해 next item에 대한 prediction 결과를 획득 가능하다.&lt;/p&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;experiment-setup&quot;&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Dataset
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://grouplens.org/datasets/movielens/1m/&quot;&gt;ML-20M&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://snap.stanford.edu/data/loc-gowalla.html&quot;&gt;Gowalla&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://jmcauley.ucsd.edu/data/amazon/&quot;&gt;Amazon-Electronics&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;baseline
    &lt;ul&gt;
      &lt;li&gt;classical SRS models
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06939&quot;&gt;GRU4Rec&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.04725&quot;&gt;NARM&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1808.09781&quot;&gt;SASRec&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1904.06690&quot;&gt;Bert4Rec&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://www.ijcai.org/proceedings/2019/0600.pdf&quot;&gt;FDSA&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3336191.3371786&quot;&gt;Ti-SASRec&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;transformer architecture
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.04768&quot;&gt;Linformer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2007.14062&quot;&gt;Big Bird&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2012.07436&quot;&gt;Informer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2001.04451&quot;&gt;Reformer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2202.10447&quot;&gt;FLASH&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2106.13008&quot;&gt;Autoformer&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Evaluation Metric
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_reciprocal_rank&quot;&gt;mean reciprocal rank(MRR)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&quot;&gt;normalized discounted cumulative gain(NDCG)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;hit ratio(HR)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;result&quot;&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;/h3&gt;
&lt;h3 id=&quot;rq1-how--the--proposed--strec--performs--in--accuracy--while--it-can-reduce-the-time-and-spatial--complexity&quot;&gt;RQ1: How  the  proposed  STRec  performs  in  accuracy  while  it can reduce the time and spatial  complexity?&lt;/h3&gt;

&lt;p&gt;RQ1에 대한 답변을 위해 accuracy 성능을 계산하여 비교한 Table 2를 제시하였다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/66fdeb97-55de-4231-a59d-e4bdafc217c5/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;분석 결과는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;모든 dataset에서 Transformer 기반 방법이 RNN 기반 방법보다 성능이 좋다.(긴 sequence를 더 잘 모델링하기 때문)&lt;/li&gt;
  &lt;li&gt;FDSA는 side information이 부족하기 때문에 성능이 좋지 않다.(공정한 비교를 위해 side information 제외하고 실험)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;STRec&lt;/strong&gt;은  65%의 sparsity를 가진 ML-20M 및 Gowalla dataset에서 다른 baseline보다 성능이 좋다.&lt;/li&gt;
  &lt;li&gt;TiSASRec과 &lt;strong&gt;STRec&lt;/strong&gt; 모두 SRS에 시간 information을 사용하였다. TiSASRec은 time interval에 따라 item embedding을 강화하기 때문에 성능이 좋지 않으나 &lt;strong&gt;STRec&lt;/strong&gt;은 시간 information을 사용하여 item의 potentioal importance를 학습한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rq2--compared--with--the--efficient--transformer--methods--how-strec-performs--in-the-aspect-of-efficiency&quot;&gt;RQ2:  Compared  with  the  efficient  transformer  methods,  how STRec performs  in the aspect of efficiency?&lt;/h3&gt;

&lt;p&gt;RQ2에 대한 답변을 위해 efficiency performance를 측정하여 비교한 Table 3를 제시하였다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/7b669acf-9769-40b8-be0b-4c766ddb5483/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;분석 결과는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Linformer와 Informer는 backbone model보다 효율적이고, Informer는 down-sampling setting을 적용했기 때문에 가장 좋은 memory 효율을 보인다.
   그러나 sampling에 많은 operation이 필요하기 때문에 &lt;strong&gt;STRec&lt;/strong&gt;에 비해 inference time이 훨씬 길다. 게다가 성능도 &lt;strong&gt;STRec&lt;/strong&gt;에 비해 좋지 않다.&lt;/li&gt;
  &lt;li&gt;Big bird의 결과가 N/A인 이유는 sparse pattern에 대한 높은 complexity로 인해 효율성이 떨어져 구현할 수 없었기 때문이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;STRec&lt;/strong&gt;은 시간 정보를 기반으로 중요한 query를 추출할 수 있기 때문에 accuracy와 time-space 효율성 모두에서 다른 transformer baseline들을 능가한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rq3-how-does-the-sparsity-and-pre-training-process-of-strec-affect-the--accuracy--performance&quot;&gt;RQ3: How does the sparsity and pre-training process of STRec affect the  accuracy  performance?&lt;/h3&gt;

&lt;h4 id=&quot;sparcity&quot;&gt;Sparcity&lt;/h4&gt;

&lt;p&gt;Figure 4는 sparsity 측면에서의 parameter study 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/16cc41d6-273b-4ed3-9b81-06009932aa8a/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 5는 sparsity 측면에서의 efficieny performance 비교 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/cc72f6ee-dbc8-478a-9cc8-e02ae18c8767/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;x축은 모든 layer애서의 sample size $k_ l$에 의해 계산된 sparsity를 의미한다.&lt;br /&gt;
e.g. sequence 길이가 50이고 $k_ l$이 5일 때 sparsity는 (50 - 5) / 50 = 90% &lt;br /&gt;
y축은 accuracy performance와 efficiency performance(backbone model과의 inference time과 memory cost의 percentage 비교)를 나타낸다.&lt;/p&gt;

&lt;p&gt;Figure 4와 5에 대한 분석 결과는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;optimal sparsity는 69%이다.&lt;/li&gt;
  &lt;li&gt;sparsity가 42%보다 낮을 때 sparsity와 model 성능은 비례한다. 그 이유는 중요하지 않은 period의 interaction에 대한 영향을 제거하여 transformer가 sequential user preference를 잘 학습할 수 있도록 중복되는 interaction 계산을 생략하기 때문이다.&lt;/li&gt;
  &lt;li&gt;너무 높은 sparsity는 성능을 감소시킨다. 77%보다 sparsity가 커질 때 모델 성능은 점점 감소된다. 그 이유는 sparsity가 너무 심하면 많은 key information을 잃어버리고 prediction을 충분히 학습할 수 없기 때문이다.&lt;/li&gt;
  &lt;li&gt;(42%-77%)의 sparsity 범위에서 STRec은 SASRec(가장 성능이 좋은 baseline)의 성능을 능가한다. 그 이유는 sequence에서 representative interaction을 선택하는 성공적인 sampling 전략 덕분이다.(denoising과 비슷)&lt;/li&gt;
  &lt;li&gt;100%에 가까운 sparsity에서도 inference을 위한 backbone model의 cost으로 인해 I/O 및 embedding layer에도 약 15%의 시간이 소요된다. Memory cost은 주로 transformer layer에 의해 발생하므로 sparsity이 100%에 가까워지면 memory cost가 거의 0%가 될 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;training-pipeline-analysis&quot;&gt;Training Pipeline Analysis&lt;/h4&gt;

&lt;p&gt;Figure 6는 pretrain epoch $C$를 변화시켜 가며 실험을 진행한 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/c0d0e1ed-e2ec-4536-85a3-bce4a0178c80/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;x축은 epoch $C$, y축은 performance(NDCG@10)를 의미하며 &lt;br /&gt;
푸른 선은 fine-tuning 단계를 skip하고 바로 pre-training 단계만을 거친 모델로 예측을 진행한 결과이다.&lt;/p&gt;

&lt;p&gt;Figure 6를 통해 다음과 같은 결과를 얻을 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$C$가 60일 때 성능이 가장 좋다. pre-training epoch이 그 이상으로 늘어나면 overfitting이 발생하여 성능이 감소한다.&lt;/li&gt;
  &lt;li&gt;$C$를 60에서 10으로 감소시키면 성능은 크게 감소한다. 이를 통해 pre-training 단계를 생략하면 underfitting 문제가 발생함을 알 수 있다.&lt;/li&gt;
  &lt;li&gt;fine-tuning 단계를 skip하면 최적의 performance를 얻을 수 없다.(blue line 참고)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rq4-what--is--the--influence--on--the--performance--of--the--core--com--ponents-in-strecablation-study&quot;&gt;RQ4: What  is  the  influence  on  the  performance  of  the  core  com- ponents in STRec?(Ablation Study)&lt;/h3&gt;

&lt;p&gt;Figure 7은 &lt;strong&gt;STRec&lt;/strong&gt;에 대한 Ablation Study 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/1a18be99-5cce-4eba-8355-ab3835f66651/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;STRec&lt;/strong&gt;에 대한 세 가지 변형으로 실험을 진행하였다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;STRec-1 : train과 inference 둘 다에서 식 (6)의 random matrix $R$ 제거(random sampling 안함)&lt;/li&gt;
  &lt;li&gt;STRec-2 : 식 (6)에서 index $I$를 random으로 만듦(첫번째 layer에서 item을 random으로 sampling하고 sort함)&lt;/li&gt;
  &lt;li&gt;STRec-3 : visiting time interval matrix $T$를 item 방문 순서를 나타내는 position index matrix로 대체&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;분석 결과는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;STRec-1은 random sampling의 부재로 성능이 감소하였다. 모든 layer에 대한 query는 sequence의 마지막 몇개의 item으로 제한되며, 이로 인해 user interaction sequence의 초기 정보를 무시하게 되기 때문이다.&lt;/li&gt;
  &lt;li&gt;STRec-2는 interaction을 query로 random으로 sampling하며 &lt;strong&gt;STRec&lt;/strong&gt;에 비해 성능 저하를 보이는 것을 통해 sampling된 query가 interaction sequence의 random query보다 훨씬 우수하다는 것을 보여 준다.&lt;/li&gt;
  &lt;li&gt;STRec-3의 성능 저하는 SRS에서의 방문 순서가 NLP의 단어 순서만큼이나 중요하다는 논문의 주장을 입증한다. 또한 이를 통해 SRS task에서 sampling 전략이 time interval 이외에 다른 정보를 기반으로 할 수 있음을 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rq5-why-the-proposed-method-can-elevate-performance-and-shrink-computation-simultaneously-case-study&quot;&gt;RQ5: Why the proposed method can elevate performance and shrink computation simultaneously? (Case Study)&lt;/h3&gt;

&lt;p&gt;Figure 8은 식 (9)에서의 MLP에 대한 sampling density function을 시각화한 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/cb1e4f53-b5ce-4d90-872c-3ba21cf0edcb/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Time interval의 절대값이 작을수록 MLP의 output이 높으며 이는 sequence 뒤쪽에 가까운 interaction이 더 중요하다는 것을 의미한다. &lt;br /&gt;
결과적으로 현재 시점에서 가까운 interaction이 sampling될 가능성이 높으며 초기 period에서는 소수의 item만 sampling된다.&lt;/p&gt;

&lt;p&gt;Figure 9는 user의 주요 관심사와 query로 sampling된 영화로만 구성된 첫 번째 layer의 attention weight matrix의 heatmap을 시각화하였다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/7e7b47d0-ddc8-4cb7-a25f-cc1aafabd5b5/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 9의 Case Study는 논문의 모델이 서로 다른 period에 대해 대표 item을 추출할 수 있음을 나타낸다. 이를 통해 시간에 따라 달라지는 사용자의 다양한 관심을 나타낼 수 있다. 이러한 sampling된 item은 모델이 다양한 time period에 더 중요한 item에 집중하도록 하는 데 도움이 될 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;이 논문에서는 학습 가능한 sparse transformer인 &lt;strong&gt;s&lt;/strong&gt;parce &lt;strong&gt;t&lt;/strong&gt;ransformer for the seqeuntial &lt;strong&gt;rec&lt;/strong&gt;ommendation(&lt;strong&gt;STRec&lt;/strong&gt;)을 설계하였다. &lt;br /&gt;
대표 item을 선택하기 위해 모든 sequence에 대해 먼저 sampling index를 
생성하는 새로운 sampling 전략을 제시하였다. 한편으로는 Cross-attention 기반 sparse transformer를 main framework로 설계하였다.&lt;br /&gt;
Sampling 전략을 최적화하고 정확도를 높이기 위해 &lt;strong&gt;STRec&lt;/strong&gt;을 pre-train과 fine-tuning의 두 단계로 train한다. &lt;br /&gt;
그 결과 &lt;strong&gt;STRec&lt;/strong&gt;은 inference time을 54% 단축하고 GPU memory 비용을 70%를 줄이면서도 다른 state-of-the-art 방법들보다 더 나은 accuracy 성능을 보인다. &lt;br /&gt;
추천시스템에서 발생하는 sparsity 특성을 활용하여 더 빠르고 memory를 적게 차지하면서도 성능이 좋은 transformer 기반 추천 모델을 제시하였다는 점이 인상깊었다.&lt;/p&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;SeungTai Yoo
    &lt;ul&gt;
      &lt;li&gt;Contact : styoo@kaist.ac.kr&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Github Implementation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/ChengxiLi5/STRec&quot;&gt;https://github.com/ChengxiLi5/STRec&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reference
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://grouplens.org/datasets/movielens/1m/&quot;&gt;ML-20M&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://snap.stanford.edu/data/loc-gowalla.html&quot;&gt;Gowalla&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://jmcauley.ucsd.edu/data/amazon/&quot;&gt;Amazon-Electronics&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06939&quot;&gt;GRU4Rec&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.04725&quot;&gt;NARM&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1808.09781&quot;&gt;SASRec&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1904.06690&quot;&gt;Bert4Rec&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.ijcai.org/proceedings/2019/0600.pdf&quot;&gt;FDSA&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3336191.3371786&quot;&gt;Ti-SASRec&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2004.05150&quot;&gt;Longformer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.04768&quot;&gt;Linformer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2007.14062&quot;&gt;Big Bird&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2012.07436&quot;&gt;Informer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2001.04451&quot;&gt;Reformer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2202.10447&quot;&gt;FLASH&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2106.13008&quot;&gt;Autoformer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;Gumbel-Softmax&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/document/5197422&quot;&gt;Matrix Factorization(MF)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 20 Nov 2023 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2023-11-20-STRec_Sparse_Transformer_for_Sequential_Recommendations.html</link>
            <guid isPermaLink="true">http://localhost:4000/2023-11-20-STRec_Sparse_Transformer_for_Sequential_Recommendations.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[NIPS 2021] Robustness of Graph Neural Networks at Scale</title>
            <description>&lt;h2 id=&quot;0-background&quot;&gt;&lt;strong&gt;0. Background&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Adversarial Attack on GNN : Adversarial Pertubation을 적용해 기존 분류기 또는 GNN 모델의 성능을 낮추는 것을 말한다.&lt;/li&gt;
  &lt;li&gt;Testing Phase Attack : 분류 모델에 대해서 간섭을 주진 않지만 모델이 정확하게 동작하지 않도록 오동작을 유발하는 공격이다. 공격을 수행할 시 사용 가능한 지식의 양에 따라 White Box, Black Box Attack으로 분류한다.
    &lt;ul&gt;
      &lt;li&gt;White Box Attacks : 분류에 사용되는 model에 대한 모든 지식을 가지고 있는 공격이다.&lt;/li&gt;
      &lt;li&gt;Black Box Attacks : model에 대한 정보를 모르는 공격자가 행하는 공격으로 input과 이것이 주는 output을 관찰함으로써 수행될 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;논문에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;testing phase&lt;/code&gt; + &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;white box&lt;/code&gt; 조건에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Adversarial Robustness&lt;/code&gt;를 달성하고자 아래 방법론들을 제시한다.&lt;/p&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Graph Neural Networks가 Adversarial Perturbations에 Robust하지 않다는 점은 발견이 되나, 이를 중점으로 한 연구들은 거의 없다. 예를 들어 PubMed Graph Dataset의 경우, 인접 행렬을 기반으로 한 공격을 위해선 약 20GB의 메모리가 필요하다. 이런 메모리 요구는 GNN의 Robustness를 확인해보고자 하는 실질적인 연구를 어렵게 한다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;해당 논문은 GNN의 Adversarial robustness에 대한 기존 연구의 한계점들을 다음과 같이 명시했다 : 
	(1) 기존의 Loss는 Global Attack에 적합하지 않음
	(2) GNN Attack에 소요되는 비용이 $O(n^2)$이상으로 매우 큼
	(3) 기존의 Robust GNN은 scalable하지 않음.&lt;/p&gt;

&lt;p&gt;따라서, 위의 한계점들을 (1) &lt;strong&gt;Surrogate loss&lt;/strong&gt;를 제시함으로써, (2) R-BCD를 기반으로 하여 &lt;strong&gt;시간복잡도를 $O(\Delta)$로 줄이는 방법을 제시함&lt;/strong&gt;으로써, 마지막으로 (3) &lt;strong&gt;Soft Median으로 효과적으로 GNN을 방어하는 방법을 관찰함&lt;/strong&gt;으로써 해결하고자 했다.&lt;/p&gt;

&lt;h2 id=&quot;3-method-and-experiment&quot;&gt;&lt;strong&gt;3. Method and Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;31-surrogate-losses-for-global-attacks&quot;&gt;3.1 Surrogate Losses for global attacks&lt;/h3&gt;

&lt;p&gt;GNN의 Global Attacks들은 평균 Cross Entropy Loss(CE)를 증가시킨다. 그러나 Node가 많은 Large Graph들의 경우 CE loss는 효율적이지 않다. Accuracy가 낮아질 때, CE loss 는 증가할 것이다. 그러나 CE의 경우, Accuracy가 감소하지 않아도 증가할 때가 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/w7fSMqc/Untitled.png&quot; alt=&quot;Untitled.png&quot; /&gt;
$\psi$는 Classification Margin으로 값이 클수록 Classification을 Confident하게 수행하는 것을, 값이 작을수록 Confident하지 않게 수행하는 것을 의미한다. 즉, 이 값이 작을 수록 misclassified될 가능성이 크다.
 위의 그림은 1% of nodes를 가지고 feature perturbation을 준 모습이다. CE Loss는 Tanh margin에 비해서 Classification margin이 낮은 node들에 대해 Attack을 가하며 Budget $\Delta$를 사용하는 모습을 볼 수 있다. ($\Delta$ : Perturbed된 인접행렬의 변경된 Entry의 수)
 &lt;img src=&quot;https://i.ibb.co/TLW11Mw/Untitled-99.png&quot; alt=&quot;Untitled-99.png&quot; /&gt;
위 그래프는 각 데이터셋에 대한 CE, CW, Tanh margin loss에 대한 실험결과이다. CE, CW는 tanh margin loss에 비해서 loss, accuracy의 그래프의 결과가 안정적이지 못하고 그 성능이 덜한 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;그래서 이들은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Surrogate loss&lt;/code&gt;를 새롭게 정의한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition of Surrogate Loss:&lt;/strong&gt; Global Attack에 대한 Surrogate Loss $L^\prime$는&lt;/p&gt;

&lt;p&gt;(1) 옳게 분류된 perturbed node들에 대해서만 incentive를 주고, $\frac{\partial L^\prime}{\partial z_ c^*} \vert \psi_ 0 = 0$&lt;/p&gt;

&lt;p&gt;(2) Decision Boundary 근처에 있는 node들을 선호하는 방식으로 Loss를 구성한다.&lt;/p&gt;

&lt;p&gt;$\frac{\partial L^\prime}{\partial z_ c^{*}} \vert \psi_ 1 &amp;lt; \frac{\partial L^\prime}{\partial z_ c^{*}} \vert \psi_ 2 \; for \, any \,0&amp;lt;\psi_ 1&amp;lt;\psi_ 2$&lt;/p&gt;

&lt;p&gt;위 정의에서 도출된 정의에 따르면, Cross Entropy Loss는 (1)을 위반하여 Global Optimum을 가질 수 없기에 Surrogate loss가 될 수 없다. 또한, Carlini-Wagner(CW) Loss는 Decision boundary에 있는 node들을 고려하지 못하기에 (2)을 위반한다.&lt;/p&gt;

&lt;p&gt;논문은 Surrogate loss에 맞는 loss로써 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Masked Cross Entropy(MCE)&lt;/code&gt;를 제안한다.&lt;/p&gt;

&lt;p&gt;$MCE = \frac{1}{\vert V^+ \vert} \sum_{i \in V^+} -\log(p^{(i)}_ {c^*})$&lt;/p&gt;

&lt;p&gt;MCE는 Projected Gradient Descent attack(PR-BCD)에 대해서는 Cross Entropy와 큰 차이를 보이지 않지만, Greedy Gradient-Based attack에 있어서는 강점을 보이는 것을 확인할 수 있다. 따라서, 이후 실험에서는 Greedy Attack에선 MCE를 사용하고 다른 경우는 Tanh margin loss를 사용한다.&lt;/p&gt;

&lt;h3 id=&quot;32-scalable-attacks&quot;&gt;3.2 Scalable Attacks&lt;/h3&gt;

&lt;p&gt;Gradient-based attacks들은 인접행렬 $A$에 대해서 모두 최적화하기에 $\Theta(n^2)$의 공간 복잡도를 보여 Large Graph에 대한 robustness는 대개 측정하기 어려웠다.&lt;/p&gt;

&lt;p&gt;Large-scale Optimization을 위해 R-BCD(Randomized Block Coordinate Descent)를 사용함으로써 변수들의 부분집합에 대해서만 gradients를 구하기 때문에 사용되는 메모리와 수행 시간을 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;Perturbation $P\in{0,1}^{n*n}$ 는 아래와 같이 모델되었다.&lt;/p&gt;

&lt;p&gt;$\max_{P\; \text{s.t.}\; P \in {0, 1}^{n \times n},\; \sum P \leq \Delta} L(f_\theta(A \oplus P, X))$
여기서 $\oplus$는 element-wise XOR을 나타내고 $\Delta$는 Edge budget을 의미한다.&lt;/p&gt;

&lt;p&gt;그러나 $n^2$만큼의 parameter를 위 식에서 저장해야 하기때문에$O(n^2)$ 만큼의 공간 복잡도를 가진다. 이에 논문은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Projected Randomized Block Coordinate Descent(PR-BCD)&lt;/code&gt;를 제안한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/Qb9hygL/Untitled-1.png&quot; alt=&quot;Untitled-1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Explanation of PR-BCD :&lt;/strong&gt; P는 이산 Edge 행렬로 element p는 edge를 뒤집을 확률을 나타낸다. 우선, epoch마다 P에서 무작위로 추출된 Block을 바탕으로 특정 부분의 edge들만을 변경한다. 업데이트 후 p에 대한 확률 질량함수를 수정하여 베르누이 분포에 대한 기댓값이 Budget을 넘지 않도록 한다. 
 PR-BCD에서는 block size로 공간 복잡도를 줄이고 효율적인 공격을 가능하게한다. 효율적인 공격을 위해서 전체 가능한 edge들을 탐색할 필요가 없다고 생각했다. Figure 3-(a)를 보면 상대적으로 작은 Dataset인 Cora ML에서는 작은 block size($b$)로도 낮은 Accuracy를 달성할 수 있었다. 그리고 Figure 3-(b)를 통해 여러 block size에 대해서 실험해본 결과 향상된 Attack을 위해서는 Epoch의 수를 늘리는 것이 중요한 것을 확인할 수 있었다. 
 이로써 PR-BCD로 이전에는 $\mathcal{O}(n^2)$가 필요했던 것을 $\mathcal{O}(b)$로 줄일 수 있어 효과적인 Attack을 시행할 수 있었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/P5hzD8b/Utitled-98.png&quot; alt=&quot;Utitled-98.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 논문은 PR-BCD에 대한 또 다른 대안으로 위와 같이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GR-BCD&lt;/code&gt;를 함께 제안한다. PR-BCD에서 Block 추출 시 가장 큰 gradient를 가진 entry만 &lt;strong&gt;greedy&lt;/strong&gt;하게 변경하는 것으로 E번의 epoch 후에 budget이 충족되도록 하는 방법이다.&lt;/p&gt;

&lt;p&gt;그러나 위 방법들은 실제 최적화 문제를 얼마나 효과적으로 근사하는지에 대한 보장은 제공하지 않고, 공격의 효과의 Upper bound만 보여준다는 점에서 한계가 있다.&lt;/p&gt;

&lt;p&gt;위 방법론에서 확장하여 더 큰 그래프들을 사용하기 위해, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PPRGo&lt;/code&gt;를 사용했다. 이는 Personalized Page Rank(PPR) Matrix($\Pi$)를 사용함으로써 explicit message passing steps 수를 1로 줄여 constant complexity를 가질 수 있게 한다.&lt;/p&gt;

&lt;p&gt;$p = softmax \big[\text{AGG}{\Pi_{uv}(A_{uv}, f_\text{enc}(x_u)\big), \; \forall u \in \mathbb{N}^\prime(v)}\big]$&lt;/p&gt;

&lt;h3 id=&quot;33-scalable-defense&quot;&gt;3.3 Scalable Defense&lt;/h3&gt;

&lt;p&gt;GNN의 메세지 패싱 프레임워크를 다음과 같이 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;$h^{(l)}_ v = \phi^{(l)} \big[( \text{AGG}^{(l)}{\big(A_ {uv}, h^{(l-1)}_ u W^{(l)}\big), \quad \forall u \in \mathbb{N}^\prime(v)}\big]$  where $\text{neighborhood} \; \mathbb{N}^\prime(v) = \mathbb{N}(v) \cup v$ 
and $AGG = \text{l-th layer message passing aggregation}$ 
and $h^{(l)}_ v = \text{embedding},\; \sigma^{(l)} \text{activation function}$&lt;/p&gt;

&lt;p&gt;이전 논문인 Geisler et al. (2020)에서는 Aggregate Function으로 Soft Medoid를 다음과 같이 제안했다 : $\tilde{f}_ {\text{WSM}}(X, a) = c(s \circ a)X \quad where  \quad s_ i = \frac{\exp \left( -\frac{1}{T} \sum_ {j=1}^{n} a_ j ||x_ j - x_ i|| \right)}{\sum_ {q=1}^{n} \exp \left( -\frac{1}{T} \sum_ {j=1}^{n} a_ j ||x_ j - x_ q|| \right)}$
 Soft Medoid는 $s_i$로 표현되는 이웃 노드들의 embedding에 대한 distance matrix에 대해 행/열 summation을 요구하기에 neighborhood size에 대해 이차 복잡도를 지닌다.&lt;/p&gt;

&lt;p&gt;이를 개선하기 위해 논문은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Soft Median&lt;/code&gt;을 제시한다.&lt;/p&gt;

&lt;p&gt;$\mu_\text{SoftMedian}(X) \= \text{softmax}(\frac{-c}{T\sqrt{d}} )^\intercal \cdot \mathbf{X} = \mathbf{s}^\intercal \cdot \mathbf{X} \approx \arg \min_{x^\prime \in \mathbf{X}} |x_{\bar{}} - x^\prime|$&lt;/p&gt;

&lt;p&gt;이로써 Dimension($d$)에만 의존함으로써 계산을 효율적으로 할 수 있다. $d$를 충분히 작게 한다면 Soft Median 스케일은 $\mathbb{N}$에 linear한 scale을 보인다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/g6v6dk2/Untitled-97.png&quot; alt=&quot;Untitled-97.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그래프는 원본 그래프와 Pertubed된 그래프를 첫 번째 message passing을 한 후의 latent space의 $L_2$ Distance를 나타낸 그래프이다. Soft Median이 Weighted Sum보다 20% 가까이 낮은 error를 보인다. 반면, 그래프에는 Soft Medoid가 Soft Median보다 Robust한 결과를 가지는 것으로 보인다. 그러나 오른쪽 표가 나타내듯 Adversarial accuracy에서는 Soft Medoid가 Soft Median보다 좋은 성능을 보이지 못했다.&lt;/p&gt;

&lt;p&gt;이처럼 Soft Median은 (1) 차원에 대한 고려 없이 단순히 Summation 한다면 computation 비용이 많이 든다는 점과 (2) Soft Median에 비해 robust하지 않은 결과와 마찬가지로 잘못된 robustness의 결과를 가져올 수 있다는 점을 한계점으로 삼을 수 있다. 그러나 PPRGo와 결합하여 사용한다면 위 한계를 완화할 수 있다고 설명한다.&lt;/p&gt;

&lt;h3 id=&quot;34-empirical-evaluation&quot;&gt;3.4 Empirical Evaluation&lt;/h3&gt;

&lt;h4 id=&quot;surrogate-loss&quot;&gt;Surrogate Loss&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/Tr2CFsN/Untitled-2.png&quot; alt=&quot;Untitled-2&quot; /&gt;
Figure 5는 logit의 classification margin을 가지고 loss들을 분류한 결과이다. CE, margin이 low margin에 Incentive를 주는 경향을 보이고, CW, NCE, elu margin들은 high confidence nodes들에 집중하는 경향을 보인다. 그리고 Surrogate loss에서 강조했듯 Decision boundary에 있는 node들에 집중하는 MCE, Tanh margin을 확인할 수 있다.
Figure 6는 Pubmed Dataset에 Loss들을 달리하여 Attack 후 Accuracy를 측정한 결과이다. 위에서 살펴본 바와 같이 MCE와 Tanh margin의 경우 Adversarial accuracy를 낮추는데 효과적이었고, 특히 MCE는 Greedy attack을 시행했을 때 더욱 효과적임을 볼 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;robustness-wrt-global-attacks&quot;&gt;Robustness w.r.t global attacks.&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/bFrdktP/Untitled-3.png&quot; alt=&quot;Untitled-3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/b6P7Xwd/Untitled-4.png&quot; alt=&quot;Untitled-4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 실험 결과는 Pubmed, arXiv, Products Dataset 각각에 대해 $\text{budget} = \Delta$만큼의 공격 후에 adversarial accuracy를 측정한 결과이다. 약 2%가량 Pertubation을 가했을 때, 대략 60%의 정확도로 떨어지는 모습을 확인할 수 있었다고 밝혔다. 각 경우에서 Soft Median GDC, Soft Median PPRGo, PPRGo Defense가 타 모델보다 비교적 좋은 결과가 보임을 확인할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;robustness-wrt-local-attacks&quot;&gt;Robustness w.r.t local attacks.&lt;/h4&gt;

&lt;p&gt;Cora ML, Citeseer, arXiv에서 PR-BCD가 SGA보다 효과적으로 공격을 하는 것을 볼 수 있었다. 그리고 아래 그래프가 보이듯 Soft Median PPRGo가 위 공격에 대해서 Vanila PPRGo와 Vanila GCN보다 대체로 잘 견디는 것을 확인할 수 있었다. (b)의 Papers100M에서 $\Delta_i = 0.25$일 때, Soft Median PPRGo는 공격자의 성공률을 90%에서 30%로 줄인 것을 그래프에서 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/m0cRXCv/Untitled-5.png&quot; alt=&quot;Untitled-5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/b5xBzvx/Untitled-6.png&quot; alt=&quot;Untitled-6&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-conclusion&quot;&gt;4. Conclusion&lt;/h2&gt;

&lt;p&gt;규모가 있는 GNN에서의 Adversarial Robustness를 살펴보았다. 논문은 이전까지 데이터셋의 규모로 인해 잘 다뤄지지 않았던 문제를 확인하기 위해 Attack과 Defense에 대해 직접 방법을 제시하고 실험한 결과를 보였다.&lt;/p&gt;

&lt;p&gt;따라서, Complexity를 줄이기 위해 PPRGo와 Soft Median이라는 방법을 도입하고 Attack과 Defense에 반영하여 실제로 큰 데이터셋에 대한 실험결과를 낸 것을 보며 문제상황에 대해 여러 모델을 활용하여 다각도로 실험해본 것을 확인할 수 있었다. 그러나, 그들이 강조한 PPRGo에 대한 모델 설명이 타 모델에 비해서 부족한 점과 white box과 attack budget에 대한 가정이 실제 적용될 수 있는 부분인지에 대한 의문이 남아있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sumin Lee&lt;/li&gt;
  &lt;li&gt;Affiliation: Dept. of Data Science, KAIST&lt;/li&gt;
  &lt;li&gt;Research Topic: Machine learning&lt;/li&gt;
  &lt;li&gt;Contact : &lt;a href=&quot;mailto:sumlee@kaist.ac.kr&quot;&gt;sumlee@kaist.ac.kr&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Geisler, Simon, et al. “Robustness of graph neural networks at scale.” &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; 34 (2021): 7637-7649.&lt;/li&gt;
  &lt;li&gt;Bojchevski, Aleksandar, et al. “Scaling graph neural networks with approximate pagerank.” &lt;em&gt;Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp;amp; Data Mining&lt;/em&gt;. 2020.&lt;/li&gt;
  &lt;li&gt;Geisler, Simon, et al. “Reliable graph neural networks via robust aggregation” &lt;em&gt;In Proceedings of the 34th International Conference on Neural Information Processing Systems (NIPS’20)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 20 Nov 2023 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2023-11-20-Robustness_of_Graph_Neural_Networks_at_Scale.html</link>
            <guid isPermaLink="true">http://localhost:4000/2023-11-20-Robustness_of_Graph_Neural_Networks_at_Scale.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICML 2022] Rethinking Graph Neural Networks for Anomaly Detection</title>
            <description>&lt;h1 id=&quot;icml-22-rethinking-graph-neural-networks-for-anomaly-detection&quot;&gt;[ICML-22] Rethinking Graph Neural Networks for Anomaly Detection&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Rethinking Graph Neural Networks for Anomaly Detection&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Author&lt;/th&gt;
      &lt;th&gt;Booktitle&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Tang, Jianheng and Li, Jiajin and Gao, Ziqi and Li, Jia&lt;/td&gt;
      &lt;td&gt;International Conference on Machine Learning&lt;/td&gt;
      &lt;td&gt;2022&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;11-background&quot;&gt;1.1 Background&lt;/h3&gt;

&lt;p&gt;이상치 (An anomaly or an outlier) 는 대부분의 개체에서 크게 벗어난 데이터 객체를 뜻하며, 이상치 탐지 (Anomaly Detection) 문제로는 사이버 보안, 사기 탐지, 장치 오류 탐지 등이 있습니다. 기술의 발전으로 인하여 그래프 데이터가 보편화되면서 structural data에 대한 분석으로 Graph Neural Networks (이하 “GNN”)이 각광받았고 자연스럽게 그래프 이상 탐지 작업 (Graph Anomaly Detection Task)에 적용되었습니다. 하지만, vanilla GNN은 지나친 확일화 문제로 인하여 이상치 탐지에 적합하지 않았고 이를 개선하기 위하여 attention 매커니즘을 적용하는 방법, resampling 전략을 사용하는 방법, 그리고 보조의 losses를 설계하는 방법이 제안되었습니다. 이 세 가지 방법은 모두 spatial domain에서의 분석이며, spectral domain에서의 분석은 거의 이루어지지 않았습니다. GNN을 설계할 때 알맞는 spectral filter을 적용하는 것 또한 중요하기에 해당 논문에서는 ‘이상치 탐지를 위한 GNN에서 적절한 spectral filter을 어떻게 고를 것인가?’ 에 대해 답변하고자 합니다.&lt;/p&gt;

&lt;h3 id=&quot;12-overview&quot;&gt;1.2 Overview&lt;/h3&gt;

&lt;p&gt;‘이상치 탐지를 위한 GNN에서 적절한 spectral filter을 어떻게 고를 것인가?’에 대해 답변하기 위해 두 가지 과정을 거칩니다. 첫 번째로, 그래프 이상 탐지에서 spectral localized band-pass filters의 중요성을 확인하는 과정입니다. 논문의 저자는 이상의 정도(degree)가 커질수록, 저주파 에너지가 점진적으로 고주파 에너지로 전환됨을 확인하였고 이를 spectral 에너지 분포의 ‘오른쪽 편이 (right-shift)’ 현상으로 정의하였습니다. ‘오른쪽 편이’ 현상에 대한 수리적 증명 및 데이터를 통한 검증으로 적절한 spectral filter의 필요성을 보입니다. 두 번째로, 그래프 이상치에서의 ‘오른쪽 편이’ 현상을 잘 다루는 새로운 알고리즘, Beta Wavelet Graph Neural Network (이하 “BWGNN”)을 제안합니다. Hammond’s graph wavelet theory에서 착안하여 Heat kernal이 아닌 Beta kernal을 사용함으로써, 매우 유동적이고 spatial/spectral-localized 하며 band-pass한 filter을 통해 고주파 이상 현상을 해결합니다.&lt;/p&gt;

&lt;h3 id=&quot;13-preliminaries&quot;&gt;1.3 Preliminaries&lt;/h3&gt;

&lt;p&gt;속성 그래프 (Attributed graph)는  $G = { V,E,X }$ 로 정의되며, $V$ 는 node, $E$는 edge, $X$는 node features을 의미합니다. $A$를 adjacency matrix, $D$를 degree matrix로 표현합니다. $V_ {a}$ 와 $V_ {n}$을 두 개의 분리된 하위집합이라 할때, $V_ {a}$ 는 모든 이상 노드를 나타내고, $V_ {n}$ 은 모든 정상 노드를 나타냅니다. 그래프 기반 이상 탐지는 주어진 그래프 구조 $E$, node features $X$, 그리고 부분적인 노드 라벨 ${V_ {a}, V_ {n}}$ 정보를 활용하여 $G$ 내의 라벨링 되지 않은 노드를 이상 또는 정상으로 분류하는 것입니다. 해당 논문은 node 이상치에 집중하며, 모든 edge는 신뢰된다고 가정합니다. 보통, 정상 노드가 이상 노드보다 훨씬 많기에 그래프 기반 이상 탐지는 불균형한 이진 노드 분류 문제로 여겨집니다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;그래프 이상 탐지에서 spatial domain에 대한 분석은 이루어졌으나 spectral domain에 대한 분석이 거의 이루어지지 않았음이 해당 논문의 동기입니다. 그래프 이상 탐지를 위한 spectral domain 분석이 유효한지를 확인하기 위하여 ‘오른쪽 편이’ 현상을 정의하고 Gaussian anomaly model로 증명하며 인조적인 데이터와 실제 데이터에서 유효한지 확인하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;21-theoretical-insights-of-the-right-shift-phenomenon&quot;&gt;2.1 Theoretical insights of the ‘right-shift’ phenomenon&lt;/h3&gt;

&lt;p&gt;Laplacian matrix L 을 $D-A$ 또는 $I-D^{-1/2}AD^{-1/2}$ 라 해봅시다. 이때, $I$는 Identity matrix 입니다. $L$ 은 $0=\lambda_1 \leq \lambda_2 \leq … \leq \lambda_N$ 인 고유값을 갖는 대칭행렬이며, 이에 대응하는 고유벡터는 $U = (u_1,u_2,…,u_N)$ 입니다. 두 끝 점 $\lambda_1$과 $\lambda_N$을 제외하고 임의의 기준값 $\lambda_k$에 대하여 우리는 고유값을 두 개의 집합, 저주파 ${\lambda_1, \lambda_2, … \lambda_k}$와 고주파 ${\lambda_ {k+1}, \lambda_ {k+2}, … \lambda_N}$ 로 나눌 수 있습니다.&lt;/p&gt;

&lt;p&gt;$G$ 에서 $x= (x_1, x_2, … , x_N)^T \in R^N$ 을 signal, $\hat{x}= (\hat{x}_ 1, \hat{x}_ 2, … , \hat{x}_ N)^T = U^Tx$ 를 $x$ 의 graph Fourier transform 이라 가정해봅시다. 
이때 $\hat{x}^2_ {k} / \sum _ {i=1} ^ N \hat{x} ^2 _i$ 를 $\lambda _k (1 \leq k \leq N)$ 에서의 spectral energy distribution 이라 합니다.&lt;/p&gt;

&lt;p&gt;논문의 저자는 이상치의 존재가 존재하면 spectral energy 에서의 ‘오른쪽 편이’ 현상이 나타남을 확인하였으며, 이는 spectral energy distribution이 낮은 주파수에는 적게 집중되어 있고 높은 주파수에는 많이 집중되어 있음을 의미합니다. 본문은 probabilistic anomaly model을 사용하여 이 현상을 증명합니다. 증명 과정은 다음과 같습니다. 그래프의 특징은 Gaussian distribution을 따르며 i.i.d 하다고  가정이 됩니다. (i.e. $x \sim N(\mu e_ N,\sigma^2 I_ N)$. 이때, $x$의 이상치 정도는 $\sigma / \vert \mu \vert$로 표현할 수 있습니다. $x$의 이상치 정도에 따라 spectral energy distribution이 얼마나 바뀌는지를 energy ratio라 할때, 어떠한 $1 \leq k \leq N-1$에 대하여 k번째 낮은 주파수 energy ratio 를 $\eta_ k(x,L) = \frac{\sum_ {i=1}^k \hat{x}^2_ i } {\sum_ {i=1}^N \hat{x}^2_ i}$ 로 정의합니다. $\eta_ k(x,L)$ 가 크다는 것은 에너지의 더 큰 부분이 처음 $k$개의 고유값으로 축소된다는 것을 의미합니다. 이때, 만약 $\vert \mu \vert \neq 0$ 이고 $L = D - A$ 라면, 저주파 energy ratio의 역의 기댓값 $E_x[1/\eta_k(x,L)]$ 는 이상치 정도 $\sigma / \vert \mu \vert$ 로 단조롭게 증가한다는 것을 수식으로 증명할 수 있습니다.(해당 논문의 Appendix A 참고) 아쉽게도, x의 이상치 정도가 바뀜에 따라 $\eta_k(x,L)$ 가 어떻게 바뀌는지를 알기 위하여 eigen-decomposition을 수행하여 계산하면 시간이 많이 소요됩니다. 따라서 본문은 계산이 쉽도록 고주파 영역 $S_ {high}$에 대한 정의를 내리는데 이것의 핵심은 고주파 영역이 위에서 표현한 $E_x[1/\eta_k(x,L)]$ 을 대체할 수 있다는 것입니다. 고주파 영역은 다음으로 계산할 수 있습니다: $S_ {high} = \frac{\sum_ {i=1}^k \lambda_k \hat{x}^2_ i } {\sum_ {i=1}^N \hat{x}^2_ i} = \frac {x^T Lx} {x^Tx}$. 낮은 주파수의 스펙트럼 에너지는 작은 고유값을 곱한 후엔 $S_ {high}$ 에 덜 기여하기에 우리는 $S_ {high}$의 변화를 이용하여 모든 스펙트럼에서의 ‘오른쪽 편이’ 현상을 표현할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;22-validation-on-datasets&quot;&gt;2.2 Validation on Datasets&lt;/h3&gt;

&lt;p&gt;해당 논문에서는 $x$가 Gaussian distribution을 따르는 데이터셋과 따르지 않은 데이터셋 각각에 대하여 ‘오른쪽 편이’ 현상을 검증합니다. 첫 번째로, 인조적인 데이터셋인 Barabasi-Albert graph (Figure 1 (a)-(b))와 Minnesota road graph (Figure 1 (c)-(d)) 에서 이상치의 효과를 보입니다. 저자는 이상 현상의 두 가지 변형을 분석합니다. (i) 이상 현상의 비율은 5%로 고정되고 이상 현상의 표준 편차는 변경되는 경우 (즉, $\sigma$ = 1, 2, 5, 20). (ii) 이상치의 표준편차는 5로 고정되고 이상치의 비율이 변경되는 경우 (즉, $\alpha$ = 0%, 1%, 5%, 20%).
 아래 그림의 상단에서 파란색 원은 spatial domain에서의 이상 노드를 나타내며 원의 크기가 클수록 이상치의 정도가 심함을 의미합니다. 그림의 하단은 $x$의 energy distribution 을 spectral domain과 이상치 정도에 따라 그린 그래프입니다. 이를 해석하면, 이상치의 정도, 즉, $\sigma$ 와 $\alpha$ 가 커질수록, $\lambda$ $\geq$ 0.5 일때의 spectral energy가 큼을 확인할 수 있으며 이는 2.1에서 설명한 ‘오른쪽 편이’ 현상이 보임을 의미합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/hgYpfq9/Figure1.png&quot; alt=&quot;Figure1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;두 번째로, node feature가 Gaussian distribution을 엄격하게는 따르지 않는 현실의 데이터셋에서의 ‘오른쪽 편이’ 현상을 입증합니다. 아래는 해당 4가지 데이터셋, Amazon, YelpChi, T-Finance, T-Social 의 특징과 이상치 효과에 대하여 정리한 도표입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/njWJRtj/Table1.png&quot; alt=&quot;Table1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아래의 표는 Amazon dataset에서 (1) 기존 그래프, (2) 모든 이상치를 없앤 그래프, (3) 임의의 같은 노드의 수를 없앤 그래프의 spectral energy를 비교한 표입니다. Figure 3의 왼쪽 그래프에서, 낮은 주파수일때, 즉, $\lambda$ 값이 작을 때, Drop-Anomaly 가 Drop-Random 보다 큰 spectral energy distribution을 가짐을 확인할 수 있으며 이는  ‘오른쪽 편이’ 현상이 있음을 나타냅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/9VCmrWV/Figure3.png&quot; alt=&quot;Figure3.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;대부분의 해당 논문 이전의 GNN은 low-pass filter 또는 adaptive filter을 사용하였으며 이는 band-pass 와 spectral-localized 를 보장하지 못합니다. 이러한 단점을 극복하기 위하여 해당 논문에서는 Hammond’s graph wavelet theory를 기반으로 한 새로운 GNN architecture인 BWGNN를 제안합니다. Hammond’s Graph Wavelet 은 graph signal $x \in R^N$ 에 wavelets $W = (W_ {\psi_1}, W_ {\psi_2},…)$ 를 적용하여 변형시키는 것이며 이때, $\psi$ 는 “mother” wavelet 입니다. graph signal $x$ 에 $W_ {\psi_i}$를 적용하는 것은 다음과 같이 쓸 수 있습니다 : $W_ {\psi_ i}(x) = Ug_ i(\Lambda)U^Tx$. 이때, $g_i(\cdot)$ 은 $[0, \lambda_N]$ 에서 정의된 spectral domain의 kernal function이며, $g_i(\Lambda) = diag(g_i(\lambda))$ 입니다.&lt;/p&gt;

&lt;p&gt;Beta distribution은 몇몇 논문에서 wavelet basis의 역할을 하였습니다. 하지만 이전에 Beta distribution을 그래프 데이터에 사용한 기록이 없어 해당 논문에서는 Graph kernal function로 Beta distribution을 선택하여 Beta graph wavelet를 만들었고 특징을 분석하였습니다. 해당 논문에서 제안하는 Beta wavelet transform $W_ {p,q}$ 는 다음과 같이 작성할 수 있습니다:&lt;/p&gt;

&lt;p&gt;$W_ {p,q} = U\beta^{*}_ {p,q}(\Lambda)U^T = \beta^{*}_ {p,q}(L) = \frac{(L/2)^p(I-L/2)^q}{2B(p+1,q+1)}$&lt;/p&gt;

&lt;p&gt;이때, $p+q = C$ 는 상수이며 Beta wavelet transform $W$ 는 $W = (W_ {0,C}, W_ {1,C-1}, …, W_ {C,0})$ 로 총 $C+1$ 개의 Beta wavelets 으로 구성될 수 있습니다. $C$ 가 클수록 더 안좋은 공간적 집약성을 희생하여 더 나은 스펙트럼 집약성을 제공할 수 있습니다.
 Heat Wavelet과 Beta Wavelet 를 비교해보면, Figure 4의 왼쪽에서 볼 수 있듯이 Beta Wavelet은 low-pass filter만 있는 Heat Wavelet 과 달리 low-pass 와 band-pass를 포함한 다양한 filter type을 포함합니다. Figure 4의 오른쪽에서는 Beta Wavelet은 긍정의 반응만 보이는 Heat Wavelet 과 달리 서로 다른 채널에 대해 긍정과 부정의 효과를 둘다 보임을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/S0FG2Nc/Figure4.png&quot; alt=&quot;Figure4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위에서 설명한 Beta graph wavelet을 활용하여 만든 BWGNN은 병렬적으로 서로 다른 wavelet kernel을 사용한 후 해당 filtering의 결과를 병합합니다. 구체적으로 BWGNN은 아래의 propagation 과정을 채택합니다.&lt;/p&gt;

&lt;p&gt;$
Z_i = W_ {i,C-i} (MLP(X))
$&lt;/p&gt;

&lt;p&gt;$
H = AGG([Z_0, Z_1, …, Z_C])
$&lt;/p&gt;

&lt;p&gt;이때, MLP($\cdot$) 은 multi-layer perceptron, AGG($\cdot$)은 단순 집계 합수를 의미하며, $W_ {i,C-i}$ 는 우리의 wavelet kernel을 뜻합니다. BWGNN의  학습을 위하여 weighted cross-entropy loss가 사용되었으며 BWGNN의 시간복잡도는 $O(C \vert \epsilon \vert)$에 해당합니다.&lt;/p&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;41-experiment-setup&quot;&gt;4.1 &lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;4 Dataset : T-Finance, T-Social , YelpChi, Amazon
    &lt;ul&gt;
      &lt;li&gt;T-Finance : 거래 네트워크에서의 이상 계좌를 찾는 것을 목적으로 하는 데이터셋&lt;/li&gt;
      &lt;li&gt;T-Social : 소셜 네트워크에서 이상 계정을 찾는 것을 목적으로 하는 데이터셋&lt;/li&gt;
      &lt;li&gt;YelpChi : &lt;a href=&quot;http://Yelp.com&quot;&gt;Yelp.com&lt;/a&gt; 에 올라온 악성 리뷰를 찾는 것을 목적으로 하는 데이터셋&lt;/li&gt;
      &lt;li&gt;Amazon : &lt;a href=&quot;http://Amazon.com&quot;&gt;Amazon.com&lt;/a&gt; 의 음악 악기 카테고리에 올라온 가짜 제품 리뷰를 찾는 것을 목적으로 하는 데이터셋&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Evaluation Metric
    &lt;ul&gt;
      &lt;li&gt;F1-macro : 두 클래스의 F1 점수에 대한 비가중 평균으로, 정상 레이블과 이상 레이블 간의 불균형 비율을 무시함&lt;/li&gt;
      &lt;li&gt;AUC : ROC 곡선 아래 영역&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Baselines
    &lt;ul&gt;
      &lt;li&gt;First group : 그래프 관계 없이 노드 기능만 고려
        &lt;ul&gt;
          &lt;li&gt;MLP : 활성화 함수가 있는 두 개의 선형 레이어로 구성된 Multi-layer Perceptron Network&lt;/li&gt;
          &lt;li&gt;SVM : RBF(Radial Basis Function) 커널을 갖춘 Support Vector Machine&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Second group : 노드 분류를 위한 일반 GNN 모델
        &lt;ul&gt;
          &lt;li&gt;GCN : 그래프의 국지적 스펙트럼 필터의 1차 근사를 사용하는 Graph Convolutional Network&lt;/li&gt;
          &lt;li&gt;ChebyNet : Convolution kernal을 Chebyshev 다항식으로 제한하는 Graph Convolutional Network&lt;/li&gt;
          &lt;li&gt;GAT : 이웃 집계(Aggregation)을 위한 Attention 메커니즘을 사용하는 Graph Attention Network&lt;/li&gt;
          &lt;li&gt;GIN : Weisfeiler-Lehman(WL) 그래프 동형성 테스트에 연결되는 GNN 모델&lt;/li&gt;
          &lt;li&gt;GraphSAGE : 고정된 이웃 노드 샘플 수를 기반으로 하는 GNN 모델&lt;/li&gt;
          &lt;li&gt;GWNN : wavelet 변환을 생성하기 위해 heat kernal을 사용하는 Graph Wavelet Neural Network&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Third group : 그래프 기반 이상 탐지를 위한 최신 기법
        &lt;ul&gt;
          &lt;li&gt;GraphConsis : 그래프 이상 탐지에서 문맥, 기능 및 관계 불일치 문제를 해결하는 heterogeneous GNN&lt;/li&gt;
          &lt;li&gt;CAREGNN : 위장 및 강화 학습에 대한 세 가지 고유 모듈을 통해 집계 프로세스를 향상하는 위장 방지 GNN&lt;/li&gt;
          &lt;li&gt;PC-GNN : 리샘플링을 통해 그래프 기반 사기 탐지의 클래스 불균형 문제를 해결하는 GNN 기반 불균형 학습 방법&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Fourth group : 해당 논문에서 제안하는 모델
        &lt;ul&gt;
          &lt;li&gt;BWGNN (homo) : 모든 종류의 edges를 동일하게 취급하는 Beta Wavelet GNN&lt;/li&gt;
          &lt;li&gt;BWGNN (hetero) : 각 관계에 대해 개별적으로 그래프 전파를 수행하고 maximum pooling을 적용한 Beta Wavelet GNN&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;42-result&quot;&gt;4.2 &lt;strong&gt;Result&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;첫 번째 표는 training 비율이 1%와 40%인 YelpChi와 Amazon에서 비교된 모든 알고리즘의 실험 결과입니다.
&lt;img src=&quot;https://i.ibb.co/k6ZSy1T/Table2.png&quot; alt=&quot;Table2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;두 번째 표는 training 비율이 다른 T-Finance 및 T-Social 데이터셋에 대한 실험 결과 및 전체 훈련 시간입니다.
&lt;img src=&quot;https://i.ibb.co/yVjMqxg/Table3.png&quot; alt=&quot;Table3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과를 분석하면, 일반적으로 BWGNN은 PC-GNN이 최고의 AUC 점수를 얻는 Amazon(1%)을 제외한 모든 데이터세트에서 최고의 성능을 보입니다. 다중 관계 그래프가 있는 두 데이터셋의 경우 BWGNN(Hetero)은 YelpChi에서 더 나은 성능을 발휘하고 BWGNN(Homo)은 Amazon에서 더 나은 성능을 발휘합니다. GraphConsis, CAREGNN 및 PC-GNN은 그래프 기반 이상 탐지를 위한 세 가지 최첨단 방법인 반면, BWGNN은 훨씬 짧은 훈련 시간으로 이들보다 훨씬 뛰어난 성능을 발휘합니다. 추가적으로, 그래프 구조가 무시되더라도 MLP와 SVM은 일부 데이터셋에서 비슷한 성능을 달성할 수 있음을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;민감도 분석을 진행한 결과는 아래와 같습니다. 중요한 hyperparameter인 order C와 이상치 정도의 영향에 대하여 민감도 분석을 진행하였고 다음의 결과를 보였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/TRSBmsj/Figure5.png&quot; alt=&quot;Figure5.png&quot; /&gt;
Beta Wavelet 은 $L$의 $C$-order 다항식이고 각 노드의 $C$-hops에 국한되어 있으므로 C-order은 BWGNN에서 중요한 hyperparameter입니다. 그림 5는 C를 1에서 5로 변경할 때 두 데이터셋에 대한 BWGNN의 F1-macro 및 AUC 점수를 나타냅니다. T-Social에서는 C가 높을수록 성능이 향상되는 반면, T-Finance에서는 C $\geq$ 2에 대한 결과에 큰 차이가 없습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/2kggTsk/Figure6.png&quot; alt=&quot;Figure6.png&quot; /&gt;
그림 6은 T-Finance(1%)에서 BWGNN, ChebyNet 및 CAREGNN의 F1-macro 및 AUC 점수를 다양한 이상 수준으로 비교합니다. $\sigma$가 증가하면 이상 현상을 더 잘 구별할 수 있으므로 세 가지 모델 모두 더 나은 성능을 발휘합니다. 그 중에서 BWGNN은 가장 빠르게 성장하는 알고리즘이며 $\sigma$ = 4에서 99% F1-macro에 도달합니다. $\alpha$ 가 변화할 때 BWGNN은 일관되게 다른 방법보다 성능이 뛰어나며 다양한 이상 정도에 대해 견고합니다.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;해당 논문은 그래프 이상 탐지에 대하여 설명한 후 ‘이상치 탐지를 위한 GNN에서 적절한 spectral filter을 어떻게 고를 것인가?’에 대해 답변합니다. 이를 위하여 핵심 특징인 ‘오른쪽 편이’에 대해 여러 데이터셋으로 검증하여 알고리즘의 필요성을 이야기한 후 Beta Wavelet Graph를 활용한 새로운 알고리즘인 BWGNN를 수식적으로 보여줍니다. 알고리즘 비교 실험에서는 4가지 datasets을 활용하였고 BWGNN은 우수한 성능을 보였습니다. Future work로 node anomalies에서 더 나아간 edge anomalies를 분석해볼 수 있다고 생각합니다. 수리적으로 energy distribution 을 표현한 것이 인상깊었습니다.&lt;/p&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;심윤주 (Yoonju Sim)
    &lt;ul&gt;
      &lt;li&gt;Master Student, Department of Industrial &amp;amp; Systems Engineering, KAIST&lt;/li&gt;
      &lt;li&gt;Interest: Computational Optimization, Reinforcement Learning, Transportation system&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Github : https://github.com/squareRoot3/Rethinking-Anomaly-Detection&lt;/li&gt;
  &lt;li&gt;Datasets :  &lt;a href=&quot;https://drive.google.com/drive/folders/1PpNwvZx_YRSCDiHaBUmRIS3x1rZR7fMr?usp=sharing&quot;&gt;google drive&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 20 Nov 2023 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2023-11-20-Rethinking_Graph_Neural_Networks_for_Anomaly_Detection.html</link>
            <guid isPermaLink="true">http://localhost:4000/2023-11-20-Rethinking_Graph_Neural_Networks_for_Anomaly_Detection.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
    </channel>
</rss>
