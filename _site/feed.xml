<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>DSAILatKAIST.github.io</title>
        <description>Intended as a documentation theme based on Jekyll for technical writers documenting software and other technical products, this theme has all the elements you would need to handle multiple products with both multi-level sidebar navigation, tags, and other documentation features.</description>
        <link>http://localhost:4000/</link>
        <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Mon, 14 Oct 2024 17:43:38 +0900</pubDate>
        <lastBuildDate>Mon, 14 Oct 2024 17:43:38 +0900</lastBuildDate>
        <generator>Jekyll v3.9.2</generator>
        
        <item>
            <title>[ACL-24] Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs</title>
            <description>&lt;h2 id=&quot;1-motivation&quot;&gt;1. Motivation&lt;/h2&gt;
&lt;p&gt;Large Language Model(LLM)은 information retrieval, text summarization, question answering과 같이 배경지식을 요구하는 task에서 일반적으로 좋은 성능을 보인다. 하지만 몇 가지 한계가 있는데, 거짓된 정보를 제공하거나 특정 분야에 대한 깊은 지식의 부재, 학습이 끝나면 지식이 갱신되지 않는다는 한계점이 있다. 이를 해결하기 위해 Knowledge Graph(KG)를 이용해 LLM을 보완하려는 시도가 있었다. KG는 최신 지식을 갖고 있고, 특정 분야에 대한 깊은 지식을 갖고 있기도 하며 지식이 잘 구조화되어 있다는 장점이 있다.&lt;/p&gt;

&lt;p&gt;KG로 LLM을 보완하는 방법은 크게 세 가지로 분류할 수 있다. pre-training 단계에서 KG를 입력하는 방법, fine-tuning 단계에서 KG를 입력하는 방법, pre-trained LLM을 그대로 두고 KG를 입력으로 하는 추가적인 모듈을 학습하는 방법이 있다. 최근의 LLM은 parameter의 개수가 매우 많기 때문에 pre-training과 fine-tuning에 매우 많은 연산이 필요하고, 심지어 모델 구조나 parameter 자체가 공개되지 않고 API를 통해서만 접근이 가능한 black-box LLM이 많다. 또한 크기가 매우 큰 KG는 메모리로 가져오기 어려워 서버에 API를 통해서만 접근이 가능하다. 추가적으로 기존의 KG-augmented LLM 모델은 여러 개의 KG를 사용할 수 없다는 한계가 있다.&lt;/p&gt;

&lt;p&gt;본 논문은 Tree-of-Traversals 알고리즘을 제안하는데, 학습 없이(zero-shot) 여러 개의 KG를 이용해 LLM을 보완할 수 있는 알고리즘이다.&lt;/p&gt;

&lt;h2 id=&quot;2-method&quot;&gt;2. Method&lt;/h2&gt;
&lt;p&gt;Tree-of-Traversals 알고리즘은 question anwering task에서 정확한 답변을 생성하기 위해 KG subgraph의 정보를 활용한다. 이때 KG의 subgraph를 점차 확장하는데, LLM이 답변에 필요한 정보가 subgraph에 모두 포함될 때까지 확장이 이루어진다. 우선 question(query)에 존재하는 entity를 포함하여 subgraph를 initialize하고, LLM의 판단에 따라 action을 수행하며 subgraph에 entity와 relation을 추가한다. 이 과정은 크게 세 가지 구성 요소로 나누어 작동하는데, knowledge graph interface, action state machine, tree search algorithm으로 나눌 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;21-knowledge-graph-interface&quot;&gt;2.1 Knowledge Graph Interface&lt;/h3&gt;
&lt;p&gt;Knowledge graph interface는 KG에서 필요한 정보를 추출하기 위해 실행된다. KG를 $K=(E, R, T)$로 표현하면 $E$는 entity set, $R$은 relation type set, $T$는 edge(fact) set을 나타낸다. 각각의 entity는 identifier, label, optional description으로 구성되고, relation type은 identifier, label, optional inverse label로 구성되며 edge는 $(s, r, o)$와 같이 두 개의 entity $s, o$와 하나의 relation type $r$로 구성된다. 하나의 예시로, (Q35332, &lt;em&gt;‘Christopher Nolan’&lt;/em&gt;, &lt;em&gt;‘British-American filmmaker’&lt;/em&gt;)는 entity에 해당하고, (P57, &lt;em&gt;‘director’&lt;/em&gt;, &lt;em&gt;‘is director of’&lt;/em&gt;)는 relation type에 해당한다.
KG에서 필요한 정보를 추출할 때는 다음과 같이 세 가지의 명령어를 사용한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;$initialize(q)$&lt;/li&gt;
  &lt;li&gt;$get_relations(E_{selected})$&lt;/li&gt;
  &lt;li&gt;$get_edges(E_{selected}, r)$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$initialize(q)$는 query $q$가 입력으로 주어졌을 때, KG $K$에서 $q$에 포함된 entity를 추출하여 subgraph를 initialize하는 함수이다. 예를 들어 “What actor played in both Inception and Interstellar?”라는 query가 주어졌을 때, label이 ‘Inception’인 entity와 ‘Interstellar’인 entity를 추출하여 entity가 두 개인 subgraph를 생성한다.&lt;/p&gt;

&lt;p&gt;다음으로 $get_relations(E_{selected})$는 entity set $E_{selected}$가 주어졌을 때, 해당 entity와 관련된 relation type을 추출하여 relation set $R_{options}$를 출력하는 함수이다. 수학적으로 $R_{options}={r\mid(s, r, o)\in T, s\in E_{selected}}$와 같이 표현할 수 있다. 예를 들어 $E_{selected}$으로 {‘Inception’, ‘Interstellar’}가 주어졌을 때, {‘cast’, ‘director’}가 출력된다.&lt;/p&gt;

&lt;p&gt;마지막으로 $get_edges(E_{selected}, r)$는 entity set $E_{selected}$와 relation type $r$이 주어졌을 때, $E_{selected}$에서 한 entity를 source entity로 갖고  $r$을 relation type으로 갖는 edge를 추출하여 edge set $T_{added}$ 출력하는 함수이다. 수학적으로 $T_{added}={(s,r,o)\in T\mid s\in E_{selected}, r=r, o\in E}$으로 표현된다.&lt;/p&gt;

&lt;h3 id=&quot;22-action-state-machine-asm&quot;&gt;2.2 Action State Machine (ASM)&lt;/h3&gt;
&lt;p&gt;LLM의 답변 과정에 KG의 지식을 고려하기 위해 과거에는 KG를 prompt에 함께 제공하는 in-context learning 기법을 시도했다. 하지만 LLM의 token 제한 때문에 크기가 큰 KG를 모두 prompt에 제공하기는 어려웠고, LLM이 KG에서 필요한 정보를 추출하는 데 어려움이 있었다. 이 문제를 해결하기 위해 본 논문에서는 KG subgraph를 추출하는데, 이때 단계별로 확장을 수행하고 각 단계마다 LLM의 판단을 거치며 KG를 점차 확장해나간다.&lt;/p&gt;

&lt;p&gt;KG의 확장은 finite state machine을 따라 이루어지고, 5개의 action &lt;em&gt;Think, Answer, ExpandKG, Select_Entities, Select_relation&lt;/em&gt;과 4개의 state &lt;em&gt;default, selecting-entities, selecting-relation, done&lt;/em&gt;으로 구성된다. 이 finite state machine을 Action State Machine (ASM)이라 칭한다.&lt;/p&gt;

&lt;p&gt;ASM을 그림으로 나타내면 다음과 같다. 주어진 query $q$에 대해서 $initialize(q)$를 수행하면 &lt;em&gt;default&lt;/em&gt; state에서 시작한다. 각 state마다 취할 수 있는 action이 존재하고 LLM의 판단에 따라 하나의 action을 취한다. 이때 state마다 정해진 양식의 prompt를 작성하여 LLM에 입력하면 LLM이 취할 수 있는 action을 출력한다. 예를 들어, &lt;em&gt;default&lt;/em&gt; state에서는 3개의 action &lt;em&gt;Think, Answer, ExpandKG&lt;/em&gt; 를 취할 수 있다. 만약 Tree-of-Traversals 알고리즘이 &lt;em&gt;ExpandKG&lt;/em&gt;를 취하도록 선택했으면 그 다음에 &lt;em&gt;selecting-entities&lt;/em&gt; state으로 이동하여 &lt;em&gt;Select_Entities&lt;/em&gt; action을 취할 수 있다. &lt;em&gt;selecting-entities&lt;/em&gt; state에서는 한 종류의 action만 취할 수 있는데, 어떤 entity set을 선택하는지에 따라 서로 다른 action으로 간주된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/hPSGwLgH/ASM.png&quot; alt=&quot;ASM&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;23-tree-search-algorithm&quot;&gt;2.3 Tree Search Algorithm&lt;/h3&gt;
&lt;p&gt;Tree-of-Traversals의 트리 탐색 알고리즘은 Tree-of-Thoughts의 접근법을 차용한다. Tree-of-Thoughts는 LLM이 주어진 query 질문에 대한 답변을 생성할 때 바로 답변하는 것이 아니라 중간 thought를 생성하는 과정을 거친 후에 최종 답변을 생성하는 알고리즘이다. 이때 다양하게 뻗어나가는 thought를 생성하여 search tree의 형태로 나타낼 수 있는데, 트리 탐색을 통해 search tree의 노드 중에서 가장 높은 점수의 노드가 답변에 사용된다. Tree-of-Traversals는 이와 유사하게 KG subgraph의 다양한 확장 결과를 search tree로 나타낸다. 최종적으로 search tree의 가장 높은 점수의 노드에 포함된 KG subgraph가 LLM의 답변에 사용되는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/Bb3vJDFP/tree-of-traversals-algorithm.png&quot; alt=&quot;Algorithm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Algorithm 1은 트리 탐색 알고리즘을 자세히 나타낸 것이다. 먼저 query $q$에 대해서 $initialize(q)$를 수행하면 &lt;em&gt;default&lt;/em&gt; state의 루트 노드가 생성된다. 루트 노드에 대해서 k개의 action을 샘플링하면 각각의 action을 수행한 결과를 자식 노드로 추가하게 된다. 루트 노드를 한 번 방문한 후에는 다시 방문하지 않고, 방문하지 않은 노드 중에서 방문할 노드를 선택한다. 이때 점수가 가장 높은 노드, 점수가 동일할 경우에는 depth가 큰 노드를 선택한다. 선택한 노드에 대해서 마찬가지로 k개의 action을 샘플링하고 자식 노드를 추가한다. 이 과정을 반복하여 search tree를 확장하고, &lt;em&gt;Answer&lt;/em&gt; state 노드의 점수가 특정 threshold를 넘으면 해당 노드의 답변이 최종 답변으로 사용된다. 또한 search tree가 무한히 확장하는 것을 방지하기 위해 &lt;em&gt;max depth&lt;/em&gt;, &lt;em&gt;max expansions&lt;/em&gt;의 두 가지 stopping criteria를 설정한다. &lt;em&gt;max depth&lt;/em&gt;에 도달하면 알고리즘이 강제로 &lt;em&gt;done&lt;/em&gt; state로 이동하여 답변을 생성하고, &lt;em&gt;max expansions&lt;/em&gt;에 도달하면 모델이 “Cannot find answer”을 답변으로 내놓는다.&lt;/p&gt;

&lt;p&gt;Tree-of-Traversals 알고리즘에서 search tree 상에 존재하는 노드의 점수를 산정하기 위해서 LLM을 사용한다. LLM에 특정 양식에 맞춰 prompt를 작성하는데, prompt에는 현재의 원래 query, KG subgraph, 이전에 수행한 action 목록과 점수 산정을 위한 instruction이 포함된다. 점수를 산정할 때 일반 노드와 &lt;em&gt;Answer&lt;/em&gt; state 노드에 서로 다른 prompt를 사용한다.&lt;/p&gt;

&lt;p&gt;Chain-of-Traversals는 Tree-of-Traversals의 일종으로 k개의 action을 샘플링할 때 k가 1인 경우에 해당한다. 따라서 방문하지 않은 노드가 하나만 존재하게 되고, 노드 중에서 점수에 따라 선택하는 대신에 확정적으로 노드를 방문한다. 이후의 실험 결과에서 Chain-of-Traversals와 Tree-of-Traversals의 question answering 성능을 비교한다.&lt;/p&gt;

&lt;h3 id=&quot;24-tree-of-traversals-with-multiple-kgs&quot;&gt;2.4 Tree-of-Traversals with Multiple KGs&lt;/h3&gt;
&lt;p&gt;Tree-of-Traversals 알고리즘에서 여러 개의 KG를 고려하기 위해 우선 각각의 KG에 KG interface를 만든다. 또한 알고리즘에 몇 가지 변화가 있다. 각각의 KG $initialize(q)$ 함수로부터 중복으로 동일한 entity가 추출되지 않도록 하고, $get_relations(E_{selected})$ 함수에서 모든 KG로부터 해당하는 relation이 출력되도록 하며 $get_edges(E_{selected}, r)$ 함수를 통해 새로운 노드가 추가될 때 기존 노드와 새로운 노드 간의 edge가 존재하는지 모든 KG에 대해 확인하도록 한다.&lt;/p&gt;

&lt;h2 id=&quot;3-experiments&quot;&gt;3. Experiments&lt;/h2&gt;
&lt;p&gt;Tree-of-Traversals 알고리즘에서 사용할 LLM으로는 Amazon Bedrock에서 API를 통해 이용할 수 있는 Claude-Instant, Llama2 70b, Llama2 13b를 사용한다. 2WikiMultiHop 데이터셋과 QALD-10 데이터셋에서 question answering task를 수행한다. 이때 metric으로 Exact Match Included (EM-in)을 사용하는데, 생성한 답변에 정답 답변이 모두 포함되어 있으면 1, 그렇지 않다면 0이다. EM-in은 EM과 다르게 생성한 답변과 정답 답변이 완전히 일치하지 않아도 되는데, LLM이 응답을 생성할 때 다양한 문장 구조와 구문을 사용할 수 있다는 점과 일반적으로 LLM의 답변에 정답 이외에 부가 설명이 추가된다는 점을 고려할 때 더 적합한 metric이다.&lt;/p&gt;

&lt;p&gt;Tree-of-Traversals 알고리즘의 성능과 비교하기 위한 baseline으로는 Chain-of-Thought (CoT) prompting, ReAct, FLARe와 같이 black-box LLM에서 동작하는 알고리즘을 사용한다. Tree-of-Traversals 알고리즘을 적용한 모델은 두 가지 사용하는데, &lt;em&gt;branching factor&lt;/em&gt; k=1인 특수한 경우를 Chain-of-Traversals, k=3인 경우를 Tree-of-Traversals라고 칭한다. 알고리즘을 수행할 때 search tree가 무한히 확장하는 걸 방지하기 위한 hyperparameter로서 &lt;em&gt;max depth&lt;/em&gt;는 7, &lt;em&gt;max expansions&lt;/em&gt;는 20으로 설정한다. 또한 최종 답변을 결정하기 위한 threshold를 0.8로 설정하여 실험을 진행한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/pdnV8kYn/experiment-result.png&quot; alt=&quot;Result&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 테이블은 2WikiMultiHop 데이터셋과 QALD-10 데이터셋에서 baseline과 Tree-of-Traversals 알고리즘의 성능을 나타낸 것이다. 먼저 2WikiMultiHop의 경우, 사용한 세 가지 LLM에서 모두 Tree-of-Traversals의 성능이 가장 높게 나타났고, 이 성능은 zero-shot 세팅에서 state-of-the-art에 해당한다. Chain-of-Traversals도 baseline보다 좋은 성능을 보인다는 점에서 ASM을 따라 action을 선택하며 KG subgraph를 추출하는 방식이 효과적이라는 점을 확인할 수 있다. Tree-of-Traversals는 Chain-of-Traversals와 달리 확정적으로 하나의 action을 선택하는 것이 아니라, 가능한 다양한 action 중에서 점수가 높은 action을 선택하여 subgraph를 확장하는 방식으로 최적의 KG subgraph를 추출하기 때문에 두 데이터셋에서 모두 Chain-of-Traversals보다 확연히 좋은 성능을 보였다. QALD-10 데이터셋의 경우에도 Llama2-13b를 사용한 경우를 제외하면 Tree-of-Traversals와 Chain-of-Traversals가 baseline보다 좋은 성능을 보였다.&lt;/p&gt;

&lt;p&gt;또한 한 가지 확인할 수 있는 것은 LLM 모델에 따라서도 question anwering 성능에 차이가 발생했다. 이는 Llama-70b와 Llama-13b의 차이에서 확인 가능한데, Tree-of-Traversals 알고리즘의 성능은 LLM의 성능에 비례한다는 점을 알 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;4-conclusion&quot;&gt;4. Conclusion&lt;/h2&gt;
&lt;p&gt;Tree-of-Traversals는 LLM이 question answering과 같이 지식을 기반으로 하는 task에서 한계가 있다는 점을 해결하기 위해 고안된 알고리즘으로, 별개의 학습 없이 LLM이 KG를 기반으로 더 정확한 답변을 생성할 수 있도록 한다. 기존의 KG-augmented LLM은 LLM의 pre-training이나 fine-tuning과 같이 LLM의 parameter를 직접적으로 학습하는 경우가 많았는데, 연산량이 매우 많을 뿐만 아니라 많은 LLM이 모델 구조와 parameter를 공개하지 않는 black-box 형태이기 때문에, 학습이 없고 LLM의 API만을 사용하여 구현 가능한 Tree-of-Traversals 알고리즘이 유용하다. 질문 query와 관련된 정보를 KG에서 추출하는 과정에서 Tree-of-Thoughts의 접근법을 차용한 알고리즘으로, 선택 가능한 다양한 KG subgraph 중에서 가장 유용한 subgraph를 선택하여 정확한 답변을 생성할 수 있다. 실제로 다양한 실험에서 기존 baseline 모델보다 좋은 성능을 나타냄으로써 그 효과를 입증했다.&lt;/p&gt;

&lt;p&gt;Tree-of-Traversals 알고리즘은 LLM의 성능에 비례하기 때문에 동일한 알고리즘을 사용하더라도 LLM의 성능이 좋아지면 question answering task의 성능을 향상시킬 수 있기에, 지금과 같이 LLM의 성능이 빠르게 좋아지는 상황에서 유용할 것이라고 생각한다. 특히 LLM의 학습이 필요하지 않기 때문에 동일한 API를 사용하여 LLM에 접근할 수 있다면 추가적인 작업 없이 바로 새로운 LLM을 사용할 수 있다. 또한 민감한 정보가 담긴 KG에 이용할 때에도, LLM을 학습하는 과정이 없어 보안 측면에서 안전하다는 점이 장점이다.&lt;/p&gt;

&lt;p&gt;그러나 LLM의 성능에 비례한다는 점이 장점이자 단점이 될 수 있는데, 좋은 성능의 LLM에 접근하기 어려운 상황이라면 task의 성능이 떨어지게 된다. 실제로 실험 결과에서 비교적 작은 크기의 LLM인 Llama-13b를 사용했을 때, 몇 개의 baseline보다도 낮은 성능을 보였다는 점에서 확인할 수 있다. 또한 KG subgraph를 추출하는 과정에서 search tree를 만드는데, search tree의 모든 노드가 LLM의 답변을 필요로 한다는 점을 고려할 때 하나의 답변을 생성하기 위해 LLM을 많이 사용하게 된다. &lt;em&gt;max expansions&lt;/em&gt;를 설정함으로써 과도하게 사용하는 것을 막기는 하지만, 그럼에도 한 번의 LLM 사용으로 답변이 생성되는 기존의 방법과 달리 수 십번의 사용이 필요하고 이에 따라 답변 생성 시간이 크게 늘어날 수밖에 없다. 뿐더러 LLM의 답변 생성에 많은 연산량이 필요하기 때문에 사용량을 제한하는 경우가 많은데, 상당히 많은 사용량을 확보하거나 로컬에 환경을 구축해야만 이 알고리즘을 적용할 수 있다. 또한 KG subgraph를 initialize할 때 query에 등장하는 entity만을 사용하는데, 질문의 맥락에 따라 그 entity만으로는 정확한 답변을 생성하기 어려운 상황이 존재할 수 있다는 점도 단점이라고 생각한다.&lt;/p&gt;

&lt;h2 id=&quot;5-references&quot;&gt;5. References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Github Implementation
    &lt;ul&gt;
      &lt;li&gt;https://github.com/amazon-science/tree-of-traversals&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Markowitz, Elan, et al. “Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs.” &lt;em&gt;arXiv preprint arXiv:2407.21358&lt;/em&gt; (2024).&lt;/li&gt;
  &lt;li&gt;Yao, Shunyu, et al. “Tree of thoughts: Deliberate problem solving with large language models.” &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; 36 (2024).&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-Tree-of-Traversals_A_Zero-Shot_Reasoning_Algorithm_for_Augmenting_Black-box_Language_Models_with_Knowledge_Graphs.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-Tree-of-Traversals_A_Zero-Shot_Reasoning_Algorithm_for_Augmenting_Black-box_Language_Models_with_Knowledge_Graphs.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[SIGIR-24] SelfGNN: Self-Supervised Graph Neural Networks for Sequential Recommendation</title>
            <description>&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;In Liu et. al (2024) they propose a self-supervised method for modeling long and short-term interaction sequences
for user-item recommendation. They call this method Self-Supervised Graph Neural Network (SelfGNN) 
which they analize with the following research questions (RQ):&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;How does SelfGNN perform w.r.t top-k recommendation as
compared with the state-of-the-art models?&lt;/li&gt;
  &lt;li&gt;What are the benefits of the components proposed?&lt;/li&gt;
  &lt;li&gt;How does SelfGNN perform in the data noise issues?&lt;/li&gt;
  &lt;li&gt;How do the key hyperparameters influence SelfGNN?&lt;/li&gt;
  &lt;li&gt;In real cases, how can the designed self-augmented learning
in SelfGNN provide useful interpretations?&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As stated by the paper (Liu et. al) recommender systems are an important field of research
for addressing user-item interactions benefitting service providers such as Amazon
(Ge et al. 2020) but also digital platforms such as TikTok, YouTube and Facebook (Wei et al. 2023; Zhang et al. 2021). 
Furthermore, self-supervised learning (SSL) have become very attractive for recommender systems and graph learning as 
they additional graphical structure compensates for the lack of labelled data. SSL methods are only limited to a few
labeled data points thus enabling usages for many more applications.&lt;/p&gt;

&lt;p&gt;An important branch of recommender systems is &lt;em&gt;sequential recommendation&lt;/em&gt;, which models user interactions over 
time (as a sequence of actions in time). Thus, by analyzing the temporal interaction patterns the model can predict future user actions. Examples of sequential recommendation could be the task of predicting the next movie
a user wants to watch given the ordered list of previously watched movies (as presented in the lectures). Modeling sequential patterns
can be crucial recommender systems as they relay chronological patterns giving insights into both short and 
long-term user preferences (Liu et al.). Thus many studies have analyzed how to incorporate temporal information to the
recommender system such as DGSR (Zhang et al. 2023), SURGE (Chang et al. 2021), GRU4Rec (Hidasi et al. 2016), SASRec (Kang and McAuley 2018), Bert4Rec (Liu et al. 2019), TiSASRec (Li et al. 2020)
and MBHT~\cite{MBHT} (where the last four methods are based on Transformers (Vaswani et al. 2017)). However, while these models manage to model dynamic user-interactions
they fail to effectivly integrate both long and short-term interaction or overlook important periodical collaborative relationships between users by 
only encoding single-user sequences (Liu et al. 2024). Furthermore, previous SSL methods for sequential recommendation like CLSR~\cite{CLSR}, are extremely dependent on
high-quality data. This means they lack the natural robustness to noisy data which is present in real-world data as the noise will propagate through the model (Lie et al. 2024).&lt;/p&gt;

&lt;p&gt;With these issues in mind, SelfGNN was designed to effectively encode both long and short-term interaction while &lt;em&gt;denoising&lt;/em&gt; the short-term
patterns with long-term dependencies thus making the model robust to noisy data (Liu et al. 2024).&lt;/p&gt;

&lt;h2 id=&quot;3-preliminary&quot;&gt;&lt;strong&gt;3. Preliminary&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;31-message-passing&quot;&gt;&lt;em&gt;3.1 Message Passing&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Message Passing is the central process of Graph Convolution Networks (GCN)
to encode graph information such as nodes~\cite{Kipf}. The core idea is to send &lt;em&gt;messages&lt;/em&gt; of 
information between the nodes to iteratively update the encoded node representations~\cite{Kipf}. In this paper (Lie et al. 2024)
were inspired by LightGCN~\cite{LightGCN} where each user-node $\bm{e}_ {u}^{(k)}$ and item-node $\bm{e}_ {i}^{(k)}$ 
encoding are updated by the weighted sum of their neighboring nodes:&lt;/p&gt;

&lt;p&gt;$
\bm{e}_ {u}^{(k+1)} = \sum_ {i\in\mathcal{N}_ u} \frac{1}{\sqrt{\vert\mathcal{N}_ u\vert}\sqrt{\vert\mathcal{N}_ i\vert}}\bm{e}_ {i}^{(k)}
$&lt;/p&gt;

&lt;p&gt;$
\bm{e}_ {i}^{(k+1)} = \sum_ {u\in\mathcal{N}_ i} \frac{1}{\sqrt{\vert\mathcal{N}_ i\vert}\sqrt{\vert\mathcal{N}_ u\vert}}\bm{e}_ {u}^{(k)}
$&lt;/p&gt;

&lt;p&gt;Where $\bm{e}_ {u}^{(0)}$ and $\bm{e}_ {u}^{(0)}$ are the inital ID embedding for the user and item respectivly.&lt;/p&gt;
&lt;h3 id=&quot;32-self-attention&quot;&gt;&lt;em&gt;3.2 Self-Attention&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Another key operation for propagating information which has seen increased popularity for graph-based learning is 
self-attention (Vaswani et al. 2017). The idea of self-attention is to project the input $\bm{X} \in \mathbb{R}^{n\times d}$ to 
the &lt;em&gt;query&lt;/em&gt;, &lt;em&gt;key&lt;/em&gt; and &lt;em&gt;value&lt;/em&gt; subspace using (the learned) projection matrices $\bm{W}_ Q\in\mathbb{R}^{d\times d_ Q}$, $\bm{W}_ K\in\mathbb{R}^{d\times d_ K}$, and $\bm{W}_ V\in\mathbb{R}^{d\times d_ V}$, respectivly (where $d_ K = d_ Q$). Then (single-head) attention is computed by:&lt;/p&gt;

&lt;p&gt;$
\text{Attn}(\bm{X}) = \text{Softmax}\left(\frac{\bm{XW}_ Q(\bm{XW}_ K)^\mathsf{T}}{\sqrt{d_ K}}\right)\bm{XW} &lt;em&gt;V = \text{Softmax}\left(\frac{\bm{QK}^\mathsf{T}}{\sqrt{d&lt;/em&gt; K}}\right)\bm{V} 
$&lt;/p&gt;
&lt;h3 id=&quot;33-validation-metrics&quot;&gt;&lt;em&gt;3.3 Validation Metrics&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;To validate the effectiveness of their proposed method, (Liu et al. 2024) use the Hit Rate (HR)@N and Normalized
Discounted Cumulative Gain (NDCG)@N (&lt;a href=&quot;https://www.evidentlyai.com/ranking-metrics/evaluating-recommender-systems&quot;&gt;www.evidentlyai.com&lt;/a&gt;). 
To calculate the Hit Rate for top $N$ recommendations, each user gets a score of either 0 or 1 depending on if they were recommended a
relevant item in their top $N$ recommendations. Then we calculate the average score for all users, which is the final validation metric.&lt;/p&gt;

&lt;p&gt;To calculate the Normalized Discounted Cumulative Gain, we first calculate the Discounted Cumulative Gain (DCG) and 
then normalize it using the Idealized discounted cumulative gain (IDCG) (&lt;a href=&quot;https://www.evidentlyai.com/ranking-metrics/ndcg-metric&quot;&gt;www.evidentlyai.com&lt;/a&gt;).
For a user with predicted item ranking-position order $p_ i$ and ground-truth item-relevance $r_ i$ DCG@N is computed as:&lt;/p&gt;

&lt;p&gt;$
DCG@N = \sum_ {i = 1}^N \frac{r_ i}{\log (p_ i +1)}
$&lt;/p&gt;

&lt;p&gt;The idea of NDCG is to normalize the DCG with the &lt;em&gt;ideal&lt;/em&gt; discounted cumulative gain (IDCG). 
The equation for IDCG is almost equivalent to that of DCG, however, we just assume
that the item positions $p &lt;em&gt;i$ are ordered according to their relevance $r&lt;/em&gt; i$. This way,
the IDCG represents the best possible ranking order the recommender could produce. With this in mind,
the final equation for NDCG is:&lt;/p&gt;

&lt;p&gt;$
NDCG@N = \frac{DCG@N}{IDCG@N} = \frac{\sum_ {i = 1}^N \frac{r_ i}{\log (p_ i +1)}}{\sum_ {i = 1}^N \frac{r_ i}{\log (p’_ i +1)}} \in [0,1]
$&lt;/p&gt;

&lt;p&gt;In the paper by Liu et al. they set $N = {10,20}$ for both HR@N and NDCG@N.&lt;/p&gt;
&lt;h2 id=&quot;4-method&quot;&gt;&lt;strong&gt;4. Method&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Given the set of users $\mathcal{U} = {u_ 1,\dots, u_ I}$ with $\vert\mathcal{U}\vert = I$ and the set of 
items $\mathcal{V} = {v_ i,\dots,v_ J}$ where $\vert\mathcal{V}\vert = J$ the time-dependent adjacency matrix
$\bm{\mathcal{A}}_ {t} \in\mathbb{R}^{I\times J}$ represents the user-item interaction at time $t$. Here, the time $t$ is
discretized by the hyperparameter $T$ such that each time-interval has length $(t_ e - t_ b)/T$ where $t &lt;em&gt;b$ and $t&lt;/em&gt; e$ is the 
first (beginning) and last (end) observed time stamp. Thus in other words, ${\mathcal{A}}_ {t,i,j}$ is 
set to 1 if user $u_ i$ interacted with item $v_ j$ at time $t$. Then giving ${\bm{\mathcal{A}}_ {t}| 1\leq t \leq T}$ the objective
is to predict future user-item interactions $\bm{\mathcal{A}_{T+1}}$. Formally, they define the objective as:&lt;/p&gt;

&lt;p&gt;$
\arg\min_ {\Theta_ f,\Theta_ g} \mathcal{L}&lt;em&gt;{recom}\left(\bm{\mathcal{\hat{A}}&lt;/em&gt; {T+1}},\bm{\mathcal{A}_ {T+1}}\right) + \mathcal{L}_ {SSL}(\bm{E}_ s,\bm{E}_ l)
$&lt;/p&gt;

&lt;p&gt;$
\bm{\mathcal{\hat{A}}_ {T+1}} = f\left(\bm{E}_ s,\bm{E}_ l\right)\quad \bm{E}_ s,\bm{E}_ l = g({\bm{\mathcal{A}}_t})
$&lt;/p&gt;

&lt;p&gt;Where $\mathcal{L}&lt;em&gt;{recom}$ is the recommendation error between the true and predicted user-item interactions $\bm{\mathcal{A}&lt;/em&gt; {T+1}}$ and $\bm{\mathcal{\hat{A}}_ {T+1}}$, respectively.
$\mathcal{L}&lt;em&gt;{att}$ is the self-attention loss (regularizer) which uses the long and short-term embeddings $\bm{E}&lt;/em&gt; l,\bm{E}_ s$ which are encoded using the sequential data and encoder $g$.
Lastly, the estimated predictions $\bm{\mathcal{\hat{A}}_ {T+1}}$ is also calculated using these embeddings and prediction function $f$.&lt;/p&gt;

&lt;h3 id=&quot;41-encoding-short-term-user-item-interactions&quot;&gt;&lt;em&gt;4.1 Encoding Short-term user-item interactions&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The model begins by modeling the short-term interactions as these will be used throughout the whole encoding process. Inspired by LightGCN~\cite{LightGCN}, they project
each user $u_ i$ and item $v_ j$ for each timestep $t$ into a $d$-dimensional latent space (using the ID). These embeddings $\bm{e}_ {t,i}^{(u)}$, $\bm{e}_ {t,j}^{(v)}$ are assembled
to the embedding matrices $\bm{E}_ t^{(u)}\in\mathbb{R}^{I\times d}$,$\bm{E}_ t^{(v)} \in\mathbb{R}^{J\times d}$ which are then updated through the 
following message passing method:&lt;/p&gt;

&lt;p&gt;$
\bm{z}_ {t,i}^{(u)} = \text{LeakyReLU}\left(\mathcal{A}&lt;em&gt;{ti,{*}}\cdot \bm{E}&lt;/em&gt; t^{(v)}\right), \quad \bm{z}_ {t,j}^{(v)} = \text{LeakyReLU}\left(\mathcal{A}&lt;em&gt;{tj,{*}}\cdot \bm{E}&lt;/em&gt; t^{(u)}\right)
$&lt;/p&gt;

&lt;p&gt;This is repeated for $L$-layers with the embeddings in the $l$-th layer defined as:&lt;/p&gt;

&lt;p&gt;$
\bm{e}_ {t,i,l}^{(u)} = \bm{z}_ {t,i,l}^{(u)}+\bm{e}_ {t,i,l-1}^{(u)},\quad \bm{e}_ {t,i,l}^{(v)} = \bm{z}_ {t,i,l}^{(v)}+\bm{e}_ {t,i,l-1}^{(v)}
$&lt;/p&gt;

&lt;p&gt;Finally, all embeddings for each layer are concatenated together to form the final short-term embeddings $\bm{e}_ {t,i}^{(u)}$ and $\bm{e}_ {t,j}^{(v)}$:&lt;/p&gt;

&lt;p&gt;$
\bm{e}_ {t,i}^{(u)} = \bm{e}_ {t,i,1}^{(u)}| \dots|  \bm{e}_ {t,i,L}^{(u)},\quad\bm{e}_ {t,j}^{(v)} = \bm{e}_ {t,j,1}^{(v)}| \dots|  \bm{e}_ {t,j,L}^{(v)}
$&lt;/p&gt;

&lt;h3 id=&quot;42-encoding-long-term-user-item-interactions&quot;&gt;&lt;em&gt;4.2 Encoding Long-term user-item interactions&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The long-term user-item information is encoded in two different ways which in the end
are combined for the final prediction. First, we have what they call &lt;em&gt;Interval-Level Sequential Pattern Modeling&lt;/em&gt; which aims to
capture dynamic changes from period to period by integrating the aforementioned short-term embeddings into long-term embeddings using temporal attention. 
Second, the use &lt;em&gt;Instance-Level Sequential Pattern Modeling&lt;/em&gt; which aims to learn the pairwise relations between specific item instances directly (Liu et al. 2024).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Interval-Level Sequential Pattern Modeling&lt;/strong&gt; To integrate short-term embeddings into long-term ones Liu et al. (2024) use the
Gated Recurrent Unit (GRU) on the sequential short-term embeddings ${\bm{e}_ {t,i}^{(u)}}$ and ${\bm{e}_ {t,j}^{(v)}}$ for each user $u_ i$ and item $v_ j$. 
More specifically, each hidden state $\bm{h}_ {t,i}^{(u)}$ and $\bm{h}_ {t,j}^{(v)}$ of the GRU model is collected to interval-level sequences $S_ i^{interval}$ and $S_ j^{interval}$:&lt;/p&gt;

&lt;p&gt;$
S_ i^{interval} = \left(\bm{h}_ {1,i}^{(u)},\dots,\bm{h}_ {T,i}^{(u)}\right),\quad S_ j^{interval} = \left(\bm{h}_ {1,j}^{(v)},\dots,\bm{h}_ {T,j}^{(v)}\right)
$&lt;/p&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;p&gt;$
\bm{h}_ {t,i}^{(u)} = \text{GRU}\left(\bm{e}_ {t,i}^{(u)},\bm{h}_ {t-1,i}^{(u)}\right)
,\quad \bm{h}_ {t,j}^{(v)} = \text{GRU}\left(\bm{e}_ {t,j}^{(v)},\bm{h}_ {t-1,j}^{(v)}\right)
$&lt;/p&gt;

&lt;p&gt;Then (multi-head dot-product) self-attention (Vaswani et al. 2017) is applied for the interval-level sequences to uncover the temporal patterns:&lt;/p&gt;

&lt;p&gt;$
\bm{\bar H}_ i^{(u)} = \text{Self-Att}\left(S_ i^{interval} \right),\quad \bm{\bar H}_ j^{(v)} = \text{Self-Att}\left(S_ j^{interval} \right),
$
Which finally, are summed across time:&lt;/p&gt;

&lt;p&gt;$
\bm{\bar e}_ i^{(u)} = \sum_ {t=1}^T \bm{\bar H}_ {i,t}^{(u)},\quad \bm{\bar e}_ j^{(v)}  = \sum_ {t=1}^T \bm{\bar H}_ {j,t}^{(v)}
$&lt;/p&gt;

&lt;p&gt;Where $\bm{\bar e}_ i,\bm{\bar e}_ j\in\mathbb{R}^{d}$ is final the long-term (interval-level) embeddings for user $u_ i$ and item $v_ j$. 
Note, that while the short-term embeddings are dependent on the given time-interval $t$ the long-term embeddings are independent of $t$ as 
while the long-term as $t$ is effectively integrated out.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Instance-Level Sequential Pattern Modeling&lt;/strong&gt; However, interval-level embeddings are not the only long-term embeddings used in the SelfGNN.
The model also uses instance-level sequential patterns by applying self-attention directly over
sequences containing users’ interacted item instances (Liu et al. 2024). Given a user $u_ i$ they denote
the $m$’th interacted item for set user as $v &lt;em&gt;{i,m}$ for $m = {1,\dots,M}$ (for a set maximum interaction length $M$).
Then the sequences of items user $u&lt;/em&gt; i$ interacted with can be modeled as:&lt;/p&gt;

&lt;p&gt;$
S_ {i,0}^{instance} = \left(\bm{\bar e}_ {v_ {i,1}}^{(v)}+ \bm{p}_ 1,\dots,\bm{\bar e}_ {v_ {i,M}}^{(v)} + \bm{p}_ M\right) 
$&lt;/p&gt;

&lt;p&gt;Where $\bm{\bar e}_ {v_ {i,m}}^{(v)} \in\mathbb{R}^d$ is the aforementioned long-term embedding for item $v_ {i,m}$ and $\bm{p}_ m\in\mathbb{R}^d$ is learnable 
position embeddings for the $m$-th position. Then $L_ {attn}$ layers of self-attention (with residual connections) are applied on the instance-level sequence $S_ {i,0}^{instance}$:&lt;/p&gt;

&lt;p&gt;$
S_ {i,l}^{instance} = \text{LeakyReLU}\left(\text{Self-Attn}\left(S_ {i,l-1}^{instance}\right)\right) + S_ {i,l-1}^{instance}
$&lt;/p&gt;

&lt;p&gt;The final instance-level embedding is calculated by summing over the elements of the final sequence $S_ {i,L_ {attn}}^{instance}$:&lt;/p&gt;

&lt;p&gt;$
\bm{\tilde e}_ i^{(u)} = \sum  S_ {i,L_ {attn}}^{instance} 
$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Predicting Future user-item interactions&lt;/strong&gt; The prediction for new user-item interactions $\mathcal{\hat A}_ {T+1,i,j}$ for user $u_ i$ and item $v_ j$
is now computed using the long-term embeddings (which implicitly uses the short-term embeddings):&lt;/p&gt;

&lt;p&gt;$
\mathcal{\hat A}_ {T+1,i,j} = \left(\bm{\bar e}_ i^{(u)} + \bm{\tilde e}_ i^{(u)} \right)^{\mathsf{T}} \cdot \bm{\bar e}_ j^{(v)} 
$&lt;/p&gt;

&lt;p&gt;They optimize with the following loss function (to prevent predicted values from becoming arbitrarily large):&lt;/p&gt;

&lt;p&gt;$
\mathcal{L}&lt;em&gt;{recom}\left(\mathcal{ A}&lt;/em&gt; {T+1,i,j},\mathcal{\hat A}_ {T+1,i,j}\right) = \sum_ {i = 1}^I\sum_ {k=1}^{N_ {pr}} \max\left(0,1 -\mathcal{\hat A}_ {T+1,i,p_ {k}} + \mathcal{\hat A}_ {T+1,i,n_ k} \right)
$&lt;/p&gt;

&lt;p&gt;where $N &lt;em&gt;{pr}$ is the number of samples and $p&lt;/em&gt; k$ and $n_ k$ is the $k$-th
positive (user-interaction) and negative (no user-interaction) item index respectively.&lt;/p&gt;

&lt;h3 id=&quot;43-denoising-short-term-user-item-interactions&quot;&gt;4.3 &lt;em&gt;Denoising short-term user-item interactions&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;While short-term user interactions are important for modeling sequential user-item 
interaction patterns they often contain noisy data. Here &lt;em&gt;noise&lt;/em&gt; refers to any temporary intents 
or misclicks, which cannot be considered as long-term user interests or new recent points of interest for predictions (Liu et al. 2024). An example of this is
when an Aunt buys Modern Warfare III for their nephew for Christmas as this interaction does not reflect user $u_ {Aunt}$’s interests. Other examples are simple misclicks or situations where
you click on something expecting it to be a different thing. Thus to &lt;em&gt;denoise&lt;/em&gt; these noisy short-term user-item interactions Liu et al. (2024) propose to use filter them using long-term interactions.
Specifically, for each training sample of the denoising SSL, they sample two observed user-item edges $(u_ i,v_ j)$  and $(u_ {i’},v_ {j’})$ from the short-term graphs $\bm{\mathcal{A}}&lt;em&gt;t$ and calculate the likelihood $s&lt;/em&gt; {t,i,j}, \bar{s}_ {i,j},s_ {t,i’,j’}, \bar{s}_ {i’,j’} \in\mathbb{R}$ that user $u_ i$/$u_ {i’}$ interacts with item $v_ j$/$v _ {j’}$ at time-step $t$ and in the long-term, respectively. For $(u_ i,v_ j)$ the likelihoods are ($s_ {t,i’,j’}, \bar{s}_ {i’,j’}$ are calculated in the same way):&lt;/p&gt;

&lt;p&gt;$
s_ {t,i,j} = \sum_ {k= 1}^d \text{LeakyReLU}\left(e_ {t,i,k}^{(u)}\cdot e_ {t,j,k}^{(v)}\right),\quad \bar{s}_ {t,i,j} = \sum_ {k= 1}^d \text{LeakyReLU}\left(\bar{e}_ {i,k}^{(u)}\cdot \bar{e}_ {t,j,k}^{(v)}\right) 
$&lt;/p&gt;

&lt;p&gt;Where $e_ {t,i,k}^{(u)},e_ {t,j,k}^{(v)},\bar{e}_ {i,k}^{(u)},\bar{e}_ {t,j,k}^{(v)}\in\mathbb{R}$ is the element value of the $k$-th embedding dimension. Thus the SSL objective functions become:&lt;/p&gt;

&lt;p&gt;$
\mathcal{L}_ {SSL} = \sum_ {t=1}^T\sum_ {(u_ {i},v_ {j}),(u_ {i’},v_ {j’})} \max\left(0,1- (w_ {t,i}\bar{s}_ {t,i,j} - w_ {t,i’}\bar{s}_ {t,i’,j’})\cdot (s_ {t,i,j} -s_ {t,i’,j’} )\right)
$&lt;/p&gt;

&lt;p&gt;With learnable stabilty weigths $w_ {t,i’},w_ {t,i’}\in\mathbb{R}$ calculated using the short and long-term embeddings:&lt;/p&gt;

&lt;p&gt;$
w_ {t,i} = \text{Sigmoid}\left(\bm{\Gamma}_ {t,i} \cdot\bm{W}_2 + b_2\right)
$&lt;/p&gt;

&lt;p&gt;$
\bm{\Gamma}_ {t,i} = \text{LeakyReLU}\left(\left(\bm{\bar{e}}^{(u)}_ i + \bm^{(u)}_ {t,i} + \bm{\bar{e}}^{(u)}_ i\odot\bm^{(u)}_ {t,i}  \right)\bm{W}_1 + \bm{b}_1\right)
$&lt;/p&gt;

&lt;p&gt;With learnable parameters $\bm{W}&lt;em&gt;1\in\mathbb{R}^{d\times d&lt;/em&gt; {SSL}}$, $\bm{W}&lt;em&gt;2\in\mathbb{R}^{d&lt;/em&gt; {SSL}\times 1}$, $\bm{b}&lt;em&gt;1\in\mathbb{R}^{d&lt;/em&gt; {SSL}}$, and ${b}_2\in\mathbb{R}$. Thus the final learning objective becomes:&lt;/p&gt;

&lt;p&gt;$
\mathcal{L} = \mathcal{L}&lt;em&gt;{recom} + \lambda&lt;/em&gt; 1\mathcal{L}_ {SSL} + \lambda_ 2\cdot |\Theta|_ F^2
$&lt;/p&gt;

&lt;p&gt;For weight-importance parameters $\lambda_1$ and $\lambda_2$. The complete procedure is shown in Figure 1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/0jBdgs4G/image.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1: Overview of the SelfGNN framework&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;5-experiment&quot;&gt;&lt;strong&gt;5. Experiment&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;51-experiment-setup&quot;&gt;&lt;em&gt;5.1 Experiment setup&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;As mentioned in the beginning, the following experiments are designed to answer the aforementioned research questions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data sets&lt;/strong&gt; The SelfGNN model is tested using an Amazon-book dataset (user ratings of Amazon books) (He and McAuley 2016), Gowalla dataset (user geolocation check-ins) (Cho et al. 2011), Movielens dataset (users’ ratings for movies from 2002 to 2009)(Harper and Konstant 2015), and Yelp data set (venue reviews sampled from 2009 to 2019) (Liu et al. 2024). Furthermore the &lt;em&gt;5-core setting&lt;/em&gt; is applied which removes all users and items with less than 5 interactions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Baselines&lt;/strong&gt; They test their method against a plethora of methods. This includes BiasMF (Koren et al. 2009), NCF (He et al. 2017), GRU4Rec (Hidasi et al. 2016), SASRec (Kang and McAuley 2018), TiSASRec (Li et al. 2020), Bert4Rec (Liu et al. 2019), NGCF (Wang et al. 2019), LightGCN~\cite{}, SRGNN~\cite{}, GCE-GNN~\cite{}, SURGE (Chang et al. 2021), ICLRec~\cite{}, CoSeRec~\cite{}, CoTRec~\cite{}, and CLSR~\cite{}.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Evaluation&lt;/strong&gt; For evaluation the data sets were split by time such that the most recent observations were used for testing, the earliest observations were used for training, and the remaining (middle) observations were used for validation. Furthermore, 10.000 users were sampled as test users for which negative samples were sampled by selecting 999 items the test user had not interacted with. Lastly, they use Hit rate (HR)@N and Normalized Discounted Cumulative Gain (NDCG)@N for $N = {10,20}$ as their evaluation metrics.&lt;/p&gt;

&lt;h3 id=&quot;52-results&quot;&gt;&lt;em&gt;5.2 Results&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The main results are presented in Figure 2:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/LsGqL3WT/image.png&quot; alt=&quot;table of results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2: Results for the top 10 and top 20 recommendations for the SelfGNN and the baselines&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;From Figure 2, it is clear that the SelfGNN is able to outperform the previous recommender methods on the top 10 and top 20 recommendations.&lt;/p&gt;

&lt;p&gt;Furthermore, they perform an ablation study on the different modules of the SelfGNN model to see what happens to the performance when different parts of the model are changed. The results are shown in Figure 3.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/C5SxsPsj/image.png&quot; alt=&quot;ablation study table&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 3: Module ablation study of the SelfGNN model.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;From the figure, we see how the performance changes when different parts of the model are either removed or changed. Notably, we see how much the performance drops when the collaborative filtering &lt;em&gt;-CF&lt;/em&gt; is dropped.&lt;/p&gt;

&lt;p&gt;Lastly, to analyze the SelfGNN robustness against noise they conducted experiments where they randomly replaced some of the real item interactions with randomly generated fake ones. Figure 4 shows the performance of the SelfGNN and the top baselines on the Amazon and Movielens data set as the percentage of fake items increased.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/d35wmq1Y/image.png&quot; alt=&quot;Noise study&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 4: Relative HR@10 as a function of noise ratio for the SelfGNN and top baselines on the Amazon (a) and Movielens (b) data set&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;From the figure, it is also clear that the performance of the SelfGNN is much more stable as more and more noise is injected into the data.&lt;/p&gt;

&lt;h2 id=&quot;6-conclusion&quot;&gt;&lt;strong&gt;6. Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Liu et al (2024) propose a novel method to encode short and long-term user-item interactions for self-supervised learning by integrating the short-term embeddings into long-term ones. They further empirically show, that their method outperforms state-of-the-art recommender system methods in top 10 and top 20 recommendations.&lt;/p&gt;

&lt;p&gt;Importantly, they propose to &lt;em&gt;denoise&lt;/em&gt; the short-term information for self-supervised learning by filtering using long-term embeddings. This is quite logical, as we would expect long-term patterns to shape individual user preferences. Thus short-term instances that deviate too much from the long-term patterns can safely be assumed to be noise.&lt;/p&gt;

&lt;p&gt;Possible direction for future research could be making the time-series continuous instead of discretized time-intervals using things such as ordinary differential equations.&lt;/p&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Author name: Christian Hvilshøj
    &lt;ul&gt;
      &lt;li&gt;Affiliation: KAIST School of Computing&lt;/li&gt;
      &lt;li&gt;Research Topic: Sequential Recommendation Learning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;7-reference--additional-materials&quot;&gt;&lt;strong&gt;7. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.20878&quot;&gt;Main paper&lt;/a&gt;: Liu, Yuxi, Lianghao Xia, and Chao Huang. “SelfGNN: Self-Supervised Graph Neural Networks for Sequential Recommendation.” Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2024.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/HKUDS/SelfGNN&quot;&gt;Github Implementation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Reference&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Vaswani, A. “Attention is all you need.” Advances in Neural Information Processing Systems (2017).&lt;/p&gt;

&lt;p&gt;Yingqiang Ge, Shuya Zhao, Honglu Zhou, Changhua Pei, Fei Sun, Wenwu Ou,
and Yongfeng Zhang. 2020. Understanding echo chambers in e-commerce recommender systems. In SIGIR. 2261–2270.&lt;/p&gt;

&lt;p&gt;Wei Wei, Chao Huang, Lianghao Xia, and Chuxu Zhang. 2023. Multi-modal
self-supervised learning for recommendation. In WWW. 790–800.&lt;/p&gt;

&lt;p&gt;Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Shu Wu, Shuhui Wang, and Liang
Wang. 2021. Mining latent structures for multimedia recommendation. In MM.
3872–3880&lt;/p&gt;

&lt;p&gt;Mengqi Zhang, Shu Wu, Xueli Yu, Qiang Liu, and Liang Wang. 2023. Dynamic
Graph Neural Networks for Sequential Recommendation. IEEE Transactions on
Knowledge and Data Engineering (TKDE) 35, 5 (2023), 4741–4753.&lt;/p&gt;

&lt;p&gt;Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng
Jin, and Yong Li. 2021. Sequential recommendation with graph neural networks.
, 378–387 pages&lt;/p&gt;

&lt;p&gt;Ruining He and Julian McAuley. 2016. Ups and Downs: Modeling the Visual
Evolution of Fashion Trends with One-Class Collaborative Filtering. In WWW.
507–517&lt;/p&gt;

&lt;p&gt;Eunjoon Cho, Seth A. Myers, and Jure Leskovec. 2011. Friendship and mobility:
user movement in location-based social networks. In KDD. 1082–1090.&lt;/p&gt;

&lt;p&gt;F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History
and Context. ACM Transactions on Interactive Intelligent Systems (TIIS) (2015).&lt;/p&gt;

&lt;p&gt;Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. Computer 42, 8 (2009), 30–37.&lt;/p&gt;

&lt;p&gt;Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng
Chua. 2017. Neural Collaborative Filtering. In WWW. 173–182.&lt;/p&gt;

&lt;p&gt;BalÃ¡zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Session-based Recommendations with Recurrent Neural Networks. In
ICLR&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Wang-Cheng Kang and Julian McAuley. 2018. Self-Attentive Sequential Recommendation. In ICDM. IEEE, 197–206.&lt;/p&gt;

&lt;p&gt;Jiacheng Li, Yujie Wang, and Julian McAuley. 2020. Time Interval Aware SelfAttention for Sequential Recommendation. In WSDM. 322–330.&lt;/p&gt;

&lt;p&gt;Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. In CIKM. 1441–1450.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019.
Neural graph collaborative filtering. In SIGIR. 165–174.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;More references is to be cited where \cite{} is presented but I ran out of time…&lt;/em&gt;&lt;/p&gt;
</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-Self-Supervised_Graph_Neural_Networks_for_Sequential_Recommendation.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-Self-Supervised_Graph_Neural_Networks_for_Sequential_Recommendation.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[NeurIPS-24] SPA: A Graph Spectral Alignment Perspective for Domain Adaptation</title>
            <description>&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;p&gt;This paper introduces &lt;strong&gt;SPA (graph SPectral Alignment Perspective)&lt;/strong&gt;, an innovative method for &lt;strong&gt;Unsupervised Domain Adaptation (UDA)&lt;/strong&gt; that leverages graph spectral alignment. &lt;strong&gt;UDA&lt;/strong&gt; addresses the challenge of adapting a model trained on a labeled source domain to perform well on an unlabeled target domain with different data distributions. Traditional UDA methods mainly focus on aligning features between domains and often overlook the rich intra-domain structures within each domain, therefore reducing the model’s ability to discriminate between classes. SPA offers a hierarchical framework that combines coarse graph alignment using spectral regularization with fine-grained message propagation through a neighbor-aware self-training mechanism. By doing so, SPA effectively balances the transfer of features across domains while maintaining discriminability within the target domain.&lt;/p&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;The main challenge in UDA is to predict labels for the target domain data without access to labeled target data during training. Existing UDA methods primarily emphasize inter-domain transferability by aligning source and target domains to reduce domain shift. However, the authors claim that there exists trade of between learning a representation that is domain invariant, and learning a representation that results in maximum separabaility of the target domain.&lt;/p&gt;

&lt;p&gt;The key innovation of this paper is the introduction of a graph spectral alignment perspective, which allows for an intrinsic and flexible alignment of the source and target domains without the need for restrictive point-wise matching. By casting the UDA problem into graph primitives, the authors aim to capture both inter-domain and intra-domain relations. The alignment of two domains via SPA appears to be more flexible and as a result the neighbor-aware self-training mechanism is able to further refines the target domain representations, improving discriminability.&lt;/p&gt;

&lt;h2 id=&quot;2-problem-definition&quot;&gt;2. Problem Definition&lt;/h2&gt;

&lt;p&gt;Formally, given:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Source Domain Data&lt;/strong&gt;: $D_ s = { (x_ i^s, y_ i^s) }_ {i=1}^{N_ s}$, where $x_ i^s$ are the samples and $y_ i^s$ are the labels associated with the given samples, $N_ s$ is the number of labeled samples associated with $C_ s$ categorites.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Target Domain Data&lt;/strong&gt;: $D_ t = { x_ i^t }_ {i=1}^{N_ t}$, where $x_ i^t$ are $N_ t$ unlabeled samples associated with $C_ t$ labels.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The goal of &lt;strong&gt;UDA&lt;/strong&gt; is to learn a model that accurately predicts the labels ${y_ i^t}_ {i=1}^{N_ t}$ for the target domain samples $x_ i^t$. Both domains are assumed to share the same feature space and label space but to have different marginal data distributions.&lt;/p&gt;

&lt;h2 id=&quot;3-related-works&quot;&gt;3. Related Works&lt;/h2&gt;

&lt;h3 id=&quot;31-adversarial-methods&quot;&gt;3.1 Adversarial Methods&lt;/h3&gt;

&lt;p&gt;Adversarial methods, such as &lt;strong&gt;Domain-Adversarial Neural Networks (DANN)[1]&lt;/strong&gt;, aim to learn domain-invariant features by confusing a domain classifier in an adversarial setup. While effective in reducing domain discrepancies, these methods often neglect intra-domain structures, which can reduce the model’s ability to discriminate between classes within the target domain.&lt;/p&gt;

&lt;h3 id=&quot;32-discrepancy-based-methods&quot;&gt;3.2 Discrepancy-Based Methods&lt;/h3&gt;

&lt;p&gt;Discrepancy-based approaches, like &lt;strong&gt;Correlation Alignment (CORAL)[2]&lt;/strong&gt;, focus on minimizing statistical differences between source and target feature distributions. They primarily emphasize inter-domain transferability but often overlook the intra-domain relationships essential for maintaining class discriminability in the target domain.&lt;/p&gt;

&lt;h3 id=&quot;33-graph-based-methods&quot;&gt;3.3 Graph-Based Methods&lt;/h3&gt;

&lt;p&gt;Graph-based UDA methods capture relationships between samples by constructing and aligning graphs based on structural properties. Techniques like &lt;strong&gt;Bipartite Spectral Matching (BSP)[3]&lt;/strong&gt; align domain graphs to enhance transferability. However, these methods rely on explicit, point-wise graph matching, which can be restrictive and computationally intensive, and insufficiently address intra-domain discriminability.&lt;/p&gt;

&lt;h3 id=&quot;34-novelty-of-spa&quot;&gt;3.4 Novelty of SPA&lt;/h3&gt;

&lt;p&gt;The proposed &lt;strong&gt;SPA (Spectral Alignment Perspective)&lt;/strong&gt; advances UDA by effectively balancing inter-domain transferability and intra-domain discriminability through a hierarchical framework:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Graph Spectral Alignment&lt;/strong&gt;: SPA introduces a spectral regularizer that aligns source and target domain graphs in the eigenspace by minimizing the spectral distance between their Laplacian eigenvalues. This implicit alignment captures essential topological features without restrictive point-wise matching.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Neighbor-aware Self-training&lt;/strong&gt;: SPA incorporates a neighbor-aware propagation mechanism that enhances discriminability within the target domain. By generating pseudo-labels using a weighted K-Nearest Neighbors (kNN) algorithm, it encourages smoothness among neighboring predictions and maintains class distinctions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Joint Balancing Mechanism&lt;/strong&gt;: By integrating spectral alignment with neighbor-aware propagation, SPA ensures domain alignment reduces transfer gaps while preserving and enhancing intra-domain structures for high discriminability.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;4-methodology&quot;&gt;4. Methodology&lt;/h2&gt;

&lt;h3 id=&quot;41-adversarial-domain-adaptation-framework&quot;&gt;4.1 Adversarial Domain Adaptation Framework&lt;/h3&gt;

&lt;p&gt;SPA contains an adversarial domain adaptation framework, which includes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Feature Encoder&lt;/strong&gt; $F(\cdot)$: Extracts features from input data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Classifier&lt;/strong&gt; $C(\cdot)$: Predicts class labels based on extracted features.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Domain Classifier&lt;/strong&gt; $D(\cdot)$: Distinguishes between source and target domain features.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Objective Functions&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;There are four objective functions parallely optimized. The supervised loss and adversarial loss components are defined as follows. The supervised loss component trains the model to learn the label information and the adversarial loss helps regularize this information to be domain invariant.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Supervised Classification Loss&lt;/strong&gt;:  $L_ {\text{cls}} = \mathbb{E}_ {(x_ i^s, y_ i^s) \sim D_ s} \left[ L_ {\text{ce}} \left( C(F(x_ i^s)), y_ i^s \right) \right]$, where $L_ {\text{ce}}$ is the cross-entropy loss.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Adversarial Loss&lt;/strong&gt;: $L_ {\text{adv}} = \mathbb{E}_ {x_ i^s \sim D_ s} \left[ \log D(F(x_ i^s)) \right] + \mathbb{E}_ {x_ i^t \sim D_ t} \left[ \log  \left( 1 - D(F(x_ i^t)) \right) \right]$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;42-dynamic-graph-construction&quot;&gt;4.2 Dynamic Graph Construction&lt;/h3&gt;

&lt;p&gt;To capture intra-domain relations, SPA constructs self-correlation graphs for both the source and target domains:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Nodes&lt;/strong&gt;: Each node represents a sample’s feature embedding from the feature encoder:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Source nodes: $f_ i^s = F(x_ i^s)$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Target nodes: $f_ i^t = F(x_ i^t)$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Edges&lt;/strong&gt;: Edges are weighted based on a similarity function $\delta(f_ i, f_ j)$, such as cosine similarity.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dynamic Nature&lt;/strong&gt;: The graphs are dynamic because they evolve as the feature encoder $F$ updates during training.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;43-graph-spectral-alignment&quot;&gt;4.3 Graph Spectral Alignment&lt;/h3&gt;

&lt;p&gt;SPA introduces a spectral regularizer to align the source and target graphs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Compute the &lt;strong&gt;graph Laplacian&lt;/strong&gt; $L$ for each graph.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Obtain the &lt;strong&gt;eigenvalues&lt;/strong&gt; $\Lambda$ of the Laplacian matrices for both source ($\Lambda^s$) and target ($\Lambda^t$) graphs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Define the &lt;strong&gt;Spectral Distance&lt;/strong&gt;: $L_ {\text{gsa}} = \left\vert  \Lambda^s - \Lambda^t \right\vert_ p$ ,where $\left\vert  \cdot  \right\vert_ p$ denotes the $L_ p$ norm.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Minimize $L_ {\text{gsa}}$ to encourage the source and target graphs to have similar spectral properties, aligning them in the eigenspace.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This implicit alignment avoids the need for explicit, restrictive point-wise matching.&lt;/p&gt;

&lt;h3 id=&quot;44-neighbor-aware-propagation-mechanism&quot;&gt;4.4 Neighbor-aware Propagation Mechanism&lt;/h3&gt;

&lt;p&gt;To enhance discriminability within the target domain, SPA introduces a neighbor-aware self-training mechanism:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Pseudo-label Generation&lt;/strong&gt;:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;The pseudo label generation is is   a weighted K-Nearest Neighbors (kNN) algorithm to assign pseudo-labels to target samples.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Voting Mechanism&lt;/strong&gt;:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Each target sample $x_ i^t$ considers its $k$ nearest neighbors $N_ i$.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Neighbors vote for the class labels, weighted by their predicted probabilities.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Confidence Weighting&lt;/strong&gt;:&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;Compute the weighted vote for class $c$ is: $q_ {i,c} = \sum_ {j \in N_ i} p_ {j,c}^m$&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;Normalize to get the confidence $\hat{q}&lt;em&gt;{i,c}$ is : $\hat{q}&lt;/em&gt; {i,c} = \frac{q_ {i,c}}{\sum_ {m=1}^{C_ t} q_ {i,m}}$&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Assign the pseudo-label: $\hat{y}_ i = \arg\max_ c \hat{q}_ {i,c}$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Memory Bank&lt;/strong&gt;:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;The Memory Bank plays a vital role in the neighbor-aware propagation mechanism by storing sharpened predictions and normalized features for target samples. Sharpening is achieved through the equation:&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;strong&gt;Sharpening&lt;/strong&gt; reduces prediction ambiguity: $\tilde{p}_ {j,c} = \frac{p_ {j,c}^{1/\tau}}{\sum_ {x=1}^{C_ t} p_ {j,x}^{1/\tau}}$, where $\tau$ is the temperature parameter.&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;strong&gt;Exponential Moving Average (EMA)&lt;/strong&gt; updates the stored predictions and features over iterations.&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Neighbor-aware Propagation Loss&lt;/strong&gt;: $L_ {\text{nap}} = -\alpha  \cdot  \frac{1}{N_ t} \sum_ {i=1}^{N_ t} \hat{q}_ {i, \hat{y}_ i} \log p_ {i, \hat{y}_ i}$&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;$\alpha$ is a scaling coefficient that increases over iterations.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://postimg.cc/TK6QdmW0&quot; alt=&quot;Image description&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;45-final-objective&quot;&gt;4.5 Final Objective&lt;/h3&gt;

&lt;p&gt;The overall loss function combines all components:&lt;/p&gt;

&lt;p&gt;$L_ {\text{total}} = L_ {\text{cls}} + \lambda_ {\text{adv}} L_ {\text{adv}} + \lambda_ {\text{gsa}} L_ {\text{gsa}} + \lambda_ {\text{nap}} L_ {\text{nap}}$&lt;/p&gt;

&lt;p&gt;This objective aims to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Learn discriminative features on the source domain ($L_ {\text{cls}}$).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Align the source and target domains ($L_ {\text{adv}}$ and $L_ {\text{gsa}}$).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Refine target domain representations through neighbor-aware propagation ($L_ {\text{nap}}$).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-experiments&quot;&gt;5. Experiments&lt;/h2&gt;

&lt;h3 id=&quot;51-experimental-setup&quot;&gt;5.1 Experimental Setup&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Datasets&lt;/strong&gt;:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Office31&lt;/strong&gt;: 4,652 images, 31 categories, 3 domains (Amazon, DSLR, Webcam).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;OfficeHome&lt;/strong&gt;: ~15,500 images, 65 categories, 4 domains (Artistic, Clipart, Product, Real-World).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;VisDA2017&lt;/strong&gt;: Over 280,000 images, 12 categories, synthetic-to-real domain adaptation.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;DomainNet&lt;/strong&gt;: ~600,000 images, 345 categories, 6 domains (Clipart, Infograph, Painting, Quickdraw, Real, Sketch).&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Baselines&lt;/strong&gt;: Compared with state-of-the-art UDA methods like DANN, CDAN, MDD, and others.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Backbone Networks&lt;/strong&gt;:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;ResNet-50&lt;/strong&gt; for Office31 and OfficeHome.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;ResNet-101&lt;/strong&gt; for VisDA2017 and DomainNet.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Optimization&lt;/strong&gt;:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Optimizer&lt;/strong&gt;: Stochastic Gradient Descent (SGD) with momentum.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Learning Rate&lt;/strong&gt;: Initialized at 0.01 with specific schedules.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Weight Decay&lt;/strong&gt;: Set to 0.005.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;52-results&quot;&gt;5.2 Results&lt;/h3&gt;

&lt;p&gt;In the  &lt;strong&gt;DomainNet&lt;/strong&gt; dataset, SPA achieved an 8.6% improvement in accuracy over previous state-of-the-art methods, demonstrating superior performance in handling large-scale datasets with significant domain gaps. On the &lt;strong&gt;OfficeHome&lt;/strong&gt; dataset, SPA showed approximately a 2.6% improvement in accuracy over existing methods, consistently outperforming competitors in all 12 adaptation scenarios. For the &lt;strong&gt;Office31 and VisDA2017&lt;/strong&gt; datasets, SPA performed on par with or better than state-of-the-art methods, showcasing its robustness and effectiveness across all domain pairs and tasks. In terms of evaluation metrics, classification accuracy on target domains was used, and SPA consistently showed improvements when compared to methods like DANN, CDAN, and MDD across all datasets.&lt;/p&gt;

&lt;h2 id=&quot;6-discussion-and-conclusion&quot;&gt;6. Discussion and Conclusion&lt;/h2&gt;

&lt;h3 id=&quot;61-efficacy-and-robustness&quot;&gt;6.1 Efficacy and Robustness&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SPA effectively balances inter-domain transferability and intra-domain discriminability, making it an efficient method. Its robustness is demonstrated across different datasets and domain shifts, showing that it can adapt well to various scenarios without a significant drop in performance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;62-comparison-with-related-works&quot;&gt;6.2 Comparison with Related Works&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;SPA distinguishes itself from methods like BSP and SIGMA by using implicit graph alignment through spectral regularization. This approach avoids the limitations of point-wise matching that are present in other techniques. Additionally, SPA’s neighbor-aware propagation mechanism enhances discriminability within the target domain, countering potential reductions that could arise from external regularization.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;64-conclusion&quot;&gt;6.4 Conclusion&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;SPA introduces a novel approach to unsupervised domain adaptation by integrating graph spectral alignment with a neighbor-aware propagation mechanism. It effectively addresses the limitations of existing methods by considering both inter-domain and intra-domain relations. The experiments show that SPA outperforms current state-of-the-art methods, significantly improving accuracy while maintaining a balance between transferability and discriminability.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;7-author-information&quot;&gt;7. Author Information&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Zhiqing Xiao&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;College of Computer Science and Technology, Zhejiang University&lt;/li&gt;
      &lt;li&gt;Key Lab of Intelligent Computing based Big Data of Zhejiang Province, Zhejiang University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;8-references-and-additional-materials&quot;&gt;8. References and Additional Materials&lt;/h2&gt;
&lt;p&gt;Xiao, Z., Wang, H., Jin, Y., Feng, L., Chen, G., Huang, F., &amp;amp; Zhao, J. (2023). &lt;strong&gt;SPA: A Graph Spectral Alignment Perspective for Domain Adaptation&lt;/strong&gt;. &lt;em&gt;arXiv preprint arXiv:2310.17594&lt;/em&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;GitHub Repository&lt;/strong&gt;: &lt;a href=&quot;https://github.com/CrownX/SPA&quot;&gt;https://github.com/CrownX/SPA&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Paper Reference&lt;/strong&gt;:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;[1] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by back propagation. In Proceedings of the 32th International Conference on Machine Learning (ICML), pages 1180–1189. PMLR, 2015.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;[2] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In ECCV 2016 Workshops, 2016.&lt;/li&gt;
      &lt;li&gt;[3] Xinyang Chen, Sinan Wang, Mingsheng Long, and Jianmin Wang. Transferability vs. discriminability: Batch spectral penalization for adversarial domain adaptation. In Proceedings of the 36th International Conference on Machine Learning (ICML), pages 1081–1090. PMLR, 2019.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-SPA_A_Graph_Spectral_Alignment_Perspective_for_Domain_Adaptation.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-SPA_A_Graph_Spectral_Alignment_Perspective_for_Domain_Adaptation.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICML 2024] Recurrent Distance Filtering for Graph Representation Learning</title>
            <description>&lt;h2 id=&quot;1-motivation&quot;&gt;1. Motivation&lt;/h2&gt;

&lt;h3 id=&quot;message-passing-neural-networksmpnns의-한계점&quot;&gt;Message Passing Neural Networks(MPNNs)의 한계점&lt;/h3&gt;
&lt;p&gt;MPNNs은 각 레이어마다 이웃 노드들의 message를 aggregate한다. 따라서 k-hop만큼 떨어진 이웃 노드의 정보에 접근하기 위해서는 k개의 MPNN 레이어를 필요로 한다. 그러나, 이로 인해 노드의 receptive field가 k에 기하급수적으로 증가하게 된다.
이렇게 증가하는 receptive field는 고정된 크기의 representation에 담기게 되고, 이는 정보 손실을 야기한다. 이러한 현상을 over-squashing이라고 하며, 이는 MPNNs의 핵심적인 한계점인 long range interaction을 잘 포착하지 못하는 특성의 원인이 된다.&lt;/p&gt;
&lt;h3 id=&quot;graph-transformersgts&quot;&gt;Graph Transformers(GTs)&lt;/h3&gt;
&lt;p&gt;GTs는 MPNNs가 해결하지 못하는 long range interaction을 잘 포착하고자 고안된 모델이다. GTs는 모든 노드에 대해 global attention을 적용하여, 모든 노드 쌍에 대한 관계를 포착할 수 있다. 그그러나 global attention에서 노드 수의 제곱에 비례하는 quadratic complexity를 요구하기 때문에, 효율성 측면에서 부족하다.&lt;/p&gt;

&lt;h2 id=&quot;2-proposed-model-gred-layer&quot;&gt;2. Proposed Model: GRED Layer&lt;/h2&gt;
&lt;p&gt;Graph Recurrent Encoding by Distance(GRED)는 long range interaction을 잘 포착하면서도 효율적인 구조로서 고안된 모델이다. Transformer 대신 linear RNN을 활용하고, multiset aggergation을 통해 RNN에 넣어줄 적절한 input을 shortest-path distance 기반으로 만들어 준다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;image.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;multiset-aggregation&quot;&gt;Multiset Aggregation&lt;/h3&gt;
&lt;p&gt;이전 layer의 output $\boldsymbol h_{u}^{(l-1)}$에 대해서, GRED는 node의 각 hop 별 이웃들의 정보를 취합하는 multiset aggregation을 먼저 수행한다.
\(\boldsymbol{x}_{v,k}^{(l)} =\mathrm{AGG}\left( \{\!\{ \boldsymbol h_{u}^{(l-1)}\;|\;u\in\mathcal N_{k}(v) \}\!\} \right)\)
이 결과물 $\boldsymbol{x}&lt;em&gt;{v,k}^{(l)}$ 은 노드 $v$의 $k$-hop 이웃들의 정보를 담은 representation vector이며, 이를 $k=0,\dots,K$ 에 대해 수행하여 최종적으로 $(\boldsymbol{x}&lt;/em&gt;{v,0}^{(l)},\boldsymbol{x}&lt;em&gt;{v,1}^{(l)},\dots,\boldsymbol{x}&lt;/em&gt;{v,K}^{(l)})$ 의 형태의 sequence를 얻을 수 있다. 
Aggregation은 permutation-invariant neural network(DeepSet이나 GIN)의 아이디어를 활용하여 sum aggregation을 사용하며, 실제로는 다음과 같은 식으로 계산된다.
\(\boldsymbol{x}_{v,k}^{(l)} =\mathrm{MLP}_2\left( \sum_{u\in\mathcal N_k(v)}\mathrm{MLP}_1\left( \boldsymbol h_u^{(l-1)} \right) \right)\in\mathbb R^d\)&lt;/p&gt;

&lt;h3 id=&quot;linear-recurrent-network&quot;&gt;Linear Recurrent Network&lt;/h3&gt;
&lt;p&gt;Linear Recurrent Network(LRU)는 SSM에서 착안한 RNN 모델로, 기존 매 update마다 있던 activation함수를 제거하여 parallel한 processing이 가능하도록 하는 효율적인 모델이다. Multiset Aggregation에서 생성된 sequence는 LRU의 각 step으로 다음과 같이 입력된다.
\(\boldsymbol{s}_{v,k}^{(l)}=\boldsymbol A\boldsymbol{s}_{v,k-1}^{(l)}+\boldsymbol B\boldsymbol{x}_{v,K-k}^{(l)}\)
식에서 볼수 있듯이 $\boldsymbol{x}_{v,K}^{(l)}$ 부터 거꾸로 넣어주는데, 이는 멀리서 ($K$-hop)부터 타겟 노드 ($v$)까지 정보가 모여들기 때문이다.
LRU에서와 같이, 위의 RNN연산을 $\boldsymbol A$를 대각화함으로써($\boldsymbol A=\boldsymbol V\bold{\Lambda}\boldsymbol V^{-1}$) 효율적인 형태로 바꾼다.
\(\boldsymbol{s}_{v,k}^{(l)}=\bold {\Lambda}\boldsymbol{s}_{v,k-1}^{(l)}+\boldsymbol {W}_{\mathrm{in}}\boldsymbol{x}_{v,K-k}^{(l)}\rarr\boldsymbol{s}_{v,k}^{(l)}=\sum_{k=0}^{K}\bold {\Lambda}^k\boldsymbol {W}_{\mathrm{in}}\boldsymbol{x}_{v,k}^{(l)}\)
결과적으로 $k$-hop에 있는 노드들의 representation은 $\bold {\Lambda}^k$ 가 곱해지고, 이를 타겟 노드로부터 $\bold {\Lambda}$로 “filter over hops”을 수행하는 것이라고 설명한다.&lt;/p&gt;

&lt;h3 id=&quot;output-of-gred-layer&quot;&gt;Output of GRED Layer&lt;/h3&gt;
&lt;p&gt;최종적으로는 LRU의 마지막 hidden state에 대하여 간단한 non-linear transform(MLP)를 적용하여 다음 GRED layer의 입력으로 넣어준다.
\(\boldsymbol{h}_{v}^{(l)}=\mathrm{MLP}_3\left( \mathfrak {R}\left[\boldsymbol {W}_{\mathrm{out}}\boldsymbol{s}_{v,K}^{(l)}\right]  \right)\)
GRED로 생성된 노드들의 representation을 활용하여 node classification, graph classificatino과 같은 다양한 graph task를 수행할 수  있다.&lt;/p&gt;

&lt;h2 id=&quot;3-expressiveness-analysis&quot;&gt;3. Expressiveness Analysis&lt;/h2&gt;
&lt;p&gt;GRED는 LRU의 도움으로 기존 MPNN의 한계인 1-WL를 뛰어넘는 expressivity를 가질 수 있음을 보인다. 요약하자면, GRED는 노드의 각 $k$-hop 이웃들에 대한 injective mapping을 수행 가능하고, 이는 논문에 언급된 다음 정리로 결론지어진다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Corollary 4.3 (Expressiveness of GRED)&lt;/strong&gt;
&lt;em&gt;When $K&amp;gt;1$, A wide enough GRED layer is more expressive than any 1-hop message passing layer.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-experiments&quot;&gt;4. Experiments&lt;/h2&gt;
&lt;p&gt;실험에서 GRED의 성능을 다양한 MPNNs 모델들 그리고 GTs 모델들과 비교한다.&lt;/p&gt;
&lt;h3 id=&quot;datasets&quot;&gt;Datasets&lt;/h3&gt;
&lt;p&gt;자주 활용되는 Benchmarking graph neural networks(Benchmarking GNN)의 4가지 데이터셋과, 큰 그래프에 대한 성능 비교를 위해 Long Range Graph Benchmark(LRGB)의 2가지 데이터셋을 활용한다.&lt;/p&gt;

&lt;p&gt;Node Classification 데이터셋: PATTERN, CLUSTER&lt;/p&gt;

&lt;p&gt;Graph Classification 데이터셋: MNIST, CIFAR10&lt;/p&gt;

&lt;p&gt;Graph Regression 데이터셋: ZINC 12k&lt;/p&gt;

&lt;p&gt;LRGB (Graph Classification) 데이터셋: Peptides-func, Peptides-struct&lt;/p&gt;

&lt;p&gt;아래는 각 데이터셋에 대한 실험 결과이다.&lt;/p&gt;

&lt;h3 id=&quot;benchmarking-gnns&quot;&gt;Benchmarking GNNs&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;image-1.png&quot; alt=&quot;Alt text&quot; /&gt;
(metric: accuracy)&lt;/p&gt;

&lt;h3 id=&quot;zinc-12k-lrgb&quot;&gt;ZINC 12k, LRGB&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;image-2.png&quot; alt=&quot;Alt text&quot; /&gt; &lt;img src=&quot;image-3.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Graph Transformer 모델들이 MPNN 모델보다 좋은 성능을 보이는 경향성이 있다.&lt;/li&gt;
  &lt;li&gt;GRED가 가장 좋은 성능을 보이는 Graph Transformer 모델과 comparable한 성능을 보인다. 그러나 GRED는 GTs에서 필수적인 positional encoding이 필요가 없으며, 훨씬 효율적인 모델이라는 점에서 강점이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;training-time&quot;&gt;Training Time&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;image-4.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GRED의 효율성을 검증하기 위해, Graph Transformer의 SOTA 모델인 GRIT와 training time, GPU 메모리 소비량을 비교하였다. 데이터셋 종류에 따라 그 정도는 다르지만, GRED가 두 방면에서 모두 어느정도 효율적인 모델임을 확인할 수 있다. 다만, 큰 그래프 데이터(Peptides-func)에서는 오히려 두 모델 간의 차이가 크지 않기 때문에, 다양한 종류의 그래프에서 확실한 효율성 개선이 있는지는 추가적인 검증이 필요하다.&lt;/p&gt;

&lt;h3 id=&quot;sequence-길이k에-대한-분석&quot;&gt;Sequence 길이($K$)에 대한 분석&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;image-5.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;논문에서는 추가적으로 multiset aggregation에서 고려하는 최대 hop에 따라 성능이 어떻게 달라지는지 확인하였다. 가장 높은 성능을 보이는 $K$값은 데이터셋 종류에 따라 다른 경향을 보였는데, 이는 각 데이터셋마다 그래프의 크기, 지름과 같은 구조에 영향을 받는다고 해석할 수 있다. $K$가 그래프의 지름보다 커지게 되면, 같은 노드가 중복해서 등장하는 등 문제가 발생하기 때문에 논문에서는 $K$가 1과 그래프의 지름 사이에서 최적의 성능을 보인다고 분석한다.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;본 논문은 MPNNs의 long range interaction 해결 문제와 GTs의 높은 computatinal cost의 문제를 해결하기 위한 모델인 GRED를 제시하였다. GRED는 $k$-hop 이웃 노드에 대한 aggregation을 통한 senquence를 생성하고, 이를 LRU input으로 활용하여, 효율적이면서도 long range interaction을 잘 해결할 수 있는 구조를 설계했다.&lt;/li&gt;
  &lt;li&gt;본 논문에서는 GRED의 표현 능력, 성능, 그리고 효율성을 여러 이론적 분석과 실험을 통해 검증하였다.&lt;/li&gt;
  &lt;li&gt;그래프 머신러닝에서 MPNN이나 Transformer을 기반으로 한 것이 아닌 새로운 approach를 제시하였다.&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-Recurrent_Distance_Filtering_for_Graph_Representation_Learning.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-Recurrent_Distance_Filtering_for_Graph_Representation_Learning.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[KDD 2024] RecExplainer: Aligning Large Language Models for Explaining Recommendation Models</title>
            <description>&lt;h2 id=&quot;1-motivation&quot;&gt;&lt;strong&gt;1. Motivation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;추천 시스템이란 사용자의 과거 이력을 토대로 성향을 분석하여 소비할 확률이 높은 상품을 추천하는 모델이며, 영화, 음악, 쇼핑 등 우리 생활에 깊게 녹아들어 있다.&lt;br /&gt;
이를 위해 임베딩 기반의 collaborative filtering, graph neural network 등의  black-box 모델들이 연구되어 왔다.&lt;br /&gt;
하지만 이러한 black-box 모델들은 신뢰있고 이해되는 결과가 필요한 추천 시스템의 특성과는 달리 출력된 결과에 대한 설명을 제공하기 어렵다는 단점이 있다.&lt;br /&gt;
기존 연구들은 이를 위해 sparse linear model, decision tree 등의 별도의 surrogate 모델을 두어 이를 해결하려 했지만, &lt;br /&gt;
그것들의 단순한 구조로 인해 사람이 이해하기 쉬운 결과들이 나오기 어려웠다. &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;최근들어 large language model (LLM) 이 등장하고 이것의 논리 추론 능력이 연구됨에 따라 다양한 AI 분야에서 활용되기 시작했다.&lt;br /&gt;
그 중에 LLM 의 뛰어난 언어 능력에 접목하여 설명 가능한 인공지능 (XAI) 으로써의 활용 또한 연구가 되고 있다.&lt;br /&gt;
해당 논문은 이에 주목하여 LLM 을 surrogate 모델로 두어 설명 가능한 추천 시스템인 RecExplainer 을 제안한다.&lt;br /&gt;
즉 LLM 은 추천 자체에 쓰이기 보다는, 학습된 별도의 추천 시스템 모델과의 aligning 을 통해 &lt;br /&gt;
해당 모델들의 출력한 결과에 대한 설명을 제공하는 중간자 역할로써 활용된다. &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-problem-formulation&quot;&gt;&lt;strong&gt;2. Problem Formulation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; &lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/2fa1106c-3f37-4b25-973a-969fb3bc4935&quot; alt=&quot;Figure1&quot; /&gt;&lt;br /&gt;
사용자의 과거 이력을 $x_u = \langle a_1, a_2, \ldots, a_{|x_u|} \rangle, a_* :=$ 소비한 아이템, 로 표현하면&lt;br /&gt;
추천 모델 $f()$ 은 후에 소비할 확률이 높은 아이템과 낮은 아이템 $a_i, a_j$ 에 대해 f(x_u, a_i) &amp;gt; f(x_u, a_j)$ 의 값을 부여하는 것을 목표로 한다.&lt;br /&gt;
이때 임베딩 기반의 모델들은 $e_u = \text{encoder}&lt;em&gt;\text{user}(x_u), \space e_i = \text{encoder}&lt;/em&gt;\text{item}(a_i)$ 두 개의 임베딩을 구하고,&lt;br /&gt;
이들 간의 similarity 를 기반으로 선호도 점수를 예측한다.&lt;br /&gt;
RecExplainer 는 이미 학습이 완료된 $f()$ 가 주어졌을 때, 이것과 잘 aligning 되도록 LLM $g()$ 을 fine-tuning 하여 $f()$ 의 출력을 $g()$ 로 설명하도록 한다.&lt;br /&gt;
Fig. 1 에서 나타나 있듰이, 이때 $f()$ 은 frozen 이며 dimension projection 을 위한 MLP 와 $g()$ 만을 학습하며,&lt;br /&gt;
$g()$ 은 전체 가중치가 아닌 parameter-efficient 하게 LoRA 를 활용한다.&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tasks&quot;&gt;&lt;strong&gt;Tasks&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;저자들은 LLM $g()$ 을 fine-tuning 할 여섯 가지의 task 를 정의한다.&lt;br /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Next item retrieval: 유저의 기록이 주어졌을 때 다음에 이용할 아이템을 찾는 작업이다.&lt;/li&gt;
  &lt;li&gt;Item ranking: 아이템 목록이 주어졌을 때 유저의 선호도 순위를 매기는 작업이다.&lt;/li&gt;
  &lt;li&gt;Interest classification: 유저의 사용 기록이 주어졌을 때 특정 아이템의 선호 여부를 예측하는 작업이다.&lt;/li&gt;
  &lt;li&gt;Item discrimination: 아이템 제목이 주어졌을 때 설명을 생성하고 유사한 아이템을 찾는 작업이다. &lt;br /&gt;
이는 활용할 LLM 의 pretraining 시에 접하지 못했던 아이템들에 대한 이해력을 얻게 해준다.&lt;/li&gt;
  &lt;li&gt;ShareGPT training: LLM fine-tuning 시에 언어적 능력을 상실하는 catastrophic forgetting 을 방지하기 위한 작업이다.&lt;br /&gt;
사람과 ChatGPT 간의 대화가 저장된 ShareGPT API 를 활용해 $g()$ 의 어휘 역량을 잃지 않도록 한다.&lt;/li&gt;
  &lt;li&gt;History reconstruction: 유저의 임베딩이 주어졌을 때 해당 유저의 아이템 사용 기록을 복원하는 작업이다.&lt;br /&gt;
이를 통해 입력된 유저에 대한 정보를 얼마나 추출할 수 있는지 확인할 수 있다.&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이때 추천과 연관된 task 들의 경우, 학습 데이터의 label 은 ground truth 값이 아닌 $f()$ 이 생성한 결과가 된다.&lt;br /&gt;
그 이유는 $g()$ 가 $f()$ 가 내놓은 결과에 대한 설명을 제공하기를 바라는 것이지, 추천 자체를 하기를 목표하는 것이 아니기 때문이다.&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-methodology&quot;&gt;&lt;strong&gt;3. Methodology&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;RecExplainer 는 fine-tuning 할 $g()$ 와 pretrained 추천 모델 $f()$ 간의 aligning 을 아래 세 가지 방법을 통해 진행하며, &lt;br /&gt;
각각의 방법론을 적용한 모델을 순서대로 RecExplainer-B, RecExplainer-I, RecExplainer-H 라 표기한다. &lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;behavior-alignment&quot;&gt;&lt;strong&gt;Behavior Alignment&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Behavior alignment 는 teacher-student architecture 에서 knowledge distillation 과 어느 정도 유사한 방법론으로, &lt;br /&gt;
$g()$ 의 prediction 이 $f()$ 의 prediction 과 일치하면 그것의 생성 로직 또한 모방할 수 있고 결국 설명 능력도 생길 것이라고 가정한다.&lt;br /&gt;
이때 $g()$ 의 학습 과정에선 임베딩을 활용하지 않으므로 학습은 task 1~5 로만 진행한다. &lt;br /&gt;
활용된 prompt 의 예시는 아래와 같다. &lt;br /&gt;
“Given a user with history: ($item_1$, $item_2$, …), what item will you recommend to the user and why?”&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;intention-alignment&quot;&gt;&lt;strong&gt;Intention Alignment&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;하지만 Behavior alignment 는 $f()$ 가 실제로 어떻게 입력을 인지하는 지보단 prediction 결과에만 의존한다는 단점이 있다.&lt;br /&gt;
Intention alignment 는 현재 여러 Multi-modal Language Model (MLM) 에서 활용하는 방법론을 차용하여, &lt;br /&gt; 
user 와 item embedding 을 별도의 modality 로 취급해 각각이 LLM 의 language space 에 align 되도록 하는 방법론이다. &lt;br /&gt;
이를 통해 $g()$ 가 $f()$ 로부터 생성된 임베딩 공간을 학습하게 되어 설명 능력을 갖게 될 것이라 저자들은 주장한다.&lt;br /&gt;
학습은 task 1~6 모두 진행하며, Fig. 1 처럼 필요한 projecting 된 임베딩 벡터를 아이템의 이름대신 프롬프트에 추가하여 답을 얻는다.&lt;br /&gt;
활용된 prompt 의 예시는 아래와 같다. &lt;br /&gt;
“Given a user: (user_embedding), what item will you recommend to the user and why?”&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;hybrid-alignment&quot;&gt;&lt;strong&gt;Hybrid Alignment&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Hybrid alignment 는 behavior alignment 와 intention alignment 을 합친 것으로, 아이템의 제목과 임베딩 벡터 모두 프롬프트에 추가한 방법론이다.&lt;br /&gt;
따라서 활용된 prompt 의 예시는 아래와 같다.&lt;br /&gt;
“Given a user with history: (user_embedding), ($item_1$, $item_2$, …), what item will you recommend to the user and why?”&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-experiments&quot;&gt;&lt;strong&gt;4. Experiments&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;metrics&quot;&gt;&lt;strong&gt;Metrics&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;RecExplainer 는 실험의 평가 지표로 두 가지를 제시한다. &lt;br /&gt;
우선 $f()$ 와 $g()$ 가 얼마나 잘 aligning 됐는지 평가하는 수치를 제공하며, 이는 기존 추천 시스템에서 널리 활용되는 leave-one-out strategy 를 차용한다.&lt;br /&gt;
이는 사용자들의 interaction 기록에서 마지막 item 을 제거하고 복원하는 task 로, 얼마나 그 사용자의 특성을 잘 파악했는지 알 수 있는 방법이다.&lt;br /&gt;
하지만 RecExplainer 에서 LLM 은 추천 모델이 아닌 설명 모델로 활용되므로, ground truth 가 아닌 제공된 추천 모델 $f()$ 의 출력을 label 로 지정한다.&lt;br /&gt;
이를 토대로 $g()$ 가 얼마나 $f()$ 를 잘 모방하였는지 확인할 수 있다.&lt;br /&gt;
&lt;strong&gt;Figure 2&lt;/strong&gt; &lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/0cd70216-3f43-4d5b-b4dc-9b6cc20ea4b7&quot; alt=&quot;Figure2&quot; /&gt;&lt;br /&gt;
또한 Explainable AI 를 목표로 하기 때문에 제공한 설명의 타당성에 대한 평가도 제공한다.&lt;br /&gt;
하지만 “설명” 이라는 것의 특성상 유일한 정답이 존재하지 않으며, 일일이 사람이 hand-labeling 하는 것은 막대한 비용을 초래한다.&lt;br /&gt;
따라서 저자들은 human-labeling 뿐만 아니라 추론 능력이 뛰어난 GPT-4 모델을 활용하는데, &lt;br /&gt;
Fig. 2 와 같은 프롬프트를 통해 $g()$ 가 생성한 설명의 타당성을 네 개의 criteria 로 분류한다.&lt;br /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Rating-0: 틀린 답안&lt;/li&gt;
  &lt;li&gt;Rating-1: 올바른 답안, 부족한 설명&lt;/li&gt;
  &lt;li&gt;Rating-2: 올바른 답안, 수용할 만한 설명&lt;/li&gt;
  &lt;li&gt;Rating-3: 올바른 답안, 적절한 설명&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이때 답안의 정확도는 RecExplainer 가 제공된 설명이 $f()$ 의 출력과 일맥상통한지 판별하는 것으로, $g()$ 가 정말 $f()$ 의 결과를 토대로 설명을 제공했는 지 평가한다.&lt;br /&gt;
아쉬운 점은 저자들이 각 rating 에 대한 예시없이 최종 수치 분포만 제공하여 직관적인 이해에 어려움이 있었다.&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;experimental-setup&quot;&gt;&lt;strong&gt;Experimental Setup&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Datasets&lt;/strong&gt;
실험은 아래 세 개의 public dataset 을 활용하여 진행한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Video Games&lt;/li&gt;
  &lt;li&gt;Movies and TV&lt;/li&gt;
  &lt;li&gt;Steam&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;각 dataset 에 대한 정보와 train/test split 은 다음과 같다.&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/20e0f0cc-4ed9-468f-a4df-f919c85a6174&quot; alt=&quot;Figure3&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/9172860b-086e-4091-9530-9fbe4089fd87&quot; alt=&quot;Figure4&quot; /&gt;&lt;br /&gt;
&lt;strong&gt;Implementation details&lt;/strong&gt;
RecExplainer 은 Vicuna-v1.3-7b 을 backbone LLM 으로 활용하며, DeepSpeed 의 ZeRO-2 를 통한 분산 학습을 진행했다.&lt;br /&gt;
또한 설명의 대상이 되는 추천 모델로는 트랜스포머 기반인 SASRec 을 차용하였고, 각 dataset 에 알맞게 fine-tuning 을 추가적으로 진행하였다.&lt;br /&gt;
&lt;strong&gt;Baselines&lt;/strong&gt;
위에서 정의한 두 가지 평가 지표에 대한 baseline 모델들은 다음과 같다.&lt;br /&gt;
우선 alignment effect 에 대해선,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Random: k 개의 아이템을 uniform distribution 에서 추출하고 random shuffling 으로 우선순위를 지정한다.&lt;/li&gt;
  &lt;li&gt;Popularity: k 개의 아이템을 popularity distribution 에서 추출하고 인기순으로 우선순위를 지정한다.&lt;/li&gt;
  &lt;li&gt;Vicuna-v.1.3-7b: Aligning 을 거치지 않은 Vicuna 를 그대로 활용한다.&lt;/li&gt;
  &lt;li&gt;Vicuna-v.1.3-7b-ICL: Aligning 을 거치지 않은 Vicuna 를 2-shot prompting 하여 활용한다.&lt;/li&gt;
  &lt;li&gt;GPT4-ICL: GPT4 에 2-shot prompting 하여 활용한다.&lt;/li&gt;
  &lt;li&gt;SASRec: Pretrained SASRec $f()$ 을 통해 knowledge distillation 으로 학습시켜 활용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Explainability 에 대해선,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Vicuna-v.1.3-7b: Aligning 을 거치지 않은 Vicuna 를 그대로 활용한다.&lt;/li&gt;
  &lt;li&gt;ChatGPT: OpenAI API 를 활용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;results&quot;&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Alignment Effect&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/4d837990-c45b-470d-98eb-b8b6dca16c6a&quot; alt=&quot;Figure5&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;H@5: 5개의 추천 목록에 올바른 품목들이 들어갔는가&lt;/li&gt;
  &lt;li&gt;$N@5: 5개의 추천 목록이 얼마나 잘 배치됐는가&lt;/li&gt;
  &lt;li&gt;$ACC: 예측한 것이 얼마나 정확한가&lt;/li&gt;
  &lt;li&gt;$HCR: Label sequence 과 prediction 이 얼마나 겹치는가&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위 테이블은 Alignment 분야에서의 성능 평가를 나타낸 표다.&lt;br /&gt;
이때 세 가지 alignment variation 모두 별도의 aligning 없이 LLM 만을 활용한 실험들과 비교해서 &lt;br /&gt;
월등한 성능 차이가 나타나는 것을 통해 RecExplainer 에서 alignment 의 중요성을 확인할 수 있다. &lt;br /&gt;
또한 prediction 결과만을 통해 모방하는 RecExplainer-B 보단 좀 더 포괄적인 이해를 목표하는 RecExplainer-I/H 가 더 좋은 성능을 기록한 것을 확인할 수 있다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Explainability&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/953be1d0-9b0a-4ef5-b153-6af7759d8358&quot; alt=&quot;Figure6&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/209aec56-c377-42c1-bc01-6f11d5bf71b0&quot; alt=&quot;Figure7&quot; /&gt;&lt;br /&gt;
위 표와 Figure 는 순서대로 GPT-4 와 Human expert 가 평가한 생성된 설명에 대한 rating 의 평균과 분포다.&lt;br /&gt;
이를 통해 RecExplainer-H 가 다른 모델들에 비해 수준 높은 설명을 생성하는 것을 확인할 수 있다.
저자들은 기존 LLM 들은 아이템들에 대한 학습이 이뤄지지 않았기 때문에 대부분의 설명들이 모호하고 평이해 Rating-2 에 분포하게 된다고 주장한다.&lt;br /&gt;
주목할 만한 점은 RecExplainer-I 의 성능이 매우 낮게 나왔다는 것인데, 저자들은 분석 결과 이것이 생성한 답변들에 hallucination 현상이 다반사로 발생하는 것을 확인하였다.&lt;br /&gt;
그들은 HCR 점수가 낮은 것을 종합하였을 때, 임베딩만 주어졌을 때 문자 형태의 정보를 복원하는 능력이 부족해 이런 현상이 발생한 것이라 추측한다.&lt;br /&gt;
또한 저자들은 RecExplainer 가 생성한 설명들이 기존의 모델들의 것들과 명확히 다른지, 즉 설명 능력이 정말 fine-tuning 의 영향을 받는지 보여주는 실험 결과를 제공한다.&lt;br /&gt;
이는 Vicuna-7b, ChatGPT, RecExplainer-H 각각으로 2500 개의 설명을 생성하고, 하나의 discriminator 을 둬서 각 2000 개로 생성한 답변이 어느 모델로부터 생성했는지 분류하게 학습한다.&lt;br /&gt;
그 후 남은 500개로 다시 분류하는데, 아래의 결과를 통해 각 모델들의 설명들 모두 구분됨을 확인할 수 있고, 이를 토대로 저자들은 별도의 학습이 설명 생성에 영향을 주었다고 말한다.&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/76c2b787-f854-44e7-be05-29bff868e803&quot; alt=&quot;Figure10&quot; /&gt;&lt;br /&gt;
&lt;strong&gt;Case Study&lt;/strong&gt;&lt;br /&gt;
아래는 실제 설명 생성의 예시 사례를 보여주며, 올바른 설명은 초록색으로, 틀린 설명은 빨간색으로 표기하였다.&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/b4716f09-b146-4008-b3b1-62b8cc3174df&quot; alt=&quot;Figure8&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/3a290ed9-8337-4136-8f6c-da6f478e2596&quot; alt=&quot;Figure9&quot; /&gt;&lt;br /&gt;
또한 LLM 의 통한 설명의 장점은 원하는 시야에서 설명을 생성할 수 있다는 것이 있다.&lt;br /&gt;
저자들은 RecExplainer-H 를 통해 두 가지 측면에서 생성한 설명의 예시를 다음과 같이 제공한다.&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/3de1694d-3169-4310-9245-71c65e3b3326&quot; alt=&quot;Figure11&quot; /&gt;&lt;br /&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/79ad6aa0-7e6a-4b5d-91d4-a5e18c195c81&quot; alt=&quot;Figure12&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;이 논문은 LLM 을 적절한 alignment 를 통해 기존의 black-box 추천 모델들을 설명할 수 있는 방법론을 제안한다.&lt;br /&gt;
이와 같이 LLM 의 성능이 나날히 증가하며 다양한 분야에서 zero-shot 능력이 입증됨에 따라 이를 활용한 추천 시스템 연구들이 많이 진행되고 있다. &lt;br /&gt;
그 중에서 위 논문과 비슷하게 LLM 과 collaborative model 의 aligning 을 통해 두 모델의 장점을 모두 취하여 추천하는 연구 [1] 또한 KDD 2024 에 발표됐다. &lt;br /&gt;
반면 RecExplainer 는 LLM 의 추천 능력에 집중하기 보다는 설명 능력에 중점을 둔 것으로, 성능 평가 또한 ground truth 가 아닌 target model 의 output 을 기준으로 진행된다.&lt;br /&gt;
두 논문을 통해 방법론이 비슷하더라도 다른 motivation 을 설정하여 문제를 해결할 수 있음을 확인할 수 있어 흥미로웠다.&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;6-author-information&quot;&gt;&lt;strong&gt;6. Author Information&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Author name: 김현철
    &lt;ul&gt;
      &lt;li&gt;Affiliation: &lt;a href=&quot;https://dsail.kaist.ac.kr/&quot;&gt;DSAIL@KAIST&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Research Topic: Self-supervised learning, Time series&lt;/li&gt;
      &lt;li&gt;Contact: khchul@kaist.ac.kr&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;7-code-and-references&quot;&gt;&lt;strong&gt;7. Code and References&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;code&quot;&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;https://github.com/microsoft/RecAI/tree/main/RecExplainer&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;[1] Kim, S., Kang, H., Choi, S., Kim, D., Yang, M., &amp;amp; Park, C. (2024, August). Large Language Models meet Collaborative Filtering: An Efficient All-round LLM-based Recommender System. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (pp. 1395-1406).&lt;br /&gt;&lt;/p&gt;
</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-RecExplainer_Aligning_Large_Models_for_Explaining_Recomendation_Models.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-RecExplainer_Aligning_Large_Models_for_Explaining_Recomendation_Models.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[KDD-24] Popularity-Aware Alignment and Contrast for Mitigating Popularity Bias</title>
            <description>&lt;h2 id=&quot;1-problem-definition&quot;&gt;1. Problem Definition&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/CLLWnsSr/motivation.png&quot; width=&quot;400&quot; height=&quot;200&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Figure 1] 아이템의 인기에 따른 추천 성능 차이 및 아이템 임베딩의 분리&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Collaborative Fitlering 기반의 방법들은 인기 없는 아이템의 경우, 사용자와 interaction이 적기 때문에 인기 있는 아이템의 supervisory로 학습이 된다. 이러한 Popularity bias로 인해 Figure1에 나타난 것처럼 인기 있는 아이템과 인기 없는 아이템 사이에서 추천 성능이 차이가 나며, 임베딩 표현도 벌어지게 된다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;2. Motivation&lt;/h2&gt;
&lt;p&gt;본 논문에서는 두 가지 모듈을 활용해 unpopoular item에 대한 표현성을 향상시키고자 하였다. 기존의 방법들은 contarstive learning을 통해 popularity bias를 완화시키고자 하였으나, 이러한 방법은 popular, unpopular item 사이의 representation sepration을 심화시킨다. 본 논문에서 제안한 PAAC의 경우는 contrastive loss에서 가중치를 조절하여 popular item과 unpopular item의 representation이 너무 분리되지 않도록 하였다.&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;3. Method&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/HWw3GdS1/framework.png&quot; width=&quot;650&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Figure 2] Popularity-Aware-Alignment and Contrast 모델의 학습 과정&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;본 논문에서 제시한 프레임워크는 Collaborative Filtering을 기반으로 하여 Supervised Alignment Module, Re-weighting Contrast Module 두 가지 모듈을 추가한 형태로 구성되어 있다.&lt;/p&gt;

&lt;h3 id=&quot;31-supervised-alignment-module&quot;&gt;3.1 Supervised Alignment Module&lt;/h3&gt;
&lt;p&gt;Figure2에 그려진 대로, GCN encoder를 통과한 item embedding에 대하여 같은 user와 interaction이 있는 아이템들에 대해서 representation을 유사하게 만들어준다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/NjKbyTxR/five.png&quot; width=&quot;250&quot; height=&quot;45&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;32-re-weighting-contrast-module&quot;&gt;3.2 Re-weighting Contrast Module&lt;/h3&gt;
&lt;p&gt;본 논문에서는 상위 50% item을 popular item으로 정의하고, 하위 50%의 item을 unpopular item으로 정의하였다. Contrastive loss를 계산할 때 popular item에 대해서 unpopular item이 negative sample로 뽑히거나, unpopular item에 대해서 popular item이 negative sample로 뽑히게 되면 representation separation이 심화된다. 따라서 본 논문에서는 아래의 식처럼 contrastive loss를 계산할 때 가중치를 주어 negative sample을 지나치게 밀어내는 것을 막도록 하였다.
&lt;img src=&quot;https://i.postimg.cc/1XGVt6Bc/cl.png&quot; width=&quot;300&quot; height=&quot;40&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/Gm6J83Kt/8.png&quot; width=&quot;300&quot; height=&quot;50&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/Gm6J83Kt/8.png&quot; width=&quot;300&quot; height=&quot;50&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;4. Experiment&lt;/h2&gt;

&lt;h3 id=&quot;research-question&quot;&gt;Research Question&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;RQ1: PAAC가 기존의 모델과 어떻게 다른지?&lt;/li&gt;
  &lt;li&gt;RQ2: PAAC의 서로 다른 구성 요소가 어떻게 역할을 수행하고 있는지?&lt;/li&gt;
  &lt;li&gt;RQ3: PAAC가 어떻게 popularity bias를 완화하는지?&lt;/li&gt;
  &lt;li&gt;RQ4: Hyper-parameter가 PAAC의 추천 성능에 어떻게 영향을 주는지?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experiment-setup&quot;&gt;Experiment setup&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Dataset: Amazon-book, Yelp2018, Gowalla&lt;/li&gt;
  &lt;li&gt;baseline: IPS, $𝛾$-AdjNorm, MACR, InvCF, Adap-$t$, SimGCL&lt;/li&gt;
  &lt;li&gt;Evaluation Metric: Recall@K, HR@K, NDCG@K&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;result&quot;&gt;Result&lt;/h3&gt;

&lt;h3 id=&quot;overall-performancerq1&quot;&gt;Overall Performance(RQ1)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/SKJ9GBZ5/test.png&quot; width=&quot;800&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Table 1] Baseline과 PAAC의 성능 및 향상 정도&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;모든 베이스라인에 대하여 본 논문에서 제시한 PAAC가 popularity bias를 완화하며 성능 향상을 보였다. 특히, LightGCN을 베이스로 사용한 PAAC는 LightGCN의 NDCG@20 성능을 모든 데이터셋에 대해 크게 향상시켰다. 그러나 sparse한 Gowalla같은 데이터에 대해서는 작은 향상만을 보였다.&lt;/p&gt;

&lt;h3 id=&quot;ablation-studyrq2&quot;&gt;Ablation Study(RQ2)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/SjFV0yPJ/ablation.png&quot; width=&quot;670&quot; height=&quot;150&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Table 2] PAAC의 Ablation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;PAAC-w/o P: popular item의 re-weighting contrastive loss가 사라진 경우&lt;/li&gt;
  &lt;li&gt;PAAC-w/o U: unpopular item의 re-weighting contrastive loss가 사라진 경우&lt;/li&gt;
  &lt;li&gt;PAAC-w/o A: popularity-aware supervised alignment loss가 사라진 경우&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;popular item의 re-weighting contrastive loss가 사라진 경우에 가장 큰 성능 하락이 있었으며, alignment loss가 없는 케이스도 SimGCL보다 좋은 성능을 보였는데 이는 popularity에 따라 구분된 contrastive loss가 적용되었기 때문이다.&lt;/p&gt;

&lt;h3 id=&quot;debias-abilityrq3&quot;&gt;Debias Ability(RQ3)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/zvC5YffQ/pop.png&quot; width=&quot;500&quot; height=&quot;200&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Figure 3] Popular/ Unpopular item 각각에서의 추천 성능&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Gowalla와 Yelp2018 데이터셋에 대하여, 상위 20%의 item을 Popular item으로, 나머지를 Unpopular item으로 분류하여 성능을 측정하면 LightGCN 베이스의 PAAC가 Unpopular item에서 성능을 많이 향상시킨다는 것을 확인할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;hyperparameter-sensitivesrq4&quot;&gt;Hyperparameter Sensitives(RQ4)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/FFyY0yb0/dd.png&quot; width=&quot;500&quot; height=&quot;200&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Figure 4] $\lambda_ 1, \lambda_ 2$에 따른 성능 향상 정도&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$\lambda_ 2$이 증가할 때, 처음엔 성능이 향상되지만 어느순간 감소하며 $\lambda_ 1$이 증가할 때 역시 초반엔 성능이 향상되지만 어느순간 감소한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/8PvfsdF8/hyper.png&quot; width=&quot;500&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Figure 5] $\gamma, \beta$에 따른 PAAC의 성능&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Yelp2018에서 $\gamma = 0.8, \beta = 0.6$일 때, Gowalla에서 $\gamma = 0.2, \beta = 0.2$일 때가 최적의 값을 보이는데, 이는 item당 interaction이 상대적으로 많은 Yelp에서는 popular item을 positive sample로 쓰는데서 많은 이득을 보기 때문이다.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h2&gt;

&lt;p&gt;본 논문에서는 popularity bias 해결을 위해 PAAC를 제안하였다. 같은 user를 공유하는 item들은 비슷한 특성을 가졌을 거라는 가정하에서, popularity-aware supervised alignment approach를 고안하고 contrastive learning 기반의 모델에서 representation separation을 방지하기 위하여 popularity level에 따라서 loss의 weight를 조절하였다. 이러한 방법으로 개선된 PAAC는 다양한 데이터셋에서 성능이 개선되는 것으로 증명되었다.
  창의적인 솔루션이 아니더라도, 문제의 존재를 명확히 밝히고 개선의 여지를 보일 수 있는 것 또한 좋은 연구라는 생각이 들었습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Author Information&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Jimin Seo&lt;/li&gt;
      &lt;li&gt;Dept. of ISysE, KAIST&lt;/li&gt;
      &lt;li&gt;Research Topic: Recommender System&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;6. Reference &amp;amp; Additional materials&lt;/h2&gt;
&lt;p&gt;- Miaomiao Cai, Lei Chen, Yifan Wang, Haoyue Bai, Peijie Sun, Le Wu. Popularity-Aware Alignment and Contrast for Mitigating Popularity Bias. &lt;em&gt;KDD(2024)&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;- Github Implementation : https://github.com/miaomiao-cai2/KDD2024-PAAC.&lt;/p&gt;

</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-Popularity-Aware_Alignment_and_Contrast_for_Mitigating_Popularity_Bias.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-Popularity-Aware_Alignment_and_Contrast_for_Mitigating_Popularity_Bias.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[SIGIR 2024] Pacer and Runner Cooperative Learning Framework between Single- and Cross-Domain Sequential Recommendation</title>
            <description>&lt;p&gt;&lt;strong&gt;저자&lt;/strong&gt;: Chung Park, Taesan Kim, Hyungjun Yoon, Junui Hong, Yelim Yu, Mincheol Cho, Minsung Choi, Jaegul Choo&lt;br /&gt;
&lt;strong&gt;출판&lt;/strong&gt;: SIGIR ‘24, July 14–18, 2024, Washington, DC, USA&lt;br /&gt;
&lt;strong&gt;리뷰어&lt;/strong&gt;: 20219003 Sang Wook Park&lt;/p&gt;

&lt;h2 id=&quot;0-preliminaries&quot;&gt;0. Preliminaries&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Cross-Domain Sequential Recommendation (CDSR)&lt;/em&gt;: CDSR은 사용자의 여러 도메인에 걸친 상호작용 시퀀스를 활용하여 다음 아이템을 예측하는 추천 시스템 접근 방식이다. 이는 Single-Domain Sequential Recommendation (SDSR)과 대조되는데, SDSR은 특정 도메인 내의 상호작용만을 고려한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Negative Transfer&lt;/em&gt;: 한 도메인에서 학습한 지식이 다른 도메인의 성능을 저하시키는 현상을 말한다.&lt;/p&gt;

&lt;p&gt;CDSR에서 이는 특히 도메인 간 관계가 약하거나 데이터 희소성 수준이 다를 때 발생할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;1-문제-정의&quot;&gt;1. 문제 정의&lt;/h2&gt;

&lt;p&gt;CDSR은 여러 도메인의 정보를 활용하여 추천 성능을 향상시키는 것을 목표로 한다. 그러나 일부 도메인에서 CDSR이 SDSR보다 성능이 떨어지는 부정적 전이 문제가 발생할 수 있다. 이 논문은 이러한 부정적 전이 문제를 해결하고 모든 도메인에서 일관된 높은 성능을 달성하는 것을 목표로 한다.&lt;/p&gt;

&lt;p&gt;구체적으로, 주어진 시간 t까지의 크로스 도메인 시퀀스 X_1:t를 기반으로 다음 아이템 x^d_t+1을 예측하는 것이 목표이다:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;argmax_{x^d_t+1 ∈ V_d} P(x^d_t+1&lt;/td&gt;
      &lt;td&gt;X_1:t)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;여기서 V_d는 도메인 d의 아이템 집합이다.&lt;/p&gt;

&lt;h2 id=&quot;2-동기&quot;&gt;2. 동기&lt;/h2&gt;

&lt;p&gt;기존 CDSR 모델들은 부정적 전이 문제를 효과적으로 해결하지 못했다. 특히, 일부 도메인에서 CDSR의 성능이 SDSR보다 낮아지는 현상이 관찰되었다. 또한 많은 모델들이 도메인 쌍 간의 관계만을 모델링하여 다수의 도메인을 다루는 데 한계가 있었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/sfkq9jSJ/figure1.png&quot; alt=&quot;Figure 1: Negative Transfer in CDSR&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 1은 Amazon 데이터셋의 Book, Clothing 도메인과 Telco 데이터셋의 Call 도메인에서 CDSR 접근법(다중 도메인으로 학습)이 SDSR 접근법(단일 도메인으로 학습)보다 성능이 낮은 것을 보여준다. 이는 다른 도메인으로부터의 부정적 전이를 나타낸다.&lt;/p&gt;

&lt;p&gt;이 논문은 이러한 한계를 극복하고 모든 도메인에서 일관된 성능 향상을 달성할 수 있는 새로운 CDSR 프레임워크를 제안하고자 한다.&lt;/p&gt;

&lt;h2 id=&quot;3-방법&quot;&gt;3. 방법&lt;/h2&gt;

&lt;p&gt;논문에서 제안하는 SyNCRec 모델은 다음과 같은 주요 구성 요소를 가진다:&lt;/p&gt;

&lt;p&gt;저자는 SyNCRec(Asymmetric Cooperative Network for Cross-Domain Sequential Recommendation)이라는 새로운 CDSR 모델을 제안했다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;각 도메인별 부정적 전이 정도를 추정하고, 이를 예측 손실의 가중치로 적용하여 부정적 전이가 큰 도메인의 그래디언트 흐름을 제어한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;비대칭 협력 네트워크를 통해 다중 도메인 시퀀스로 학습한 모델(CDSR)과 단일 도메인 시퀀스로만 학습한 모델(SDSR)의 성능을 비교하여 각 도메인의 부정적 전이를 평가한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SDSR과 CDSR 태스크 간 유용한 정보 전달을 촉진하기 위해, 도메인별로 두 태스크의 표현 쌍 간 상호 정보를 최대화하는 보조 손실을 개발했다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;31-shared-embedding-layer&quot;&gt;3.1 Shared Embedding Layer&lt;/h3&gt;

&lt;p&gt;모든 도메인의 아이템에 대한 임베딩을 공유한다. 이는 도메인 간 지식 전이를 촉진하고 모델의 일반화 능력을 향상시킨다.&lt;/p&gt;

&lt;h3 id=&quot;32-asymmetric-cooperative-network-with-mixture-of-sequential-experts-acmoe&quot;&gt;3.2 Asymmetric Cooperative Network with Mixture-of-Sequential Experts (ACMoE)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;MoE 아키텍처를 사용하여 SDSR과 CDSR 태스크를 동시에 수행하는 멀티태스크 학습 구조이다.&lt;/li&gt;
  &lt;li&gt;Transformer 기반의 experts 네트워크들로 구성된다.&lt;/li&gt;
  &lt;li&gt;Stop-gradient 연산을 통해 일부 experts는 SDSR에, 다른 experts는 CDSR에 특화되도록 한다.&lt;/li&gt;
  &lt;li&gt;이를 통해 두 태스크의 손실을 독립적으로 계산할 수 있어 부정적 전이를 정확히 평가할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ACMoE의 수학적 formulation은 다음과 같다:&lt;/p&gt;

&lt;p&gt;(Y_d)_{single} = h_d(f_d(E_d))&lt;/p&gt;

&lt;p&gt;f_d(E_d) = \sum_{k=1}^j g_d(E_d)&lt;em&gt;k SG(f^k&lt;/em&gt;{TRM}(E_d)) + \sum_{k=j+1}^K g_d(E_d)&lt;em&gt;k f^k&lt;/em&gt;{TRM}(E_d)&lt;/p&gt;

&lt;p&gt;여기서 h_d는 도메인 d의 tower network, f_d는 sequential expert layer의 mixture, SG는 stop-gradient 연산을 나타낸다.&lt;/p&gt;

&lt;h3 id=&quot;33-loss-correction-with-negative-transfer-gap-lc-ntg&quot;&gt;3.3 Loss Correction with Negative Transfer Gap (LC-NTG)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SDSR과 CDSR 태스크의 손실 차이를 이용해 각 도메인의 부정적 전이 정도(NTG)를 계산한다.&lt;/li&gt;
  &lt;li&gt;계산된 NTG를 CDSR 손실의 가중치로 사용하여 부정적 전이가 큰 도메인의 그래디언트 흐름을 줄인다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;부정적 전이 간격(NTG)은 다음과 같이 정의된다:&lt;/p&gt;

&lt;p&gt;\phi_\pi(d) = \sum_{t=1}^T (l^d_t - l_t)&lt;/p&gt;

&lt;p&gt;여기서 l^d_t와 l_t는 각각 SDSR과 CDSR 태스크의 t 시점에서의 손실을 나타낸다.&lt;/p&gt;

&lt;h3 id=&quot;34-single-cross-mutual-information-maximization-sc-mim&quot;&gt;3.4 Single-Cross Mutual Information Maximization (SC-MIM)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SDSR과 CDSR 태스크에서 얻은 표현 간의 상호 정보를 최대화하는 보조 손실을 도입한다.&lt;/li&gt;
  &lt;li&gt;이를 통해 두 태스크 간 유용한 정보 전달을 촉진한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;L^d_{SC-MIM} = \rho((Y_d)&lt;em&gt;{single}, (Y_d)&lt;/em&gt;{cross}) - \log \sum_{u^-} \exp(\rho((Y_d)&lt;em&gt;{single^-}, (Y_d)&lt;/em&gt;{cross}))&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/mkCd69My/figure2.png&quot; alt=&quot;Figure 2: SyNCRec Architecture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 2는 SyNCRec의 전체 아키텍처를 보여준다. 이 모델은 SDSR과 CDSR 태스크를 동시에 학습하면서 부정적 전이를 최소화하고 도메인 간 지식 전이를 최적화한다.&lt;/p&gt;

&lt;h2 id=&quot;4-실험&quot;&gt;4. 실험&lt;/h2&gt;

&lt;p&gt;실험은 다음 다섯 가지 연구 질문에 답하기 위해 설계되었다:&lt;/p&gt;

&lt;p&gt;RQ1) 세 개 이상의 도메인을 포함하는 실제 응용에서 SyNCRec의 성능이 현재의 최신 기준 모델들을 능가하는가?
RQ2) SyNCRec이 CDSR(Cross-Domain Sequential Recommendation) 작업에서 모든 도메인에 걸친 부정적 전이 문제를 효과적으로 해결할 수 있는가?
RQ3) SyNCRec의 다양한 구성 요소들이 CDSR 작업에서의 성능에 어떤 영향을 미치는가?
RQ4) 하이퍼파라미터 설정의 변화가 SyNCRec의 성능에 어떤 영향을 미치는가?
RQ5) 모델을 온라인에 배포했을 때 어떤 성능을 보이는가?&lt;/p&gt;

&lt;h3 id=&quot;41-데이터셋-및-평가-지표&quot;&gt;4.1 데이터셋 및 평가 지표&lt;/h3&gt;

&lt;p&gt;실험은 Amazon(5개 도메인)과 Telco(5개 도메인) 두 개의 실제 데이터셋에서 수행되었다. 평가 지표로는 HR, NDCG, MRR을 사용했다. 각 데이터셋의 통계는 다음과 같다:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/sgwT8sBq/table1.png&quot; alt=&quot;Table 1: 데이터셋 통계&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;42-베이스라인-모델&quot;&gt;4.2 베이스라인 모델&lt;/h3&gt;

&lt;p&gt;다양한 베이스라인 모델들(BPRMF, GCMC, SASRec, BERT4Rec, CAT-ART, CGRec 등)과 비교 실험을 진행했다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;일반 추천: BPRMF, GCMC&lt;/li&gt;
  &lt;li&gt;단일 도메인 순차적 추천(SDSR): GRU4Rec, SASRec, BERT4Rec 등&lt;/li&gt;
  &lt;li&gt;크로스 도메인 추천(CDR): BiTGCF, DTCDR, CMF 등&lt;/li&gt;
  &lt;li&gt;크로스 도메인 순차적 추천(CDSR): MIFN, 𝜋-net, MAN, C2DSR, CGRec 등&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;43-주요-결과&quot;&gt;4.3 주요 결과&lt;/h3&gt;

&lt;p&gt;SyNCRec의 성능을 다른 베이스라인 모델들과 비교한 결과는 다음과 같다:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/59LnJwYw/table2.png&quot; alt=&quot;Table 2: 모델 성능 비교&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SyNCRec은 모든 도메인에서 가장 높은 HR@5 성능을 보여주었다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SyNCRec은 대부분의 도메인에서 최고의 성능을 달성했다. 예를 들어, Amazon 데이터셋의 Books 도메인에서 HR@5를 3.13% 향상시켰고, Telco 데이터셋의 Call-Use 도메인에서는 11.96% 향상시켰다.&lt;/li&gt;
  &lt;li&gt;특히 기존 모델들이 SDSR보다 성능이 떨어졌던 도메인들에서도 SyNCRec은 일관된 성능 향상을 보였다.&lt;/li&gt;
  &lt;li&gt;모델의 각 구성 요소를 제거한 실험에서 모든 구성 요소가 성능 향상에 기여함을 확인했다.&lt;/li&gt;
  &lt;li&gt;LC-NTG, SC-MIM, ACMoE 각 컴포넌트를 제거한 변형 모델들과의 비교를 통해 각 요소의 중요성을 입증했다.&lt;/li&gt;
  &lt;li&gt;특히 ACMoE를 통한 SDSR/CDSR 태스크 분리가 정확한 부정적 전이 추정에 중요함을 확인했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.postimg.cc/BvRB96JY/figure3.png&quot; alt=&quot;Figure 3: Performance Comparison&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 3은 SyNCRec과 주요 베이스라인 모델들의 성능을 비교한 그래프이다. SyNCRec이 대부분의 도메인에서 우수한 성능을 보이는 것을 확인할 수 있다.
실제 서비스에 SyNCRec을 적용한 결과, 기존 SASRec 기반 모델 대비 17.3%, 규칙 기반 모델 대비 25.6%의 CTR 향상을 달성했다.&lt;/p&gt;

&lt;h2 id=&quot;5-결론&quot;&gt;5. 결론&lt;/h2&gt;

&lt;p&gt;이 논문은 CDSR에서의 부정적 전이 문제를 해결하기 위한 새로운 프레임워크 SyNCRec을 제안했다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;도메인별 부정적 전이를 동적으로 추정하고 이를 손실 함수에 반영한다.&lt;/li&gt;
  &lt;li&gt;SDSR과 CDSR 태스크 간 정보 공유를 위한 보조 손실을 도입한다.&lt;/li&gt;
  &lt;li&gt;실제 데이터셋에서의 성능 검증 및 온라인 A/B 테스트를 통한 실용성을 입증했다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;향후 연구 방향으로는 더 다양한 도메인과 태스크에 대한 확장성 검증, 온라인 학습 시나리오로의 적용 등을 고려해볼 수 있을 것 같다.
SyNCRec은 SDSR과 CDSR 태스크 간의 협력적 학습을 통해 모든 도메인에서 일관된 성능 향상을 달성했다. 실험 결과는 SyNCRec이 기존 방법들의 한계를 극복하고 실제 추천 시스템에서 유용하게 적용될 수 있음을 보여준다.&lt;/p&gt;

&lt;h2 id=&quot;6-critics&quot;&gt;6. Critics&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;모델의 복잡성: SyNCRec은 여러 컴포넌트로 구성된 복잡한 모델로, 해석 가능성과 실제 시스템 적용 시 계산 비용 측면에서 단점이 될 수 있을 것 같다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;민감도: 모델의 성능이 여러 하이퍼파라미터(Sequential Expert Networks 수, 임베딩 차원 등)에 민감할 수 있다. 이에 대한 더 자세한 분석이 필요해 보인다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;확장성: 현재 실험은 5개 도메인으로 제한되어 있는데, 더 많은 도메인으로 확장 시 성능과 계산 효율성이 어떻게 변화하는지 추가 검증이 필요할 것으로 보인다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;장기 종속성: 현재 모델은 Transformer 기반 구조를 사용하고 있어 매우 긴 시퀀스에 대한 처리에 한계가 있을 수 있다. 이를 개선하기 위한 방안도 고려해보면 좋을 것으로 보인다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-참고문헌&quot;&gt;6. 참고문헌&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining (ICDM). IEEE, 197–206.&lt;/li&gt;
  &lt;li&gt;Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management. 1441–1450.&lt;/li&gt;
  &lt;li&gt;Chenglin Li, Yuanzhen Xie, Chenyun Yu, Bo Hu, Zang Li, Guoqiang Shu, Xiaohu Qie, and Di Niu. 2023. One for All, All for One: Learning and Transferring User Embeddings for Cross-Domain Recommendation. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining. 366–374.&lt;/li&gt;
&lt;/ol&gt;
</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-Pacer_and_Runner_Cooperative_Learning_Framework_between_Single-_and_Cross-Domain_Sequential_Recommendation.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-Pacer_and_Runner_Cooperative_Learning_Framework_between_Single-_and_Cross-Domain_Sequential_Recommendation.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[WWW-2024] On the Feasibility of Simple Transformer for Dynamic Graph Modeling</title>
            <description>&lt;p&gt;===&lt;/p&gt;
&lt;h1 id=&quot;세줄-요약&quot;&gt;세줄 요약&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;기존 Message passing GNNs(GAT, GCN)들은 모델 구조가 복잡해질수록 Over-smoothing, Over-squashing의 문제가 존재한다.&lt;/li&gt;
  &lt;li&gt;최근 Transformer 기반 모델들이 &lt;strong&gt;Static graph (t = T)&lt;/strong&gt; 에 대해서 이 문제들을 잘 해결하고, 좋은 성능을 나타내고 있다.&lt;/li&gt;
  &lt;li&gt;본 논문은 Static graph에 적용되는 Transformer 기반 모델을 발전시켜 &lt;strong&gt;Dynamic graph (t = 1 ~ T)&lt;/strong&gt; 에 적용하였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;h2 id=&quot;기존-message-passing-gnn의-단점&quot;&gt;기존 Message Passing GNN의 단점&lt;/h2&gt;
&lt;p&gt;GNN의 장점은 특정 node에 대해 이웃 node들이 미치는 네트워크 효과를 잘 포착한다는 점이다. 이를 위해 Graph Convolution Network(GCN), Graph Attention Network(GAT)와 같은 모델을 통해 주변 node에서 정보를 추출하는 방법론이 제시되었고, 최근까지 좋은 성능을 보여주었다. 하지만 해당 방법들은 주변 Node에서 정보를 추출하는 과정에서 GNN의 Layer가 증가하여 각 Node의 Embedding이 동일해지는 현상(&lt;strong&gt;Over-Smoothing&lt;/strong&gt;)과 먼 Node에서 정보를 가져오는 과정에서 해당 정보가 손실되는 현상(&lt;strong&gt;Over-Squashing&lt;/strong&gt;)의 단점이 관찰되었다.&lt;/p&gt;

&lt;h2 id=&quot;temporality-with-transformer&quot;&gt;Temporality with Transformer&lt;/h2&gt;
&lt;p&gt;기존 GNN 방법론들에서 Dynamic Graph의 temporality를 다루는 방법에는 크게 두 가지가 있다. &lt;strong&gt;Discrete time step GNN&lt;/strong&gt;은 시간/일/월 등 특정한 시간 단위로 Snapshot을 찍은 후(ex: 1월 snapshot, 2월 snapshot, …) 그에 맞게 Graph를 나누어 다루는 방법이고, &lt;strong&gt;Continuous time step GNN&lt;/strong&gt;은 말 그대로 연속적인 Graph의 변화를 보는 방법이다. 
Discrete의 경우에는 Graph가 특정 시간대로 나뉘어 데이터를 다루기가 쉽다는 장점이 있지만, 해당 시간대 이하에서 나타나는 fine-grained temporality를 포착하기 어렵다는 단점이 있다. Continuous는 세부적인 temporality를 잃지 않는 장점이 있지만, 모델이 더 복잡해지고 Gradient vanishing 문제가 발생하여 Graph의 Long-term dependency를 잘 포착하지 못한다고 알려져있다. 
&lt;strong&gt;Transformer&lt;/strong&gt;를 사용하면 1. continous의 장점인 fine-grained temporality를 놓치지 않을 수 있고, 2. self-attention을 통해 long-term dependency의 성능이 향상된다. 3. Message passing GNNs의 단점인 Over-smoothing과 Over-squashing의 문제도 덜하다는 장점이 있다.&lt;/p&gt;

&lt;h1 id=&quot;related-works&quot;&gt;Related Works&lt;/h1&gt;
&lt;h2 id=&quot;dynamic-graph-learning&quot;&gt;Dynamic Graph Learning&lt;/h2&gt;
&lt;p&gt;Dynamic graph를 다루기 위해 제시된 주요 방법론은 다음과 같다.
|방법론|Graph Structure|Temporal Structure|
|——|—|—|
|DySAT(WSDM 2020)|GAT|Self-attention|
|EvolveGCN(AAAI 2020)|GCN|RNN|
|TGAT(ICLR 2020)|Temporal graph attention|Temporal graph attention|
|TGN(ICML 2020)|Temporal graph attention|Temporal graph attention|
|GraphMixer(ICLR 2022)|Temporal graph attention(MLP mixer)|Temporal graph attention(MLP Mixer)|&lt;/p&gt;

&lt;h2 id=&quot;transfomer-기반-gnns&quot;&gt;Transfomer 기반 GNNs&lt;/h2&gt;
&lt;p&gt;최근에는 Transformer 구조를 사용해 Graph 구조를 파악하게 하는 연구들이 활발하게 진행되었는데, 대표적으로는 NeurIPS 2022에 발표된 &lt;strong&gt;Pure Transformers are Powerful Graph Learners&lt;/strong&gt;가 있다. 이 논문에서는, vanila Transformer 구조에 Node, Edge와 같은 그래프 구성물들을 Node, Edge라고 표시해주는 Type identifier들만 추가하여 input으로 넣었을 때, 기존 Message Passing GNN에 기반한 SOTA 모델보다 좋은 성능을 냈다고 보고하고 있다.
&lt;img src=&quot;image.png&quot; alt=&quot;test&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;proposed-approach&quot;&gt;Proposed Approach&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;image-1.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;temporal-ego-graph&quot;&gt;Temporal Ego-graph&lt;/h2&gt;
&lt;p&gt;Dynamic graph의 특성상 Static graph를 다뤘던 이전 논문처럼 바로 Transformer에 Graph를 input으로 넣을 수 없기에, Temporal Ego-graph라는 subgraph을 Node마다 생성한다. Temporal Ego-graph는 Node  &lt;strong&gt;$v$&lt;/strong&gt; 가 다른 Node들과 상호작용한 기록이 담겨있는 Graph로, 수식으로 표시하면 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;image-2.png&quot; alt=&quot;alt text&quot; /&gt;
$v^k_i$는 Node $v$가 Node $k$와 timestep $\tau$에 상호작용한 정보를 담고 있다($v_i, v_k, \tau$). training data $x_i$는 Node $i$에 대해 sequence length $w$만큼의 길이를 가지는 Temporal Ego-graph로, training data임을 Transformer model에 알려주기 위해 앞뒤로 &amp;lt;|hist|&amp;gt;와 &amp;lt;|endofhist|&amp;gt; token으로 감싸주었다. $y_i$는 Node i의 label data로, 상세 사항은 $x_i$와 같다.&lt;/p&gt;
&lt;h2 id=&quot;temporal-alignment&quot;&gt;Temporal Alignment&lt;/h2&gt;
&lt;p&gt;Transformer model이 자연적으로 sequence의 상대적 위치에 따라 temporality를 학습하기는 하지만, 서로 다른 Node 간에는 다른 time step을 따르는 맹점이 아직 남아있다. 다음과 같은 예시를 보자&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Node $u$는 24년 1월에 Graph에 추가되어 sequence가 $w_u$ = &amp;lt;$v_u^{24년 1월}$,$v_u^{24년 2월}$, …, $v_u^{24년 10월}$&amp;gt;이고,&lt;/li&gt;
  &lt;li&gt;Node $k$는 23년 7월에 Graph에 추가되어 sequence가 $w_k$ = &amp;lt;$v_k^{23년 7월}$,$v_k^{23년 8월}$, …, $v_k^{24년 10월}$&amp;gt;이라면 
Transformer model은 해당 sequence들만으로는 $v_u^{24년 1월}$와 $v_k^{23년 7월}$가 같은 time step에 일어났는지 판단할 수 없다.
이에 저자들은 특정 time step마다 다른 Temporal token을 삽입하여, Node전체에 적용되는 universal timeline을 부여하고자 하였다.
    &lt;h2 id=&quot;training-objectives&quot;&gt;Training objectives&lt;/h2&gt;
    &lt;p&gt;생성한 Temporal Ego-graph에 Temporal Alignment과정을 통해 Temporal token을 추가한 sequence를 $R = &amp;lt;r_1, r_2, …, r_{|R|}&amp;gt;$이라고 하자($|R|$은 Sequence R의 길이). 해당 sequence의 joint probability는 아래와 같이 표현할 수 있다.
&lt;img src=&quot;image-3.png&quot; alt=&quot;alt text&quot; /&gt;
$p(r_i|R_{&amp;lt;i})$는 $R_{&amp;lt;i}$까지의 token이 주어졌을 때 step i에서의 token의 probability distribution이고, 아래와 같이 놓고 train할 수 있다.(LN은 Layer normalization)
&lt;img src=&quot;image-4.png&quot; alt=&quot;alt text&quot; /&gt;
결과적으로 이를 Negative log-likelihood 방식으로 바꾸면 아래와 같이 loss를 정의할 수 있다.
&lt;img src=&quot;image-5.png&quot; alt=&quot;alt text&quot; /&gt;
최종적인 학습 Process는 아래와 같다.
&lt;img src=&quot;image-6.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;
    &lt;h1 id=&quot;experiments&quot;&gt;Experiments&lt;/h1&gt;
    &lt;h2 id=&quot;datasets&quot;&gt;Datasets&lt;/h2&gt;
  &lt;/li&gt;
  &lt;li&gt;UCI: SNS 상에서 user들간의 message 교환 기록이 있는 dataset&lt;/li&gt;
  &lt;li&gt;ML-10M: MovieLens dataset 중 하나로, user들이 각 영화들에 대해 어떤 tag를 부여했는지가 나와있는 dataset&lt;/li&gt;
  &lt;li&gt;Hepth: 고에너지 물리학 논문들의 citation network&lt;/li&gt;
  &lt;li&gt;MMConv: Multi-turn task oriented dialogue dataset
    &lt;h2 id=&quot;evaluation-metrics&quot;&gt;Evaluation Metrics&lt;/h2&gt;
  &lt;/li&gt;
  &lt;li&gt;NDCG@5: 추천시스템/검색 엔진 평가에 자주 쓰이는 Metric으로, Top 5개의 추천 항목을 기준으로 함&lt;/li&gt;
  &lt;li&gt;Jaccard Similarity: 추천 set과 정답 set의 유사도를 측정하는 지표
    &lt;h1 id=&quot;results&quot;&gt;Results&lt;/h1&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;image-7.png&quot; alt=&quot;alt text&quot; /&gt;
결과는 위의 그림과 같다. 4개 dataset 모두에서 NDCG@5와 Jaccard 모두 해당 논문의 방법론인 &lt;strong&gt;SimpleDyG&lt;/strong&gt;가 최고 성능을 보였다.&lt;/p&gt;

&lt;h2 id=&quot;effect-of-extra-tokens&quot;&gt;Effect of Extra Tokens&lt;/h2&gt;
&lt;h3 id=&quot;impact-of-special-tokens&quot;&gt;Impact of Special Tokens&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;image-8.png&quot; alt=&quot;alt text&quot; /&gt;
Special tokens(“&amp;lt;|hist|&amp;gt;”, “&amp;lt;|endofhist|&amp;gt;”, “&amp;lt;|pred|&amp;gt;”, “&amp;lt;|endofpred|&amp;gt;”)와 같은 special token의 효과를 알아보기 위해 두 가지 Ablation 실험을 진행하였다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SimpleDyG: 원 모델, 각기 다른 special token 사용(ex: hist, endofhist, pred, endofpred)&lt;/li&gt;
  &lt;li&gt;same special: 같은 special token 사용(ex: x, x, x, x)&lt;/li&gt;
  &lt;li&gt;no special: special token 미사용
결과적으로는 dataset에 따라 SimpleDyG와 same special이 엎치락뒤치락하는 모습을 보여주었다.
    &lt;h3 id=&quot;impact-of-temporal-tokens&quot;&gt;Impact of Temporal Tokens&lt;/h3&gt;
    &lt;p&gt;&lt;img src=&quot;image-9.png&quot; alt=&quot;alt text&quot; /&gt;
Temporal tokens의 효과를 알아보기 위해 역시 두 가지 Ablation 실험을 진행하였다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;SimpleDyG: 원 모델, 각기 다른 temporal token 사용(ex: 24년 1월, 24년 2월, …)&lt;/li&gt;
  &lt;li&gt;same time: 같은 temporal token 사용(ex: x, x, …)&lt;/li&gt;
  &lt;li&gt;no time: temporal token 미사용
결과를 보면, 의외로 same time이나 no time의 결과가 좋은데, 이는 transformer 모델에게 temporality를 자연스럽게 배우게 하는 것이 인위적인 temporal token을 부여하는 것보다 때때로 더 나을 수 있다고 해석할 수 있다.
    &lt;h2 id=&quot;performance-of-multi-step-prediction&quot;&gt;Performance of Multi-step Prediction&lt;/h2&gt;
    &lt;p&gt;&lt;img src=&quot;image-10.png&quot; alt=&quot;alt text&quot; /&gt;
t시점에서 단순히 다음 time step인 t+1만 예측하는 것이 아닌, 그 이후를 예측하는 성능을 검증하기 위해 다른 baseline 모델과 비교 실험을 해본 결과이다. 당연하지만 t+3으로 갈수록 모델의 성능이 낮아지지만, SimpleDyG가 다른 baseline model인 TGAT과 GraphMixer보다 꾸준히 성능이 낫다는 것을 보여준다.&lt;/p&gt;
    &lt;h2 id=&quot;hyper-parameter-analysis&quot;&gt;Hyper-parameter Analysis&lt;/h2&gt;
    &lt;p&gt;&lt;img src=&quot;image-11.png&quot; alt=&quot;alt text&quot; /&gt;
Hyper-parameter에 따른 성능 변화도 꽤나 robust한 결과를 보여주어, 특정한 setting에서만 성능이 좋은 것이 아니라는 것을 입증한다.&lt;/p&gt;
    &lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
    &lt;p&gt;본 논문은 그래프 분석에 Transformer를 도입하려는 최근의 연구흐름 속에서, Dynamic graph에의 적용을 다룬 논문이다. Dynamic graph의 특징인 Temporality를 도입하기 위해 저자들은 새로운 방법인 Temporal ego-graph과 Temporal alignment를 도입하였고, 4가지 dataset에서 기존 baseline model들보다 성능이 좋다는 것을 여러 실험으로 밝혔다. 저자들이 제안한 방법론은 vanila Transformer 구조를 사용해 구현이 쉽다는 장점이 있고, 추가적인 Transformer 구조의 수정 없이도 SOTA 성능을 보이는 것을 보여주어 Dynamic graph에서의 Transformer 적용가능성을 열었다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-On_the_Feasibility_of_Simple_Transformer_for_Dynamic_Graph_Modeling.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-On_the_Feasibility_of_Simple_Transformer_for_Dynamic_Graph_Modeling.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICLR-22] On Evaluation Metrics For Graph Generative Models</title>
            <description>&lt;p&gt;Title : On Evaluation Metrics For Graph Generative Models
Aurthor : R. Thompson et al.
Venue : ICLR 2022&lt;/p&gt;

&lt;h3 id=&quot;1-graph-generation-task는-무엇인가&quot;&gt;1. Graph Generation Task는 무엇인가?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Graph(그래프)&lt;/strong&gt;는 &lt;strong&gt;노드(Node)&lt;/strong&gt;와 &lt;strong&gt;엣지(Edge)&lt;/strong&gt;로 이루어진 데이터 구조를 의미한다. 그래프는 현실 세계의 다양한 관계와 상호작용을 표현하는데 사용된다. 예컨대, 사람들 간의 소셜 네트워크나 인터넷의 링크 구조, 분자 내의 원자 간 결합, 도로망에서의 교차로와 길 등이 있다. 즉, node는 개체를 나타내고, edge는 그들 간의 관계를 나타낸다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;image-1.png&quot; alt=&quot;그래프 데이터의 예시&quot; /&gt;&lt;/p&gt;

&lt;p&gt;최근 노벨화학상을 수상한 단백질 구조 예측 관련 연구에서도 아미노산의 결합 구조를 모델링하는데 그래프 구조가 쓰이는 등 다양한 분야의 데이터를 나타낼 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;graph-generation그래프-생성란-무엇인가&quot;&gt;Graph Generation(그래프 생성)란 무엇인가?&lt;/h3&gt;

&lt;p&gt;그래프 생성 작업은 주어진 데이터셋이나 규칙에 기반하여 새로운 그래프 구조를 생성하는 것을 의미한다. 생성된 그래프는 특정한 목표를 염두에 두고 있다. 예를 들어 소셜 네트워크의 확장, 화합물의 분자 구조 예측, 도로망 시뮬레이션 등을 통해 실세계의 문제를 해결하거나 예측할 수 있다.&lt;/p&gt;

&lt;p&gt;이러한 그래프 생성의 핵심 목표는 새로운 그래프가 기존 그래프의 특성을 얼마나 잘 모방할 수 있는가에 있다. 즉, 새로운 그래프는 실제 데이터에 기반한 현실적인 특성과 구조를 가져야 한다. 저자들은 다음과 같은 관점에서 생성된 그래프를 평가할 것을 주장한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;패턴 학습 및 예측&lt;/strong&gt;: 생성된 그래프가 실제 데이터에서 나타나는 패턴을 잘 반영하면, 미래의 데이터나 네트워크 구조를 예측하는 데 사용할 수 있다. 예를 들어, 소셜 네트워크에서 사람들 간의 관계를 시뮬레이션하거나, 과학적 발견을 위해 새로운 분자의 구조를 예측할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;모델링 및 시뮬레이션&lt;/strong&gt;: 실제 네트워크를 모방한 그래프를 생성하여 다양한 상황을 시뮬레이션할 수 있다. 예를 들어, 교통 네트워크에서 차량 흐름을 최적화하거나 인터넷 네트워크의 보안 취약점을 발견하기 위해 시뮬레이션할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;연구 및 실험&lt;/strong&gt;: 현실에서 수집한 데이터가 제한적이거나 비용이 많이 들 경우, 그래프 생성을 통해 연구와 실험을 더 효율적으로 수행할 수 있다. 생성된 그래프는 추가적인 실험 데이터를 제공하며, 이를 통해 다양한 연구 결과를 도출할 수 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;graph-generation의-중요성&quot;&gt;Graph Generation의 중요성&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;그래프 생성 모델(GGMs)&lt;/strong&gt;은 다양한 연구 및 산업 분야에서 중요한 역할을 한다. 실제 네트워크나 시스템의 동작을 시뮬레이션하거나 예측할 수 있으며, 새로운 발견이나 효율적인 시스템 설계를 가능하게 한다. 그래프 생성의 중요성은 여러 가지 이유에서 강조된다. 첫째, 데이터 부족 문제를 해결할 수 있다. 많은 경우, 충분한 실제 데이터를 확보하기 어려운 상황에서 그래프 생성은 부족한 데이터를 보완할 수 있는 강력한 도구로 사용된다. 예를 들어, 약물 개발에서 새로운 분자의 구조를 예측하는 데 필요한 데이터가 부족할 때, 그래프 생성 모델은 그 갭을 메울 수 있다. 둘째, 그래프 생성은 현재까지의 데이터에 기반하여 미래의 패턴이나 구조를 예측하는 데 필수적이다. 예를 들어, 소셜 네트워크에서 사용자가 새로운 연결을 형성할 가능성을 예측하거나, 인터넷 트래픽이 향후 어떻게 변화할지 시뮬레이션할 수 있다. 셋째, 그래프 생성은 다양한 분야에서 널리 활용될 수 있는 여지가 크다. 화학, 생물학, 물리학 등 과학 분야 뿐 아니라 경제학, 사회학 등 사회과학 분야 까지 많은 학문 분야에서 그래프는 중요한 데이터 구조이며, Graph generation은 다양한 분야의 연구에서 폭넓게 활용될 수 있다는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;graph-generation-task의-주요-도전-과제&quot;&gt;Graph Generation Task의 주요 도전 과제&lt;/h3&gt;

&lt;p&gt;그래프 생성은 다양한 응용 가능성에도 불구하고 몇 가지 도전 과제를 가지고 있다. 생성된 그래프가 얼마나 현실적인지를 평가하고, 그 품질을 측정하는 것은 매우 중요한 일인데, 저자들이 제시한 기준은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;그래프의 복잡성&lt;/strong&gt;: 그래프는 매우 복잡한 구조를 가지며, node 간의 다양한 상호작용을 모두 반영해야 한다. 이 때문에 생성된 그래프가 원본 그래프와 동일한 특성을 유지하도록 만드는 것은 매우 어려운 과제이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;diversity 유지&lt;/strong&gt;: 생성된 그래프는 다양한 형태와 구조를 가져야 하며, 단순히 기존 데이터를 복제하는 것이 아닌, 새로운 패턴을 반영할 수 있어야 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;평가 메트릭&lt;/strong&gt;: 그래프 생성의 결과물을 평가하기 위한 메트릭이 부족하거나 부정확할 수 있다. 그래프의 구조적 특성을 평가하면서도, 그 그래프가 얼마나 사실적이고 유용한지를 측정하는 새로운 메트릭이 필요하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 논문은 이러한 과제 중 특히 그래프 생성 결과를 평가하는 방법에 집중하고 있다. 기존의 평가 메트릭이 가지는 한계를 분석하고, 이를 해결하기 위한 새로운 메트릭을 제안함으로써, 보다 정확하고 효율적인 그래프 생성을 가능하도록 하고자 한다.&lt;/p&gt;

&lt;h3 id=&quot;2-기존-graph-generation-평가-지표의-한계&quot;&gt;2. 기존 Graph Generation 평가 지표의 한계&lt;/h3&gt;

&lt;p&gt;”””&lt;/p&gt;
&lt;h2 id=&quot;2-배경-및-관련-연구&quot;&gt;2. 배경 및 관련 연구&lt;/h2&gt;

&lt;p&gt;생성 모델을 평가하는 것은 어떤 도메인에서도 매우 어려운 작업이다 (Theis et al., 2016). 기존의 생성 모델 연구에서는 주로 두 가지 평가 지표에 의존해왔다:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;샘플 기반 지표&lt;/strong&gt; (Heusel et al., 2017)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;우도 기반 지표&lt;/strong&gt; (Theis et al., 2016)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러나 auto regressive GGM의 log likelihood를 비교하는 것은 모든 가능한 node 순서를 marginalize 해야 하므로 계산이 불가능하다 (Chen et al., 2021). 최근 연구에서는 최적의 순서를 학습하고 이를 추정하려고 하지만 (Chen et al., 2021), likelihood가 생성된 그래프의 품질을 나타내지 않을 수 있다는 사실을 고려한다는 점을 반영했다(Theis et al., 2016).&lt;/p&gt;

&lt;h3 id=&quot;샘플-기반-평가-지표&quot;&gt;샘플 기반 평가 지표&lt;/h3&gt;

&lt;p&gt;샘플 기반 평가 지표는 실제 분포 $P_r$과 생성된 분포 $P_g$ 사이의 거리 $\rho$를 랜덤 샘플을 통해 추정한다 (Heusel et al., 2017; You et al., 2018; Bińkowski et al., 2018). 이는 다음과 같이 계산된다고 한다:&lt;/p&gt;

\[\hat{\rho}\left(\mathbb{S}_g, \mathbb{S}_r\right) \approx \rho\left(P_g, P_r\right)\]

&lt;p&gt;여기서,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\mathbb{S}_r = {\mathbf{x}_1^r, \ldots, \mathbf{x}_m^r} \sim P_r$&lt;/li&gt;
  &lt;li&gt;$\mathbb{S}_g = {\mathbf{x}_1^g, \ldots, \mathbf{x}_n^g} \sim P_g$&lt;/li&gt;
  &lt;li&gt;$\mathbf{x}_i$는 그래프 $G_i$로부터 추출된 어떤 feature 벡터&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;본 연구에서는 모델에 종속적이지 않고 모든 GGM에 적용 가능한 샘플 기반 지표를 사용한다.&lt;/p&gt;

&lt;h2 id=&quot;21-기존의-평가-지표&quot;&gt;2.1 기존의 평가 지표&lt;/h2&gt;

&lt;p&gt;그래프 통계에 기반한 지표는 GGM 평가에서 표준으로 사용된다 (You et al., 2018; Liao et al., 2019; Dai et al., 2020). 이러한 지표는 $\mathbf{x}_i$를 클러스터링 계수, node 차수, 또는 4-node 오빗 카운트 히스토그램으로 설정하고, 생성된 집합 $\mathbb{S}_g$와 참조 집합 $\mathbb{S}_r$ 사이의 경험적 MMD를 계산한다 (Gretton et al., 2006):&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;167419716-bd7da8f8-0830-4c35-b2e3-2fc21bff657a.png&quot; alt=&quot;alt text&quot; /&gt;
  &lt;figcaption&gt;MMD는 분포 사이의 거리를 각 분포의 평균 사이의 L2로 하는 metric이다&lt;/figcaption&gt;
&lt;/figure&gt;

\[\operatorname{MMD}\left(\mathbb{S}_g, \mathbb{S}_r\right) = \frac{1}{m^2} \sum_{i,j=1}^{m} k\left(\mathbf{x}_i^r, \mathbf{x}_j^r\right) + \frac{1}{n^2} \sum_{i,j=1}^{n} k\left(\mathbf{x}_i^g, \mathbf{x}_j^g\right) - \frac{2}{nm} \sum_{i=1}^{n} \sum_{j=1}^{m} k\left(\mathbf{x}_i^g, \mathbf{x}_j^r\right)\]

&lt;p&gt;여기서 $k(\cdot, \cdot)$는 일반적인 커널 함수이다. You et al. (2018)은 RBF 커널의 한 형태를 제안하였다:&lt;/p&gt;

\[k\left(\mathbf{x}_i, \mathbf{x}_j\right) = \exp\left(-d\left(\mathbf{x}_i, \mathbf{x}_j\right) / 2\sigma^2\right)\]

&lt;ul&gt;
  &lt;li&gt;$d(\cdot, \cdot)$는 쌍별 거리를 계산하며, 그 연구에서는 Wasserstein Distance (=EMD)를 선택하였다.&lt;/li&gt;
  &lt;li&gt;이는 각 그래프 통계에 대해 세 가지 지표를 생성한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;계산 비용을 줄이기 위해 $d(\cdot, \cdot)$로 총 변동 거리를 사용하여 (1)식을 계산할 수 있지만 (Liao et al., 2019), 이는 indefinite 커널 또는 undefined behavior, 즉 불안정한 연산을 초래한다 (O’Bray et al., 2022). 따라서 본 연구에서는 EMD를 사용하여 이러한 지표를 계산한다 (You et al., 2018).&lt;/p&gt;

&lt;p&gt;추가로, 여러 연구 (Goyal et al., 2020; Podda &amp;amp; Bacciu, 2021; Kawai et al., 2019)에서는 $k(\cdot, \cdot)$를 NSPDK 그래프 커널로 대체하여 GGM을 평가하였다. 이 지표는 이산적인 edge와 node feature과 그래프 구조를 평가에 통합할 수 있다는 이점이 있다.&lt;/p&gt;

&lt;p&gt;Moreno et al. (2018)은 You et al. (2018)이 제안한 것과 유사하게 node 차수, 클러스터링 계수, 지오데식 거리와 같은 그래프 구조 특성을 추출하였다. 그러나 이러한 특성들은 Kolmogorov-Smirnov (KS) 다차원 거리 (Justel et al., 1997)를 통해 스칼라 지표로 결합된다. 본 연구에서는 KS를 edge와 node feature을 통합할 수 없기 때문에 실험에서 제외하였다.&lt;/p&gt;

&lt;p&gt;마지막으로, “유효한 그래프의 비율”과 같은 도메인 특화 지표도 존재한다. 우리의 목표는 이러한 지표를 통합하거나 제거하거나 평가하는 것이 아니다; 그것들은 생성된 그래프의 특성이며, 위에서 설명한 지표들과 달리 참조 분포와의 비교를 제공하지 않는다. 이러한 지표들은 GGM 평가에서 여전히 유용한 정보를 제공할 수 있다고 믿는다.&lt;/p&gt;

&lt;h2 id=&quot;22-그래프-신경망-gnn&quot;&gt;2.2 그래프 신경망 (GNN)&lt;/h2&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;그래프를 $\mathcal{G} = (\mathbb{V}, E)$로 정의하며, 여기서 $\mathbb{V}$는 node들의 집합, $E = {(i, j) \mid i, j \in {1, \ldots,&lt;/td&gt;
      &lt;td&gt;\mathbb{V}&lt;/td&gt;
      &lt;td&gt;}}$는 edge들의 집합이다. GNN은 임의의 그래프 $G_i$로부터 고정 크기의 표현 $\mathbf{x}_i$를 추출할 수 있다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;많은 GNN 구조가 존재하지만 (Wu et al., 2020), 본 연구에서는 일반적인 GNN으로 Graph Isomorphism Networks (GINs)를 고려한다 (Xu et al., 2019). GIN은 $L$개의 전파 레이어와 그래프 Readout 레이어로 구성되어 $\mathbf{x}_i$를 얻는다.&lt;/p&gt;

&lt;p&gt;node $v \in \mathbb{V}$에 대해, 레이어 $l \in [1, L]$에서의 node 임베딩 $\mathbf{h}_v^{(l)}$는 다음과 같이 계산된다:&lt;/p&gt;

\[\mathbf{h}_v^{(l)} = \operatorname{MLP}^{(l)}\left( \mathbf{h}_v^{(l-1)} + f^{(l)}\left( \left\{ \mathbf{h}_u^{(l-1)} : u \in \mathcal{N}(v) \right\} \right) \right)\]

&lt;ul&gt;
  &lt;li&gt;$\mathbf{h}_v^{(0)}$는 node $v$의 입력 feature이다.&lt;/li&gt;
  &lt;li&gt;$\mathbf{h}_v^{(l)} \in \mathbb{R}^d$는 $l$번째 레이어 이후의 node $v$의 $d$차원 임베딩이다.&lt;/li&gt;
  &lt;li&gt;$\mathcal{N}(v)$는 node $v$의 이웃이다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\operatorname{MLP}^{(l)}$는 완전 연결 신경망이다.중ㅇ&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;$f^{(l)}$는 node들에 대한 합산, 평균 또는 최대값과 같은 aggregate 함수이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그래프 Readout 레이어는 각 레이어 $l \in [1, L]$에서 모든 node의 feature을 aggregate하고, 이를 단일한 $L \cdot d$차원 벡터 $\mathbf{x}_i$로 연결한다 (Xu et al., 2019):&lt;/p&gt;

\[\mathbf{x}_i = \operatorname{CONCAT}\left( \operatorname{READOUT}\left( \left\{ \mathbf{h}_v^{(l)} \mid v \in \mathbb{V} \right\} \right) \mid l = 1, 2, \ldots, L \right)\]

&lt;ul&gt;
  &lt;li&gt;여기서 $\operatorname{READOUT}$은 $f^{(l)}$와 유사하며, 보통 합산, 평균 또는 최대값 연산을 선택한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-랜덤-gnn의-효과성&quot;&gt;3 랜덤 GNN의 효과성&lt;/h2&gt;

&lt;p&gt;이미지 생성 샘플의 평가에서는 Inception v3(Szegedy et al., 2016)가 널리 사용되지만, 그래프 기반 연구에서는 이러한 평가모델이 존재하지 않는다는 점이 지적된다. 이는 그래프 생성 모델(GGMs)의 표준화된 분석을 어렵게 만든다는 것이다. 이를 해결하기 위해 단일 GNN을 여러 데이터셋에 사전 학습하여 새로운 데이터셋에서도 의미 있는 임베딩을 추출하는 방법이 제안되었다(Hu et al., 2020). 그러나 그래프 데이터셋 간에 node와 edge feature의 차원이 호환되지 않는 경우가 많고, 사전 학습과 목표 작업 간의 그래프 분포 차이가 커서 사전 학습된 네트워크의 성능이 저하될 수 있다.&lt;/p&gt;

&lt;p&gt;반면에, 랜덤 GNN은 사전 학습 없이도 의미 있는 feature을 추출하고 많은 그래프 작업을 수행할 수 있다(Kipf &amp;amp; Welling, 2017; Morris et al., 2019; Xu et al., 2019). 따라서 사전 학습을 피하고 랜덤 GNN을 활용하는 것을 본 연구에서는 제안한다.&lt;/p&gt;

&lt;p&gt;이 접근법을 예비적으로 테스트하기 위해, 본 연구에서는 Grid 그래프에서 에지를 확률 $p$로 무작위 재연결하여 permutation을 적용했다. $p$가 증가할수록 원래 그래프와 변형된 그래프 사이의 차이가 증가한다. 만약 GNN이 그래프에서 강력한 표현을 추출할 수 있다면, 그래프 임베딩 간의 차이도 $p$에 따라 증가해야 한다. 사전 학습된 GIN(Xu et al., 2019)과 랜덤 GIN에서 추출한 임베딩을 시각화한 결과, 두 모델 모두 실험 전반에 걸쳐 매우 유사한 표현을 추출하는 것을 발견했다. 이는 랜덤 및 사전 학습된 GIN 모두 GGMs를 평가하는 데 유용할 수 있음을 시사한다. 본 연구에서는 그래프 동형성을 탐지하는 이론적인 능력(Xu et al., 2019) 때문에 모든 실험에서 GIN을 사용했으며, 다른 일반적인 GNN과의 비교는 부록 C.6에 제공되었다.&lt;/p&gt;

&lt;h2 id=&quot;4-실험&quot;&gt;4 실험&lt;/h2&gt;

&lt;p&gt;저자들은 실험 절에서 GGM 평가 지표의 주요 속성을 설명하고, 각 지표를 이러한 속성에 대해 철저히 테스트했다. 이러한 속성에는 생성된 그래프의 &lt;strong&gt;fidelity&lt;/strong&gt;와 &lt;strong&gt;diversity&lt;/strong&gt;에 대한 지표의 상관성, 샘플 효율성(sample efficiency), 그리고 &lt;strong&gt;계산 효율성(computational efficiency)&lt;/strong&gt;이 포함된다. 이러한 속성들은 강력한 평가 지표의 원하는 특성을 포착하고 GGMs의 신뢰할 수 있는 순위를 가능하게 한다고 판단된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;image-3.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;데이터셋: 그래프 도메인 전반에 걸쳐 GGMs를 평가하는 능력을 테스트하기 위해 여섯 가지 다양한 그래프 데이터셋을 사용했다(표 1). 특히 Lobster, Grid, Proteins, Community, Ego와 같은 일반적인 GGM 데이터셋을 포함하였다(You et al., 2018; Liao et al., 2019; Dai et al., 2020). 또한, 각 지표가 node 및 edge feature 분포의 변화를 감지하는 능력을 보여주기 위해 분자 데이터셋 ZINC(Irwin et al., 2012)를 활용하였다.&lt;/p&gt;

&lt;p&gt;GNN feature 추출기: GGM 문헌에서는 작은 데이터셋을 자주 사용하므로, 각 지표의 샘플 효율성이 매우 중요하다. 그래프 임베딩 $\mathbf{x}$의 차원은 여러 지표에서 핵심 요소이므로, 구별 가능성을 유지하면서 $\mathbf{x}$의 길이를 최소화하는 것이 바람직하다. 식 (4)에서 볼 수 있듯이, 전파 라운드 수 $L$과 node 임베딩 크기 $d$는 $\mathbf{x}$의 차원을 직접 결정한다. You et al.(2020)은 $L$의 선택이 다양한 그래프 작업에서 성능에 가장 중요한 요소 중 하나임을 보여주었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;image-4.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;실험에서는 $L \in [2, 3, \ldots, 7]$, $d \in [5, 10, \ldots, 40]$인 GIN 모델(식 3과 4)을 고려했다. 이 범위 내에서 20개의 아키텍처를 무작위로 선택하여 랜덤 초기화된 GIN과 사전 학습된 GIN 모두를 사용하여 실험을 진행했다. 사전 학습 과정에서는 각 네트워크에 그래프 분류 작업을 수행하도록 했으며, 방법론은 부록 B에 설명되어 있다. 개별 실험에서 사전 학습된 GIN을 사용하여 계산된 지표의 결과는 부록 C.1에 제시되었으며, 논의를 용이하게 하기 위해 이러한 결과를 표 3에 요약하였다. 랜덤 및 사전 학습된 네트워크 모두에서 구별 가능성을 향상시키는 방법으로 node 차수 feature을 정수로 표현하여 사용했다. 실제로는 초기화된 랜덤 네트워크에서 직교 가중치 초기화(Saxe et al., 2014)를 활용했는데, 이는 초기화 간 지표의 분산을 약간 줄여주기 때문이다.&lt;/p&gt;

&lt;p&gt;평가 지표 평가: 모든 실험은 $P_g \approx P_r$로 시작하며, $\mathbb{S}_g$와 $\mathbb{S}_r$ 사이의 유사성의 척도인 perturbation 정도 $t \in [0, 1]$이 단조롭게 증가한다. 저자들은 각 지표를 객관적으로 평가하기 위해 지표 점수 $\hat{\rho}$와 perturbation 정도 $t$ 사이의 Spearman 순위 상관 계수를 계산했다. 모든 지표는 $P_r = P_g$일 때 $\hat{\rho} = 0$이 되도록 정규화되었으며, 강력한 지표의 경우 $\hat{\rho}$는 $t$에 따라 증가해야 하고, 순위 상관 계수 1.0이 이상적이라고 가정하였다.&lt;/p&gt;

&lt;p&gt;또, 이들은 각 지표와 GIN 아키텍처 조합에 대해 10개의 랜덤 시드를 통해 테스트했으며, 이는 GIN 모델 가중치(해당되는 경우)와 적용된 perturbation에 영향을 미친다. 주어진 지표에 대한 결과를 report 하는 데 있어 단일 랜덤 시드, 실험(i.e.Edge 재연결), 데이터셋(i.e.Grid), GIN 구성(i.e.$L=4, d=25$)에 대한 순위 상관 계수를 계산했다. 그런 다음 이러한 변이 요인의 조합에 걸쳐 순위 상관 계수 점수를 집계했다.&lt;/p&gt;

&lt;h2 id=&quot;41-fidelity-측정&quot;&gt;4.1 fidelity 측정&lt;/h2&gt;

&lt;p&gt;지표의 가장 중요한 속성 중 하나는 생성된 샘플의 &lt;strong&gt;fidelity&lt;/strong&gt;를 반영할 수 있는가 이다. 이들은 fidelity에 대한 지표를 테스트하기 위해 두 가지 실험을 구성했다. 첫 번째 실험은 실제 샘플에 다양한 양의 랜덤 샘플을 섞어 지표의 감지 능력을 테스트하고(Xu et al., 2018), 두 번째 실험은 Edge를 무작위로 재연결하여 그래프의 품질을 서서히 저하시켰다(O’Bray et al., 2022). 두 실험 모두 $\mathbb{S}_g$를 $\mathbb{S}_r$의 복사본으로 시작하며, $\mathbb{S}_r$ 자체는 데이터셋의 복사본이다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;첫 번째 실험에서는 $\mathbb{S}_g$의 품질에 영향을 주기 위해 랜덤 그래프를 활용했다. $\mathbb{S}_r$와 $\mathbb{S}_g$ 사이의 유사성을 감소시키기 위해, $\mathbb{S}_g(t)$에서 랜덤 그래프를 실제 그래프와 섞는 비율 $t$를 서서히 증가시켰다. 동시에 실제 그래프를 제거하여 $\left&lt;/td&gt;
      &lt;td&gt;\mathbb{S}_g\right&lt;/td&gt;
      &lt;td&gt;$가 전체적으로 일정하게 유지되도록 했다. 랜덤 그래프는 $\mathbb{S}_r$와 유사하도록 크기와 $p$ 값을 선택한 Erdős-Rényi(E-R) 그래프(Erdős &amp;amp; Rényi, 1960)이다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;두 번째 실험에서는 $\mathbb{S}g$의 에지를 무작위로 재연결하여 $P_r$와 $P_g$ 사이의 거리를 증가시켰다. 여기서 perturbation 정도 $t$는 각 에지 $(i, j) \in E$를 재연결할 확률이다. 각 $G \in \mathbb{S}g$와 각 $(i, j) \in E$에 대해, $x{i,j} \sim \operatorname{Bernoulli}(t)$를 샘플링했다. $x{i,j} = 1$인 에지는 재연결되며, 또 다른 샘플 $y_{i,j} \sim \operatorname{Bernoulli}(0.5)$를 사용하여 에지의 두 node 중 하나 ${i, j}$를 선택하고, 이 에지의 새로운 연결은 $\mathbb{V}$에서 균일하게 선택된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;image-2.png&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과: Recall과 Orbits MMD를 제외하면, 테스트한 대부분의 지표는 순위 상관 계수가 1.0에 가까워 이 실험에서 우수한 성능을 보였다(그림 3, 1행). 그러나 Recall은 $\mathbb{S}_g$의 다양성을 측정하도록 설계되었으므로, 여기서 fidelity에 대한 낮은 민감도는 예상된 결과이다. 놀랍게도 Coverage는 $\mathbb{S}_g$의 diversity을 측정하도록 설계되었음에도 불구하고 fidelity에 대한 강한 민감도를 보였다. 또한, GRAN(Li et al., 2018)이 생성한 그래프를 사용하여 혼합 실험을 반복했으며 유사한 결과를 얻었다고 한다.&lt;/p&gt;

&lt;h2 id=&quot;42-diversity-측정&quot;&gt;4.2 diversity 측정&lt;/h2&gt;

&lt;p&gt;다음으로 조사한 속성은 $\mathbb{S}_g$에 생성된 샘플의 &lt;strong&gt;diversity&lt;/strong&gt; 을 측정하는 지표의 능력이다. 저자들이 원하는 지표는 생성 모델의 두 가지 일반적인 문제인 ** mode dropping &lt;strong&gt;과 **mode collapse&lt;/strong&gt;에 민감해야 한다는 것이다. Xu et al.(2018)의 두 가지 실험을 그래프 도메인에 맞게 조정하여 각 지표를 독립적으로 테스트했다. 두 실험 모두 Affinity Propagation(Frey &amp;amp; Dueck, 2007)을 사용하여 데이터셋을 클러스터링하여 $P_r$의 모드를 식별하는 것으로 시작한다. 이 실험들은 모두 데이터셋의 절반으로 이루어진 $\mathbb{S}_r$와 $\mathbb{S}_g$로 시작한다.&lt;/p&gt;

&lt;p&gt;mode collapse시뮬레이션: 각 데이터 포인트를 해당 클러스터의 centroid로 점차 대체했다. perturbation 정도 $t$는 이러한 방식으로 collapse한 클러스터의 비율을 나타낸다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;mode dropping 시뮬레이션: $\mathbb{S}_g$에서 클러스터를 점진적으로 제거했다. $\left&lt;/td&gt;
      &lt;td&gt;\mathbb{S}_g\right&lt;/td&gt;
      &lt;td&gt;$를 일정하게 유지하기 위해, 남은 클러스터에서 샘플을 무작위로 선택하여 중복했다. 이 실험에서 perturbation 정도 $t$는 $\mathbb{S}_g$에서 삭제된 클러스터의 비율이다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;결과: mode collapse실험에서, 모든 고전적인 지표(You et al., 2018)는 순위 상관 계수가 0.5 미만으로 저조한 성능을 보였다(그림 3, 하단). 고전적인 지표는 mode dropping 실험에서 약간 더 나은 결과를 얻었지만 여전히 최적의 결과는 아니다. 예상대로 Recall과 Coverage는 $\mathbb{S}_g$의 diversity과 강한 양의 상관 관계를 보였으며, Precision과 Density는 음의 상관 관계를 보였다. 또한, MMD RBF와 F1 PR과 같은 몇몇 스칼라 지표는 $\mathbb{S}_g$의 diversity과 강한 상관 관계를 보였으며, 두 실험 모두에서 고전적인 지표보다 우수한 성능을 보였다.&lt;/p&gt;

&lt;h2 id=&quot;43-node-및-edge-feature에-대한-민감도&quot;&gt;4.3 node 및 edge feature에 대한 민감도&lt;/h2&gt;

&lt;p&gt;이 실험에서는 기본 그래프 구조는 그대로 두면서 node 또는 edge feature 분포의 변화에 대한 각 지표의 민감도를 측정했다. Edge 재연결 실험과 유사하게, 이는 확률 $t$로 feature 를 randomize 하여 수행된다. 평가에서 node와 edge feature을 모두 포함할 수 없기 때문에 You et al.(2018)의 지표는 이 실험에서 제외되었다. 모든 NN 기반 지표와 NSPDK MMD가 이러한 perturbation에 민감하다는 것이 눈에 띈다.&lt;/p&gt;

&lt;h2 id=&quot;44-샘플-효율성&quot;&gt;4.4 샘플 효율성&lt;/h2&gt;

&lt;p&gt;GGM 문헌에서는 작은 데이터셋을 자주 사용하므로 &lt;strong&gt;샘플 효율성(sample efficiency)&lt;/strong&gt;이 중요하다. 이 실험에서는 랜덤 그래프 집합 $\mathbb{S}_g$를 실제 샘플 $\mathbb{S}_r$과 구별하는 데 필요한 최소 샘플 수를 찾아 각 지표의 샘플 효율성을 결정했다. 랜덤 그래프는 4.1절에서 설명한 동일한 프로세스를 사용하여 생성된 E-R 그래프이다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$\mathbb{S}_r$에서 서로소인 두 집합 $\mathbb{S}_r’$과 $\mathbb{S}_r’’$, 그리고 $\mathbb{S}_g$에서 랜덤 그래프 집합 $\mathbb{S}_g’$를 샘플링했다. 여기서 $\left&lt;/td&gt;
      &lt;td&gt;\mathbb{S}_r’\right&lt;/td&gt;
      &lt;td&gt;= \left&lt;/td&gt;
      &lt;td&gt;\mathbb{S}_r’’\right&lt;/td&gt;
      &lt;td&gt;= \left&lt;/td&gt;
      &lt;td&gt;\mathbb{S}_g’\right&lt;/td&gt;
      &lt;td&gt;= n$이고 $n$은 작다. 샘플 효율성이 높은 지표는 작은 $n$으로 $\hat{\rho}\left(\mathbb{S}_r’, \mathbb{S}_r’’\right) &amp;lt; \hat{\rho}\left(\mathbb{S}_r’, \mathbb{S}_g’\right)$를 만족해야 한다. 이 실험에서는 순위 상관 계수를 사용하지 않고, 이 조건을 만족하는 가장 작은 $n$을 각 지표의 샘플 효율성으로 기록했다. $K$-최근접 이웃에 기반한 모든 지표와 많은 고전적인 지표는 높은 샘플 효율성을 보였으며, $\mathbb{S}_r’’$와 $\mathbb{S}_g’$을 올바르게 구별하는 데 최소한의 샘플만 필요로 했다(표 3).&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;45-계산-효율성&quot;&gt;4.5 계산 효율성&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;계산 효율성(computational efficiency)&lt;/strong&gt;은 평가 지표의 마지막으로 조사한 속성이다. 계산하기에 효율적인 지표는 학습 과정 전반에 걸쳐 진행 상황을 측정하고 모델 선택을 도울 수 있다. 그래프 데이터셋은 샘플 수, node의 평균 수, Edge의 평균 수 등 여러 차원에서 확장될 수 있다. 임의의 node 및 에지 수를 가진 그래프를 생성하기 위해 E-R 그래프를 사용하여 각 차원에서 그래프를 독립적으로 확장할 수 있게 했다.&lt;/p&gt;

&lt;p&gt;데이터셋 크기가 10,000 샘플로 증가함에 따라 각 지표의 계산 효율성을 측정한 결과는 표 3에 나와 있다. MMD등 고전적인 지표(You et al., 2018)는 샘플 수가 증가함에 따라 계산 비용이 급격히 증가하여 계산이 부담스러워지는 반면, NN 기반 지표는 여러 배의 속도로 더 빠르며 어떤 규모에서도 효율적이라는 점을 확인할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;5-향후-연구-방향과-한계&quot;&gt;5. 향후 연구 방향과 한계&lt;/h3&gt;

&lt;p&gt;이 논문에서는 랜덤 GNN(Random Graph Neural Networks) 기반의 평가 지표를 도입하여 기존 메트릭이 가지는 한계를 극복하고자 했다. 그러나 저자들은 몇가지 한계를 언급하며, 추후 연구 방향을 아래와 같이 제시하였다.&lt;/p&gt;

&lt;h4 id=&quot;51-이론적-기반의-부족&quot;&gt;5.1. 이론적 기반의 부족&lt;/h4&gt;

&lt;p&gt;랜덤 GNN을 사용하여 그래프 생성 모델(GGMs)을 평가하는 접근 방식은 실험적으로 매우 그럴듯한 결과를 보였지만, 이를 뒷받침하는 이론적 근거가 부족하다. 랜덤 GNN이 훈련되지 않았음에도 불구하고 유용한 feature을 추출할 수 있다는 것은 흥미로운 발견이지만, 이를 뒷받침하는 수학적 또는 이론적 분석이 부재하다는 것이다. 저자들은 향후 랜덤 GNN의 성능을 이론적으로 분석하고, 더 정교한 GNN 구조를 사용해 샘플 효율성을 높이는 방향으로 나아갈 수 있을 것으로 기대된다고 덧붙였다.&lt;/p&gt;

&lt;h4 id=&quot;52-특정-도메인에-대한-한계&quot;&gt;5.2. 특정 도메인에 대한 한계&lt;/h4&gt;

&lt;p&gt;랜덤 GNN 기반 메트릭은 다양한 도메인에서 유용할 수 있지만, 특정 도메인에서의 사용에는 한계가 존재한다. 예를 들어 &lt;strong&gt;Molecular Graphs&lt;/strong&gt;과 같은 특수한 도메인에서는 “약물 적합성(drug-likeness)“과 같은 도메인 특유의 평가 지표가 중요하다고 한다. 이러한 domain specific 정보를 랜덤 GNN이 충분히 반영하지 못할 수 있기 때문에, 이러한 메트릭이 모든 도메인에서 최적의 평가 도구로 사용되기에는 한계가 있다는 것이다. 따라서 향후 도메인 특화된 지표와 랜덤 GNN을 결합하여 더 나은 평가 방법을 개발하는 방향이 제안되었다.&lt;/p&gt;

&lt;h4 id=&quot;3-기존-메트릭과의-조화&quot;&gt;3. 기존 메트릭과의 조화&lt;/h4&gt;

&lt;p&gt;본 논문에서 저자들은 기존의 그래프 생성 모델 평가 메트릭들이 diversity과 사실성을 충분히 측정하지 못한다는 한계가 지적되었다. 그러나, 이는 기존 메트릭이 무용하다는 의미는 아니며,  &lt;strong&gt;You et al. (2018)&lt;/strong&gt;에서 제시된 고전적 지표는 특정한 그래프 통계에 기반한 평가에는 여전히 유용할 수 있다. 따라서 향후 연구는 기존 메트릭과 랜덤 GNN 기반 메트릭을 어떻게 결합하여 더 나은 평가를 제공할 수 있을지 탐구할 필요가 있다는 것이다.&lt;/p&gt;

&lt;h4 id=&quot;4-샘플-효율성-및-계산-효율성의-개선&quot;&gt;4. 샘플 효율성 및 계산 효율성의 개선&lt;/h4&gt;

&lt;p&gt;랜덤 GNN 기반의 메트릭은 기존 메트릭에 비해 계산 효율성이 높지만, 샘플 효율성 측면에서는 여전히 개선의 여지가 있다는 점 또한 언급되고 있다. 저자들은 소규모 데이터셋에서 랜덤 GNN이 얼마나 효율적으로 작동할 수 있는지에 대한 추가적인 연구의 필요성을 제기하고 있다. 더 정교한 GNN 구조나 최적화된 알고리즘을 도입하여 샘플 효율성과 계산 비용을 더욱 줄이는 방향으로 연구가 진행될 필요가 있다.&lt;/p&gt;

&lt;h4 id=&quot;5-미래-연구-방향&quot;&gt;5. 미래 연구 방향&lt;/h4&gt;

&lt;p&gt;이 논문은 여러 가지 흥미로운 연구 방향을 제시하고 있다. 특히, 향후 연구에서는 더 정교한 GNN 구조를 탐구하여 랜덤 GNN의 성능을 향상시키는 방법을 찾는 것이 중요하다. 또한, 실험적 성능을 뒷받침하는 이론적 근거를 마련하는 작업이 필요하며, 랜덤 GNN의 다양한 변형을 실험하여 그래프 생성 모델 평가에서 최적의 메트릭을 찾아낼 수 있을 것이다.&lt;/p&gt;

</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-On_Evaluation_Metrics_For_Graph_Generative_Models.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-On_Evaluation_Metrics_For_Graph_Generative_Models.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[AAAI-24] No prejudice! Fair Federated Graph Neural Networks for Personalized Recommendation</title>
            <description>&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The primary issue addressed by this paper is the challenge of achieving &lt;strong&gt;fairness across demographic groups&lt;/strong&gt; in Federated Learning (FL)-based recommendation systems (RSs), particularly while ensuring &lt;strong&gt;user privacy&lt;/strong&gt;. Traditional, centralized recommendation systems tend to produce biased recommendations that favor certain demographic groups (e.g., gender or age), while also violating user privacy by gathering sensitive data on central servers. FL provides a solution to the privacy issue by decentralizing data processing, but ensuring fairness without access to users’ demographic information is an unresolved problem. The goal of this paper is to develop a recommendation system that mitigates demographic biases within FL environments using Graph Neural Networks (GNNs), while preserving the privacy of sensitive user information and maintaining high utility for recommendations.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;
&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;2.1 Limitations and Challenges&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;The use of recommendation systems has grown significantly in various industries such as e-commerce, healthcare, and entertainment. However, the following challenges remain unresolved:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Privacy and Security:&lt;/strong&gt; Traditional RSs rely on centralized data collection, where sensitive user information is stored and processed, leading to privacy violations [2].&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Fairness Concerns:&lt;/strong&gt; FL allows for the decentralized training of models on local devices and transmitting the updated model back to the sever, to preserve user privacy. However, FL fail to ensure fairness across demographic groups [1] when sensitive data like gender or race, is unavailable for analysis [3].&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Amplified Bias:&lt;/strong&gt; GNNs are effective at modeling user-item interactions in RSs but can inherit and  exacerbate existing biases in the data, making fairness even harder to achieve in FL environments [4].&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;2.2 Proposed Approch&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;The authors introduce F&lt;sup&gt;2&lt;/sup&gt;PGNN (Fair Federated Personalized Graph Neural Network), a novel framework that addresses these issues through three key pillars:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Fairness:&lt;/strong&gt; F&lt;sup&gt;2&lt;/sup&gt;PGNN ensures fairness in recommendations without requiring access to sensitive demographic information.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Privacy:&lt;/strong&gt; By using &lt;strong&gt;Local Differential Privacy (LDP)&lt;/strong&gt;, the model maintains user privacy while sharing group-level statistics.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Personalization:&lt;/strong&gt; The system captures both higher-order and explicit user-item interactions through a GNN model, improving recommendation accuracy while reducing bias.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;3-related-work&quot;&gt;&lt;strong&gt;3. Related Work&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Research on fairness in recommendation systems and federated learning has been extensive, but integrating fairness with privacy-preserving techniques in federated settings is still a challenging area. Previous studies on fairness in centralized recommendation systems, such as those by Yao and Huang (2017) [5] and Li et al. (2021) [6], focus on mitigating bias using demographic data. However, these methods require access to centralized data, which violates privacy norms.&lt;/p&gt;

&lt;p&gt;In the federated learning domain, models like &lt;strong&gt;FedMF&lt;/strong&gt; [7] and &lt;strong&gt;FedPerGNN&lt;/strong&gt; [8] have integrated fairness into federated settings, but they either rely on &lt;strong&gt;Matrix Factorization&lt;/strong&gt;, which lacks the ability to model higher-order interactions, or introduce significant computational overhead with encryption techniques.&lt;/p&gt;

&lt;p&gt;This paper builds on existing works but proposes a more efficient and scalable solution by utilizing GNNs for recommendation and adding privacy constraints through LDP, ensuring fairness while preserving privacy.&lt;/p&gt;

&lt;h2 id=&quot;4-methodology&quot;&gt;&lt;strong&gt;4. Methodology&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The proposed F&lt;sup&gt;2&lt;/sup&gt;PGNN  is designed to ensure fairness in federated recommendation systems by leveraging GNNs, which allow users to train models locally while preserving privacy. Below are the core components of this framework:&lt;/p&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;4.1 Inductive Graph Expansion Algorithm&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;One of the key innovations in the F&lt;sup&gt;2&lt;/sup&gt;PGNN framework is the &lt;strong&gt;Inductive Graph Expansion&lt;/strong&gt; algorithm, which allows users to incorporate higher-order interactions into their local user-item interaction graphs. Higher-order interactions refer to indirect relationships between users and items that may not be immediately apparent but can be inferred from the broader graph structure. For instance, users who have interacted with similar items can be connected, thus uncovering latent relationships and improving the quality of recommendations.&lt;/p&gt;

&lt;p&gt;The steps in this algorithm are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Users encrypt their item IDs using a public key.&lt;/li&gt;
  &lt;li&gt;These encrypted IDs are sent to a server, which matches them across different users to find co-interacted items (i.e., items that have been rated by multiple users).&lt;/li&gt;
  &lt;li&gt;The server provides anonymous embeddings for users who share interactions with the same items, allowing users to expand their graphs while maintaining privacy.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These expanded subgraphs enable each client to capture higher-order interactions, significantly improving recommendation quality.&lt;/p&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;4.2 Local GNN Training&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;Once users have expanded their local subgraphs, they train a &lt;strong&gt;Graph Attention Network (GAT)&lt;/strong&gt; locally. GATs are particularly suited to recommendation systems as they allow the model to assign varying levels of importance to neighboring nodes (users or items), depending on the strength of their connections. The GAT model updates user and item embeddings by aggregating information from neighboring nodes, with the attention mechanism determining how much influence each neighbor has on the final embedding.&lt;/p&gt;

&lt;p&gt;Mathematically, the attention coefficient between a user node $v$ and its neighbor $k$ is calculated as:
\(e_{vk} = \text{LeakyReLU}(\mathbf{a}^\top [\mathbf{W}\mathbf{h}_v \| \mathbf{W}\mathbf{h}_k])\)&lt;/p&gt;

&lt;p&gt;Here, $h_v$ and $h_k$ are the feature vectors of nodes $v$ and $k$, respectively, and $\mathbf{W}$ is the weight matrix. The operator $||$ denotes concatenation, and $\mathbf{a}$ is the attention weight vector that learns the relative importance of neighboring nodes. This attention score is then normalized across all neighbors $j \in \mathcal{N}_v$ of node $v$:
\(\alpha_{vk} = \frac{\exp(e_{vk})}{\sum_{j \in N_v} \exp(e_{vj})}\)
The final node embedding $\mathbf{h}_v’$ for node $v$ is updated by aggregating the normalized attention-weighted features from all its neighbors:
\(\mathbf{h}&apos;_v = \sigma \left( \sum_{k \in N_v} \alpha_{vk} \mathbf{W}\mathbf{h}_k \right)\)
where $\sigma$ is a non-linear activation function (e.g., ReLU).
&lt;img src=&quot;./F2PGNN.png&quot; alt=&quot;img1&quot; /&gt;
&lt;em&gt;Figure 1: The overall structure of the F&lt;sup&gt;2&lt;/sup&gt;PGNN framework.&lt;/em&gt;&lt;/p&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;4.3 Fairness-Aware Loss Function&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;A core innovation of F&lt;sup&gt;2&lt;/sup&gt;PGNN is its &lt;strong&gt;fairness-aware loss function&lt;/strong&gt;, designed to ensure equitable recommendations across different demographic groups. The function balances two objectives: utility (i.e., recommendation accuracy) and fairness (i.e., reducing bias between demographic groups).&lt;/p&gt;

&lt;p&gt;The overall loss function is defined as:
\(L = L_{util} + \beta L_{fair}\)
Here, $L_{util}$ is the utility loss, which can be the mean squared error (MSE) between the predicted and true ratings, and $L_{fair}$ is the fairness loss, which penalizes the model for disparities in performance across different demographic groups. The parameter $\beta$ ontrols the trade-off between utility and fairness, with higher values of $\beta$ placing more emphasis on fairness.&lt;/p&gt;

&lt;p&gt;The fairness loss is defined as the absolute difference in the average performance of the model between two demographic groups $S_0$ (e.g., males) and $S_1$ (e.g., females):
\(L_{fair}(M, S_0. S_1) = |\frac{1}{S_0}\sum_{u \in S_0}\mathcal{M}(u)-\frac{1}{S_0}\sum_{u \in S_1}\mathcal{M}(u)|^\alpha\)
where $\mathcal{M}(u)$  is the performance metric for user $u$ (e.g., the negative loss for user $u$) and $\alpha$ is an exponent that determines the severity of the fairness penalty (typically set to 1 or 2).&lt;/p&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;4.4 Fairness-Aware Gradient Adjustment&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;To incorporate fairness into the training process, the gradients of the model are adjusted based on the fairness loss. This is crucial because it allows the model to reduce bias during training by controlling the learning speed for different groups.&lt;/p&gt;

&lt;p&gt;Specifically, if a user belongs to an overperforming demographic group, their learning rate is scaled down, whereas the learning rate is increased for underperforming groups, promoting fairness throughout training.&lt;/p&gt;

&lt;p&gt;The adjusted gradient for user $u$ is computed using the following formula:
\(\nabla \Theta_u = (1 - \beta R|P - Q|^{\alpha-1}) \frac{\partial L^u_\text{util}}{\partial \Theta_u}\)
where $\nabla \Theta_u$ represents the gradient update for user $u$, $\beta$ is the fairness budget determining how much weight is given to fairness during training. $R$ is a scalar determined by the difference in performance between groups and user group membership:
\(R = \alpha \cdot (-1)^{1(P&amp;lt;Q)} \cdot (-1)^{1(u \notin S_0)}\)
$P$ and $Q$ represent the average performance metrics (e.g., accuracy or utility) for groups $S_0$ and $S_1$ respectively:
\(P = \frac{1}{|S_0|} \sum_{u \in S_0} \mathcal{M(u)}, \quad Q = \frac{1}{|S_1|} \sum_{u \in S_1} \mathcal{M(u)}\)
Here, $\mathcal{M(u)}$ represents the utility metric for user $u$, such as the recommendation accuracy.&lt;/p&gt;

&lt;p&gt;The adjusted gradient ensures that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Overperforming users (i.e., those in group $S_0$ if $P&amp;gt;Q$) experience slower learning, reducing potential biases toward their group.&lt;/li&gt;
  &lt;li&gt;Underperforming users (i.e., those in group $S_1$ if $P&amp;lt;Q$) experience faster learning, helping to close the performance gap.
Thus, fairness is promoted by adjusting the learning rates dynamically, ensuring that both groups are treated equitably during the training process.&lt;/li&gt;
&lt;/ul&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;4.5 Local Differential Privacy (LDP)&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;To ensure privacy, F&lt;sup&gt;2&lt;/sup&gt;PGNN employs LDP. This mechanism ensures that sensitive information (such as individual interactions or group membership) is obfuscated during model updates. LDP is applied both to the model gradients and to the group statistics (i.e., the information used to adjust the model based on fairness).
&lt;strong&gt;Model Updates:&lt;/strong&gt; After computing the adjusted gradients, each user applies gradient clipping to ensure that the updates are bounded, followed by adding noise to the gradients using the Laplace mechanism. This results in differentially private gradient updates, which protect the user’s data even from inference attacks.
The clipped and noisy gradient is computed as follows:
\(\nabla \Theta_u^\text{LDP} = \text{clip}(\nabla \Theta_u, \delta) + \text{Laplace}(0, \lambda)\)
where $\text{clip}(\nabla \Theta_u, \delta)$ ensures that the gradient norm is bounded by $\delta$, and $\lambda$ controls the variance of the Laplace noise, with larger values of $\lambda$ providing stronger privacy but potentially reducing model accuracy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Group Statistics Updates:&lt;/strong&gt; To ensure fairness, the server needs to know the group-level statistics (i.e.,$P$ and $Q$) that measure the performance of different demographic groups. However, directly uploading these statistics could reveal sensitive group membership information. To address this, LDP is also applied to the group statistics updates.&lt;/p&gt;

&lt;p&gt;For each user $u$ the server receives the following noisy updates:
\(P_u^\text{perf} = \mathbb{I}(u \in S_0)\mathcal{M(u)} + \epsilon_1, \quad Q_u^\text{perf} = \mathbb{I}(u \in S_1)\mathcal{M(u)} + \epsilon_2\)&lt;/p&gt;

&lt;p&gt;\(P_u^\text{count} = \mathbb{I}(u \in S_0) + \epsilon_3, \quad Q_u^\text{count} = \mathbb{I}(u \in S_1) + \epsilon_4\)
where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\mathbb{I}(u \in S_0)$ is an indicator function that equals 1 if user $u$ belongs to group $S_0$ and 0 otherwise.&lt;/li&gt;
  &lt;li&gt;$\epsilon_1, \epsilon_2, \epsilon_3, \epsilon_4 \sim \mathcal{N}(0, \sigma^2)$ re noise terms drawn from a normal distribution with variance $\sigma^2$, ensuring privacy.&lt;/li&gt;
  &lt;li&gt;By adding noise to the group statistics, the server cannot accurately infer which users belong to each group, thus preserving privacy.&lt;/li&gt;
&lt;/ul&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;4.6 Training Process&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;The overall training process involves the following steps during each communication round:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Users receive the global model parameters and group statistics.&lt;/li&gt;
  &lt;li&gt;Each user expands their local graph using the Inductive Graph Expansion algorithm and trains their GNN on the expanded subgraph.&lt;/li&gt;
  &lt;li&gt;Users compute adjusted gradients that incorporate fairness scaling.&lt;/li&gt;
  &lt;li&gt;LDP is applied to both gradients and group statistics to preserve privacy.&lt;/li&gt;
  &lt;li&gt;Updated parameters and statistics are sent back to the server.&lt;/li&gt;
  &lt;li&gt;The server aggregates these updates, computes new global model parameters, and rebroadcasts them to the users.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:
In a movie recommendation system with two demographic groups (e.g., males and females), if the average recommendation accuracy for males is higher, the fairness-aware gradient adjustment will slow the learning rate for male users and increase it for female users to reduce group disparity.&lt;/p&gt;

&lt;h2 id=&quot;5-experiment&quot;&gt;&lt;strong&gt;5. Experiment&lt;/strong&gt;&lt;/h2&gt;
&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;5.1 Experiment Setup&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;The experimental evaluation of the F&lt;sup&gt;2&lt;/sup&gt;PGNN framework  was conducted using three well-known real-world datasets commonly used in recommendation tasks:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MovieLens-100K (ML-100K): Contains 100,000 ratings from 943 users on 1,682 movies. This dataset is frequently used in recommendation research due to its manageable size and well-documented structure.&lt;/li&gt;
  &lt;li&gt;MovieLens-1M (ML-1M): A larger dataset with 1 million ratings from 6,040 users on 3,706 movies. It provides richer interactions, allowing for more thorough analysis of performance across different user types.&lt;/li&gt;
  &lt;li&gt;Amazon-Movies: A large-scale dataset with approximately 500,000 ratings from 5,515 users on 13,509 movies. Its diversity and sparse interactions make it a challenging benchmark for recommendation models.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the experiments, two types of sensitive attributes were considered:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Gender (G): Users were categorized as male or female based on available metadata. This was used to test how well F&lt;sup&gt;2&lt;/sup&gt;PGNN mitigates gender bias in recommendations.&lt;/li&gt;
  &lt;li&gt;Activity Level (A): Users were classified as either “active” or “inactive” based on the number of ratings they provided. This tested the model’s ability to ensure fairness across users with varying levels of engagement.&lt;/li&gt;
&lt;/ol&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;5.2 Baseline&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;The authors compare F&lt;sup&gt;2&lt;/sup&gt;PGNN against the &lt;strong&gt;F2MF&lt;/strong&gt; (Fair Federated Matrix Factorization) model, a federated recommendation system that also incorporates fairness constraints. However, F2MF does not utilize the graph structure of user-item interactions, which limits its ability to capture higher-order relationships. The comparison between these models aims to highlight the advantages of GNNs in federated learning environments, particularly in terms of balancing fairness and utility.&lt;/p&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;5.3 Evaluation Metrics&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;Two key metrics were used to evaluate the performance of the model:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Utility Metric:&lt;/strong&gt; The accuracy of the recommendations was measured using &lt;strong&gt;Root Mean Square Error (RMSE)&lt;/strong&gt;. A lower RMSE indicates better prediction accuracy.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fairness Metric:&lt;/strong&gt; Fairness was measured using &lt;strong&gt;group unfairness&lt;/strong&gt;, which calculates the absolute difference in average performance (RMSE) between demographic groups. Lower group unfairness scores indicate more equitable treatment of different user groups.&lt;/li&gt;
&lt;/ul&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;5.4 Results&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;The experimental results demonstrated the effectiveness of F&lt;sup&gt;2&lt;/sup&gt;PGNN in improving fairness while maintaining high utility across all datasets. The key findings can be summarized as follows:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Fairness Improvement:&lt;/strong&gt; F&lt;sup&gt;2&lt;/sup&gt;PGNN &lt;strong&gt;significantly reduced group disparity&lt;/strong&gt; compared to the F2MF baseline in all datasets. For example, when gender was used as the sensitive attribute in the MovieLens-1M dataset, F&lt;sup&gt;2&lt;/sup&gt;PGNN reduced group disparity by up to 84% compared to F2MF. This improvement showcases the strength of incorporating fairness-aware loss functions and fairness-driven gradient adjustments in GNN-based federated recommendation systems.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Utility Preservation:&lt;/strong&gt; Despite focusing on fairness, F&lt;sup&gt;2&lt;/sup&gt;PGNN &lt;strong&gt;maintained comparable or even better RMSE scores&lt;/strong&gt; compared to the baseline. For instance, in the MovieLens-100K dataset, F&lt;sup&gt;2&lt;/sup&gt;PGNN achieved a lower RMSE than F2MF, demonstrating that the accuracy of recommendations was not compromised by introducing fairness constraints. In some cases, the RMSE slightly increased, especially when fairness constraints were stronger, but the increase was justifiable by the significant improvements in fairness.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Effect of Fairness Budget ($\beta$):&lt;/strong&gt;  The fairness budget parameter ($\beta$) controlled the trade-off between fairness and utility. Increasing $\beta$ improved fairness by reducing group disparity, with only a minimal impact on RMSE in most cases. This trade-off makes F&lt;sup&gt;2&lt;/sup&gt;PGNN adaptable to real-world applications where fairness is a critical requirement, such as personalized recommendation systems for e-commerce or healthcare.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Below is a table summarizing the performance and fairness of F&lt;sup&gt;2&lt;/sup&gt;PGNN compared to F2MF in different datasets. G denotes Gender while A denotes Activity. 
&lt;img src=&quot;./result.png&quot; alt=&quot;img2&quot; /&gt;
&lt;em&gt;Figure 2: Performance vs Fairness comparison with different fairness budget $\beta$.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disparity vs. Epochs:&lt;/strong&gt; The experiments included a visualization of group disparity over time. The results showed that group disparity consistently decreased with F&lt;sup&gt;2&lt;/sup&gt;PGNN, particularly when a higher fairness budget ($\beta$) was used. This graph reinforced that the model is effective at reducing demographic bias as training progresses.
&lt;img src=&quot;./disparity.png&quot; alt=&quot;img3&quot; /&gt;
&lt;em&gt;Figure 3: &lt;strong&gt;Top Row:&lt;/strong&gt; Disparity vs epoch for different fairness budget $\beta$ on validation data. &lt;strong&gt;Bottom row:&lt;/strong&gt; % change in fairness (left y-axis) and % change in RMSE (right y-axis) w.r.t different $\beta$&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Privacy-Utility Trade-off:&lt;/strong&gt; Another experiment explored the trade-off between privacy and utility by varying the parameters of the LDP mechanism. Increasing the noise variance ($\lambda$) enhanced privacy by adding more noise to the model updates, but it slightly increased RMSE. However, with proper tuning of LDP parameters (e.g., the noise variance $\lambda$ and gradient clipping threshold $\delta$), the model achieved a good balance between privacy protection and utility.
&lt;img src=&quot;./privacy.png&quot; alt=&quot;img4&quot; /&gt;
&lt;em&gt;Figure 4: Privacy budget $\epsilon$ (left y-axis) and the personalization RMSE (right y-axis) w.r.t different clipping threshold $\delta$ and noise variance $\lambda.$&lt;/em&gt;&lt;/p&gt;

&lt;font color=&quot;red&quot; size=&quot;3px&quot;&gt;&lt;b&gt;5.4.1 Analysis of Results&lt;/b&gt;&lt;/font&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Fairness vs. Utility:&lt;/strong&gt; The results demonstrate that F&lt;sup&gt;2&lt;/sup&gt;PGNN achieves substantial improvements in fairness without a significant loss of utility. The framework provides flexibility in adjusting the fairness budget ($\beta$), allowing practitioners to prioritize fairness or accuracy based on the specific requirements of their application. This flexibility is crucial for practical implementations in industries where both fairness and recommendation accuracy are important.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Privacy Protection:&lt;/strong&gt; The use of LDP ensures that sensitive user data, such as gender or activity level, remains protected. Even with the added noise from LDP, F&lt;sup&gt;2&lt;/sup&gt;PGNN was able to maintain high utility, proving that privacy, fairness, and utility can be effectively balanced in a federated learning setup.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;6-conclusion&quot;&gt;&lt;strong&gt;6. Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;6.1 Summary&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;The paper introduces F&lt;sup&gt;2&lt;/sup&gt;PGNN, a novel framework that incorporates fairness into federated GNN-based RSs while preserving user privacy. By leveraging GNNs and incorporating a fairness-aware loss function, F&lt;sup&gt;2&lt;/sup&gt;PGNN is able to reduce demographic biases without requiring access to sensitive user attributes such as gender or activity level. The framework uses LDP to protect both model updates and group statistics, ensuring that privacy regulations are adhered to while still delivering fair recommendations.&lt;/p&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;6.2 Key Contributions&lt;/b&gt;&lt;/font&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Fair Federated GNNs:&lt;/strong&gt; F&lt;sup&gt;2&lt;/sup&gt;PGNN is the first framework to address fairness in federated GNN-based recommendation systems, providing significant improvements in reducing group disparity and promoting equitable treatment across demographic groups.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Privacy-Preserving Techniques:&lt;/strong&gt; By using LDP for both model updates and group statistics, F&lt;sup&gt;2&lt;/sup&gt;PGNN adheres to strict privacy regulations, making it applicable in scenarios where privacy is of paramount importance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Practical Effectiveness:&lt;/strong&gt; The framework achieves fairness improvements without incurring major utility losses, demonstrating its scalability and adaptability for large datasets. Its flexibility to incorporate various sensitive attributes (e.g., gender, activity level) further underscores its practical value.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;font color=&quot;red&quot; size=&quot;4px&quot;&gt;&lt;b&gt;6.3 Take-Home Messages&lt;/b&gt;&lt;/font&gt;
&lt;p&gt;F&lt;sup&gt;2&lt;/sup&gt;PGNN demonstrates that integrating fairness into federated GNN-based recommendation systems is both feasible and beneficial. By carefully designing the loss function and applying privacy-preserving techniques, the framework effectively mitigates demographic biases without sacrificing recommendation quality or violating user privacy. This work provides a foundation for future developments in fair federated learning with GNNs, particularly in sensitive domains such as healthcare and finance.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Qiuli Jin
    &lt;ul&gt;
      &lt;li&gt;Affiliation: KAIST, &lt;a href=&quot;https://hfel.kaist.ac.kr/&quot;&gt;Human Factors and Ergonomics Lab&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Research Topics: Virtual Reality; Data science&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;7-references&quot;&gt;&lt;strong&gt;7. References&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;[1] Gupta, Manjul, Carlos M. Parra, and Denis Dennehy. “Questioning racial and gender bias in AI-based recommendations: Do espoused national cultural values matter?.” Information Systems Frontiers 24.5 (2022): &lt;a href=&quot;https://doi.org/10.1007/s10796-021-10156-2&quot;&gt;1465-1481&lt;/a&gt;.
[2] Himeur, Yassine, et al. “Latest trends of security and privacy in recommender systems: a comprehensive review and future perspectives.” Computers &amp;amp; Security 118 (2022): &lt;a href=&quot;https://doi.org/10.1016/j.cose.2022.102746&quot;&gt;102746&lt;/a&gt;.
[3] Kairouz, Peter, et al. “Advances and open problems in federated learning.” Foundations and trends® in machine learning 14.1–2 (2021): &lt;a href=&quot;https://www.nowpublishers.com/article/Details/MAL-083&quot;&gt;1-210&lt;/a&gt;.
[4] Wu, Chuhan, et al. “A federated graph neural network framework for privacy-preserving personalization.” Nature Communications 13.1 (2022): &lt;a href=&quot;https://doi.org/10.1038/s41467-022-30714-9&quot;&gt;3091.&lt;/a&gt;
[5] Lyu, He, et al. “Advances in neural information processing systems.” Advances in neural information processing systems 32 (2019): &lt;a href=&quot;https://par.nsf.gov/biblio/10195511&quot;&gt;1049-5258&lt;/a&gt;.
[6] Li, Yunqi, et al. “User-oriented fairness in recommendation.” Proceedings of the web conference 2021. (2021): &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3442381.3449866&quot;&gt;624-632&lt;/a&gt;.
[7] Chai, Di, et al. “Secure federated matrix factorization.” IEEE Intelligent Systems 36.5 (2020): &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9162459&quot;&gt;11-20&lt;/a&gt;.
[8] Wu, Shiwen, et al. “Graph neural networks in recommender systems: a survey.” ACM Computing Surveys 55.5 (2022): &lt;a href=&quot;https://dl.acm.org/doi/full/10.1145/3535101&quot;&gt;1-37&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;8additional-materials&quot;&gt;&lt;strong&gt;8.Additional materials&lt;/strong&gt;&lt;/h2&gt;
&lt;h2 id=&quot;8-additional-materials&quot;&gt;&lt;strong&gt;8. Additional Materials&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2312.10080&quot;&gt;Paper Link&lt;/a&gt;:&lt;/strong&gt; Access the full paper on arXiv.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/nimeshagrawal/F2PGNN-AAAI24&quot;&gt;GitHub Implementation&lt;/a&gt;:&lt;/strong&gt; Explore the implementation of F&lt;sup&gt;2&lt;/sup&gt;PGNN on GitHub.&lt;/li&gt;
&lt;/ul&gt;

</description>
            <pubDate>Sun, 13 Oct 2024 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/2024-10-13-No_prejudice!_Fair_Federated_Graph_Neural_Networks_for_Personalized_Recommendation.html</link>
            <guid isPermaLink="true">http://localhost:4000/2024-10-13-No_prejudice!_Fair_Federated_Graph_Neural_Networks_for_Personalized_Recommendation.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
    </channel>
</rss>
