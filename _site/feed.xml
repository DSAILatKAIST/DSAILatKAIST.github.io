<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>DSAILatKAIST.github.io</title>
        <description>Intended as a documentation theme based on Jekyll for technical writers documenting software and other technical products, this theme has all the elements you would need to handle multiple products with both multi-level sidebar navigation, tags, and other documentation features.</description>
        <link>http://localhost:4000/</link>
        <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Mon, 27 Mar 2023 14:44:50 +0900</pubDate>
        <lastBuildDate>Mon, 27 Mar 2023 14:44:50 +0900</lastBuildDate>
        <generator>Jekyll v3.9.2</generator>
        
        <item>
            <title>[ICML 2022] Deep Variational Graph Convolutional Recurrent Network for Multivariate Time Series Anomaly Detection</title>
            <description>&lt;p&gt;Write your comments&lt;/p&gt;

&lt;h1 id=&quot;1-motivation&quot;&gt;1. Motivation&lt;/h1&gt;

&lt;p&gt;제목에서 알 수 있듯, 본 논문의 목적은 Multivariate time series (MTS) data, 즉 여러개의 chanel에서 (ex. 센서) 발생하는 시계열 데이터의 이상치 탐지를 위한 모델을 제시하는 것 입니다. 저자들이 제시 하는 MTS에서의 이상치 탐지의 어려움 3가지는 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;MTS에서의 이상치는 시간적 (time series의 특성) 그리고 관계적 (multivariate의 특성) 변화 양쪽에 의해 모두 영향을 받음.&lt;/li&gt;
  &lt;li&gt;여러 chanel 중 몇몇은 noisy time series 일 가능성이 매우 높음.&lt;/li&gt;
  &lt;li&gt;MTS 데이터에는 deterministic 하지 않고 stochastic 한 움직임이 존재.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이러한 어려움을 해결하기 위해 저자가 제시하는 해결 방법은 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Reccurent 구조와 Graph 구조를 모두 가지고 있는 모델을 이용.&lt;/li&gt;
  &lt;li&gt;Hierarchical 구조를 이용하여 nosiy time series에 대한 강건성 (robustness)를 제고.&lt;/li&gt;
  &lt;li&gt;Probabilistic 모델링을 통해 stochastic한 움직임을 고려.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;저자들은 위 3가지 해결 방안을 모두 통합한 모델로서 Deep Variational Graph Convolutional Recurrent Network (DVGCRN)을 제시합니다. 해당 모델은 Deep Embedding-guided Probabilistic generative Network (DEPN)과 Stacked Graph Convolutional Recurrent Network (SGCRN)으로 이루어져 있는데, 여기서 EPN과 GCRN은 각각 3번과 1번 해결 방안을 맡고 있으며 Deep과 Stacked는 Hierarchical 구조를 의미합니다.&lt;/p&gt;

&lt;h1 id=&quot;2-proposed-model&quot;&gt;2. Proposed model&lt;/h1&gt;

&lt;h2 id=&quot;21-problem-definition&quot;&gt;2.1 Problem definition&lt;/h2&gt;

&lt;p&gt;본격적으로 해당 모델에 대해 이야기하기 전에 풀고자 하는 문제를 정확히 정의하도록 하겠습니다. 먼저 n번째 다변량 시계열(n-th MTS)를&lt;/p&gt;

\[x_n = \{x_{1,n},x_{2,n},...,x_{T,n}\} \in \mathbb{R}^{T \times V}, \ \text{where} \ n = 1,...,N\]

&lt;p&gt;으로 정의합니다. 여기서 &lt;em&gt;N&lt;/em&gt;는 관측치의 수, &lt;em&gt;T&lt;/em&gt;는 각 관측치의 time duration, 마지막으로 &lt;em&gt;V&lt;/em&gt;는 chanel의 수를 의미합니다.&lt;/p&gt;

&lt;p&gt;이제 MTS에서의 이상치 탐지는 주어진 데이터를 바탕으로 특정 시간과 특정 chanel에서의 관측치가 abnormal 한지를 판단하는 문제로 볼 수 정의할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;22-chanel-embedding&quot;&gt;2.2 Chanel embedding&lt;/h2&gt;

&lt;p&gt;MTS의 가장 큰 특징은 여러개의 chanel에서 시계열 데이터가 생성되고 그 chanel들은 서로 관계를 맺고 있다는 것입니다. 본 논문에서는 각 chanel의 특성을 embedding vector&lt;/p&gt;

\[\boldsymbol{\alpha}_i^{(0)} \in \mathbb{R}^{d}, i \in \{1,2,...,V\} \ \text{and} \  \boldsymbol{\alpha}^{(0)} = [\boldsymbol{\alpha}_i^{(0)},...,\boldsymbol{\alpha}_V^{(0)}],\]

&lt;p&gt;를 통해 표현합니다. 이제 각 chanel이 &lt;em&gt;d&lt;/em&gt;-dimension vector로 표현되기 때문에 chanel 사이의 관계는 embedding vector 간의 inner product를 통해 계산할 수 있습니다. 또한, 최종 모델은 deep (stacked) 모델, 즉 layer가 여러개인 모델이기 때문에 layer-wise embedding&lt;/p&gt;

\[\boldsymbol{\alpha}_i^{(l)} \in \mathbb{R}^{d}, l \in {1,...,L} \ \text{where} \ L: \text{number of layers},\]

&lt;p&gt;을 생각할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이러한 chanel embedding은 parameter로서 학습되는 것이며, chanel간의 stochastic한 관계를 모델링하기 위해&lt;/p&gt;

\[\boldsymbol{\alpha}_i^{(l)}  = \mathcal{N}(\hat{\boldsymbol{\mu}}_i^{l},\text{diag}(\hat{\boldsymbol{\sigma}}_i^{(l)})),\]

&lt;p&gt;즉 Gaussian distributed vector로 설정합니다. 이러한 chanel embedding은 이후 설명할 EPN, GCRN module 모두에서 사용됩니다.&lt;/p&gt;

&lt;h2 id=&quot;23-variational-graph-convolutional-recurrent-network&quot;&gt;2.3 Variational Graph Convolutional Recurrent Network&lt;/h2&gt;

&lt;p&gt;최종 모델인 DVGCRN을 다루기 전에 layer 개수가 하나인 VGCRN을 기준으로 모델을 설명하도록 하겠습니다. DVGCRN은 Motivation 섹션에서 언급한 robustness를 위해 VGCRN을 여러개 stack 한 것으로 VGCRN의 구조를 이해한다면 그 일반화로 이해할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이전에 말씀드렸다시피 VGCRN은 ENP과 GCRN으로 구성되어있기 때문에 각각에 대해 따로 설명하도록 하겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;231-embedding-guided-probablisitic-generative-network&quot;&gt;2.3.1 Embedding-guided Probablisitic generative Network&lt;/h3&gt;

&lt;p&gt;EPN은 probabilistic generative model로 다음과 같은 generation process를 가지고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/EPN.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서&lt;/p&gt;

\[\boldsymbol{z}_{t,n} \in \mathbb{R}^{K}\]

&lt;p&gt;은 Gaussian distributed probabilistic latent variable 이며,&lt;/p&gt;

\[\boldsymbol{h}_{t,n} \in \mathbb{R}^{K&apos;}, \ \boldsymbol{\beta} \in \mathbb{R}^{d \times K&apos;}\]

&lt;p&gt;는 각각 시계열적 특성을 반영하기 위해 GCRN에서 가져온 deterministic latent state 그리고 latent state를 embedding space로 mapping 하기 위한 행렬입니다.&lt;/p&gt;

&lt;p&gt;최종적으로 EPN은 probabilistic generative process에 chanel embedding을 사용함으로서 여러 chanel들 간의 복잡한 관계를 고려하면서 latent space를 학습할 수 있습니다. 또한, GCRN에서 가져온 deterministic latent state를 통해 시계열적인 특성까지 반영한 generation이 가능합니다.&lt;/p&gt;

&lt;h3 id=&quot;232-graph-convolutional-recurrent-network&quot;&gt;2.3.2 Graph Convolutional Recurrent Network&lt;/h3&gt;

&lt;p&gt;GCRN은 chanel 간의 inter-dependence를 추론하기 위해 data adaptive graph convolutional generation module을 먼저 사용합니다. 해당 module은 다음과 같은 형태를 가지고 있는데,&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/GCRN.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;chanel embedding과 EPN에서 추론한 latent vector가 사용됨을 알 수 있습니다. 여기서 &lt;em&gt;A&lt;/em&gt;를 symmetric한 adjacent matrix로 생각할 수 있고 (degree matrix &lt;em&gt;Q&lt;/em&gt;를 이용해 normalized), &lt;em&gt;W&lt;/em&gt;는 GCN filter를 의미합니다. 또한, temporal correlation을 발견하기 위해 GCN에 reccurent 구조,&lt;/p&gt;

\[\boldsymbol{h}_{t,n} = f_{\theta}(\boldsymbol{H}_{t,n}^{(1)},\boldsymbol{h}_{t-1,n})\]

&lt;p&gt;를 도입힙나다. 여기서 함수 &lt;em&gt;f&lt;/em&gt;는 non-linear transition function으로 LSTM을 통해 구현할 수 있습니다. 최종적으로 GCRN은 chanel간의 dependency와 temporal correlation을 고려함과 동시에 EPN의 latent vector를 사용함으로서 probabilistic한 특성까지 가질 수 있게 되었습니다.&lt;/p&gt;

&lt;h2 id=&quot;24-deep-variational-graph-convolutional-reccurent-network&quot;&gt;2.4 Deep Variational Graph Convolutional Reccurent Network&lt;/h2&gt;

&lt;p&gt;DVGCRN은 모델의 robustness를 위해 VGCRN에 layer를 겹겹이 쌓은 것으로 VGCRN의 일반화로 이해할 수 있습니다. VGCRN이 geneartion module EPN과 spatio-temporal module GCRN으로 이루어져 있기 때문에, 각각의 모듈에 대한 일반화인 Deep EPN과 Stacked GCRN으로 DVGCRN을 구성합니다.&lt;/p&gt;

&lt;p&gt;먼저, DEPN은 다음과 같은 구조를 가지고 있으며&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/DEPN.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SGCRN 역시 layer 단위의&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/SGCRN.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;구조를 가지고 있습니다. 각 역할은 EPN과 GCRN과 동일하기 때문에 자세한 설명은 생략하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;다만, hierarchical structure로 인해 고차원 layer에서 stochastic한 잠재변수가 prior distribution으로 collapse 하는 경우가 발생할 수 있습니다. 이를 막기 위해 deterministic-upward path 뿐만 아니라 input에서 direct하게 multi-layer latent representation으로 이어지는 다음과 같은 mapping을 이용합니다:&lt;/p&gt;

\[\hat{\mathbf{\mu}}_{t,n}^{(l)} = f(\mathbf{C}^{(l)}_{x \mu} \mathbf{x}_{t,n} + \mathbf{C}^{(l)}_{h \mu}\mathbf{h}_{t-1,n}) \ \text{and} \ \hat{\mathbf{\sigma}}_{t,n}^{(l)} = f(\mathbf{C}^{(l)}_{x \sigma} \mathbf{x}_{t,n} + \mathbf{C}^{(l)}_{h\sigma}\mathbf{h}_{t-1,n}).\]

&lt;p&gt;여기서 C로 표시된 matrix들은 모두 학습가능한 parameter입니다. 이제, latent feature와 stochastic-downward path를 통해 구한 prior를 함께 이용하여 latent space의 variational posterior를 구합니다:&lt;/p&gt;

\[q(\mathbf{z}_{t,n}^{(l)}) = \mathcal{N}(\mathbf{\mu}^{(l)}_{t,n}, \text{diag}(\mathbf{\sigma}^{(l)}_{t,n})),\]

&lt;p&gt;where&lt;/p&gt;

\[\mathbf{\mu}^{(l)}_{t,n} = \text{linear}(\hat{\mathbf{\mu}}_{t,n}^{(l)} + \mathbf{W}^{(l)}_{z \mu} \mathbf{z}^{(l+1)}_{t,n}) \ \text{and} \ \mathbf{\sigma}^{(l)}_{t,n} = \text{Softplus}(\text{linear}(\hat{\mathbf{\sigma}}_{t,n}^{(l)} + 1)).\]

&lt;p&gt;최종적으로 DVGCRN을 도식화하면 다음과 같이 나타낼 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/Figure_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DVGCRN 모델은 이름에서 알 수 있듯, variational inference를 통해 학습을 진행합니다 (ELBO 사용). 또한, generative model인 DEPN과 recurrent model인 SGCRN을 module로 사용하고 있기 때문에 각각 reconstruction loss과 forecasting loss를 combine 하여 loss function을 구성합니다. 최종적으로 ELBO는 다음과 같은 형태를 띄게 되는데,&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/ELBO.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;첫번째 term은 reconstruction loss, 두번째 term은 forecasting loss 그리고 마지막 term은 KL-Divergence로 이해할 수 있습니다. 두번째 term을 보면 앞에 hyperparameter를 통해 reconstruction loss와 forecasting loss 사이의 balance를 조절할 수 있음을 알 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;3-anomaly-detection-based-on-dvgcrn&quot;&gt;3. Anomaly detection based on DVGCRN&lt;/h1&gt;

&lt;p&gt;DVGCRN의 목적은 MTS 데이터의 unsupervised anomaly detection입니다. 이를 위해 다른 abnomaly detection 모델들과 유사하게, reconstruction probability와 prediction error를 합친 anomaly score를 이용하여 일정 threshold를 넘기면 abnormal로 판단합니다.&lt;/p&gt;

\[S_{t,n} = (S_{t,n}^r + \gamma(-S_{t,n}^p))/(1+\gamma) \ \text{where} \ \\
S_{t,n}^r = \text{log} \ p(\boldsymbol{x}_{t,n}|\boldsymbol{z}_{t,n}), \ S_{t,n}^{p} = (\boldsymbol{x}_{t,n} - \hat{\boldsymbol{x}}_{t,n})^2\]

&lt;p&gt;이때, multi-layer representation을 더 적극적으로 활용하기 위해 reconstruction score를 united conditional probability&lt;/p&gt;

\[\begin{aligned}
\hat{S}_{t,n}^r &amp;amp;= \cfrac{1}{L} \text{log} \ p \big(\boldsymbol{x}_{t,n}, \boldsymbol{z}_{t,n}^{(1)},...,\boldsymbol{z}_{t,n}^{(L-1)}| \boldsymbol{z}_{t,n}^{(L)} \big) \\ &amp;amp;= \cfrac{1}{L}(\text{log} \ p(\boldsymbol{x}_{t,n}|\boldsymbol{z}_{t,n}^{(1)})+ \sum_{l = 1}^{L-1} \text{log} \ p (\boldsymbol{z}_{t,n}^{l}|\boldsymbol{z}_{t,n}^{l+1}))
 \end{aligned}\]

&lt;p&gt;로 사용할 수도 있습니다.&lt;/p&gt;

&lt;p&gt;마지막으로 threshold의 경우 Peaks-Over-Threhold (POT) (Siffer et al., 2017)를 통해 구합니다. DVGCRN을 이용한 MST의 anomaly detection을 도식화 하면 다음과 같이 그릴 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/Figure_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;# 4. Empricial results&lt;/p&gt;

&lt;p&gt;마지막으로 본 논문은 실제 multivariate KPI 데이터인 DND와 public data 3개 (MD,MSL,SMAP)를 이용한 experiment 결과를 제시합니다. (각 data에는 ground-truth anomaly가 알려져 있음) 데이터에 대한 자세한 설명은 원문에 자세하게 나와있으니 리뷰에서는 따로 다루지 않겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;41-quantitative-comparison&quot;&gt;4.1 Quantitative comparison&lt;/h2&gt;

&lt;p&gt;먼저 quantitative comparison 입니다. quantitative comparison에 쓰인 metric은 Precision, Recall 그리고 F1 score 입니다.&lt;/p&gt;

&lt;p&gt;다음 그림은 DVGCRN의 hyperparameter 설정에 따른 score의 변화와 ablation study입니다.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/Figure_4,5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3-layer 모델에서 window size(T)가 클수록 성능이 개선 되는 것(왼쪽 그림)과 network의 사이즈와 무관하게 layer의 수가 클 수록 좋은 성능을 보이는 것(중간 그림)을 통해 deep network가 좋은 성능을 보이고 있음을 알 수 있습니다. 다만, embedding dimension의 경우 layer의 개수와 무관하게 너무 큰 값의 경우 성능이 하락하는 모습을 보이고 있습니다.&lt;/p&gt;

&lt;p&gt;Ablation study를 통해서는 graph와 recurrent 구조 모두 DVGCRN의 성능에 중요한 영향을 끼치고 있다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;다음 표는 여러 baseline method들과 DVGCRN을 비교한 결과입니다.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/Table_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;해당 표를 통해 모든 dataset에서 F1 score를 기준으로 proposed method들이 다른 baseline 모델들에 비해 훨씬 좋은 성능을 보이는 것을 확인할 수 있습니다. 이를 통해 MST의 stochastic 한 특성을 잡아냄과 동시에 chanel dependency를 고려하는 본 논문의 framework가 성공했음을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;Proposed method 내에서는&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;VGCRN-rec의 경우 loss function에 reconstruction loss만 사용하여 학습한 경우인데, 가장 낮은 성능을 보이는 것으로 보아 loss function에 forecasting loss를 추가한 것이 옳은 방향이었음을 알 수 있습니다.&lt;/li&gt;
  &lt;li&gt;또한, VGCRN에 비해 DVGCRN이 우월한 성능을 보여 hierarchical structure를 도입한 것이 실제로 robustness에 도움을 줬음을 확인할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;마지막으로 DVGCRN-M 모델은 section 3에서 언급한 united conditional probability를 reconstruction loss로 사용한 모델인데, 역시 가장 좋은 성능을 보여 해당 loss를 사용 하는 것이 학습에 도움이 되었음을 알 수 있습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;42-qulitative-comparison&quot;&gt;4.2 Qulitative comparison&lt;/h2&gt;

&lt;p&gt;다음으로는 실제 anomaly socre의 시각화를 통해 qualitative comparison을 진행합니다.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;140&quot; src=&quot;/images/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection/Figure_7.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Deterministic model인 LSTM-NTD 그리고 GNN의 경우 MTS의 stochastic property를 고려하지 않아 anomaly score가 굉장히 불안정한 모습을 확인할 수 있고, 다른 probabilistic model들인 Interfusion과 Omni Anomaly와 비교해봐도 MTS의 3가지 특성을 모두 고려한 VGCRN과 DVGCRN이 더욱 매끄럽고 안정적으로 anomaly를 찾아내는 것을 확인할 수 있습니다. 이는 quantitative comparison에서 보았던 결과와 일맥상통하는 모습으로 생각할 수 있습니다.&lt;/p&gt;

&lt;p&gt;또한, latent spcae의 log-likelihood를 시각화 해보아도 normal situation에서는 안정적인 모습을 보이다가 anormaly segment에서 불안정한 모습을 확인할 수 있는데, 이는 multi-layer structure의 채택이 좋은 전략임을 보이고 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h1&gt;

&lt;p&gt;본 논문은 Multivariate Time Series의 3가지 특성&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Temporal and chanel dependency&lt;/li&gt;
  &lt;li&gt;Existence of noisy chanels&lt;/li&gt;
  &lt;li&gt;Stochasticity&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;을 모두 고려한 Deep Variational Graph Convolutional Recurrent Network와 그 학습 방법을 제시합니다. 그리고, 실제 데이터를 이용한 quantitative comparison과 qualitative comparison을 통해 기존의 baseline 모델들에 비해 MTS의 unsupervised anomaly detection에 우수한 성능을 보임을 증명합니다.&lt;/p&gt;
</description>
            <pubDate>Sun, 20 Nov 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection.html</link>
            <guid isPermaLink="true">http://localhost:4000/Deep_Variational_Graph_Convolutional_Recurrent_Network_for_Multivariate_Time_Series_Anomaly_Detection.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[KDD 2020] ConSTGAT: Contextual Spatial-Temporal Graph Attention Network for Travel Time Estimation at Baidu Maps</title>
            <description>&lt;h1 id=&quot;constgat&quot;&gt;ConSTGAT&lt;/h1&gt;

&lt;h1 id=&quot;10--introduction&quot;&gt;1.0  Introduction&lt;/h1&gt;

&lt;p&gt;우리가 일상에서 사용하는 네비게이션의 역할은 도착 시간을 예측하는 것 입니다. 흔히들 도착시간 예측을 TTE(Travel Time Estimation)이라고 하는데요. 이는 네비게이션 / 라이드헤일링 / 경로예측 등등 도로 상황을 이해하고 대응하려는 다방면의 분야에서 중요하게 다뤄지는 주제입니다. 한편으로 정확하면서도 효율적으로 TTE문제를 푸는 것은 쉽지 않은데요. 이 페이지에서 다룰 논문은 이 문제를 해결하여 실제로 바이두맵에서 적용되고 있는 알고리즘입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Figure_1.png&quot; alt=&quot;Figure 1.PNG&quot; /&gt;&lt;/p&gt;

&lt;p&gt;TTE 태스크가 풀어야 하는 문제는 크게 두가지입니다. 정확한 예측이 어렵다는 점, 그리고 주변 정보를 고려하기 어렵다는 점입니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Accuracy of Traffic Prediction :&lt;/strong&gt; 루트(경로)는 여러개의 링크(도로)로 구성되어 있는데요.전체 소요 시간은 루트 안의 각 도로 세그먼트의 교통량에의해 좌우되겠습니다. 특히 시작점으로부터 떨어져 있을수록 예측이 더 어렵다는 문제가 있습니다.&lt;/p&gt;

    &lt;p&gt;TTE문제를 다뤄왔던 기존 알고리즘인 &lt;strong&gt;ST-GNN&lt;/strong&gt; 의 경우 Spatial / Temporal 정보가 네트워크 안에서 각각 독립적으로 이용되기 때문에 두 정보의 상관성을 최대한 활용하지 못하고 있는 상황입니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Considering Contextual Info :&lt;/strong&gt; 예측 시간은 인접한 두 링크의 관계도 큰 상관이 있는데요, 가령 좌회전과 우회전에 걸리는 속도가 다르다던지, 교차로의 상태가 어떠한가도 큰 영향을 미치게 됩니다. 이 문제를 푸는데 두가지 접근법이 있습니다.&lt;/p&gt;

    &lt;p&gt;첫 번째 가장 기본적인 &lt;strong&gt;Segment-based Approache&lt;/strong&gt;가 있습니다. 단순히 각각의 도로 세그먼트들을 독립적으로 계산해 합산하는 방식이라, 효율적이긴 하지만 contextual information를 무시한다는 맹점이 있습니다.&lt;/p&gt;

    &lt;p&gt;두 번째 방법인 &lt;strong&gt;End-to-end Approaches&lt;/strong&gt;입니다. 앞선 방법과 달리 루트의 모든 링크와 연결점들을 감안하여 전체를 한번에 계산합니다. 따라서 순차적으로 학습하기 위해 Sequence Encoding을 하다보니 연산속도가 현저히 느려진다는 단점이 있습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;따라서 이 논문에서는 위에 언급된 &lt;strong&gt;(1)Traffic Prediction&lt;/strong&gt; 과 &lt;strong&gt;(2)Contextual Info&lt;/strong&gt; 의 문제를 동시에 해결하고자 ConSTAGAT라는 모델을 제안합니다. &lt;strong&gt;(1) Traffic Prediction&lt;/strong&gt; 차원에서 이 모델은 시간적, 공간적 데이터 결합해 둘 사이의 상관성을 충분히 학습하도록 Spatio-temporal GNN에 Graph Attention Mechanism을 사용하고, &lt;strong&gt;(2) Contextual Info&lt;/strong&gt; 면에서는 주변정보를 효율적으로 수집하기 위해 Convolution을 활용하도록 했습니다. 마지막으로 이 두 솔루션을 합치는 과정에서 Multi-task Learning으로 퍼포먼스를 증대시키도록 했습니다.&lt;/p&gt;

&lt;p&gt;이 논문은 크게 세 가지 점에서 Contribution을 하고 있는데요:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Potential Impact :&lt;/strong&gt; 산업적 솔루션으로서 end-to-end neural framework 제시한 것으로 수천만건의 요청을 처리할 수 있다는 것 입니다. 실제로 바이두맵에 ConSTGAT가 적용되어 운영되고 있다는 점이 이 사실을 증명합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Novelty :&lt;/strong&gt; 시간과 공간의 정보를 밀접하게 활용하기 위해 Spatial-temporal graph attention network를 개발하고 적용했다는 점, 그리고 contextual info를 효율적으로 처리하게 위해 convolution과 Multi-task Learning을 적용했다는 점에서 학계에 기여한다는 점.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Technical Quality :&lt;/strong&gt; 거대한 현실 트래픽 데이터로 성능을 검증했다는 점 그리고 바이두맵에 성공적으로 적용해 실사용되고 있다는 점에서 실용적이고 robust한 TTE 솔루션이라는 점입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;20--preliminary&quot;&gt;2.0  Preliminary&lt;/h1&gt;

&lt;p&gt;본격적으로 설명하기 앞서, 두 가지 사항을 짚고 넘어가도록 하겠습니다. Notation 및 필요한 데이터를 확인하고, 추출하려는 대상이 무엇인지 파악하도록 합니다.&lt;/p&gt;

&lt;h2 id=&quot;21-notation&quot;&gt;2.1 Notation&lt;/h2&gt;
&lt;p&gt;이 모델에 사용되는 데이터는 크게 네트워크에 해당되는 그래프 &lt;strong&gt;$G$&lt;/strong&gt; / 데이터셋 &lt;strong&gt;$D$&lt;/strong&gt; 이 있습니다. 후술할 실험과정에 사용되는 Taiyuan, Hefei, Huizhou 세 도시의 로그데이터 샘플값도 &lt;strong&gt;$G$&lt;/strong&gt; 와 &lt;strong&gt;$D$&lt;/strong&gt; 를 포함하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/52244004/195804203-91877da2-3bdb-4376-81f1-bbefe876f9fe.PNG&quot; alt=&quot;Notation_01&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;22-feature-extraction&quot;&gt;2.2 Feature Extraction&lt;/h2&gt;

&lt;p&gt;학습을 위해 사용하는 특성들은; Road Network / Historical Traffic Conditions / Background Info 세 가지가 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Road Network&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Road Network는 링크 사이의 관계를 표현합니다. 특히 다음 여덟가지가 feature로 구성됩니다 : ID, Length, Width, # of lanes, Type, Speed Limit, Type of Crossing, Kind of Traffic Light. 여기에 추가적으로 링크 간의 지리적 관계를 표현하기 위해 graph structure을 활용합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Historical Traffic Conditions&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;과거 데이터로부터 주어진 링크 $l$에 대한 타임 슬롯 $t$ 의 평균/중앙값을 feature로 추출합니다. 이 연구에서 사용되는 타임 슬롯은 5분 간격입니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Background Information&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;TTE는 수 많은 다른 배경 정보에도 영향을 받을 수 있는데요. 가령 출발시간이 러시아워이거나, 주중이거나, 혹은 다른 시간 관련 특징에 따라 다른 결과를 낼 수 있기 때문입니다. 따라서 이러한 시간 관련 특징도 사용하게 됩니다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;$x_i^{(B)}$ : $i$번째 링크의 배경정보&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;30--constgat&quot;&gt;3.0  ConSTGAT&lt;/h1&gt;

&lt;h2 id=&quot;31-framework&quot;&gt;3.1 Framework&lt;/h2&gt;

&lt;p&gt;본격적으로 ConSTGAT 모델의 구조로 들어가도록 하겠습니다. ConSTGAT는 크게 &lt;em&gt;Contextual Information&lt;/em&gt;, &lt;em&gt;Traffic Prediction&lt;/em&gt; 모듈로 정보를 취합하고, &lt;em&gt;Integration&lt;/em&gt; 모듈을 통해 두 모듈을 합치고 예측하는 식 입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Figure_2.png&quot; alt=&quot;Figure 2.PNG&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Traffic Prediction 모듈 :&lt;/em&gt;&lt;/strong&gt; 시간과 공간 데이터, 그리고 그 둘의 상관성을 포착하기 위한 모듈로, 이 논문에서 제시하는 새로운 방법인 spatial-temporal graph attention network을 통해 진행됩니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Contextual Information 모듈 :&lt;/em&gt;&lt;/strong&gt;  Contextual Info를 잡아내는 데 활용되는 모듈로, 인접한 링크의 관계를 포착하기 위해 Convolution을 활용합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Integration 모듈 :&lt;/em&gt;&lt;/strong&gt; Traffic Prediction 모듈, Contextual Information 모듈, 그리고 Background 정보까지 모든 잇풋을 취합해 예측을 하는 모듈로, Multi-task Learning으로 효율적으로 계산하는 모듈입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;32-traffic-prediction-module&quot;&gt;3.2 Traffic Prediction Module&lt;/h2&gt;

&lt;p&gt;우선 첫 번째로 Traffic Prediction Module을 살펴보겠습니다. 한 링크의 교통 상황은 해당 링크의 과거 이력과 주변 이웃 링크와 큰 상관관계가 있습니다. 가령 한 링크의 교통량이 많아지면 주변 노드들의 교통량도 잇따라 많아지는 상황 같은 것이지요. 이러한 상황을 예측을 하기 위한 방법으로 STGNN이 활용되어 왔지만, 공간정보와 시간정보가 개별적으로 활용된다는 단점이 있었습니다. ConSTGAT는 이 정보의 상관성까지도 활용하기 위해, 공간정보와 시간정보를 동시에 다루는 방법인 Spatial-temporal graph attention network를 제안합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Figure_3.png&quot; alt=&quot;Figure 3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Traffic Prediction 모듈은 교통 히스토리, 그래프&lt;strong&gt;$G$&lt;/strong&gt; , 출발시간 s 를 인풋으로 받아 앞으로의 교통상황을 예측합니다. 여기서 시간-공간 관계를 포착하기 위해 Graph attention n
etwork의 일종인 3D-attention mechanism 을 사용합니다. 그리고 결과적으로 1번 식과 같이 출발시간 이수 $T_{f}$개의 타임슬롯에 대한 교통상황을 예측하도록 하는 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/52244004/195804388-b1867422-7761-4e39-8aa5-7ebda292ca9f.PNG&quot; alt=&quot;Notation_02&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이를 구현하기 위한 단계는 크게 3개 단계가 있겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1단계 ) ST-tensor 추출하기 : 시간-공간 관계 표현&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이를 진행하기 위해 우선 Spatial-temporal tensor $X_i^{^{(MST)}}$을 추출합니다.  $X_i^{^{(MST)}}$는 교통 히스토리  $X^{(ST)}_i$, 이웃 링크 특성 $X^{(S)}_i$, 타임슬롯 특성$X^{(T)}$ 행렬을 결합함으로써 얻을 수 있습니다. 세부 내용은 아래를 참조하세요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/52244004/195804461-a99865c6-1724-4403-9bff-d0d903371aed.PNG&quot; alt=&quot;Notation_03&quot; /&gt;&lt;/p&gt;

&lt;p&gt;조금 더 구체적으로 들어가자면, $k$번째 타임슬롯에서 링크 $i$의 이웃인 링크 $j$의 시공간 행렬은 Concat을 통해 구현될 수 있고, 이를 통해 기존의 행렬이 3D-tensor로 변환됩니다. 이 3D-tensor는 $l_i$에서의 교통상황을 예측할 spatio-temporal tensor (ST-tensor)를 만들기 위해서 반드시 가져야 할 형태이기도 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/52244004/195804513-869f2f04-d4e7-4d96-a53d-e7557daf9d88.PNG&quot; alt=&quot;Notation_04&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2단계 ) Attention Mechanism으로 시간과 공간의 연관 정보 추출하기 : 교통상황 파악&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이 단계에선 시간과 공간 관계를 포착하기 위해 새로운 3D-attention 메커니즘을 제안하고 있습니다. 어텐션 메커니즘을 수행하려면 key, value, query가 필요한데요. 각각 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Query : Contextual Information $x^{(CI)}_{i,w}$ , Background Information $x^{(B)}_i$&lt;/li&gt;
  &lt;li&gt;Key : ST-tensor $X^{(MST)}_{i,j,k}$&lt;/li&gt;
  &lt;li&gt;Value : ST-tensor $X^{(MST)}_{i,j,k}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이를 바탕으로 3D-attention은 다음과 같이 전개됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/52244004/195804543-f44a6c2f-79d6-4d6d-9949-764b1614bd8b.PNG&quot; alt=&quot;Notation_05&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이에 따라 링크 $l_i$에서 지난 교통 히스토리와 query간의 관계는 8번 식에 따라  $x_i^{(TC)}=Attention(Q_i, K_i, V_i)$ 로 정리될 수 있습니다. 따라서 이렇게 3D-attention으로 구현한 GNN을 “3DGAT”라 부릅니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3단계 ) Masking Mechanism으로 Robustness 개선하기&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이러한 모델을 학습하는 경우, 종종 약한 시그널 때문에 교통 상태 정보가 사라지게 되는 경우도 있는데요, 이러한 문제를 해결하고 모델의 robustness를 개선하기 위해 이 논문은 Masking Mechanism도 제안합니다. Masking은 NLP 분야에서 성능이 입증된 바 있습니다.&lt;/p&gt;

&lt;p&gt;학습단계에서 랜덤하게 과거 교통 컨디션의 10%에 mask를 씌우는 것인데, 보다 구체적으로는 $req=(r,s)$에서 $c_i^t \;(i\in[1,m], t\in[s-T_h,s-1])$의 10%를 제로 벡터로 만드는 것입니다. 이렇게 뉴럴네트워크에 노이즈를 넣어 과적합을 방지하고, 모델의 generalization을 개선하려는 목적입니다.&lt;/p&gt;

&lt;h2 id=&quot;33-contextual-information-module&quot;&gt;3.3 Contextual Information Module&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Figure_4.png&quot; alt=&quot;Figure 4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 섹션에서는 : Convolution을 통해 주변 정보를 효율적으로 학습하는 Contextual Information Module과, Multi-task Learning을 하는 Integration Module을 다룹니다. 총 4개 단계로 이루어질 수 있는데요.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1단계 )&lt;/strong&gt; &lt;strong&gt;Contextual Information Module : 주변정보 인코딩&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;여기에서 주변정보, Contextual Information이라 함은, 두 링크 사이의 각도, 중심도로와 보조도로와의 관계 등을 말합니다. 이 주변정보는 travel time을 예측하는데 중요한 역할을 합니다. 여기에서는 루트에 포함된 모든 링크의 travel time을 예측하는데요, 그럴 때 루트 안의 주변 노드의 정보를 활용함으로써 예측 성능을 높이는 식입니다. 주변 노드는 sub-path라고 정의되며, 다음과 같이 표현합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$p_{i,w}=[l_{i-w},\cdot\cdot\cdot, l_{i-1}, l_{i}, l_{i+1},\cdot\cdot\cdot,l_{i+w}]$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기에서 $i$는 계산할 대상 링크이고, $w$는 주변정보를 고려하는 window 크기를 말합니다. 가령, $w=0$ 이라면, 링크 $i$의 정보만을 고려하는 것 입니다. 이런 경우에는 segment-base method와 같은 설정이 되겠습니다. 만약 $w\rightarrow \infin$ 이라면, 루트 $r$의 모든 링크들이 고려 대상이 되고, 이는 vanilla end-to-end method와 같은 설정이 되겠습니다.&lt;/p&gt;

&lt;p&gt;이처럼 이 모델은 특정 링크의 travel time은 주변 노드의 상황으로부터 영향을 받는다는 가정을 깔고 있는데, 이런 상황에서 CNN은 주변 정보, 즉 지역적 의존성을 수집하기 효율적인 방법입니다. 다음과 같이 $l_i$의 주변 정보를 인코딩 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/52244004/195804610-c4ff1423-8eaa-4efe-aecc-ff270434c786.PNG&quot; alt=&quot;Notation_06&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 도출된 주변 정보 인코딩은 앞서 살펴보았던 Traffic Prediction Module의 쿼리와 Integration Module에 사용됩니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2단계 ) Integration Module : Travel Time 예측&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이제 최종 예측을 위한 모듈인 Integration Module만 남았습니다. 이 단계에서는 Traffic Prediction Module $x_{i}^{(TC)}$, Context Information Module $x_{i,w}^{(CI)}$, Background Information $x_{i}^{(B)}$ 이 세개로부터 인풋을 받습니다. 이렇게 받은 인풋은 그림과 같이 Concatenation을 거쳐 Multiple Fully-connected Layer을 지나 루트안에 있는 모든 링크의 travel timed을 예측합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/52244004/195804664-6a31f149-7ab7-4fbb-9362-c2c243b52d12.PNG&quot; alt=&quot;Notation_07&quot; /&gt;&lt;/p&gt;

&lt;p&gt;각각 계산된 링크들의 travel time을 모두 더해 전체 루트의 travel time을 구하므로써 끝이 납니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/52244004/195804804-a7e26d78-f6c8-47a6-83f7-c239d4a27b13.PNG&quot; alt=&quot;Notation_08&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3단계 ) Loss 계산&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이렇게 도출된 예측 Travel time을 기반으로 Loss function을 구축하게 되는데요. 서로 다른 방식인 Segment-based method와 End-to-end method의 장점을 한번에 녹이기 위해, 지금까지 계산한 값에 대해 각각의 방식에 따른 Loss Function을 적용합니다.&lt;/p&gt;

&lt;p&gt;Segment-based method 차원에서 사용한 손실함수는 Huber Loss로, 루트 안에 포함된 모든 각각의 링크의 travel time에 대해 계산합니다. 한편, End-to-end method 차원에서 사용한 손실함수는 APE로, 합산된 루트의 travel time에 대해 계산합니다. 이 두 방식을 한번에 담은 손실함수는 다음과 같고, 이 손실함수를 최소화 하는 방향으로 학습이 진행됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/52244004/195804769-700a8888-55a5-4389-883f-a244787cae9e.PNG&quot; alt=&quot;Notation_09&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4단계 ) 현실 적용&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Baidu Maps의 네비게이션은 하루에 몇백만건을 처리해야 하는데, 이런 상황에서는 반응 시간이 매우 중요합니다. 하지만 대부분 높은 정확도를 가진 모델들은 연산시간이 오래 걸리는 End-to-end 방식을 사용하기 때문에 어플리케이션을 스케일업 하기가 어려운 상황입니다.&lt;/p&gt;

&lt;p&gt;정확도를 높게 가져가면서도, 연산의 효율성을 보장하기 위해, 이 논문에서는 segment-based method의 방법을 채택합니다. segment-based method처럼 링크 하나하나의 travel time을 단순 합산하되, 그 값들을 미리 계산해둠으로써 시간을 아끼는 방식입니다. 크게 두 스텝이 필요합니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;$G$&lt;/strong&gt; 에 포함된 모든 링크 &lt;strong&gt;$L$&lt;/strong&gt; 각각의 travel time과 관련 데이터를 병렬로 계산해 look-up 테이블에 저장합니다.
    &lt;ul&gt;
      &lt;li&gt;이때, 링크와 연결된 이웃링크 &lt;strong&gt;$P(l)$&lt;/strong&gt; 를 감안해 걸리는 시간까지 함께 계산합니다. 1단계에서 진행한 w를 고려한 만큼 계산하게 됩니다.&lt;/li&gt;
      &lt;li&gt;또한 history에 존재하는 서로 다른 출발시간에 대하여도 위의 모든 정보를 계산합니다: $s, s+1, \cdot\cdot\cdot , s+T_f-1$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;위의 계산을 사전에 저장해 둔 뒤, 유저로부터 request가 도착하면, 요청에 해당되는 링크들의 travel time이 저장되어있는 look-up 테이블에서 정보를 불러와 후보 경로(루트)들이 되도록 합산합니다.
이러한 방식으로 정확하면서도 효율적인 TTE가 가능하도록 하는 것입니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;40--experiments&quot;&gt;4.0  Experiments&lt;/h1&gt;

&lt;p&gt;이렇게 디벨롭된 모델의 실제 성능은 어떨까요? 실제 데이터셋을 통해 검증한 결과를 살펴봅시다.&lt;/p&gt;

&lt;h3 id=&quot;41-experimental-settings&quot;&gt;4.1 Experimental Settings&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;사용한 데이터셋&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;2019년 7월 한달 실제 바이두맵의 Taiyuan, Hefei, Huizhou 세 도시의 로그 데이터 샘플링 값&lt;/li&gt;
      &lt;li&gt;첫 4주 간의 데이터는 Training 용으로, 마지막 1주 간의 데이터는 Testing 용으로 분리&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;평가지표&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;회귀 문제에 널리 활용되는 평가 지표인 MAPE / MAE / RMSE 사용&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Table_1.png&quot; alt=&quot;Table 1.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;42-methods-for-comparison&quot;&gt;4.2 Methods for Comparison&lt;/h3&gt;

&lt;p&gt;비교를 위해 사용한 모델 목록입니다. *표시 되어있는 모델이 ConSTGAT모델입니다.&lt;/p&gt;

&lt;p&gt;| Baselines | Description |
| — | — |
| AVG | 2016 각 도시별 평균속도
 |
| DeepTravel | (1) 시간 / 공간 특성 추출
(2) bi-directional LSTM 적용 |
| STANN | (1) Graph Attention으로 공간 특성 추출
(2) LSTM &amp;amp; Attention으로 시간 특성 추출&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;하지만 계산 과정에서 이웃 링크만 고려하는게 아니라 모든 링크를 계산한다는 단점 존재 |
| DCRNN | (1) GCN으로 공간 특성 추출
(2) LSTM으로 시간 특성 &amp;amp; Dependency 추출 |
| GAT+Attention* | (1) Graph Attention Network으로 공간 특성 추출
(2) Attention으로 공간특성 추출
→ 각각 공간 / 시간 특성 별도로 취급
 |
| 3DGAT* | (1) Graph Attention Network으로 공간 특성 추출
(2) Attention으로 공간특성 추출
→ 각각 공간 / 시간 특성 동시에 취급 |&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;43-experimental-results&quot;&gt;4.3 Experimental Results&lt;/h3&gt;

&lt;h4 id=&quot;431-overall-evaluation&quot;&gt;4.3.1 Overall Evaluation&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Table_2.png&quot; alt=&quot;Table 2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ConSTGAT 는 모든 데이터셋에 대해, 다른 모든 모델의 성능을 압도합니다.&lt;/p&gt;

&lt;h4 id=&quot;432-spatial-temporal-graph-neural-networks&quot;&gt;4.3.2 Spatial-Temporal Graph Neural Networks&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Table_3.png&quot; alt=&quot;Table 3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;일반적인 STGNN은 전체 루트를 예측하기보다, 특정 링크를 예측하는데 최적화 되어 있습니다. 따라서 STGNN모델들간에 링크를 예측하는 지엽적인 실험도 진행되었는데요. 마찬가지로 ConSTGAT가 다른 모델을 압도하고 있는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;*3DGAT는 이 실험을 위해 최적화된 $w=0$인 ConSTGAT의 또 다른 버전.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Figure_5.png&quot; alt=&quot;Figure 5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Spatial 정보와 Temporal 정보간의 상관관계를 보기 위해 Attention Weight의 행렬을 그린 것입니다. 특정 링크 $l$과 자신을 포함한 9개의 이웃들을 5분의 타임슬롯 위에서 비교했는데요. 행렬과 결과에 대한 설명입니다 :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;ROW : itself-자기 자신&lt;/td&gt;
          &lt;td&gt;downstream 앞으로 갈 링크&lt;/td&gt;
          &lt;td&gt;upstream 지나온 링크&lt;/td&gt;
          &lt;td&gt;other 나머지&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;COLUMN : 첫번째 열 - 최신 타임슬롯&lt;/td&gt;
          &lt;td&gt;마지막 열 - 가장 나중 타임슬롯&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;COLOR : 어두운 색 - 링크 $l$에 적합함&lt;/td&gt;
          &lt;td&gt;옅은 색 - 링크 $l$에 적합하지 않음&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;분석결과는 첫 번째로 Downstream 링크들이 링크 $l$에 더 적합한 것으로 확인되었고, 두 번째로는 교통 기록이 더 많거나, 더 긴 travel time을 가진 링크가 예측에 더 중요한 역할을 한다는 것을 확인했습니다.&lt;/p&gt;

&lt;h4 id=&quot;433-contextual-information&quot;&gt;4.3.3 Contextual Information&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Figure_6.png&quot; alt=&quot;Figure 6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;한 루트에서 contextual information의 영향이 얼마나 중요할지 알아본 분석인데요. 이 분석을 하기 위해 ConSTGAT의 contextual window size를 바꿔가며 travel time을 예측해 보았습니다. window size의 의미는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$w=0$ : Segment-based method와 똑같다. 계산 시 어떠한 주변 정보도 고려하지 않음&lt;/li&gt;
  &lt;li&gt;$w&amp;gt;0$ : 클 수록 주변 링크의 정보를 활용해 계산&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;결과적으로 주변 정보를 활용할수록 RMSE가 감소하는 것으로 보아 모델의 퍼포먼스가 개선되는 것으로 확인되었습니다. (단 Hefei의 경우 딱히 그런것 같진 않네요.)&lt;/p&gt;

&lt;h4 id=&quot;434-robustness&quot;&gt;4.3.4 Robustness&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps/Figure_7.png&quot; alt=&quot;Figure 7.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 Masking이 모델의 robustness를 개선시키는지 확인하는 테스트입니다. 마스크 비율의 의미는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Train mask rate = 0% : 모든 정보를 알되, 일부 노이즈가 있는 정도&lt;/li&gt;
  &lt;li&gt;Train mask rate = 100% : 모든 기존 교통 컨디션은 알지 못하고, contextual info와 background info만 있는 상태&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;결과적으로 Train mask rate 10%인 상황이 아닌상황보다 RMSE가 전반적으로 낮게 나오는 것을 확인할 수 있습니다. 따라서 Masking은 모델의 robustness를 개선하는데 도움이 된다고 볼 수 있겠네요.&lt;/p&gt;

&lt;h1 id=&quot;50--conclusion&quot;&gt;5.0  Conclusion&lt;/h1&gt;

&lt;p&gt;이 논문에은 효율적인 end-to-end STGNN모델인 ConSTGAT를 제안합니다. 기존 모델들이 (1)Traffic prediction 과 (2)Contextual information를 수집하고 가공하는데 가졌던 문제를 해결하기 위해, Spatial / Temporal 의 연관성을 깊게 가져간 3D-attention 메커니즘을 개발했습니다. 또한 주변 정보를 효율적으로 습즉하기 위해 루트의 정보를 convolution을 통해 습득했고, 나아가 퍼포먼스를 개선하기 위해 Multi-task Learning을 도입했습니다.&lt;/p&gt;

&lt;p&gt;이 모델을 기반으로 Segment-based 방법에서 힌트를 얻어, 각각의 링크에 대한 travel time을 계산을 동시에 그리고 미리 계산하는 식으로 최종 travel time을 예측하는 프로세스까지. 유저 차원에서의 사용성까지 고려된 모델입니다.&lt;/p&gt;

&lt;p&gt;거대 스케일의 현실 데이터를 활용한 실험을 통해 ConSTGAT의 우수성을 증명했고, 또 ConSTGAT는 바이두맵에 실제로 사용되는 알고리즘이기 때문에 실용적이며 안정적인 방법론이라고 할 수 있겠습니다.&lt;/p&gt;
</description>
            <pubDate>Sun, 20 Nov 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps.html</link>
            <guid isPermaLink="true">http://localhost:4000/ConSTGAT_Contextual_Spatial_Temporal_Graph_Attention_Network_for_Travel_Time_Estimation_at_Baidu_Maps.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>Graph Neural Controlled Differential Equations for Traffic Forecasting</title>
            <description>&lt;h1 id=&quot;paper-review-of-graph-neural-controlled-differential-equations-for-traffic-forecasting&quot;&gt;&lt;strong&gt;Paper-Review of “Graph Neural Controlled Differential Equations for Traffic Forecasting”&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;&lt;strong&gt;1. Introduction&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Recent advances in data acquisition technology help collect a variety of spatio-temporal (ST) data in urban areas, such as urban traffic, air quality, and etc. Such data has complex spatial and temporal correlations, which can be depicted by spatio-temporal graphs(STG), as shown in Fig. 1. For example, spatio-temporal data describes various things and movements as $[x, y, h, t]$. Take the geodetic coordinate system (rectangular coordinate system) as an example to describe, that is $[longitude, latitude, altitude, time]$. This can describe almost all kinds of things. As small as the trajectory of a car, the process of building construction, and as large as the movement of plates, they can all be abstracted as $[x, y, h, t]$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Graph_Neural_Controlled_Differential_Equations_for_Traffic_Forecasting.assets/picfig3.jpeg&quot; alt=&quot;picfig3&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 1: ST data and the related ST graph structure in urban areas&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For instance, the traffic forecasting task( Forecasting highway traffic volume(i.e., # of vehicles) ) launched by California Performance of Transportation (PeMS) is one of the most popular problems in the area of spatio-temporal processing.&lt;/p&gt;

&lt;p&gt;For this task, a diverse set of techniques have been proposed. The most important is Neural controlled differential equations (NCDEs), which are a breakthrough concept for processing sequential data.&lt;/p&gt;

&lt;p&gt;In this paper, the author presents the method of spatio-temporal graph neural controlled differential equation (STG-NCDE). They extend the concept and design two NCDEs: one for the temporal processing and the other for the spatial processing. After that, they combine them into a single framework.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;2. Motivation&lt;/h2&gt;

&lt;p&gt;It has not been studied yet how to combine the NCDE technology (i.e., temporal processing(because NCDE technology is good at time-series tasks)) and the graph convolutional processing technology (i.e., spatial processing(because graph is good at constructing position and distance)) to solve the spatio-temporal forecasting problem.&lt;/p&gt;

&lt;h2 id=&quot;3-proposed-method&quot;&gt;3. Proposed Method&lt;/h2&gt;

&lt;p&gt;Time-series of graphs:&lt;/p&gt;

\[\{\mathcal{G}_{t_i} \overset{\text{def}}{=} (\mathcal{V},\mathcal{\varepsilon},\boldsymbol{F}_i,t_i)\}_{i=0}^N ...(1)\]

&lt;p&gt;where $\mathcal{V}$ is a ﬁxed set of nodes, $\mathcal{\varepsilon}$ is a fixed set of edges, $t_i$ is a time-point when $\mathcal{G}_{t_i}$ is observed, and $\boldsymbol{F}_i \in \mathbb{R}^{\vert \mathcal{V} \vert \times D}$ is a feature matrix at time $t_i$ which contains $D$-dimensional input features of the nodes, the spatio-temporal forecasting is to predict $\hat{\boldsymbol{F}} \in \mathbb{R}^{\vert \mathcal{V} \vert \times S \times M}$&lt;/p&gt;

&lt;p&gt;For example, when we predict the trafﬁc volume for each location of a road network for the next $S$ timepoints (or horizons) given past $N + 1$ historical traffic patterns, where $\vert\mathcal{V}\vert$ is the number of locations to predict and $M = 1$ because the volume is a scalar(i.e., # of vehicles)&lt;/p&gt;

&lt;p&gt;Here is the NCDEs, which are considered as a continuous analogue to recurrent neural networks (RNNs), can be written as follows:&lt;/p&gt;

\[\begin{split}     		
		z(T)     		
		&amp;amp;=z(0)+\int_0^Tf(z(t);\theta_f)dX(t)
		\\    		
		&amp;amp;=z(0)+\int_0^Tf(z(t);\theta_f)\frac{dX(t)}{dt}dt ...(2)
	\end{split}\]

&lt;p&gt;where $X$ is a continuous path taking values in a Banach space. The entire trajectory of $z(t)$ is controlled over time by the path $X$. The path $X$ is created from ${(t_i,x_i)}_{i=0}^N$ by an interpolation algorithm.&lt;/p&gt;

&lt;h4 id=&quot;31-overall-design&quot;&gt;3.1 Overall design&lt;/h4&gt;

&lt;p&gt;Pre-processing and main processing steps as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Its pre-processing step is to create a continuous path $X^{(v)}$ for each node $v$, where $1 \leq v \leq \vert\nu\vert$, from ${F_i^{(v)}}_{i=0}^N$. $F_i^{(v)} \in \mathbb{R}^D$ means the $v$-th row of $F_i$, and $F_i^{(v)}$ stands for the time-series of the input features of $v$.&lt;/li&gt;
  &lt;li&gt;The above pre-processing step happens before training their model. Then, their main step, which combines a GCN and an NCDE technologies, calculates the last hidden vector for each node $v$, denoted $z^{(v)}(T)$.&lt;/li&gt;
  &lt;li&gt;After that, they have an output layer to predict $\hat{y}^{(v)} \in \mathbb{R}^{S \times M}$ for each node v. After collecting those predictions for all nodes in $\nu$, they have the prediction matrix $\hat{Y} \in \mathbb{R}^{\vert\nu\vert \times S \times M}$.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;32-graph-neural-controlled-differential-equations-stg-ncde&quot;&gt;3.2 Graph neural controlled differential equations (STG-NCDE)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Temporal processing&lt;/p&gt;

    &lt;p&gt;The first NCDE for the temporal processing can be written as follows:&lt;/p&gt;

\[h^{(v)}(T) = h^{(v)}(0) + \int_0^Tf(h^{(v)}(t);\theta_f)\frac{dX^{(v)}(t)}{dt}dt ...(3)\]

    &lt;p&gt;where $h^{(v)}(t)$ is a hidden trajectory (over time $t \in [0,T])$ of the temporal information of node $v$.&lt;/p&gt;

    &lt;p&gt;Eq. (3) can be equivalently rewritten as follows using the matrix notation:&lt;/p&gt;

\[H(T) = H(0) + \int_0^Tf(H(T);\theta_f)\frac{dX(t)}{dt}dt ...(4)\]

    &lt;p&gt;where $X(t)$ is a matrix whose $v$-th row is $X^{(v)}$. The CDE function $f$ separately processes each row in $H(t)$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Spatial processing&lt;/p&gt;

    &lt;p&gt;After that, the second NCDE starts for its spatial processing as follows:&lt;/p&gt;

\[Z(T) = Z(0) + \int_0^Tg(Z(t);\theta_g)\frac{dH(t)}{dt}dt ...(5)\]

    &lt;p&gt;where the hidden trajectory $Z(t)$ is controlled by $H(t)$ which is created by the temporal processing.&lt;/p&gt;

    &lt;p&gt;After combining Eqs. (4) and (5), they have the following single equation which incorporates both the temporal and the spatial processing:&lt;/p&gt;

\[Z(T) = Z(0) + \int_0^Tg(Z(t);\theta_g)f(H(t);\theta_f)\frac{dX(t)}{dt}dt ...(6)\]

    &lt;p&gt;where $Z(t) \in \mathbb{R}^{\vert\nu\vert \times dim(z^{(v)})}$ is a matrix created after stacking the hidden trajectory $z^{(v)}$ for all $v$.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-experimental-evidence&quot;&gt;&lt;strong&gt;4. Experimental Evidence&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Datasets&lt;/p&gt;

    &lt;p&gt;The datasets are collected by the Caltrans Performance Measurement System (PeMS) in real time every 30 seconds. The traffic data are aggregated into every 5-minute interval from the raw data. The system has more than 39,000 detectors deployed on the highway in the major metropolitan areas in California. Geographic information about the sensor stations are recorded in the datasets. There are three kinds of traffic measurements considered in our experiments, including total flow, average speed, and average occupancy.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/Graph_Neural_Controlled_Differential_Equations_for_Traffic_Forecasting.assets/image-20221118110320351.png&quot; alt=&quot;image-20221118110320351&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;Table 1: Datasets list in this experinment&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;PeMSD4 Dataset Example:&lt;/p&gt;

    &lt;p&gt;distance.csv file:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;from&lt;/th&gt;
      &lt;th&gt;to&lt;/th&gt;
      &lt;th&gt;cost&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;352.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;347.2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;263&lt;/td&gt;
      &lt;td&gt;392.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;263&lt;/td&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;440.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;96&lt;/td&gt;
      &lt;td&gt;374.6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;pems04.npz file using 307 detectors(nodes), from Jan to Feb in 2018, also contains 3 features: flow, occupy, speed. The shape is (sequence_length, num_of_vertices, num_of_features).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Baselines(parts)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;HA (Hamilton 2020) uses the average value of the last 12 times slices to predict the next value.&lt;/li&gt;
      &lt;li&gt;ARIMA is a statistical model of time series analysis.&lt;/li&gt;
      &lt;li&gt;VAR (Hamilton 2020) is a time series model that captures spatial correlations among all trafﬁc series.&lt;/li&gt;
      &lt;li&gt;TCN (Bai, Kolter, and Koltun 2018) consists of a stack of causal convolutional layers with exponentially enlarged dilation factors.&lt;/li&gt;
      &lt;li&gt;FC-LSTM (Sutskever, Vinyals, and Le 2014) is LSTM with fully connected hidden unit.&lt;/li&gt;
      &lt;li&gt;GRU-ED (Cho et al. 2014) is an GRU-based baseline and utilize the encoder-decoder framework for multi-step time series prediction.&lt;/li&gt;
      &lt;li&gt;DSANet (Huang et al. 2019) is a correlated time series prediction model using CNN networks and self-attention mechanism for spatial correlations.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Results&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/Graph_Neural_Controlled_Differential_Equations_for_Traffic_Forecasting.assets/pictable2.png&quot; alt=&quot;pictable2&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;Table 2: The average error of some selected highly performing models across all the six datasets. Inside the parentheses, it shows the others performance relative to STG-NCDE.&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;Overall, STG-NCDE, clearly marks the best average accuracy as summarized in Table 2. For instance, STGCN shows an MAE that is 17.0% worse than that of STG-NCDE. All existing methods show worse errors in all metrics than STG-NCDE (by large margins for many baselines).&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/Graph_Neural_Controlled_Differential_Equations_for_Traffic_Forecasting.assets/pictable3.png&quot; alt=&quot;pictable3&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;Table 3: Forecasting error on PeMSD3, PeMSD4, PeMSD7 and PeMSD8&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;For each dataset. STG-NCDE shows the best accuracy in all cases, followed by Z-GCNETs, AGCRN, STGODE and so on in Table 3. For instance, STGODE shows reasonably low errors in many cases, e.g., an RMSE of 27.84 in PeMSD3 by STGODE, which is the second best result vs. 27.09 by STG-NCDE. However, it is outperformed by AGCRN and Z-GCNETs for PeMSD7. Only STG-NCDE, shows reliable predictions in all cases.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/Graph_Neural_Controlled_Differential_Equations_for_Traffic_Forecasting.assets/image-20221118110145566.png&quot; alt=&quot;image-20221118110145566&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;Figure 2: Trafﬁc forecasting visualization.&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;We can see from Fig. 2 that node 111 and 261 (resp. Node 9 and 112) are two of the highest trafﬁc areas in PeMSD4 (resp. PeMSD8). STG-NCDE shows much more accurate predictions. For example, as highlighted with boxes, STG-NCDE signiﬁcantly outperforms Z-GCNETs for the highlighted timepoints for Node 111 in PeMSD4 and Node 9 in PeMSD8 where the prediction curves of Z-GCNETs are straight which shows nonsensical predictions.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;They presented a spatio-temporal NCDEs model to perform traffic forecasting: one for temporal processing and the other for spatial processing.&lt;/p&gt;

&lt;p&gt;In their experiments with 6 datasets and 20 baselines, their method clearly shows the best overall accuracy.&lt;/p&gt;

&lt;p&gt;In addition, their model can perform irregular traffic forecasting where some input observations can be missing, which is a practical problem setting but not actively considered by existing methods.&lt;/p&gt;

&lt;h2 id=&quot;6-paper-evaluation&quot;&gt;6. Paper Evaluation&lt;/h2&gt;

&lt;p&gt;The innovation in this paper is to propose the combination of graph convolutional network and NCDEs.&lt;/p&gt;

&lt;p&gt;But, you need to be familiar with the two basic topics of controlled differential equations and graphs to understand more deeply. Because there is no more detailed introduction to them here. Actually, there are some parts I can’t  fully understand.&lt;/p&gt;

&lt;p&gt;In the process of converting dynamic graphs into time series, each point is converted into a sequence, and then processing is performed on each sequence. We can see that this approach results in invalid data storage. Because the graph structure will have many intersection nodes, this will cause the storage of time series to have redundancy.&lt;/p&gt;

&lt;p&gt;Moreover, the paper involves a large number of descriptions of partial differential equations, and there is not much content that is obviously useful.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Authors: Jeongwhan Choi, Hwangyong Choi, Jeehyun Hwang, Noseong Park&lt;/p&gt;

&lt;p&gt;Affiliation: Yonsei University, Seoul, South Korea&lt;/p&gt;

&lt;p&gt;Comments: Accepted by AAAI Conference on ArtiAcial Intelligence pp.6367-6374 (2022)&lt;/p&gt;

&lt;p&gt;Cite As: https://doi.org/10.48550/arXiv.2112.03558&lt;/p&gt;

&lt;h2 id=&quot;7-reference--additional-materials&quot;&gt;&lt;strong&gt;7. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Github Implementation: https://github.com/jeongwhanchoi/STG-NCDE&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Datasets Used: https://paperswithcode.com/dataset/pemsd8&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Fri, 18 Nov 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Graph_Neural_Controlled_Differential_Equations_for_Traffic_Forecasting.html</link>
            <guid isPermaLink="true">http://localhost:4000/Graph_Neural_Controlled_Differential_Equations_for_Traffic_Forecasting.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[KDD 2022] Streaming Graph Neural Networks via Generative Replay</title>
            <description>&lt;h1 id=&quot;streaming-graph-neural-networks-with-generative-replay&quot;&gt;Streaming Graph Neural Networks with Generative Replay&lt;/h1&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Continual Learning에서 사용할 Replay Buffer를 Generative Model을 활용시켜 생성한다!&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;본 논문은 Continual Learning을 Graph Neural Network(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;)과 접목시킴과 동시에 이에 사용할 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Replay buffer&lt;/code&gt;를 Generative Model을 사용해 생성합니다.&lt;/p&gt;

&lt;p&gt;이미 Continual Learning에 Generative Model을 사용한 연구는 예전에도 있었으나 &lt;a href=&quot;https://proceedings.neurips.cc/paper/2017/hash/0efbe98067c6c73dba1250d2beaa81f9-Abstract.html&quot;&gt;(여기)&lt;/a&gt;, 이는 이미지 데이터를 주로 targeting한 반면에 지금 다루는 논문은 Graph domain의 데이터에 적용, 그에 맞는 특성(structure of graph)를 고려했다는 점에서 novelty가 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Continual Learning이란?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Continaul Learning은 Lifelong Learning, Incremental Learning이라고도 불리며, 과거의 정보를 최대한 유지하며 새로운 정보를 학습하는 방법론입니다.&lt;/p&gt;

&lt;p&gt;예를 들어, 인간이 ‘강아지’ 라는 지식을 알고 있는 상태로, ‘고양이’라는 지식을 새로 습득했을 때, ‘강아지’를 잊지 않고 ‘강아지’와 ‘고양이’를 구별해 낼 수 있는 것 처럼, 지속적으로 들어오는 새로운 데이터를 학습함과 동시에 이전에 학습되었던 데이터를 잊지 않도록 인공지능을 설계하는 것이 Continual Learning의 목적입니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Catastrophic Forgetting이란?&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Continual Learning에서, 새로운 데이터가 들어옴에 따라 이전에 학습했던 데이터의 정보를 망각하는 현상을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Catastrophic Forgetting&lt;/code&gt;이라고 합니다. 아래 그림을 보시겠습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/99710438/194873406-84f4a722-c562-4c39-adec-5ecc498a498f.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림에서 볼 수 있듯이, Task 1에서는 파란색 node들을 구별하도록 학습합니다. Task 2에서는 새로운 보라색 node가 추가되면서 파란색과 보라색을 포함해 학습시키고, Task 3에서는 빨간색의 새로운 node가 추가되면서 새롭게 학습이 진행됩니다. 이 과정이 Continual Learning 입니다.&lt;/p&gt;

&lt;p&gt;그리고 Task가 진행됨에 따라 이전 Task에서 학습했던 node들에 대한 예측 성능이 떨어지는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;예를 들어, Task 1에서 파란 node들을 분류하는 데에는 95%의 성능을 보였으나, Task 2에서는 55%로 줄었고, Task 2에서 학습했던 보라색 node들도 Task 3에서의 성능은 현저히 줄어든 것을 볼 수 있습니다. 이러한 현상이 앞서 말씀드린 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Catastrophic Forgetting&lt;/code&gt;입니다.&lt;/p&gt;

&lt;p&gt;Continual Learning 중 Replay approach는 이전 Task에서 학습했던 데이터 중 &lt;strong&gt;일부&lt;/strong&gt;만을 sampling하여 이후 Task에 사용합니다. 전체 데이터를 계속해서 누적하여 학습하면 효율이 좋지 않기 때문이죠. 이렇게 sampling되어 이후 Task에서 같이 학습될 data를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Replay buffer&lt;/code&gt;라고 부릅니다. 이 과정에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Catastrophic Forgetting&lt;/code&gt;현상이 일어나게 되는데, 이 현상을 최소화 하도록 이전 Task에서 학습했던 데이터를 잘 대표하는 데이터를 sampling하는 것이 관건입니다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;기존 Replay based Continual Learning 방법들은 storage limitation을 가진다!&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;앞서 언급한대로, Replay based Continual Learning은 이전에 학습했던 데이터 중 전체 데이터를 잘 represent하는 &lt;strong&gt;일부&lt;/strong&gt;의 데이터를 sampling해서 이후 Task에서 등장하는 데이터와 같이 학습시킵니다.&lt;/p&gt;

&lt;p&gt;하지만 이럴 경우 Task가 계속해서 진행됨에 따라, 각 Task에서 아무리 적은 데이터를 sampling한다 해도 기억해야하는 데이터가 지속적으로 늘어나고, 결국에는 memory를 다 사용해버리는 일이 생길 것입니다.&lt;/p&gt;

&lt;p&gt;저자들은 이런 한계를 지적하며 Generative Model을 도입해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Replay buffer&lt;/code&gt;에 데이터를 누적시키는 것이 아니라, Task가 시작될 때 마다 필요한 만큼 Generative Model로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Replay buffer&lt;/code&gt;를 생성해 학습을 진행하고자 합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;기존 Replay based Continual Learning 방법들은 온전한 graph distribution을 보존하지 못한다!&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Image 도메인과 달리, Graph 도메인의 데이터를 다룰 때는 각 데이터의 성질(feature)뿐 만 아니라 그래프의 전체적인 structure도 고려해야 합니다. 어떤 node가 어떤 node와 연결되어 있으며, 연결된 node들은 어떤 특성을 가지고 있는지까지 종합적으로 고려되어야 한다는 것이죠.&lt;/p&gt;

&lt;p&gt;저자들은 Continual Learning 중에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Replay buffer&lt;/code&gt;를 생성할 때 각 node들의 feature만 고려될 뿐, 전체적인 그래프의 distribution(structure)이 보존되지 못한다고 주장합니다. 이는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Graph Neural Network&lt;/code&gt;가 학습될 때 성능 저하를 야기하는 가장 큰 문제 중 하나로, 이 논문에서는 Generative Model을 통해 이러한 topological information까지 저장하도록 하는 것을 목표로 합니다.&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Preliminaries: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;논문에서 제안한 방법론을 이해하기 위해서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;의 개념을 알고 있어야 합니다.&lt;/p&gt;

&lt;p&gt;본 리뷰에서는 간단하게 소개를 하겠습니다.&lt;/p&gt;

&lt;p&gt;\(N\)개의 노드를 가진 그래프 \(\mathcal{G}= \lbrace \mathcal{V},\mathcal{E} \rbrace\)가 주어지고, \(X = \lbrace x_{1}, x_{2}, ..., x_{N} \rbrace\) 을 node feature의 집합이라고 하고, \(A\)를 node들의 관계를 표현하는 adjacency matrix라고 하겠습니다.&lt;/p&gt;

&lt;p&gt;\(l-th\) hidden layer에서의 \(v_{i}\)의 hidden representation을 \(h_{i}^{(l)}\) 이라고 할 때, 이 \(h_{i}^{(l)}\)는 다음과 같이 계산됩니다:&lt;/p&gt;

&lt;p&gt;$h_{i}^{(l)} = \sigma(\sum_{j \subset \mathcal{N}(i)} \mathcal{A_{ij}}h_{j}^{(l-1)}W^{(l)})$&lt;/p&gt;

&lt;p&gt;이 때, \(\mathcal{N}(i)\) 는 \(v_{i}\)의 neighbors를 의미하고, \(\sigma ( \bullet )\)는 activation function, \(W^{(l)}\)은 \(l-th\) layer의 transform matrix를 나타냅니다.&lt;/p&gt;

&lt;p&gt;\(h_{i}^{(0)}\)은 node \(v_{i}\)의 input feature를 나타내고, \(\mathcal{A}\)는 neighbors의 aggregation strategy이며, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;의 핵심 중 하나입니다.&lt;/p&gt;

&lt;p&gt;본 논문에서는 다양한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;중 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GraphSAGE&lt;/code&gt;라는 모델을 사용하는데, 이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GraphSAGE&lt;/code&gt;의 \(k\)번째 layer는 다음과 같이 정의됩니다:&lt;/p&gt;

&lt;p&gt;$h_{v}^{k} = \sigma(W^k \cdot MEAN( \lbrace h_v^{k-1} \rbrace \cup \lbrace h_u^{k-1}, \forall u \in \mathcal{N}(v)\rbrace)$&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Problem Definition&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Continual Learning setting에서, 데이터는 그래프의 형태를 띠고 연속적으로 들어옵니다. 이는 다음과 같이 표현이 가능합니다.&lt;/p&gt;

&lt;p&gt;$\mathcal{G} = (\mathcal{G}^1, \mathcal{G}^2, …, \mathcal{G}^T)$$&lt;/p&gt;

&lt;p&gt;where \(\mathcal{G^t} = \mathcal{G}^{t-1}+\Delta \mathcal{G}^t\)&lt;/p&gt;

&lt;p&gt;여기서 \(\mathcal{G} = (A^t, X^t)\) 는 attributed graph at time \(t\)이고, \(\Delta \mathcal{G} = (\Delta A^t , \Delta X^t)\)는 time \(t\)에서의 node attribute와 network의 structure의 변화량을 나타냅니다.&lt;/p&gt;

&lt;p&gt;이 때 Streaming &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;은 traditional &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;을 streaming setting으로 확장한 것이 됩니다. Streaming graph가 있을 때, Continual Learning의 목적은 \((\theta^1, \theta^2, ..., \theta^T)\) 를 배우는 것입니다. 이 때 \(\theta^t\) 는 time \(t\) 에서의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt; parameter를 의미합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Model Framework&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;저자들은 이 논문에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SGNN-GR&lt;/code&gt;이라는 방법론을 제시합니다. 모델 구조는 아래 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/99710438/194887946-3f736cc4-1c2c-47ca-97aa-4516da0ae42e.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이 그림을 참고해 방법론을 개괄적으로 설명하자면, 아래와 같습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;새로운 task가 오면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAN&lt;/code&gt;으로 sequence를 생성(이게 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replay buffer&lt;/code&gt;가 되는 것이죠)해서 이번 task의 그래프와 &lt;strong&gt;같이&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;을 학습합니다.&lt;/li&gt;
  &lt;li&gt;이러면 이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;은 &lt;strong&gt;현재 그래프를 학습함과 동시에 이전의 정보까지 기억&lt;/strong&gt;하게 될 것입니다.&lt;/li&gt;
  &lt;li&gt;또한 이번 task에서 새롭게 생성된 node들과 그것들로부터 영향받은 node들을 다시 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAN&lt;/code&gt;의 input으로 주어 학습시킵니다.&lt;/li&gt;
  &lt;li&gt;이러면 다음 task에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAN&lt;/code&gt;은 더 양질의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replay buffer&lt;/code&gt;를 만들어 낼 수 있을 것입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;지금부터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SGNN-GR&lt;/code&gt;의 자세한 내용을 살펴보겠습니다. 위 그림을 잘 참고하면서 아래 설명을 따라오시기 바랍니다.&lt;/p&gt;

&lt;p&gt;가장 먼저, Streaming GNN의 time \(t\)에서의 loss는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;$\mathcal{L}(\theta^t ; \mathcal{G}^t) = \mathcal{L}(\theta^t ; \mathcal{G}_A^t) + \lambda \mathcal{R} (\theta^{t-1} ; \mathcal{G}_S^t)$&lt;/p&gt;

&lt;p&gt;우변의 첫 항은 incremental learning에 관한 것이고, 두 번째 항은 historical knowledge에 관한 것입니다.&lt;/p&gt;

&lt;p&gt;본 논문에서 \(\mathcal{G}_A^t\) 는 graph의 affected part, \(\mathcal{G}_S^t\) 는 graph의 stable part로 정의합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;여기서 affected part는 계속해서 새로운 data가 들어옴에 따라 영향을 받는(변화된) part, 즉 새롭게 학습해야하는 part라고 생각하면 되고, stable part는 이전에 학습했던 part, 즉 변하지는 않았지만 기존의 지식을 잊지 않기 위해(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Catastrophic forgetting&lt;/code&gt;을 방지하기 위해) 지속적으로 학습시켜야하는 part라고 생각하면 됩니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 때 \(\Delta \mathcal{G}^t \subset \mathcal{G}_A^t\) 이고 \(\mathcal{G}_S^t \subset \mathcal{G}^{t-1}\) 입니다. 몇몇 node들이 새롭게 바뀐 node들에 대해서 영향을 받는 것입니다.&lt;/p&gt;

&lt;p&gt;각 time step에서 모델은 main model(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;)과 Generative Model로 구성됩니다. 위 그림에서 확인할 수 있듯이, Generative Model은 \(\mathcal{G}_ A^t\)에서 바뀐 node들과 \(\mathcal{G}^{t-1}\)에서의 replayed node를 training data로 받습니다. 이 때 replayed node는 이전 time step의 Generative Model로부터 나옵니다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 Generative Model로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAN&lt;/code&gt;을 사용하였습니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAN&lt;/code&gt;에 대한 자세한 설명은 생략하며, 원 논문은 &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3422622&quot;&gt;여기&lt;/a&gt;를 참고하시기 바랍니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt; 모델도 changed node와 replayed node를 똑같이 input으로 받습니다.&lt;/p&gt;

&lt;p&gt;Main model의 loss function은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;$\mathcal{L}_ {GNN} (\theta^t) = r \mathbf{E}_ {v \sim \mathcal{G}_ A^t } [ l(F_{\theta^t}(\upsilon), y_{\upsilon} ) ] + (1-r) \mathbf{E}_ {v’ \sim G_{\phi^{t-1}}} [ l(F_{\theta^t}(\upsilon ‘), F_{\theta^{t-1}}(\upsilon ‘)] $&lt;/p&gt;

&lt;p&gt;여기서 \(v\)는 changed node, \(v&apos;\)는 replayed node입니다. 즉, 이 모델은 새로 들어온 node와 이전에 학습했던 node(replayed)를 동시에 학습합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Generative Model for Node Neighborhood&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;앞서 언급한대로, 일반적인 Generative model(ex. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAN&lt;/code&gt;)은 주로 computer vision 분야에서 활발하게 연구되었으나, graph data는 structure에 dependent하기 때문에, edge의 생성은 independent한 event가 아니라 jointly structured 되어야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NetGan&lt;/code&gt;이나 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GraphRNN&lt;/code&gt;같은 Graph Generative model들이 있지만, 이는 전체 그래프를 생성하기 위함이지 node의 neighborhood를 생성하기 위함이 아니어서, 저자들은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ego network&lt;/code&gt;라는 node neighborhood 생성모델을 제시합니다. 이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ego network&lt;/code&gt;는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAN&lt;/code&gt;의 프레임워크와 유사하지만, 그래프 상에서의 random walks with restart, 즉 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RWRs&lt;/code&gt;를 학습하는 방향으로 사용합니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RWRs&lt;/code&gt;는 일반적인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Random Walk&lt;/code&gt;모델에서 일정 확률로 starting node로 돌아가고, 그렇지 않으면 neighborhood node로 넘어갑니다. 이는 기존 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RWRs&lt;/code&gt;가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Random Walk&lt;/code&gt;보다 훨씬 적은 step으로 explore가 가능하게 한다고 합니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;어떻게 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Random Walk with Restart(RWR)&lt;/code&gt;이 기존 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Random Walk&lt;/code&gt;보다 적은 length로 graph를 explore할까?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Graph \(\mathcal{G}= \lbrace \mathcal{V},\mathcal{E} \rbrace\) 가 있다고 합시다. Starting node는 \(v_0\)이고 그 node의 degree는 \(m\)이고 neighborhood는 \(N(v_0)\)이라고 합니다. \(T_{RW}\)를 기존 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Random Walk&lt;/code&gt;가 \(v_0\)의 ego network를 explore하는데 필요한 step이라고 하면, \(E[T_{RW}] = \frac{(m-1)}{c} \cdot \frac{\sum_{v \in \mathcal{V} \setminus \mathcal{E} (v_0) } deg(v)}{d_{max}}\), where \(\mathcal{E} (v_0) = \lbrace v_0 \rbrace \cup N(v_0)\), \(d_{max}\) : maximum degree of nodes in \(v\)’s neighborhood, \(c\): the size of cut set of cut \((\mathcal{E} (v_0), \mathcal{V} \setminus \mathcal{E}(v_0) )\) 이라고 합니다. 자세한 증명은 논문의 appendix를 참고하시기 바랍니다.&lt;/p&gt;

&lt;p&gt;실제 그래프에는 node가 많으므로, $ \left \vert \sum_{v \in \mathcal{V} \setminus \mathcal{E} (v_0)} deg(v) \right \vert \gg \left \vert cd_{max} \right \vert $ 이고, \(E[T_{RW}]\)는 굉장히 큰 수가 되게 됩니다.&lt;/p&gt;

&lt;p&gt;하지만 \(\alpha\)의 확률로 restart하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RWR&lt;/code&gt;의 expected length to explore는 \(E[T_{RWR}] &amp;lt; \frac{m(\ln m+1)}{\alpha (1-\alpha)}\)가 된다고 합니다. 역시 자세한 증명은 논문의 appendix를 참고하시기 바랍니다.&lt;/p&gt;

&lt;p&gt;\alpha를 예를 들어 0.2로 설정하면, \(E[T_{RW}] = \frac{(m-1)}{c} \cdot \frac{\sum_{v \in \mathcal{V} \setminus \mathcal{E} (v_0) } deg(v)}{d_{max}} \gg \frac{m(\ln m+1)}{\alpha (1-\alpha)} &amp;gt; E[T_{RWR}]\)이므로, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RWR&lt;/code&gt;를 사용하는 것이 기존 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Random Walk&lt;/code&gt;를 사용하는 것 보다 훨씬 빠른것을 확인할 수 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;지금부터 Generative Model에 관한 설명을 보겠습니다.&lt;/p&gt;

&lt;p&gt;저자들은 node간의 dependency를 capture하기 위해 &lt;strong&gt;m&lt;/strong&gt;이라는 graph state를 정의합니다. 각 walk step에서 \(m_l\)과 \(v_l\)을 계산하는데, 이 때의 input은 last state \(m_{l-1}\)과 last input \(s_{l-1}\)입니다. 이 \(s_{l-1}\)은 node identity \(v_{l-1}\)과 node attribute \(x_{l-1}\)을 포함하고 있습니다.&lt;/p&gt;

&lt;p&gt;Current state \(m_ l\)은 neural network \(f\)로 계산됩니다.&lt;/p&gt;

&lt;p&gt;Generator의 update process는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;$m_l = f(m_{l-1}, s_{l-1}),$&lt;/p&gt;

&lt;p&gt;$v_l = softmax(m_l \cdot W_{up,adj}),$&lt;/p&gt;

&lt;p&gt;$x_l = m_l \cdot W_{up,fea},$&lt;/p&gt;

&lt;p&gt;$s_l = (v_l \oplus x_l) \cdot W_{down}$&lt;/p&gt;

&lt;p&gt;여기서 \(W_{up}, W_{down}\)은 차원을 맞춰주기 위한 projection matrix라고 생각하시면 됩니다.&lt;/p&gt;

&lt;p&gt;저자들은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WGAN&lt;/code&gt; 프레임워크를 사용해 모델을 학습을 진행했고, 위의 그림에서 확인할 수 있듯이 이 generator는 새로운 그래프 \(\mathcal{G}_ t\) 에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RWRs&lt;/code&gt;로 생성된 Sequence들을 input으로 받아 학습을 진행하고, 다음 task에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replay buffer&lt;/code&gt;에 넣을 sequence를 뱉어줍니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;은 이 sequence까지 포함해 학습하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catastrophic forgetting&lt;/code&gt;을 방지합니다.&lt;/p&gt;

&lt;p&gt;Discriminator는 역시 sequence W의 node identity와 그에 해당하는 attrribute를 받아서 sequence의 score를 output으로 반환합니다.&lt;/p&gt;

&lt;p&gt;$p_{score} (W) = q(\lbrace (v_l, x_l), l=1,…,L \rbrace)$&lt;/p&gt;

&lt;p&gt;여기서 \(q\)는 일반적인 neural network입니다.&lt;/p&gt;

&lt;p&gt;다들 아시다시피, 이 discriminator는 sequence가 real인지 fake인지 판별하면서 generator의 성능을 높이게 되며 positive sample들은 real graph로부터 오는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RWR&lt;/code&gt;, negative sample들은 위에서 정의한 generator로부터 오게 됩니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Incremental Learning on Graphs&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;지금부터는 Continual Learning이 어떻게 이루어지는지 보겠습니다.&lt;/p&gt;

&lt;p&gt;먼저 저자들은 affected nodes를 정의합니다.&lt;/p&gt;

&lt;p&gt;그래프가 time step에 따라 변하면서, 새로운 node나 edge가 생성되면 주위 K(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;의 layer 수)-hop 이내의 neighborhood만 change 됩니다. (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;의 layer가 2개라면, 한 node가 변할 때 그 node와 edge 2개 이내로만 연결되어 있는 node들만 변한다는 의미입니다.)&lt;/p&gt;

&lt;p&gt;Changed node중에 &lt;strong&gt;크게 변한 것들&lt;/strong&gt;이 있을 것이고, &lt;strong&gt;유의미한 변화가 없는 것들&lt;/strong&gt;이 있을 것입니다. 이 &lt;strong&gt;크게 변한 것들&lt;/strong&gt;이 전체적인 neighborhood의 패턴을 바꿀 가능성이 있는 node 들이라, 학습에 사용해야합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;다시 말해서, node 중에 성질이(feature) 크게 변한 node들은 새로운 data의 패턴을 반영할 확률이 성질이 변하지 않은 node보다 높으므로, model을 학습할 때 train data에 포함시켜서 학습시켜야 한다는 것입니다. 성질이 변한 node를 제쳐두고 변하지 않은 node만을 사용해서 학습한다면 model은 새로 들어온 data를 충분히 반영하지 못하겠죠.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그렇다면 어떤 node가 크게 변했다는 것을 어떻게 확인할 수 있을까요?&lt;/p&gt;

&lt;p&gt;저자들은 아래와 같은 influenced degree를 정의하고 그 influence degree가 threshold \(\delta\) 보다 크다면 affected node라고 취급합니다.&lt;/p&gt;

&lt;p&gt;$ \mathcal{V}_ C^t = \lbrace v \lVert F_ {\theta^{t-1}} (v, \mathcal{G}^t) - F_ {\theta^{t-1}} (v, \mathcal{G}^{t-1}) \rVert &amp;gt; \delta \rbrace$&lt;/p&gt;

&lt;p&gt;위 식을 해석해보면, 어떤 node \(v\)의 이전 그래프 \(\mathcal{G}^{t-1}\)에서의 representation와 현재 그래프 \(\mathcal{G}^t\)에서의 representation이 많이 차이난다면, 이 node는 이전 그래프에서 현재 그래프로 넘어오면서 영향을 받았다고 보는 겁니다. 꽤 직관적인 해석입니다.&lt;/p&gt;

&lt;p&gt;이런 affected node들은 이전 그래프가 가지고 있지 않은 새로운 패턴을 가지고 있으므로, Generative Model에 input으로 넣어 학습시킨 뒤에 다음 task부터 새로운 패턴을 반영해서 좋은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replay buffer&lt;/code&gt;를 만들도록 합니다.&lt;/p&gt;

&lt;p&gt;추가로, 저자들은 간단한 filter를 추가해 generator가 생성한 node \(v_i\)가 affected node \(v_j\)와 &lt;strong&gt;많이 비슷한 경우&lt;/strong&gt;, 패턴의 redundancy를 줄이기 위해 아래의 식처럼 필터링합니다.&lt;/p&gt;

&lt;p&gt;$p_{reject} = max(p_{sim} (v_i, v_j) , j \subset \mathcal{V}_ C^t) \times p_r$$&lt;/p&gt;

&lt;p&gt;여기서 \(p_r\)은 disappearacne rate로 사전에 정의하고, similarity는 다음과 같이 정의됩니다.&lt;/p&gt;

&lt;p&gt;$p_{sim} (v_i, v_j) = \sigma (- \lVert F_ {\theta^{t-1}}(v_i, \mathcal{G}^{t-1}) - F_ {\theta^{t-1}}(v_j, \mathcal{G}^{t-1})  \rVert)$&lt;/p&gt;

&lt;p&gt;이때 \(\sigma\)는 sigmoid function이고, 위 식도 직관적으로 두 node의 representation의 차이가 적으면 비슷하다고 보는 겁니다.&lt;/p&gt;

&lt;p&gt;이 filter를 통해 저자들은 중복되는 지식은 점차 잊혀지고 바뀌는 distribution이 안정적으로 학습될 것이라 했습니다.&lt;/p&gt;

&lt;p&gt;아래의 알고리즘을 통해 지금까지 설명했던 내용들을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/99710438/194888070-5da986d2-1702-4cd5-b77e-cfa3d76a0467.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;본 논문에서 저자들은 다양한 dataset을 통해 baseline들과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SGNN-GR&lt;/code&gt;을 비교했습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;experiment-setup&quot;&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Dataset
    &lt;ul&gt;
      &lt;li&gt;Cora&lt;/li&gt;
      &lt;li&gt;Citeseer&lt;/li&gt;
      &lt;li&gt;Elliptic (bitcoin transaction)&lt;/li&gt;
      &lt;li&gt;DBLP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;baseline
    &lt;ul&gt;
      &lt;li&gt;SkipGram models
        &lt;ol&gt;
          &lt;li&gt;LINE&lt;/li&gt;
          &lt;li&gt;DNE&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;GNNs (Retrained)
        &lt;ol&gt;
          &lt;li&gt;GraphSAGE&lt;/li&gt;
          &lt;li&gt;GCN&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;GNNs (Incremental)
        &lt;ol&gt;
          &lt;li&gt;PretrainedGNN (첫 time step때만 학습되고 이후로는 학습하지 않음)&lt;/li&gt;
          &lt;li&gt;SingleGNN (각 time step마다 한 번씩 학습)&lt;/li&gt;
          &lt;li&gt;OnlineGNN (Continual Learning setting, without knowledge consolidation)&lt;/li&gt;
          &lt;li&gt;GNN-EWC&lt;/li&gt;
          &lt;li&gt;GNN-ER&lt;/li&gt;
          &lt;li&gt;DiCGRL&lt;/li&gt;
          &lt;li&gt;TWP&lt;/li&gt;
          &lt;li&gt;ContinualGNN&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SGNN-GR&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기서 Retrained &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;은 각 time step마다 Graph &lt;strong&gt;전체&lt;/strong&gt;를 학습시킨 것으로, Continual Learning model 성능의 upper bound라고 생각하면 됩니다. Incremental &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN&lt;/code&gt;이 Continual Learning model들이라고 생각하시면 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;result&quot;&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Overall Results&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위의 data를 사용한 실험의 결과는 아래와 같습니다. 저자들은 average Macro/Micro-F1를 성능 평가 지표로 사용했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/99710438/195345047-bd69d686-e6d3-4ea6-ab81-4baff5f95e1e.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;말씀드린대로, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LINE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RetrainedGCN&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RetrainedSAGE&lt;/code&gt;는 각 task에서 그래프 &lt;strong&gt;전부&lt;/strong&gt;를 사용해서 Continual Learning setting의 성능을 상회합니다. 하지만 저자들의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SGNN-GR&lt;/code&gt;의 성능 또한 Retrained model과 유사한 것으로 보아 generator가 꼭 필요한 sample들만 생성해줬음을 알 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Analysis of Catastrophic Forgetting&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;앞서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catastrophic forgetting&lt;/code&gt;을 방지하는 것이 Continual Learning에서 가장 중요한 포인트 중 하나라고 말씀드렸는데, 저자들의 모델은 얼마나 이전의 정보를 잘 기억했는지 보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/99710438/195346345-51daec92-bc57-4c36-a6d5-a4b883a6aeb2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;왼쪽 (a) 그림은 Cora dataset에서 모델이 14 step을 가는동안 0번째 task를 얼마나 잘 기억하는지 보여주는 그래프이고, 오른쪽 (b) 그림은 6번째 task를 얼마나 잘 기억하는지 보여주 그래프입니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OnlineGNN&lt;/code&gt;은 이전 task의 정보를 거의 저장하지 못하는 것을 확인할 수 있고, 저자들의 방법론이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GNN-ER&lt;/code&gt;보다 더 이전 task의 지식을 잘 보존하는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Anaylsis of Generative Model&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그렇다면 과연 저자들이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replay buffer&lt;/code&gt;를 Generative Model로 생성한 것은 옳은 선택이었을까요?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/99710438/195347882-15c5016a-3f55-4799-892a-4e73935493b6.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림 (a) 는 실제 그래프의 label당 node 개수(파란색)와 Generative Model로 생성된 label당 node 개수(빨간색)을 보여줍니다. Generative Model이 실제 그래프의 label 분포와 굉장히 유사하게 node를 생성하고 있음을 보여줍니다.&lt;/p&gt;

&lt;p&gt;또한 오른쪽 그림 (b) 는 generated 된 데이터를 보여주는데, 다양한 topological 정보를 담고 있음을 볼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ablation Study&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/99710438/195348924-c5e2fe7f-5238-4acb-a127-ba4bd18bdfbc.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;마지막으로, 저자들은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SGNN-GR&lt;/code&gt;의 두 part들이 얼마나 성능 향상에 도움을 주는지 ablation study를 통해 Cora, Citeseer에서 확인했습니다.&lt;/p&gt;

&lt;p&gt;여기서 Non-Affected는 새롭게 추가된 node들만 고려하고, 그로 인한 affected node들은 고려하지 않은 모델입니다. 또한 Non-Generator는 모든 affected node를 찾아 다시 학습시키지만, generator는 쓰지 않은 모델입니다.&lt;/p&gt;

&lt;p&gt;당연하게 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SGNN-GR&lt;/code&gt;이 가장 좋은 성능을 보이는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 논문에서는 지속적으로 들어오는 Graph 데이터를 학습하는 데, Generative Model을 사용해 이전에 학습했던 그래프와 비슷한 그래프를 계속 생성해 새로운 데이터와 함께 학습시킵니다.&lt;/p&gt;

&lt;p&gt;저자들은 여러 Continual Learning 방법 중 regularization method는 optimal solution을 얻는 것이 어렵다고 주장하고 replay based Continual Learning은 task가 진행됨에 따라 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replay buffer&lt;/code&gt;에 그래프의 일부를 저장하고, task가 많이 늘어나면 그에 따라 요구되는 메모리도 커진다고 주장하며 Generative Model로 그때그때 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replay buffer&lt;/code&gt;를 생성해서 메모리 효율을 높이겠다고 했습니다.&lt;/p&gt;

&lt;p&gt;본 논문은 단순히 메모리 효율을 높인 것에 그치지 않고, 새롭게 등장하는 패턴은 적극적으로 학습하면서 불필요해 보이는 패턴은 줄이도록 학습해서 단순한 Continual Learning을 보완했습니다.&lt;/p&gt;

&lt;p&gt;그 사이사이에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Random Walk&lt;/code&gt;가 아니라 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Random Walk with Restart&lt;/code&gt;를 씀과 동시에 그 효율을 증명으로 보인 것과 같은 디테일, 본인들이 주장하는 모델의 장점을 잘 보여주는 알찬 실험들까지, 좋은 연구인 것 같습니다.&lt;/p&gt;

&lt;p&gt;이 논문 뿐만 아니라 Continual learning에서 Generative Model은 중대한 역할을 할 것으로 보이며 관련 연구들이 꼭 필요할 것으로 보입니다.&lt;/p&gt;

&lt;p&gt;추가적으로, 본 논문은 task incremental setting에서 generative model을 활용하고 있습니다만, 조금 더 어려운 setting(e.g. class incremental)에서의 활용 방안도 고안할 필요가 있다고 생각합니다.&lt;/p&gt;

&lt;p&gt;Class incremental setting에서는 task incremental setting과 달리 한 번 등장한 class는 이후 task에서 다시 등장하지 않기 때문에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAN&lt;/code&gt;같은 생성 모델을 활용하는 데 추가적인 전략이 필요할 것으로 보이며, 그런 경우에 task간의 similarity를 측정해서 활용하는 것도 하나의 future work가 될 것 같습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;개인적인 생각&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;올게 왔구나&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;본 논문은 Graph Neural Network에서의 Continual Learning에 Generative Model을 접목시킨 방법입니다. 사실 이 논문이 나오는 것은 시간문제라고 생각하던 찰나에 역시나 등장했습니다.&lt;/p&gt;

&lt;p&gt;이미 Continual Learning에 Generative Model을 접목시킨 연구는 꽤 오래전에(AI 연구의 속도가 매우 빠른 것을 감안하면) 등장했지만, GNN에 접목된 것은 없었기 때문이죠.&lt;/p&gt;

&lt;p&gt;관련 연구를 하시는 분들은 아시겠지만, 이 논문이 novelty가 엄청 높다거나, 기존의 상식을 깨는 굉장한 발견을 한 논문이라기 보단.. (&lt;strong&gt;분명히 좋은&lt;/strong&gt; 논문입니다, 오해금지)&lt;/p&gt;

&lt;p&gt;가장 큰 contribution은 특정 분야에서 처음 시도된 연구, 적절한 시기에 등장한 연구인 것 같습니다. Novelty만을 좇는게 아니라, trend에 맞는 연구를 하는 능력도 필요해 보입니다.&lt;/p&gt;

&lt;p&gt;우리도 최신 논문을 잘 follow up 하는 ‘트렌디한’ 연구자가 되도록 합시다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Wonjoong Kim
    &lt;ul&gt;
      &lt;li&gt;Affiliation: &lt;a href=&quot;http://dsail.kaist.ac.kr&quot;&gt;DSAIL@KAIST&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Research Topic: Graph Neural Network, Continual Learning&lt;/li&gt;
      &lt;li&gt;Contact: wjkim@kaist.ac.kr&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference--additional-materials&quot;&gt;&lt;strong&gt;Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Github Implementation
    &lt;ul&gt;
      &lt;li&gt;None&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reference
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/16602&quot;&gt;[AAAI-21] Overcoming catastrophic forgetting in graph neural networks with experience replay&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://proceedings.neurips.cc/paper/2017/hash/0efbe98067c6c73dba1250d2beaa81f9-Abstract.html&quot;&gt;[NIPS-17] Continual learning with deep generative replay&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Sat, 12 Nov 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Streaming_Graph_Neural_Networks_via_Generative_Replay.html</link>
            <guid isPermaLink="true">http://localhost:4000/Streaming_Graph_Neural_Networks_via_Generative_Replay.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[AAAI 2019] Learning to Solve NP-Complete Problems - A Graph Neural Network for Decision TSP</title>
            <description>&lt;h1 id=&quot;learning-to-solve-np-complete-problems-a-graph-neural-network-for-decision-tsp&quot;&gt;&lt;strong&gt;Learning to Solve NP-Complete Problems: A Graph Neural Network for Decision TSP&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;This post is a review of “Learning to Solve NP-Complete Problems: A Graph Neural Network for Decision TSP” by Marcelo Prates, Pedro H. C. Avelar, Henrique Lemos, Luis C. Lamb, and Moshe Y. Vardi. This paper proposes a Graph Neural Network (GNN) model to solve the decision variant of the famous Travelling Salesman Problem (TSP).&lt;/p&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;This paper investigates the decision variant of the TSP. The Traveling Salesman Problem is defined as finding the shortest possible tour visiting every node exactly once (Hamiltonian tour) on a given fully connected graph G = (V, E) composed of n vertices V and the edges E connecting them. The decision variant of the TSP is to answer whether there exists a Hamiltonian route with a cost (tour length) no larger than C on a given graph. The solution of the decision TSP is “YES” or “NO”.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;The aim of the paper is to bring a data-driven approach to solve the decision TSP which is an NP-Complete problem. The traditional methods require the supervision of an expert to solve the problem. The main motivation is to propose a GNN based trainable model to solve the decision TSP which removes the need for domain knowledge. In addition to that, the time required to solve the decision TSP increases substantially as the graph becomes larger. The authors claim that their model can be generalized to larger graph sizes. Lastly, the model to solve the decision TSP can be combined with traditional search methods to predict the optimal tour length of TSP.&lt;/p&gt;

&lt;p&gt;There are existing works to solve the TSP with Deep Learning (DL) based methods. However, to the best of my knowledge, this paper is the first attempt to bring DL approach to the decision TSP. The models in the literature to solve TSP mostly focuses on the node features namely, the coordinates of the nodes. This paper sees the TSP as a graph with labeled edges where edge labels are the distance between the nodes connected. They utilize the Typed Graph Networks (TGN) based model proposed by the authors of this paper previously to assign embeddings to both vertices and edges.&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;The proposed GNN-based model to solve the decision TSP inputs a TSP instance X = (G, C) composed of a graph G = (V, E) and a target cost C ∈ R and outputs the decision which is either yes or no. It assigns a multidimensional embedding to each vertex and edge in the graph representation of the problem instance through message-passing iterations. The procedure can be divided into 3 stages: generating initial edge and vertex embeddings, updating the embeddings and predicting the output. At the initialization step, vertex embeddings are chosen to be equal for all vertices and seen as the parameter of the model. This is because of the fact that vertices do not have labels associated with them. However, the edges have labels which are the weights (distances) associated with them. The target cost C is also fed to each edge embedding alongside its corresponding weight. The initial embedding for an edge is generated via the projection of 2 dimensional vector of the edge weight and target cost to d-dimensional space with Multilayer perceptron (MLP). Each vertex and edge embedding is updated based on the incoming messages from its neighbors by feeding the resulting vector into a Recurrent Neural Network (RNN). Finally, updated edge embeddings are fed into an MLP to compute a logit probability corresponding to the prediction of the answer to the decision problem.&lt;/p&gt;

&lt;h3 id=&quot;31-model-training&quot;&gt;&lt;strong&gt;3.1 Model Training&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;The model is trained in a supervised fashion and training instances are composed of a graph G, the target cost C and the grand truth answer which is the optimal cost of the given problem. The input grahs are generated randomly. The optimal cost is computed for each training graph using the Concorde TSP solver and then present the model with two examples containing G, one with a target cost slightly smaller than the optimal (for which the correct prediction would be NO as there is no route cheaper than the optimal) and one with a target cost slightly greater than the optimal (for which the correct prediction would be YES as there is in fact routes more expensive or equal to the optimal). Stochastic Gradient Descent (SGD) is utilized to minimize the binary cross entropy loss between the model prediction and the ground-truth. A total of $2^{20}$ instances of grah size 40 are generated for training. The evaluation of the training loss can be seen below.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;400&quot; src=&quot;/images/Learning to Solve NP-Complete Problems - A Graph Neural Network for Decision TSP/loss.PNG&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-experimental-results-and-analyses&quot;&gt;&lt;strong&gt;4. Experimental Results and Analyses&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;41-model-performance-on-larger-instances&quot;&gt;&lt;strong&gt;4.1 Model Performance on Larger Instances&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;The model is originally trained on graphs of size 40 with target cost varying by 2% from the optimal. The generalization ability of the model is tested on varying graph sizes. The model sustains 80% accuracy on instances of size smaller than 40. However, its performance degrades progressively for larger problem sizes until 50% which would be the accuracy of a random prediction.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;400&quot; src=&quot;/images/Learning to Solve NP-Complete Problems - A Graph Neural Network for Decision TSP/sizes.PNG&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;42-generalizing-to-larger-deviations&quot;&gt;&lt;strong&gt;4.2 Generalizing to Larger Deviations&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;The model achieved 80.16% accuracy averaged over the training set and 80% accuracy on a testing set of 2048 instances it had never seen before. Instances from training
and test datasets were produced with the same configuration (n ∼ U(20, 40) and 2% percentage deviation).&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;400&quot; src=&quot;/images/Learning to Solve NP-Complete Problems - A Graph Neural Network for Decision TSP/acc.PNG&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The generalization ability of the model to larger deviations is tested by observing the accuracy of the model on the same graphs in the test set but with target costs with varying deviations from the optimal cost. The model accuracy increases as the deviation from the optimal increases.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;400&quot; src=&quot;/images/Learning to Solve NP-Complete Problems - A Graph Neural Network for Decision TSP/deviations.PNG&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;43-baseline-comparison&quot;&gt;&lt;strong&gt;4.3 Baseline Comparison&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;The proposed method is intended to be tested against baselines. However, this is not a straightforward task because of the lack of baseline methods for the decision TSP. Therefore, the classical baselines Nearest Neighbor (NN) and Simulated Annealing (SA) to solve TSP are adapted to create solutions for the decision TSP. This was done by measuring, for a given decision instance X = (G, C) the frequency with which either of these algorithms produced a solution with a cost no greater than C. This frequency is compared with the True Positive Rate (TPR) of the proposed model. The TPR is chosen instead of the accuracy since the classical baseline methods cannot decide that there is no shorter path since they construct a solution for the TSP. The results below show that the proposed method outperforms both methods.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;400&quot; src=&quot;/images/Learning to Solve NP-Complete Problems - A Graph Neural Network for Decision TSP/tpr.PNG&quot; /&gt;
&lt;img width=&quot;400&quot; src=&quot;/images/Learning to Solve NP-Complete Problems - A Graph Neural Network for Decision TSP/gnnsa.PNG&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;A GNN based model is proposed to solve the decision TSP problem. The model generates embeddings for the vertices and edges of a given graph via message passing iterations and utilizes these embeddings to answer whether it is possible to find a Hamiltonian path on the graph with a smaller cost than target cost C. The training is performed on dual decision instances, + and - x% deviations, of a given optimal cost. The model admits 80% accuracy when it is trained on instances with 2% deviations. The experiments also showed that it generalizes to the larger deviations and varying problem sizes to some extent. The work presented in the paper is one of the first attempts to solve decision TSP with a Deep Learning method which makes it meaningful for the Combinatorial Optimization research community. The authors provided the training and model architecture details and performed several experiments to show the validity of their method. However, I think the baseline comparison part is not a fair comparison since the standard methods were not designed to solve the decision TSP. The paper also mentions shortly that the same model can be used to predict the optimal tour length of a given graph but I excluded that part in my review since the details of implementation was not satisfactory and there were no solid comparison results with the baseline methods. Lastly, one takeaway from this paper would be the graph representation of the TSP. Most of the existing works on deep learning based approaches to solve TSP use the coordinates of the nodes to represent the graph. On the other hand, this paper views the TSP graph as edge labeled graph with labels being the distance between the nodes and assuming that the initial embeddings for the vertices are equal. I personally think that this perspective better fits the nature of a TSP graph and might be providing a hint to improve the existing methods to solve TSP.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Marcelo Prates
    &lt;ul&gt;
      &lt;li&gt;Institute of Informatics, UFRGS, Porto Alegre, Brazil&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pedro H. C. Avelar
    &lt;ul&gt;
      &lt;li&gt;Institute of Informatics, UFRGS, Porto Alegre, Brazil&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Henrique Lemos
    &lt;ul&gt;
      &lt;li&gt;Institute of Informatics, UFRGS, Porto Alegre, Brazil&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Luis C. Lamb
    &lt;ul&gt;
      &lt;li&gt;Institute of Informatics, UFRGS, Porto Alegre, Brazil&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Moshe Y. Vardi
    &lt;ul&gt;
      &lt;li&gt;Dept. of Computer Science, Rice University, Houston, TX&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Github Implementation
    &lt;ul&gt;
      &lt;li&gt;https://github.com/machine-reasoning-ufrgs/TSP-GNN.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reference
    &lt;ul&gt;
      &lt;li&gt;https://arxiv.org/abs/1809.02721&lt;/li&gt;
      &lt;li&gt;https://www.lume.ufrgs.br/bitstream/handle/10183/199216/001100446.pdf?sequence=1&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 17 Oct 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Learning_to_Solve_NP_Complete_Problems_A_Graph_Neural_Network_for_Decision_TSP.html</link>
            <guid isPermaLink="true">http://localhost:4000/Learning_to_Solve_NP_Complete_Problems_A_Graph_Neural_Network_for_Decision_TSP.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[KDD 2021] Relational Message Passing for Knowledge Graph Completion</title>
            <description>&lt;p&gt;description : Wang, Hongwei et al. / Relational Message Passing for Knowledge Graph Completion / KDD-2021&lt;/p&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;relational-message-passing-for-knowledge-graph-completion&quot;&gt;&lt;strong&gt;Relational Message Passing for Knowledge Graph Completion&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;지식 그래프는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Entity&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Relation&lt;/code&gt;으로 지식 구조를 그래프로 표현한 것입니다.&lt;br /&gt;
Entity는 그래프의 node와 같은 역할이며, 지식 그래프의 개체를 나타냅니다.&lt;br /&gt;
Relation은 그래프의 edge와 유사하며, 지식 그래프에서 &lt;strong&gt;연결된 개체간의 관계&lt;/strong&gt;를 나타냅니다.&lt;br /&gt;
예를 들어, Entity pair ‘Mona Lisa”와 ‘Da Vinci’ 사이에는 ‘painted by’의 relation이 존재합니다.&lt;br /&gt;
일반적으로 지식 그래프는 규모가 크며 불완전하므로 &lt;strong&gt;missing relation&lt;/strong&gt;을 예측해 완전하게 만드는 것이 목표입니다.&lt;/p&gt;

&lt;!-- &lt;p align=&quot;center&quot;&gt; --&gt;
&lt;p&gt;&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Figure.png&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;entity pair $(h,t)$가 주어졌을 때 entity간의 relation인 $r$의 분포를 모델링합니다.
베이즈 정리에 의해 다음과 같이 나타낼 수 있습니다.
\(p(r|h,t) \propto p(h,t|r) \cdot p(r)\)&lt;/p&gt;

&lt;p&gt;$p(r)$은 prior distribution이므로, $p(h,t|r)$을 모델링합니다. 
\(p(h,t \vert r)=\frac{1}{2}(p(h \vert r) \cdot p(t \vert h,r)+p(t \vert r) \cdot p(h \vert t,r))\)&lt;/p&gt;

&lt;p&gt;여기서 $p(h|r), p(t|r)$은 주어진 relation에 대한 entity의 likelihood입니다. &lt;br /&gt;
본 논문의 모델에서는 entity의 자체 특징을 이용하지 않으므로, entity의 local relational subgraph로 대체합니다.&lt;br /&gt;
이로부터 entity에 인접한 &lt;strong&gt;relation set&lt;/strong&gt;에 대해 생각할 수 있습니다.&lt;/p&gt;

&lt;p&gt;$p(t|h,r)$, $p(h|t,r)$는 entity와 relation이 주어졌을때 다른 entity에 어떻게 도착할지에 대한 likelihood입니다.&lt;br /&gt;
이는 &lt;strong&gt;entity와 entity 사이의 경로&lt;/strong&gt;를 모델링하는 문제가 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;2motivation&quot;&gt;2.&lt;strong&gt;Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;기존 방법은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;relation type&lt;/code&gt; 정보를 효과적으로 파악하지 못했고, 이를 해결한 방법은 복잡도가 높다는 단점이 있다.&lt;/strong&gt;
대부분의 기존 연구에서는 entity와 relation을 embedding space에 나타내고 이를 학습하는 방법을 제안했습니다.&lt;br /&gt;
그러나 학습하지 않은 데이터에 대해 예측하는 inductive setting에서 한계를 보이므로, 이를 해결하기 위해 GNN의 아이디어를 가져오게 됩니다.&lt;br /&gt;
일반적으로 지식 그래프에서 relation type은 균일하게 나타나지 않고, 공간적으로 연관되어 있다는 특징이 있습니다.&lt;/p&gt;

&lt;p&gt;예를 들어 지식 그래프에 ‘보유하다’, ‘구매하다’, ‘헤엄치다’, ‘졸업하다’의 relation이 있다고 합시다.&lt;br /&gt;
‘보유하다’와 가장 가까운 relation으로 ‘구매하다’가 ‘헤엄치다’, ‘졸업하다’보다 더 적합할 것입니다.&lt;/p&gt;

&lt;p&gt;따라서 relation type을 특성화한다면 추론하는데 있어서 중요한 정보를 제공하게 됩니다. &lt;br /&gt;
이러한 정보를 효과적으로 얻기 위해 인접한 개체의 정보를 통합해 전달하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;message passing&lt;/code&gt; 이 적용되었습니다.&lt;/p&gt;

&lt;p&gt;기존에는 node간의 message passing을 통해 정보를 얻었으나, 이 문제에서는 인접한 &lt;strong&gt;relation&lt;/strong&gt;의 관계를 통해서 해결하고자 하므로 &lt;strong&gt;edge&lt;/strong&gt;에 message passing을 적용하는게 더 적절합니다.   &lt;br /&gt;
이 방법을 &lt;strong&gt;Relational Message Passing&lt;/strong&gt;이라고 하며, 다음의 장점이 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;inductive setting&lt;/strong&gt;에서도 효과적으로 예측할 수 있다.&lt;/li&gt;
  &lt;li&gt;entity의 embedding을 계산하지 않으므로 &lt;strong&gt;효율적&lt;/strong&gt;이다.&lt;/li&gt;
  &lt;li&gt;relation type간의 correlation을 통해 예측 &lt;strong&gt;결과를 설명&lt;/strong&gt;할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러나 각 entity에서 인접한 모든 relation의 정보를 결합해서 전달하므로 relation이 많을수록 계산 복잡도가 크게 증가한다는 단점이 있습니다.&lt;/p&gt;

&lt;p&gt;본 논문은 인접한 relation의 정보를 결합하는 과정을 2단계로 나눠 계산 복잡도를 낮추고, relation의 2가지 structure를 활용해 missing relation을 예측하는 모델을 제안합니다.&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;methodologies&quot;&gt;Methodologies&lt;/h3&gt;
&lt;h3 id=&quot;message-passing&quot;&gt;Message Passing&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Node-based message passing
초기 message passing은 node를 기반으로 했으며 다음의 과정을 반복해서 학습합니다.
\(m_{v}^{i}=A(\lbrace s_{u}^{i}\rbrace_{u \in N(v)}),\)
\(s_{v}^{i+1}=U(s_{v}^{i}, m_{v}^{i})\)
$s_{v}^{i}$: node v의 i번째 iteration에서의 hidden state  &lt;br /&gt;
$m_{v}^{i}$: node v가 i번째 iteration에서 받은 message&lt;br /&gt;
$N(v)$: node v에 인접한 모든 node&lt;/p&gt;

    &lt;p&gt;인접한 모든 node의 정보를 aggregate하고 자신의 정보와 함께 input으로 넣어 update합니다.&lt;/p&gt;

    &lt;p&gt;지식 그래프에서는 edge는 feature(relation type)를 가지나 node는 그렇지 않습니다.&lt;br /&gt;
또한 node의 수가 edge보다 훨씬 많으므로, iteration마다 node embedding 정보를 저장해야 함에 따라 메모리 문제가 발생합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Relational message passing&lt;br /&gt;
위의 문제를 해결하기 위해 edge에 message passing을 적용한 방법이 제안되었습니다.&lt;br /&gt;
이를 message passing이라고 하며, 학습 과정은 다음과 같습니다.
\(m_{e}^{i}=A(\lbrace s_{e&apos;}^{i}\rbrace_ {e&apos; \in N(e)}),\)
\(s_{e}^{i+1}=U(s_{e}^{i},m_{e}^{i})\)&lt;/p&gt;

    &lt;p&gt;edge $e$와 인접한 edge의 정보를 aggregate하고 자신의 정보와 함께 input으로 넣어 update합니다.&lt;br /&gt;
$N$ nodes, $M$ edges, node degree의 분산 $var[d]$에 대해 회당 기대 계산 비용은 다음과 같습니다.&lt;br /&gt;
node-based message passing: $2M+2N$&lt;br /&gt;
relational message passing: $N \cdot Var[d]+\frac{4M^2}{N}$&lt;/p&gt;

    &lt;p&gt;relational message passing은 이전의 문제들을 해결할 수 있었으나, edge의 개수가 많아지면 복잡도가 크게 증가한다는 문제점이 있습니다. &lt;br /&gt;
이에 본 논문의 저자들은 새로운 방법을 제안합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pathcon&quot;&gt;PATHCON&lt;/h3&gt;
&lt;h3 id=&quot;notations&quot;&gt;Notations&lt;/h3&gt;
&lt;p&gt;여기부터는 논문에서 제안하는 모델에 대한 설명입니다. Notation이 다음과 같이 정리됩니다.&lt;br /&gt;
$h, t$: head entity, tail entity&lt;br /&gt;
$r$: relation type&lt;br /&gt;
$s_{e}^{i}$: i번째 iteration에서 edge e의 hidden state&lt;br /&gt;
$m_{v}^{i}$: i번째 iteration에서 node v의 message&lt;br /&gt;
$N(e)$: edge e의 endpoint nodes &lt;br /&gt;
$N(v)$: node v의 인접한 edges&lt;br /&gt;
$s_{(h, t)}$: entity 쌍 $(h,t)$의 context representation&lt;br /&gt;
$s_{h \rightarrow t}$:entity h에서 t로 가는 모든 path의 representation&lt;br /&gt;
$\alpha_P$: path P의 attention weight&lt;br /&gt;
$P_{h \rightarrow t}$: entity h에서 t로 가는 path의 집합&lt;/p&gt;

&lt;h3 id=&quot;alternate-relational-message-passing&quot;&gt;Alternate relational message passing&lt;/h3&gt;
&lt;p&gt;학습 과정은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;$m_{v}^{i}=A_{1}(\lbrace s_{e}^{i}\rbrace_{e \in N(v)}),$&lt;/p&gt;

&lt;p&gt;$m_{e}^{i}=A_{2}(m_{v}^{i},m_{u}^{i}),   v, u \in N(e),$&lt;/p&gt;

&lt;p&gt;$s_{e}^{i+1}=U(s_{e}^{i},m_{e}^{i})$&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;각 &lt;strong&gt;node&lt;/strong&gt;에  대해  연결된  edge의 message를  aggregate하여  message을  생성합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;edge&lt;/strong&gt;의 message는 양쪽  node의  message을  aggregate한 것으로 정의됩니다.&lt;/li&gt;
  &lt;li&gt;2번에서 얻은 message와 자신의 message를 통해서 message를 update합니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;relational message passing에서는 인접한 모든 relation의 message를 결합했으나, 여기서는 relation의 양 끝 entity의 message만 결합하면 되므로 복잡도가 줄어들 것으로 생각됩니다.
  이론적으로 Alternate relational message passing의 기대 복잡도가 $6M$임이 증명되었습니다.&lt;br /&gt;
  지식 그래프는 relation의 수가 entity에 비해서 많이 적은 그래프이므로, 제안된 모델이 복잡도를 크게 낮춘 것을 확인할 수 있습니다.&lt;br /&gt;
  다음은 모델에서 학습할 relation의 특징을 나타내는 구조에 대해 알아보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;relational-context&quot;&gt;Relational Context&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Relational Context&lt;/code&gt;는 entity에 연결되어 있는 모든 relation의 집합을 의미합니다. &lt;br /&gt;
예시는 다음과 같습니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Relational_Context.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ron Weasley와 Hedwig가 Harry Potter의 애완동물인지 예측하는 문제를 생각해봅시다.&lt;br /&gt;
두 Entity는 Harry Potter로 가는 경로가 {‘Brother of’,’Lives with’}로 같습니다.&lt;br /&gt;
그러나 Harry Potter와 인접한 relation이 각각 ‘Brother of’,’Bought’로 다릅니다.   &lt;br /&gt;
따라서 Ron Weasley와 Hedwig은 서로 다른 relational context를 가집니다. &lt;br /&gt;
모델은 이를 파악해서 두 entity에 대해 적절한 예측 결과를 제공합니다.&lt;/p&gt;

&lt;p&gt;Alternate relational message passing에서 relational context 학습 과정은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;\(m_{v}^{i}=\sum_{e \in N(v)}s_{e}^{i}\)
\(s_{e}^{i+1}=\sigma([m_{v}^{i},m_{u}^{i},s_{e}^{i}] \cdot W^i + b^i), \: v, u \in N(e)\)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;각 node에 대해 relational context의 feature를 학습합니다.&lt;/li&gt;
  &lt;li&gt;head, tail node와 relation의 정보를 결합합니다. 그리고 Weight를 곱해준 후 bias를 더하고 비선형 활성화 함수를 적용합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 과정을 K번 반복해 얻은 최종 message $m_{h}^{K-1}$와 $m_{t}^{K-1}$가 head, tail entity의 표현이 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;relational-paths&quot;&gt;Relational Paths&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Relational Path&lt;/code&gt;는 entity에서 entity로 갈때 거치는 relation의 sequence입니다.&lt;br /&gt;
예시는 다음과 같습니다.
&lt;!-- &lt;p align=&quot;center&quot;&gt; --&gt;
&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Relational_Path.png&quot; /&gt;
&lt;!-- &lt;/p&gt; --&gt;&lt;/p&gt;

&lt;p&gt;Hermione Granger와 Draco Malfoy가 Harry Potter와의 relation이 같은지 알아봅시다. &lt;br /&gt;
두 Entity는 같은 relational context {‘Occupation’,’House’}를 가집니다.  &lt;br /&gt;
그러나 Harry Potter를 tail로 하는 relational path는 {(‘Occupation’,’Occupation’), (‘House’,’House’)}, {(‘Occupation’,’Occupation’)}로 다릅니다.&lt;br /&gt;
따라서 Hermione Granger와 Draco Malfoy는 Harry Potter와의 relation이 서로 다른 것을 알 수 있습니다.&lt;br /&gt;
모델은 이를 파악해서 두 Entity에 대해 Harry Potter와의 ‘friendship’ relation이 존재하는지 예측할 수 있습니다.&lt;/p&gt;

&lt;p&gt;Relational context message passing은 node와 edge의 identity을 고려하지 않으므로, entity간의 상대적인 위치는 알 수 없습니다.&lt;br /&gt;
이 문제를 해결하기 위해 두 entity가 어떻게 연결됐는지 확인합니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Relational Path&lt;/code&gt;는 경로 내 relation type의  sequence로  나타냅니다. 이때 각 path에서 거쳐가는 entity의 sequence는 유일합니다.&lt;br /&gt;
Notation은 다음과 같습니다.&lt;br /&gt;
$P = {r_{e_0},r_{e_1},…,r_{e_{L-1}}}$ : relation path&lt;br /&gt;
$P_{h \rightarrow t}$ : entity h에서 t로 가는 relation path의 set&lt;/p&gt;

&lt;p&gt;이제 relation path의  표현을 정의하고 구해야 합니다. PATHCON은  각  path에  embedding vector를  할당합니다. &lt;br /&gt;
이렇게 되면 path의 수가 크게 늘어날 수 있으나, 실제 지식그래프는 relation의 밀도가 매우 낮으므로 문제되지 않습니다.&lt;br /&gt;
그러므로 relational path의 길이가 짧고 개수도 적다고 전제할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;model-framework&quot;&gt;Model Framework&lt;/h3&gt;

&lt;h4 id=&quot;combining-relational-context-and-paths&quot;&gt;Combining Relational Context and Paths&lt;/h4&gt;
&lt;p&gt;PATHCON의 모델 학습 과정은 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;head, tail entity의 최종 정보를 통해 entity pair $(h,t)$ 의 context representation을 구합니다.&lt;br /&gt;
  이때 실제 relation $r$은 예측 대상이므로, unobserved를 가정합니다.&lt;/p&gt;

    &lt;p&gt;$s_{(h,t)} = \sigma([m_{h}^{K-1}, m_{t}^{K-1}] \cdot W^{K-1} + b^{K-1})$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;relational context representation이 포함된 Attention weight을 계산합니다.&lt;/p&gt;

    &lt;p&gt;$\alpha_{P}= \frac{exp((s_{P})^{\top} s_{(h,t)})}{\sum_{P \in P_{h \rightarrow t}} exp((s_{P})^{\top} s_{(h,t)})}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;path들의 중요도를 고려한 가중 평균을  구해  path의  representation을 얻습니다.&lt;/p&gt;

    &lt;p&gt;$s_{h \rightarrow t}=\sum_{P \in P_{h \rightarrow t}} \alpha_P s_P$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;context representation과  더해서  softmax을  적용한 후 실제  relation와 predicted relation의  차이에  대해  cross entropy loss를  최소화하는  relation을  구합니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;\(p(r \vert h,t)=\text{SOFTMAX}(s_{(h,t)}+s_{h \rightarrow t})\)
\(\min L= \sum_{(h,r,t) \in D} J(p(r \vert h,t),r)\)&lt;/p&gt;

&lt;p&gt;Context representation $s(h,t)$는  predicted relation의  분포와 relation path의  중요도에 모두 큰 영향을 미치는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;model-explainability&quot;&gt;Model Explainability&lt;/h3&gt;

&lt;p&gt;PATHCON은  relation만으로  모델링하므로 서로  다른  relation간의  관계를  파악하기 쉽습니다. 
이로부터 예측 결과에 대한 explainability를 제공합니다.&lt;/p&gt;

&lt;p&gt;1) relational context을 모델링하여 contextual relation과 predicted relation간의 상관관계를 파악할 수 있습니다. &lt;br /&gt;
이를 통해 주어진 relation의 중요한 이웃 relation을 나타낼 수 있습니다.
2) relational path을 모델링하여 path와 predicted relation간의  상관관계를  파악할  수  있습니다. &lt;br /&gt;
이를 통해 중요한 relational path을 나타낼 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;design-alternatives&quot;&gt;Design Alternatives&lt;/h3&gt;
&lt;h4 id=&quot;context-aggregator&quot;&gt;Context Aggregator&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Mean aggregator
relational context에서 concatenation 대신 mean을 사용해 통합합니다. &lt;br /&gt;
head와 tail의 순서가 바뀌어도 같은 결과를 제공합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cross aggregator&lt;br /&gt;
추천 시스템의 combinatorial features에서 가져온 아이디어이며, 과정은 다음과 같습니다.&lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;Head와  tail의  message의  element-wise pairwise interaction을  계산합니다. 
  \(m_{v}^{i} (m_{u}^{i})^{\top}\)&lt;/li&gt;
      &lt;li&gt;interaction matrix를 flatten하고, relational context와 동일하게 정보를 update합니다.
  \(s_{e}^{i+1}=\sigma(\text{flatten}(m_{v}^{i} (m_{u}^{i})^{\top}) \cdot W_{1}^{i} + s_{e}^{i} \cdot W_{2}^{i} + b^i),  v, u \in N(e)\)&lt;br /&gt;
  이 방법은 입력한 node의 순서를 보존한다는 장점이 있습니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;relational-path-learning&quot;&gt;Relational Path learning&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Learning path representation with RNN&lt;br /&gt;
path에 embedding을  거치지 않고 바로 RNN을  적용해 표현을 학습합니다.&lt;br /&gt;
모델의 Parameter의  수가  고정되고  relational path의 개수에 영향을 받지 않는 장점이 있습니다.&lt;br /&gt;
또한, 경로 간의 유사성을 파악할 수 있을 것으로 기대됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;path-aggregator&quot;&gt;Path Aggregator&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Mean path aggregator: relational path에서 attention weight 대신 mean을 적용해 통합합니다.&lt;br /&gt;
Relational context의 표현을 사용할 수 없을 때 대체하기 위해 사용합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;experiment-setup&quot;&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Dataset&lt;br /&gt;
지식 그래프 Dataset인 FB15K, FB15K-237, WN18, WN18RR, NELL995, DDB14을 사용하였습니다.&lt;br /&gt;
summary는 아래와 같습니다.
    &lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Table2.png&quot; width=&quot;600&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;
    &lt;p&gt;각 Dataset의 Parameter의 수는 다음과 같습니다.&lt;/p&gt;
    &lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Table3.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Baseline&lt;br /&gt;
TransE, ComplEx, DistMult, RotatE, SimplE, QuitE, DRUM, CON, PATH&lt;br /&gt;
Relational Context, Relational Path 중 하나만 적용한 모델 CON, PATH을 추가해 각각의 효과를 확인하고자 합니다.&lt;/li&gt;
  &lt;li&gt;Evaluation Metric&lt;br /&gt;
MRR(Mean Reciprocal Rank)&lt;br /&gt;
Hit@1,3 : cut-off value가 1, 3인 Hit Ratio
    &lt;h3 id=&quot;result&quot;&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;Overall Results
    &lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Table4.png&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;PATHCON이 모든 경우에서 기존 baseline보다 성능이 뛰어나며 특히 &lt;strong&gt;sparse&lt;/strong&gt; 데이터에서 강점을 보입니다.&lt;br /&gt;
한편 PATH, CON 모델에서도 대체로 다른 baseline보다 성능이 뛰어난 것을 확인할 수 있습니다. &lt;br /&gt;
이로부터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;relational path&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;relational context&lt;/code&gt;가 각각 성능 향상에 기여하는 것을 알 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Inductive Knowledge Graph Completion
    &lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Figure3.png&quot; /&gt;&lt;/p&gt;
    &lt;p&gt;PATHCON의 주요 contribution 중 하나인 inductive setting에서의 performance에 대한 결과입니다. 차트의 가로축은 test set의 entity subset 중에서 train set에 포함되지 않은 entity의 비율이며 값이 클수록 inductive setting에 가까워집니다.&lt;/p&gt;

    &lt;p&gt;Embedding 기반의 baseline은 학습하지 않은 데이터에 대해 예측하는 비율이 높아질수록 성능이 떨어지는 반면, PATHCON의 성능은 setting에 robust합니다.&lt;br /&gt;
이로부터 PATHCON이 inductive setting에 적합한 모델임을 알 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;model-variants&quot;&gt;&lt;strong&gt;Model Variants&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Context Hops / Path Length&lt;br /&gt;
Relational Context와 Path Length의 sensitivity를 확인합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Figure4.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;relational context와 path length의 값이 커짐에 따라서 성능이 향상됨을 알 수 있습니다. 
이를 통해 context에 더 많은 정보를 포함하는 것과 path의 길이가 학습에 중요하다는 것을 알 수 있습니다. 두 structure 모두 값이 커질수록 성능 향상폭이 작아집니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Context Aggregator&lt;br /&gt;
context aggregator를 바꿔가면서 성능을 비교하였습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Figure5.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;mean aggregator의 성능이 가장 나쁘므로, 특징을 결합할 때 entity의 순서가 중요한 것을 확인할 수 있습니다.&lt;br /&gt;
concat과 cross은 데이터에 따라 상대적인 성능이 달라지지만, cross의 parameter가 더 많으므로 학습 시간이 길어집니다. &lt;br /&gt;
데이터의 특성에 더 적합한 aggregator를 선택해야 합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Path Representation
    &lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Figure6.png&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;relation type과 relation aggregator에 따라 성능을 비교합니다.&lt;br /&gt;
relation type을 embedding으로 나타낼 때 RNN보다 성능이 뛰어났는데, 이는 전체 지식 그래프의 relation density가 낮아서 relation path가 대체로 짧기 때문인 것으로 생각됩니다.&lt;br /&gt;
또한 attention이 mean보다 좋은 aggregator임을 확인할 수 있으며, relation path의 중요도를 고려해서 모델을 학습해야 함을 알 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Model Explainability&lt;br /&gt;
모델이 예측 결과를 얼마나 잘 설명하는지에 대해 알아보고자 합니다.&lt;br /&gt;
&lt;!-- &lt;&lt;p align=&quot;center&quot;&gt;&gt; --&gt;
&lt;img src=&quot;/images/Relational_Message_Passing_for_Knowledge_Graph_Completion/Table5.png&quot; /&gt;
&lt;!-- &lt;/p&gt; --&gt;&lt;/p&gt;

    &lt;p&gt;실험 과정은 다음과 같습니다.&lt;br /&gt;
1) context hop $=1$, path length $\leq 2$로 설정합니다.
2) 학습이 완료된 상태에서 3개의 relation을 선택합니다.
3) 각 relation에 대해 가장 중요도가 높은 relational context와 path를 제시합니다.&lt;/p&gt;

    &lt;p&gt;제시된 결과를 보면, relational context와 path의 내용이 relation과 문맥상 의미가 통하는 것을 알 수 있습니다.&lt;br /&gt;
이를 통해 모델이 예측한 relation에 대해 explainability를 제시한다고 할 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;본 논문은 지식 그래프 완성 문제를 해결하기 위해 기존의 연구들과 달리 relation path를 기반으로 했습니다.&lt;/li&gt;
  &lt;li&gt;relation에 대한 message passing을 적용하였고, 정보 통합 과정을 수정해서 복잡도를 낮추는 alternate relational message passing을 제안하였습니다.&lt;/li&gt;
  &lt;li&gt;Alternate relational message passing의 강점인 inductive setting, storage efficiency, model explainability를 확인하였습니다.&lt;/li&gt;
  &lt;li&gt;지식 그래프의 subgraph 구조인 relation context와 relation path가 모두 모델의 성능을 높이는 요인임을 확인하였습니다.&lt;/li&gt;
  &lt;li&gt;sparse한 지식 그래프에서도 성능을 유지하는 것을 보였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;review&quot;&gt;&lt;strong&gt;Review&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;message passing을 활용하는 대부분의 기존 GNN 모델은 node feature에 초점을 맞추고 있습니다. &lt;br /&gt;
그러나 본 논문에서는 edge feature에 message passing을 적용해서 학습하는 프레임워크를 제시하였습니다.&lt;br /&gt;
message passing 개념이 나옴에 따라 생각해볼 만한 아이디어였지만, 실제로 구현되었다는게 신기했습니다. &lt;br /&gt;
여기서 더 나아간다면, 화학이나 생명공학처럼 개체 그래프의 node feature와 edge feature가 모두 중요한 도메인에 대해 이 논문의 아이디어를 적용할 수 있을 것입니다.&lt;/p&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Author name&lt;br /&gt;
김대영 (Daeyoung Kim)&lt;/li&gt;
  &lt;li&gt;Affiliation&lt;br /&gt;
KAIST ISysE HS Lab&lt;/li&gt;
  &lt;li&gt;Research Topic&lt;br /&gt;
Application of statistics&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Github Implementation&lt;br /&gt;
(https://github.com/hwwang55/PathCon)&lt;/li&gt;
  &lt;li&gt;Reference&lt;br /&gt;
[KDD ‘21] Relational Message Passing for Knowledge Graph Completion
(https://arxiv.org/pdf/2002.06757.pdf)&lt;br /&gt;
지식 그래프의 정의 (https://www.samsungsds.com/kr/insights/techtoolkit_2021_knowledge_graph.html)&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Sun, 16 Oct 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Relational_Message_Passing_for_Knowledge_Graph_Completion.html</link>
            <guid isPermaLink="true">http://localhost:4000/Relational_Message_Passing_for_Knowledge_Graph_Completion.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[Recsys 2021] Quality Metrics in Recommender Systems: Do We Calculate Metrics Consistently?</title>
            <description>&lt;p&gt;추천시스템은 일반적으로 기업이 이익을 극대화하기위해 사용되고, 이에따라 산업계와 밀접하게 연관되어있다고 생각합니다.&lt;br /&gt;
추천시스템만을 다루는 Recsys, 그중 industrial part에서 이러한 논문을 선정한데에는 그만큼 실제 산업에서 추천시스템을 다룰때 믿을만한 평가기준이 중요하다는것을 의미한다고 생각합니다.&lt;br /&gt;
저 또한 연구를 진행하면서 가장 중요한 부분중 하나인 평가지표에 대해서는 다른사람들의 구현을 그대로 사용하기도 하는 등, 별다른 관심을 가지지 않고있었어서 이번기회에 추천시스템에 관심있는 학우분들께 다같이 생각해 볼 수 있는 기회가 되었으면 하여 소개하게 되었습니다.&lt;/p&gt;

&lt;h1 id=&quot;0-abstract&quot;&gt;0. ABSTRACT&lt;/h1&gt;

&lt;p&gt;논문에서 정의하는 오프라인 테스트는 A/B 테스트가 아닌 metric을 사용하는 일반적인 테스트이다.&lt;br /&gt;
이러한 오프라인 테스트는 A/B 테스트에 비해 비용이 없다시피하고 일관성을 가질 수 있으나, 실제로 현장에서 사용될 때는 종종 생각과 달리 움직이는 면이 있다.
적절한 metric 이 사용되고 있지 않거나, 같은 metric을 사용한다고 하지만 실제로는 그 계산 방식이 매우 상이한 것도 있다.&lt;br /&gt;
저자들은 다양한 추천시스템 프레임워크와 논문들을 살펴보며 이에 대해 논의해보고, 각 metric에 대한 정확한 정의와 세부사항에 대한 합의가 필요함을 이야기 하고자 한다.&lt;/p&gt;

&lt;h1 id=&quot;1-introduction&quot;&gt;1. INTRODUCTION&lt;/h1&gt;

&lt;p&gt;추천 시스템에서 가장 효과적인 평가방식은 A/B 테스트이다. 다만, 이는 시간적으로나 비용적으로 현실적이지 못한 경우가 많기 때문에, 주로 metric을 사용하는 오프라인 테스트를 사용하게 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;테스트는 크게 온라인과 오프라인 두 가지 평가 방법으로 나뉜다. 온라인은 실제 서비스에 적용해 유저의 반응을 살펴보는 방식이다. &lt;strong&gt;오프라인 테스트는 과거에 적용한 알고리즘의 이력(히스토리) 데이터를 이용해 B알고리즘의 성능을 추론한다.&lt;/strong&gt; 비용이 높다는 단점이 있는 온라인 A/B 테스트의 대안으로 등장했다. 하지만 많은 가정이 필요하고 결과가 실제 결과와 다를 수 있다는 위험(리스크)가 존재한다.
[&lt;strong&gt;&lt;a href=&quot;https://post.naver.com/viewer/postView.nhn?volumeNo=31699325&amp;amp;memberNo=34059480&quot;&gt;NDC21-오프라인 A/B 테스트 필요성과 적용 사례&lt;/a&gt;]&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이러한 오프라인 테스트에서 가장 중요한 것 중 하나가 일관성 있고 정확한 metric 인데, 최근 추천시스템에서는 결과의 재현성과 신뢰성에 우려를 나타내는 보고들이 나오고 있다. 이는 추천시스템이 아직 발전하고있고 계속하여 발전하는 영역이기 때문에 보편적으로 적용되는 프로토콜이 없고, 평가를 위해 다양한 metric 들이 산재하기 때문인 것으로 보인다.&lt;/p&gt;

&lt;p&gt;저자들은 일반적으로 베이스라인 실험을 위해 사용되는 라이브러리들과 이들 논문들을 대상으로 적절한 metric을 정확한 계산방식에 따라 사용했는지에 대한 리뷰를 다루며, metric 계산방식을 체계화 하여 요약하였다고 이야기 한다.&lt;/p&gt;

&lt;h1 id=&quot;2-evaluation-methodology&quot;&gt;2. EVALUATION METHODOLOGY&lt;/h1&gt;

&lt;p&gt;Evaluation 과정에서의 명시적인 선택들은 결과에 영향을 끼치기에 논문을 작성함에 있어 이러한 프로토콜들을 정의하여야 할 필요가 있다.
데이터 셋 선택, 데이터 필터링, 분할 전략(splitting strategy), 순위를 매길 항목 선택(choice of items to rank), metric 및 컷오프 depth가 이러한 프로토콜에 해당되고, 저자들은 이를 모든 실험에서 통일하여 일관성을 갖췄음을 밝힌다.&lt;/p&gt;

&lt;p&gt;본 논문에서는 HitRate, Precision, Recall, MRR, MAP, NDCG, RocAuc를 주요한 metric으로 뽑고있다.&lt;/p&gt;

&lt;p&gt;앞의 나머지는 depth cut-off 20 (k=20)을 기준으로 하였으며, RocAuc는 training data를 제외하고 사용했다.&lt;/p&gt;

&lt;p&gt;저자들은 ‘RePlay’라는 자신들의 library를 포함 &lt;a href=&quot;https://github.com/beta-team/beta-recsys&quot;&gt;Beta RecSys&lt;/a&gt; , &lt;a href=&quot;https://github.com/AmazingDD/daisyRec&quot;&gt;DaisyRec&lt;/a&gt; , &lt;a href=&quot;https://github.com/RUCAIBox/RecBole&quot;&gt;RecBole&lt;/a&gt; , &lt;a href=&quot;https://github.com/sisinflab/elliot&quot;&gt;Elliot&lt;/a&gt; , &lt;a href=&quot;https://github.com/ylongqi/openrec&quot;&gt;OpenRec&lt;/a&gt; , DL RS Evaluation, &lt;a href=&quot;https://github.com/microsoft/recommenders&quot;&gt;MS Recommenders&lt;/a&gt;, &lt;a href=&quot;https://github.com/wubinzzu/NeuRec&quot;&gt;NeuRec&lt;/a&gt; , &lt;a href=&quot;https://github.com/yoongi0428/RecSys_PyTorch&quot;&gt;RecSys PyTorch&lt;/a&gt; , &lt;a href=&quot;https://github.com/Darel13712/rs_metrics&quot;&gt;rs_metrics&lt;/a&gt; 을 비교하였다.&lt;/p&gt;

&lt;p&gt;데이터셋과 모델로는 Movie-Lens20m 과 &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3308558.3313710&quot;&gt;EASE&lt;/a&gt;를 사용했다(Autoencoder’st 모델, hidden layer 없이 closed form을 가짐-&lt;a href=&quot;https://glanceyes.tistory.com/entry/Embarrassingly-Shallow-Autoencoders-for-Sparse-Data-%EB%AA%A8%EB%8D%B8%EC%9D%B4-%ED%9D%AC%EC%86%8C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%90-%EA%B0%95%ED%95%9C-%EC%9D%B4%EC%9C%A0&quot;&gt;리뷰&lt;/a&gt;) 4.5점 미만은 negative, 이상은 positive 처리했다.&lt;/p&gt;

&lt;p&gt;Test set으로는 가장 최신의 20%를 가지도록 global timestamp split을 진행, testset 에서만 나타나는 user, item은 제거하였다. 당연하게도 train/test set은 고정하여 진행되었다.&lt;/p&gt;

&lt;h1 id=&quot;3-evaluation&quot;&gt;3. EVALUATION&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/metrics/Untitled.png&quot; alt=&quot;Main result table&quot; /&gt;
결과는 꽤나 흥미로운데, Precision, recall을 제외한 모든 metric에서 라이브러리에 따라 다양한 결과가 발생한다.&lt;/p&gt;

&lt;h3 id=&quot;notations&quot;&gt;Notations&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;$u$ is a user identificator&lt;/li&gt;
  &lt;li&gt;$i$ is an item identificator&lt;/li&gt;
  &lt;li&gt;$rec_k(u)$ is a &lt;strong&gt;recommendation list&lt;/strong&gt; for user $u$ containing top-k recommended items&lt;/li&gt;
  &lt;li&gt;$rel(u)$ is a list of &lt;strong&gt;relevant items&lt;/strong&gt; for user u from the test set&lt;/li&gt;
  &lt;li&gt;$rank(u,i)$ is a &lt;strong&gt;position of item&lt;/strong&gt; $i$ in recommendation list $rec_k(u)$&lt;/li&gt;
  &lt;li&gt;$I[·]$ is an indicator function&lt;/li&gt;
  &lt;li&gt;별다른 표현이 없는 경우 모든 metric은 단일 user에 대해 평가 후 전체 유저에 대해 평균을 낸다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;31-precision-and-recall&quot;&gt;3.1 Precision and Recall&lt;/h2&gt;

&lt;p&gt;믿음의 precision and recall, 이걸 자의적으로 해석하는 경우는 없다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Precision
    &lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;추천한&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;k개&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;중에&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;hit한&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;item의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;비율&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;$
\text { Precision@k(u)=} \frac{\left|\operatorname{rel}(u) \cap \operatorname{rec}_{k}(u)\right|}{k}
$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Recall
    &lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;relevant&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;중에&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;한&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;item의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;비율&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;$
\text { Recall@k(u)=} \frac{\left|\operatorname{rel}(u) \cap \operatorname{rec}_{k}(u)\right|}{|\operatorname{rel}(u)|}
$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;32-hitrate&quot;&gt;3.2 HitRate&lt;/h2&gt;

&lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Single&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;k개의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;추천&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;목록&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;내에서&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;적어도&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;하나가&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;relevant&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;이면&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;아니면&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;→&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;전체&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;에&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;대해&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;한&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;비율&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;HitRate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$
\text { HitRate@k(u)=I[|rel(u)}\left. \cap \operatorname{rec}_{k}(u) \mid&amp;gt;0\right]
$&lt;/p&gt;

&lt;p&gt;상식적으로 Hit rate는 1이하여야 하나 DL RS Evaluation 에서는 1이 넘는 경우가 발생, 해당 문제는 올바르게 예측한 항목의 평균수(precision*k)를 Hitrate라 칭한것으로 나타남&lt;/p&gt;

&lt;h2 id=&quot;33-mrrmean-reciprocal-rank&quot;&gt;3.3 MRR(Mean Reciprocal Rank)&lt;/h2&gt;

&lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Single&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;k개의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;추천&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;목록&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;내에&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;첫번째로&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;relevant&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;한&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;position의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;역수&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;→&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;전체&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;user에&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;대해&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;해당&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;inverse&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;평균&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;MRR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$
M R R @ k(u)=\frac{1}{\min _{i \in \operatorname{rel}(u) \cap \operatorname{rec}(u)} \operatorname{rank}(u, i)}
$&lt;/p&gt;

&lt;p&gt;DaisyRec 의 경우 첫번째 relevant item 의 inverse position 이 아닌, 전체 relevant item 들의 inverse position의 합을 계산했음. 이때 MRR은 1이 넘을 수도 있다.&lt;/p&gt;

&lt;h2 id=&quot;34-mapmean-average-precision&quot;&gt;3.4 MAP(Mean Average Precision)&lt;/h2&gt;

&lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Single&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;User의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;AP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;AP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;u에&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;대한&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Precision&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;평균&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;→&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;모든&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;에&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;대한&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;AP의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;평균&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;MAP&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$
A P @ k(u)=\frac{1}{x} \sum_{i \in \operatorname{rec}_{k}(u)} \mathbb{I}[i \in \operatorname{rel}(u)] \operatorname{Precision@rank}(u, i)(u)
$&lt;/p&gt;

&lt;p&gt;MAP 에서 ‘M’ 에 해당하는 mean term 은 일반적으로 이견이 없다. 문제는 ’A’에 해당하는 averaging term $x$ 의 정의가 모호하다는 것, 일반적으로는 해당 세개 중 하나의 의미가 사용된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$x=k$ : 추천 목록 item의 수(length of recommendation list)&lt;/li&gt;
  &lt;li&gt;$x = r=\vert rel(u)\vert $ : user 의 relevant item의 수&lt;/li&gt;
  &lt;li&gt;$x = min(k,r)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;MAP&lt;/strong&gt; 는 모든 metric 중 가장 일관성 없는 값을 보였음(5개)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;AP&lt;/strong&gt;는 원래 precision-recall curve 에서 area를 의미하기 때문에, recall 에 해당하는 relevant item 수를 를 가져가는게 합당해보이다. 두번째 케이스인 $x=r$ 이 이에 해당한다. Beta Recsys, MS Recommenders, rs_metrics. 가 이런 정의를 따른다.&lt;/p&gt;

    &lt;p&gt;→ 단 r &amp;gt; k 라면 AP는 절대 1에 도달 할 수 없음.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;DaisyRec 은 첫번째 케이스인 x=k를 사용한다.
→ 단 r &amp;lt; k 라면 더이상 개선 할 수 없음에도 AP는 1을 달성할 수 없음.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;위 두가지 케이스 때문에 $x = min(k,r)$ 을 사용하는 경우가 있다. RecBole, RePlay , DL RS 는 이러한 이유로 해당 정의를 사용한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;위 세가지를 제외하고도 다른 해석을 적용하는 경우가 있었다. 대부분 구현 실수로 보인다.
    &lt;ul&gt;
      &lt;li&gt;Eliot의 경우 documentation 에서는 $x = min(k,r)$을 사용한다고 적어놓았지만, 실제로는 $x=k$를 사용하였으며, Indicator function을 빼먹어 추천대상이 아닌 아이템에 대해서도 precision 을 계산하였다.&lt;/li&gt;
      &lt;li&gt;NeuRec 의 경우 역시 $x = min(k,r)$ 를 사용한다고 적혀있지만, sum 과정에서 변수명 꼬임과 같은 오류로 누적이 제대로 이뤄지지 않아, 이상한 값을 내놓았다.(다른 케이스 대비 1/10 수준)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;34-ndcgnormalized-discounted-cumulative-gain&quot;&gt;3.4 NDCG(Normalized Discounted Cumulative Gain)&lt;/h2&gt;

&lt;div class=&quot;language-jsx highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;추천결과의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;상위항목에&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;보다&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;높은&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;가중치를&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;부여하기&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;위해&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;사용&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;임의의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;relevance&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;value인&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;rating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;를&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;가중치로&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;부여&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;DCG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Discounted&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Cumulative&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Gain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;이상치인&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;IDCG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Ideal&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DCG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;와&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DCG의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;비로&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;NDCG값이&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;계산&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;이때&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Idial&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;한&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;값은&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;rating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;으로&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;정렬되었을때의&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DCG값을&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;의미&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$
N D C G @ k(u)=\frac{D C G @ k(u)}{I D C G @ k(u)}
$&lt;/p&gt;

&lt;h3 id=&quot;dcg-weighted-version&quot;&gt;DCG-weighted version&lt;/h3&gt;

&lt;p&gt;$
D C G @ k(u)=\sum_{i \in r e c_{k}(u)} \frac{2^{\text {rating }(u, i)}-1}{\log _{2}(\operatorname{rank}(u, i)+1)}
$&lt;/p&gt;

&lt;h3 id=&quot;dcg-binary-version&quot;&gt;DCG-Binary version&lt;/h3&gt;

&lt;p&gt;$
D C G @ k(u)=\sum_{i \in r e c_{k}(u)} \frac{\mathbb{I}[i \in \operatorname{rel}(u)]}{\log _{2}(\operatorname{rank}(u, i)+1)}
$&lt;/p&gt;

&lt;h3 id=&quot;dcg-논문에선-언급하지-않음&quot;&gt;DCG-??(논문에선 언급하지 않음)&lt;/h3&gt;

&lt;p&gt;국내 블로그에서는 rating이 정해져 있고, 분자에서 이를 모두 더하는 방식을 많이 소개한다.&lt;/p&gt;

&lt;p&gt;$
D C G @ k(u)=\sum_{i \in r e c_{k}(u)} \frac{\text {rating }(u, i)}{\log _{2}(\operatorname{rank}(u, i)+1)}
$&lt;/p&gt;

&lt;p&gt;라이브러리들은 weighted version 과 binary version 중 하나를 선택하는데&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Beta RecSys, RecBole, RePlay, DaisyRec, MS Recommenders, NeuRec, rs_metrics 에서는 Binary version을 사용.&lt;/li&gt;
  &lt;li&gt;OpenRec 에서는 Binary version 을 사용한다고 되어있으나 normalization term 을 빼먹었다. 즉 NDCG 가 아닌 DCG 값을 출력.&lt;/li&gt;
  &lt;li&gt;DL RS Evaluation ,Elliot 에서는 weight version을 사용하고 relevance value를 입력하도록 함, 단 Eliot 에서는 $log_2$ 가 아닌 자연로그 사용.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;36-rocaucreciever-operating-characteristic-area-under-curve&quot;&gt;3.6 RocAuc(Reciever Operating Characteristic Area Under Curve)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;(참고)ROC 와 precision-recall은 다르다..
&lt;img src=&quot;/images/metrics/Untitled_1.png&quot; alt=&quot;ROC vs Precision-recall&quot; /&gt;
&lt;a href=&quot;https://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves&quot;&gt;ROC vs precision-and-recall curves&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;RocAuc는 굉장히 애매하다. 일반적으로 classification 에서 많이 사용되는데(1/0 값을 가지는 이진 결과), 아직 추천시스템에서 어떻게 사용할것인지에 대해 명확히 정해진바가 없음.&lt;/p&gt;

&lt;p&gt;그래서 ROC를 왜 쓰게 되었나? ← BPR(Bayesian Personalized Ranking from Implicit Feedback)의 영향으로 보인다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/metrics/Untitled_2.png&quot; alt=&quot;Bayesian Personalized Ranking from Implicit Feedback&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Bayesian Personalized Ranking from Implicit Feedback&lt;/p&gt;

&lt;p&gt;1,0의 binary implicit feed을 다룰때 BPR은 사용자의 선호도를 두 아이템 간의 pairwise-ranking 문제로 formulation 함으로써 각 사용자 $u$의 personalized ranking function을 추정&lt;/p&gt;

&lt;p&gt;→ User-item 선호를 구분하는 classifier 문제로 생각할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/metrics/Untitled_3.png&quot; alt=&quot;Tipycal ROC curve in classifiacation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;→ 임의의 positive와 negative sample이 주어졌을 때, negative sample보다 positive sample을 더 높은 순위(더 높은 positive 확률)로 평가할 확률을 의미한다.&lt;/p&gt;

&lt;p&gt;쉽게말하면 유저에게 item 들이 임의의 rating 을 가지고 있을때 이를 정렬(rating에 따른 ranking)하여 반갈하는 classification 하는 문제로 볼 수 있다는 것&lt;/p&gt;

&lt;p&gt;문제는 단순한 생각으로 T/F를 무작위로 찍는 classifier는 RocAuc에서 0.5를 얻겠지만, 무작위로 추천하는 추천시스템에서는 0.5를 얻을리가 없다는 것, 따라서 classifier 와 같은 단순한 생각은 추천시스템에서 곧바로 적용시키기 힘들다.&lt;/p&gt;

&lt;p&gt;이러한 상황에서 두가지 핵심적인 결정이 필요한데&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;전체 item 들을 대상으로 생각할 것인지, k 개의 item을 대상으로 할 것인지&lt;/li&gt;
  &lt;li&gt;전체 user 에 대한 계산을 한번에 할 것인지, 아님 개인의 AUC를 구한 뒤 averaging 할 것인지&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/metrics/Untitled_4.png&quot; alt=&quot;RocAuc variance&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;saucstacked-auc&quot;&gt;SAUC(Stacked AUC)&lt;/h3&gt;

&lt;p&gt;가장 simple 하게 생각한다. 전체 item 들에 대해 full ranking 을 부여하고 이를 classification 문제와 같이 다루는 것 Beta RecSys, RecBole ,MS Recommenders&lt;/p&gt;

&lt;h3 id=&quot;gaucgroup-auc&quot;&gt;GAUC(Group AUC)&lt;/h3&gt;

&lt;p&gt;SAUC 에서 서로다른 사용자의 추천이 다른것에 문제 제기, 각 user 의 ROC 커브에서 AUC를 계산 한 후, 이를 averaging. OpenRec, DL RS Evaluation, Elliot, RePlay, RecBole&lt;/p&gt;

&lt;h3 id=&quot;gauck&quot;&gt;GAUC@k&lt;/h3&gt;

&lt;p&gt;전체 ranking 이 아닌 k 개의 ranking 만 고려한다, Replay, DL RS Evaluation, DaisyRec&lt;/p&gt;

&lt;h1 id=&quot;4-paper-analysis&quot;&gt;4. Paper Analysis&lt;/h1&gt;

&lt;p&gt;위에서 살펴보았듯, 몇몇 metric 들은 잘못해석될 여지가 있고 다양한 베리에이션과 그에 따른 해석이 존재한다. 문제는 어떤 metric 을 사용했는지 정확히 적어두기라도 했으면 모르겠는데, 그렇지 않은 경우가 많다는 것이다. 논문에서도 이러한 현상은 비슷하게 나타는데, 저자들은 이를 확인하기 위해 몇몇 베이스라인으로 주로 사용되는 논문들에서는 이를 어떻게 다루는지 살펴보았다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/metrics/Untitled_5.png&quot; alt=&quot;Paper analysus&quot; /&gt;
자신들이 사용한 metric 에대해 정확히 기술한 논문은 5/15, 정확히 기술한 레퍼런스를 단 논문은 3/15, 잘못된 레퍼런스를 달았더나 정확히 어떤 metric 을 사용했는지 알 수 없게 기술한 경우는 7/15 거의 절반에 가까운 상황이었다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Recsys의 큰 획을 그은것으로 여겨지고 그만큼 많이 인용되는 NCF(&lt;strong&gt;Neural Collaborative Filtering&lt;/strong&gt;) 의 경우
    &lt;blockquote&gt;
      &lt;p&gt;“the HR intuitively measures whether the test item is present on the top-10 list, and the NDCG accounts for the position of the hit by assigning higher scores to hits at top ranks.”
와 같이 명확하지 않은 설명을 적어놓았다. 물론 HR 과 NDCG에 대해 정확히 적어놓은 &lt;strong&gt;TriRank: Review-aware Explainable Recommendation by Modeling Aspects&lt;/strong&gt; 를 참조했지만 두 논문의 Hit rate는 같은 의미였던 반면 NDCG에서는 모순된 결과를 보였다.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MultiVAE(Variational Autoencoders for Collaborative Filtering) 에서는 recall에서 위에서 설명한 것들과는 달리 또다른 정의를 사용한다.&lt;/p&gt;

    &lt;p&gt;AP 에서처럼 rel(u) 대신 min(r,k)를 사용)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;CDL(&lt;strong&gt;Collaborative Deep Learning for Recommender Systems)&lt;/strong&gt; 에서는
    &lt;blockquote&gt;
      &lt;p&gt;“Another evaluation metric is the mean average precision (mAP)”
로 설명을 끝내고 만다. 이는 MAP 가 가장 variation 이 컸던만큼, 결과해석을 어렵게 만드는 부분이다.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;5-conclusion&quot;&gt;5. CONCLUSION&lt;/h1&gt;

&lt;p&gt;저자들은 라이브러리와 논문들에서 다양한 metric 들이 어떤식으로 차이를 보이는지 살펴보았고, 각 metric 들이 표준화 되지 않아 다양하게 해석될 가능성이 있음을 설명한다.&lt;/p&gt;

&lt;p&gt;일반적으로 단순한 metric 일 수록 의견차가 없음(precision, recall등)이 나타났고, 복잡한 metric 일 수록 다양한 해석이 존재하였다. 이에대해 recommenation system 커뮤니티에서 표준화된 합의가 필요함을 밝히며 논문을 마친다.&lt;/p&gt;

&lt;h1 id=&quot;6-opinion&quot;&gt;6. OPINION&lt;/h1&gt;

&lt;p&gt;특히 baseline등을 구현할 때 별 생각없이 사용해오던 구현체 들이 많은데, 이번 논문을 읽으며 좀 더 주의하고 한번 더 코드를 살펴봐야겠다는 경각심을 갖게 되었습니다.&lt;br /&gt;
저자들은 future work로 별다른 내용을 담진 않았지만, 실제 산업에서 A/B 테스트 대비 어떤 metric이 비슷한 결과를 보이는지에 대한 연구를 진행하면 좋겠다 라는 생각이 들었습니다.&lt;br /&gt;
특히 rating prediction 문제에서는 rmse를 평가지표로 많이 활용하는데, 이러한 결과가 실제 구매/클릭 전환에 얼마나 기여하는지에 대한 궁금증이 있어왔습니다. 공개된 데이터셋으로는 아마 쉽지 않겠지만, 기회가 닿는다면 이러한 연구를 진행해 보고 싶습니다.&lt;/p&gt;
</description>
            <pubDate>Sun, 16 Oct 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Quality_Metrics_in_Recommender_Systems_Do_We_Calculate_Metrics_Consistently.html</link>
            <guid isPermaLink="true">http://localhost:4000/Quality_Metrics_in_Recommender_Systems_Do_We_Calculate_Metrics_Consistently.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICLR 2022] Online Coreset Selection for Rehearsal-based Continual Learning</title>
            <description>&lt;h1 id=&quot;title&quot;&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Online Coreset Selection for Rehearsal-based Continual Learning&lt;/p&gt;
&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Static한 setting에 맞춰져 있는 현재의 Learning process는 현실의 상황과는 거리가 멀다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sequence of tasks에 continuously 적용될 수 있는 model 고안하는 것이 본 논문의 주된 목적이다.&lt;/li&gt;
  &lt;li&gt;Sequence of tasks에 continuously 적용될 수 있는 model을 고안하는 것이 본 논문의 주된 목적이다.&lt;/li&gt;
  &lt;li&gt;Continual Learning에서 발생하는 주된 문제인 catastrophic forgetting 문제도 보완한다.&lt;/li&gt;
  &lt;li&gt;더욱 specific한 setting으로 imbalanced / noisy한 data 상황에서도 높은 accuracy와 적은 catastrophic forgetting을 목표한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;21-continual-learning과-catastrophic-forgetting&quot;&gt;2.1 Continual Learning과 Catastrophic Forgetting&lt;/h3&gt;
&lt;p&gt;Continual Learning은 많은 관심을 받고 있는 연구 분야이며, 눈에 띌만한 성장세를 보이고 있다.
현재까지의 Learning Scenario는 static한 setting에 초점이 맞춰져 개발되었다. 하지만 현실에서의 setting은 dataset이 고정되어 있지 않고, 새로운 data / class 등이 끊임없이 추가된다. 이러한 상황에서 model은 정확성을 지속적으로 유지할 수 있어야 한다. 그렇다면 이러한 setting에서 새로운 task까지 잘 해내는 모델을 학습해야 한다면 어떻게 해야할까?
당연히 모델을 retraining 시켜야한다. 
모델을 retraining 시키기 위해 아래 두 가지 방법을 쉽게 떠올려 볼 수 있다.
첫째, 기존 데이터에 새로운 데이터까지 추가해서 모델을 처음부터 다시 학습하는 방법이다. 이 방법이 직관적일 수 있지만, 새로운 데이터가 수집될 때마다 전체 데이터셋에 대하여 모델의 모든 가중치값들을 학습하는 것은 시간과 computational cost 측면에서 큰 손실이다. 
그렇다면, 모델을 새로운 데이터로만 retraining 시키면 어떻게 될까? 이전에 학습했던 데이터와 유사한 데이터셋을 학습하더라도 아래의 그림처럼 이전의 데이터셋에 대한 정보를 잊어버리게 될 것이다. 이 문제를 일컬어 &lt;strong&gt;Catastrophic Forgetting&lt;/strong&gt; 이라고 부른다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Catastrophic Forgetting : Single task에 대해서 뛰어난 성능을 보인 모델을 활용하여 다른 task를 위해 학습했을 때 이전에 학습했던 task에 대한 성능이 현저하게 떨어지는 현상&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;910&quot; alt=&quot;스크린샷 2022-10-16 오후 8 45 19&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196033585-efd48b3d-fc30-47e8-90ba-083fd2fa713b.png&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;Catastrophic forgetting은 neural network의 더욱 general한 problem인 “stability-plasticity” dilema의 결과이다. 
이 때, stability는 previously acquired knowledge의 보존을 의미하고, plasticity는 new knowledge를 integrate하는 능력을 의미한다.&lt;/p&gt;
&lt;h3 id=&quot;22-limitation&quot;&gt;2.2 Limitation&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Training instances are not equally useful!
    &lt;ul&gt;
      &lt;li&gt;Current task를 학습하는데 더 representative / informative한 data들이 있다.&lt;/li&gt;
      &lt;li&gt;그렇지 않은 data를 쓸 경우 오히려 성능을 떨어뜨릴 가능성이 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Imbalanced / Noisy instances
    &lt;ul&gt;
      &lt;li&gt;Real-world에서는 data가 imbalanced / noisy한 경우가 있다.
        &lt;h3 id=&quot;23-purpose&quot;&gt;2.3 Purpose&lt;/h3&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;새로운 task를 학습할 때 이전 task에 대한 catastrophic forgetting 방지.&lt;/li&gt;
  &lt;li&gt;새로운 task 학습을 용이하게 하기 위해 이전 task의 knowledge를 사용.&lt;/li&gt;
  &lt;li&gt;Online Corset Selection (OCS) 방법론을 고안하여 representative하고 diverse한 subset을 선정하여 buffer에 저장하고 새로운 task 학습에 함께 사용.&lt;/li&gt;
  &lt;li&gt;Current task에 대해서도 모든 data를 사용하는 것이 아닌 이전 task의 buffer들과 high affinity를 갖는 data를 선정하여 함께 training 시킴.&lt;/li&gt;
  &lt;li&gt;Online Corset Selection (OCS) 방법론을 고안하여 representative하고 diverse한 subset을 선정하여 &lt;strong&gt;buffer&lt;/strong&gt;에 저장하고 새로운 task 학습에 함께 사용.&lt;/li&gt;
  &lt;li&gt;Current task에 대해서도 모든 data를 사용하는 것이 아닌 이전 task의 buffer들과 high &lt;strong&gt;affinity&lt;/strong&gt;를 갖는 data를 선정하여 함께 training 시킴.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- buffer : 이전 task의 dataset 중 현재의 task dataset과 함께 training 시키기 위해 저장시키는 data의 subset
- affinity : 현재의 task dataset이 이전 task의 buffer들과 갖는 친밀도(유사도)를 의미한다. 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;24-contributions&quot;&gt;2.4 Contributions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Class-imbalanced / noisy setting이 존재하는 continual scenario를 다루었다.&lt;/li&gt;
  &lt;li&gt;OCS (Online Coreset Selection)이라는 simple하지만 effective한 방법론을 개발하였고, 이는 similarity (대표성) &amp;amp; diversity (overfitting 방지)를 함께 고려하여 replay시킬 data point를 select한다.&lt;/li&gt;
  &lt;li&gt;다양한 세팅으로 이루어진 여러 실험을 통해 각 component와 제안한 model의 효과를 입증하였다.
    &lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;31-online-coreset-selection&quot;&gt;3.1 Online Coreset Selection&lt;/h3&gt;
&lt;p&gt;이 부분에서는 주어진 task에서 어떠한 기준으로 replay 시킬 data를 선정하는지에 대해 설명합니다.&lt;br /&gt;
크게 두가지의 기준을 적용하는데, “similarity”와 “diversity”입니다.&lt;/p&gt;
&lt;h4 id=&quot;311-minibatch-similarity&quot;&gt;3.1.1 Minibatch similarity&lt;/h4&gt;
&lt;p&gt;&lt;img width=&quot;549&quot; alt=&quot;스크린샷 2022-10-16 오후 5 54 49&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196027003-a953f49a-e062-4475-835e-ae90e3b4e4d1.png&quot; /&gt;&lt;br /&gt;
$b_{t,n} = {x_{t,n}, y_{t,n}} \in B_t$는 data point의 n-th pair를 의미하고, 분모의 좌측에 있는 식은 해당 datapoint의 gradient를 의미한다. 또한, 분모의 우측에 있는 식은 집합 $B_t$내에 있는 data들의 gradient의 평균을 의미한다.&lt;br /&gt;
즉, 이 식은 특정 data point의 gradient와 집합 $B_t$내의 data들의 gradient의 평균 간의 similarity를 나타낸 식이다.&lt;/p&gt;
&lt;h4 id=&quot;312-sample-diversity&quot;&gt;3.1.2 Sample diversity&lt;/h4&gt;

&lt;p&gt;&lt;img width=&quot;782&quot; alt=&quot;스크린샷 2022-10-16 오후 6 11 45&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196027577-52824602-f595-4d0a-93e5-6145d6b639cf.png&quot; /&gt;
본 식에서는 특별히 새롭게 설명할 notation은 없을 것이다. 본 식은 특정 data point $b_{t,n}$과 subset 내의 다른 datapoint $b_{t,p}$ 간의 dissimilarity의 평균이다. 따라서 값이 클수록 subset 내의 다른 data와 다른, 즉 다양성을 갖는 data point라는 것이다.&lt;/p&gt;
&lt;h3 id=&quot;32-online-coreset-selection-for-current-task-adaptation&quot;&gt;3.2 Online Coreset Selection for Current Task Adaptation&lt;/h3&gt;
&lt;p&gt;&lt;img width=&quot;954&quot; alt=&quot;스크린샷 2022-10-16 오후 6 12 43&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196027593-ced3a9f0-9dde-4996-8697-a2664bef41d6.png&quot; /&gt;
이제 위의 section 3.1에서 다룬 두 가지 기준 “similarity”와 “diversity”를 고려하여 replay 시킬 data를 뽑아야 할 것이다.&lt;br /&gt;
Similarity와 diversity 값을 더하여 그 값이 가장 큰 top k개를 선정한 $u^{*}$집합을 선정한다.&lt;br /&gt;
그 이후 아래와 같이 replay할 data를 갖고 loss가 최소가 되도록 model을 training 시키는 간단한 방법론을 제시하였다.
&lt;img width=&quot;680&quot; alt=&quot;스크린샷 2022-10-16 오후 6 13 07&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196027612-158471e7-2a59-4981-91c3-74616208434d.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;33-online-coreset-selection-for-continual-learning&quot;&gt;3.3 Online Coreset Selection for Continual Learning&lt;/h3&gt;
&lt;p&gt;지금부터는 저자가 제시한 OCS (Online Coreset Selection) 방법론에 대해 구체적으로 다룰 것이다.&lt;br /&gt;
OCS 방법론의 목적은 previous task의 지식을 앞서 다룬 similarity와 diversity의 관점에서 고려하여 현재 task에서 활용도가 높은 coreset을 찾는 것이다.&lt;br /&gt;
더 직관적으로 설명하자면, 현재 task에 대해서는 모든 dataset을 사용할 수 있는 것 아닌가라는 의문이 들 수 있다. 하지만 늘 그렇듯 real-world dataset에는 noise가 있기도 하고, 틀리지 않은 data 이지만 이전 task가 지향하는 방향과는 방향성이 다를 수 있다. 이에, 저자는 현재 task 이더라도, continual한 세팅에서 sequential한 학습에 도움이 되는 data subset을 선정하여 그 data들에 대해서만 training을 진행한다.&lt;/p&gt;
&lt;h4 id=&quot;331-coreset-affinity&quot;&gt;3.3.1 Coreset Affinity&lt;/h4&gt;
&lt;p&gt;&lt;img width=&quot;628&quot; alt=&quot;스크린샷 2022-10-16 오후 6 13 53&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196027637-03f9f7eb-a93d-43ec-860e-9f611003029f.png&quot; /&gt;&lt;br /&gt;
위의 similarity 수식과 굉장히 유사하다. 분모의 우측에 있는 식이 의미하는 것은 coreset C로부터 randomly sampled 된 subset $B_c$에 대한 gradient의 평균이다. 따라서 이는 현재 task의 data distribution만 고려하는 것이 아니라 이전 task의 coreset과의 similarity도 고려한다는 의미이다.&lt;br /&gt;
그렇다면 새로운 data selection equation은 아래와 같이 구성된다.&lt;br /&gt;
&lt;img width=&quot;1151&quot; alt=&quot;스크린샷 2022-10-16 오후 6 14 15&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196027645-e90bb248-d44c-431a-9cc5-e066dc4f4bc3.png&quot; /&gt;&lt;br /&gt;
그리고, 마찬가지로 아래와 같은 수식을 통해 current task의 coreset과 이전 task들에서 replay된 data들의 loss를 최소화하는 parameter를 찾는 방향으로 model이 training된다.&lt;br /&gt;
&lt;img width=&quot;726&quot; alt=&quot;스크린샷 2022-10-16 오후 6 14 42&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196027655-da4f626d-89e3-4d1e-bd97-87f7b85f8e8f.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;34-algorithm&quot;&gt;3.4 Algorithm&lt;/h3&gt;
&lt;p&gt;위의 방법론을 하나의 algorithm으로 정리하면 아래와 같다.&lt;br /&gt;
&lt;img width=&quot;1232&quot; alt=&quot;스크린샷 2022-10-16 오후 6 15 09&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196027674-50e06f92-2355-4010-9e01-ed2adb793666.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;41-experiment-setup&quot;&gt;&lt;strong&gt;4.1 Experiment setup&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&quot;411-dataset&quot;&gt;4.1.1 Dataset&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Domain Incremental&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;Task간에 겹치는 class가 있다. 즉, 모든 task에 class가 섞여서 존재한다.&lt;/li&gt;
      &lt;li&gt;Rotated MNIST&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Task Incremental&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;Task간에 겹치는 class가 없는 setting이다. Test 상황에서 data point가 속한 task의 class에 대해 test한다. (task 정보 있음)&lt;/li&gt;
      &lt;li&gt;Split CIFAR-100 / Multiple Datasets (a sequence of five datasets)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Class Incremental&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;Task간에 겹치는 class가 없는 setting이다. Test 상황에서 전체 class에 대해 test한다. (task 정보 없음)&lt;/li&gt;
      &lt;li&gt;Balanced and ?Imbalanced Split CIFAR-100
        &lt;h4 id=&quot;412-baseline&quot;&gt;4.1.2 baseline&lt;/h4&gt;
        &lt;p&gt;OCS과의 비교를 위해 continual setting에서 아래의 모델들과 비교하였다.&lt;br /&gt;
~~~&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;ul&gt;
      &lt;li&gt;EWC&lt;/li&gt;
      &lt;li&gt;Stable SGD&lt;/li&gt;
      &lt;li&gt;A-GEM&lt;/li&gt;
      &lt;li&gt;ER-Reservior&lt;/li&gt;
      &lt;li&gt;Uniform Sampling &amp;amp; k-means features&lt;/li&gt;
      &lt;li&gt;k-means Embeddings&lt;/li&gt;
      &lt;li&gt;iCaRL&lt;/li&gt;
      &lt;li&gt;Grad Matching&lt;/li&gt;
      &lt;li&gt;GSS&lt;/li&gt;
      &lt;li&gt;ER-MIR&lt;/li&gt;
      &lt;li&gt;Bilevel Optim
~~~
        &lt;h4 id=&quot;413-evaluation-metric&quot;&gt;4.1.3 Evaluation Metric&lt;/h4&gt;
        &lt;p&gt;본 논문의 주된 목적은 continual learning에서 고질적으로 발생하는 문제인 catastrophic forgetting을 줄이기 위함이므로 이에 알맞은 evaluation metric을 저자는 제안한다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Average Accuracy : 일반적인 accuracy value이다.&lt;/li&gt;
  &lt;li&gt;Average Forgetting : 이후 task를 학습하고 난 뒤, task의 accuracy가 떨어지는 정도를 측정한 값이다.
    &lt;h3 id=&quot;42-result&quot;&gt;&lt;strong&gt;4.2 Result&lt;/strong&gt;&lt;/h3&gt;
    &lt;h4 id=&quot;421-quantitative-analysis-for-continual-learning&quot;&gt;4.2.1 Quantitative Analysis for Continual Learning&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;773&quot; alt=&quot;스크린샷 2022-10-16 오후 7 19 44&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196030031-5b891dbe-a690-4443-9a50-b37a6996469e.png&quot; /&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Baseline model 모두 일정 수준의 catastrophic forgetting은 발생하는 것을 관찰할 수 있다.&lt;/li&gt;
  &lt;li&gt;Balanced continual learning setting에서 random replay based methods (A-GEM &amp;amp; ER-Reservoir)과 비교하면 OCS는 average accuracy 관점에서 약 19%의 gain이 있다.&lt;/li&gt;
  &lt;li&gt;마찬가지로, balanced continual learning setting에서 forgetting average도 다른 baseline보다 현저히 낮은 수치가 관찰된다.&lt;/li&gt;
  &lt;li&gt;OCS는 imbalance setting에서 balanced setting에서보다 더욱 큰 강점을 보였다.&lt;/li&gt;
  &lt;li&gt;Accuracy와 forgetting 측면에서 baseline model들보다 훨씬 좋은 성능을 보였고, 이는 baseline model에서는 imbalance 상황에서 current task에 대해 coreset을 select하는 과정이 없으므로 biased estimation이 진행되어 performance degenerate이 일어났다고 볼 수 있다.
    &lt;h4 id=&quot;422-noisy-continual-learning&quot;&gt;4.2.2 Noisy Continual Learning&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;847&quot; alt=&quot;스크린샷 2022-10-16 오후 7 30 40&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196030490-c293e4c2-740d-40ee-8464-ae1f289c0852.png&quot; /&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Gaussian noise를 적용하여 Rotated MNIST dataset을 noise하게 setting하였다.&lt;/li&gt;
  &lt;li&gt;위의 table을 보면, noise는 모든 baseline의 성능을 상당히 저하시키는 것을 관찰할 수 있다.&lt;/li&gt;
  &lt;li&gt;하지만 저자가 제안한 OCS의 경우, noise rate이 증가함에 따라 accuracy와 forgetting이 심각하게 저하되지는 않는 것으로 보여진다. 이는 task 내에서 similarity와 diversity를 고려하여 coreset을 선정하는 과정이 noise data를 상당부분 제외시키는 것으로 해석 가능하다.&lt;/li&gt;
  &lt;li&gt;하지만 저자가 제안한 OCS의 경우, noise rate이 증가함에 따라 accuracy와 forgetting이 심각하게 저하되지는 않는 것으로 보여진다.&lt;/li&gt;
  &lt;li&gt;이는 과거 task에 대해 similarity와 diversity를 고려하여 coreset을 선정하고, 현재 task에 대해서도 affinity를 고려하여 coreset을 선정하기 때문에 noise data를 상당부분 제외시킨 채로 학습을 진행하기 때문인 것으로 해석이 가능하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;423-ablation-studies&quot;&gt;4.2.3 Ablation Studies&lt;/h4&gt;
&lt;p&gt;&lt;img width=&quot;591&quot; alt=&quot;스크린샷 2022-10-16 오후 7 36 47&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196030702-cf33ae30-28ab-4559-89bc-7ba82aeacc6e.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;본 실험은 gradient 활용의 효과를 검증한 실험이다.&lt;/li&gt;
  &lt;li&gt;Gradient를 활용하여 coreset selection을 한 경우와 raw input (Input-OCS), feature-representations (Feat-OCS)를 활용하여 coreset selection을 한 경우를 비교하였는데, balanced / imbalanced CL setting에서 모두 gradient가 다른 두 방법에 비해 좋은 성능을 보였다.
&lt;img width=&quot;589&quot; alt=&quot;스크린샷 2022-10-16 오후 7 36 55&quot; src=&quot;https://user-images.githubusercontent.com/89853986/196030706-9da699fc-630a-4c11-909d-de476780342a.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Coreset에 들어갈 top k개의 data를 고르는 과정에서 “Minibatch similarity”, “Sample diversity”, “Coreset affinity”라는 세가지 식이 적용된다.&lt;/li&gt;
  &lt;li&gt;본 실험은 이러한 세가지 component의 효과를 관찰하기 위해 component를 제외해보며 abalation study를 진행하였다.&lt;/li&gt;
  &lt;li&gt;Similarity와 diversity를 혼자만 사용하는 것은 성능 저하가 상당했다. Similarity만 사용할 경우, 중복되는 data를 선정할 가능성이 있고, diversity만 고려할 경우 representative한 data point를 선정하는데에 한계가 있을 것이다.&lt;/li&gt;
  &lt;li&gt;따라서 similarity와 diversity의 고려 비율을 적절히 interpolate해야 좋은 성능이 도출될 것이고, 아래의 그림은 “noisy rotated MNIST”, “multiple dataset”에서 각각의 interpolate ratio에서의 average test accuracy를 나타낸다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&quot;center&quot;&gt;

![image](https://user-images.githubusercontent.com/89853986/202894674-b7e36149-dbaa-4c12-aca7-c52f707eb0d4.png)

&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Affinity는 이전 task의 coreset과 유사한 gradient direction을 가진 candidates를 선정하기 때문에 forgetting을 방지한다.&lt;/li&gt;
  &lt;li&gt;하지만, affinity는 앞선 task의 replay buffer의 quality에 dependent하기 때문에 홀로 고려될 경우 performance에 큰 도움을 주지 못한다.&lt;/li&gt;
  &lt;li&gt;따라서 위의 table을 보면, multiple dataset에서 affinity가 홀로 고려될 경우에는 performance가 낮지만, task마다 동일한 class set이 혼재되어있는 domain-incremental setting (Noisy Rot-MNIST)에서는 꽤나 좋은 성능이 관찰된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&quot;51-summary&quot;&gt;5.1 Summary&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Vision 분야의 continual learning problem에서 catastrophic forgetting을 방지할 수 있는 framework를 제안함.&lt;/li&gt;
  &lt;li&gt;Continual learning의 큰 줄기 중에서 replay 방식을 채택하였고, online coreset selection을 접목시켜 similarity (대표성), diversity (overfitting 방지)를 동시에 고려하여 가장 영향력이 높은 node를 buffer에 저장하도록 함.&lt;/li&gt;
  &lt;li&gt;다양한 실험을 통해 targeting problem의 예시를 실제로 보임.
    &lt;h4 id=&quot;52-discussion&quot;&gt;5.2 Discussion&lt;/h4&gt;
  &lt;/li&gt;
  &lt;li&gt;본 논문의 가장 주요한 novelty는 replay를 할 때, similarity (대표성), diversity (overfitting 방지)를 함께 접목시킨 것이다.&lt;/li&gt;
  &lt;li&gt;또한, 저자는 current task 내에서도 이전 task의 replay buffer와의 관계를 고려하여 data를 select하기 때문에 sequential task의 순서가 바뀌더라도 robust하게 대응할 수 있는 order-robustness의 특성을 가진다고 주장한다.&lt;/li&gt;
  &lt;li&gt;Method에 담은 algorithm에서의 task의 개수를 미리 알고 있다는 가정은 real-world setting에 맞지 않은 strong assumption일 수 있겠다.&lt;/li&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;이렇듯-replay-방식에서는-buffer에-넣을-node를-선택하는-방법론이-매우-주요할-것이고-experience-selection-strategy에-대하여-연구해보는-것도-좋은-future-research-topic이-될-것-같다&quot;&gt;이렇듯 replay 방식에서는 buffer에 넣을 node를 선택하는 방법론이 매우 주요할 것이고, experience selection strategy에 대하여 연구해보는 것도 좋은 future research topic이 될 것 같다.&lt;/h2&gt;
    &lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;
  &lt;/li&gt;
  &lt;li&gt;Seungyoon Choi
    &lt;ul&gt;
      &lt;li&gt;Affiliation : &lt;a href=&quot;https://dsail.kaist.ac.kr/&quot;&gt;DSAIL@KAIST&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Research Topic : GNN, Continual Learning, Active Learning
        &lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;
        &lt;h4 id=&quot;61-github-implementation&quot;&gt;6.1 Github Implementation&lt;/h4&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;https://github.com/jaehong31/OCS
    &lt;h4 id=&quot;62-reference&quot;&gt;6.2 Reference&lt;/h4&gt;
  &lt;/li&gt;
  &lt;li&gt;Yoon, Madaan, Yang, Hwang. “Online Coreset Selection for Rehearsal-based Continual Learning.”&lt;/li&gt;
  &lt;li&gt;Yoon, Yang, Lee, Hwang. “Lifelong Learning with Dynamically Expandable Networks.”&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Sun, 16 Oct 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Online_Coreset_Selection_for_Rehearsal_based_Continual_Learning.html</link>
            <guid isPermaLink="true">http://localhost:4000/Online_Coreset_Selection_for_Rehearsal_based_Continual_Learning.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICML 2022] How Powerful are Spectral Graph Neural Networks</title>
            <description>&lt;h2 id=&quot;how-powerful-are-spectral-graph-neural-networks&quot;&gt;&lt;strong&gt;How Powerful are Spectral Graph Neural Networks&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이 리뷰에서 소개하는 논문 ‘How Powerful are Spectral Graph Neural Networks’는 &lt;a href=&quot;https://icml.cc/virtual/2022/spotlight/17796&quot;&gt;이번 ICML 2022에서 Spotlight로 선정된 논문&lt;/a&gt; 중 하나입니다. 이 논문에서는 Spectral GNN의 표현력에 대한 분석 및 이를 기반으로 한 새로운 Spectral GNN 모델, ‘JacobiConv’를 소개합니다.&lt;/p&gt;

&lt;p&gt;참고로, 이 리뷰 본문에서의 Section X.X.와 같이 어떤 section을 언급하는 부분은 리뷰 기준이고, Proposition X.X. 와 같이 어떤 Theorem 등을 언급하는 것은 논문 본문 기준임을 알드립니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;&lt;strong&gt;1. Introduction&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Message Passing Framework를 활용하여 이웃한 node의 정보를 aggregate 함으로써 node들의 표현(representation)을 학습하는 Graph Neural Network(GNN)는, 그동안의 Graph Representation Learning 방법론들 가운데 여러 Downstream Task에서 State-of-the-art(SOTA) 성능을 보여줬습니다.&lt;/p&gt;

&lt;p&gt;그 한 갈래인 Spectral GNN은, Spatial한 그래프 신호(graph signal)를 Graph Laplacian을 활용해 Spectral domain으로 변환하여 필터링하고  필터링된 신호를 다시 Spatial domain으로 가져와 prediction을 수행합니다. GCN[2], GAT[3]과 같이 Popular한 모델이 등장하기 이전부터도 ChebyNet[4]과 같은 Spectral GNN이 연구되었고, 그중 GCN의 경우 ChebyNet에서의 Spectral 필터를 단순화한 모델입니다.&lt;/p&gt;

&lt;p&gt;이외에도 이 논문에서 언급되는 여러 Spectral GNN 모델들이 등장하지만, 저자들은 이러한 Spectral GNN 모델의 표현력(expressive power)에 대해 분석하고 연구한 논문이 없었음을 지적합니다. 저자들은 이 논문을 통해 Spectral GNN 모델의 표현력에 대해 이론적인 분석을 제시하고, 이를 바탕으로 ‘JacobiConv’라는  Spectral GNN 모델을 제안합니다.&lt;/p&gt;

&lt;p&gt;이 논문의 Contribution은 아래와 같이 정리할 수 있습니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;이 논문에서는 비선형성(non-linearlity)이 없는, 간단한 형태의 Linear Spectral GNN조차도 강력한 표현력이 있음(universal함)을 이론적으로 보이며, 그런 표현력을 갖추기 위한 조건을 제시하고 이에 대해 분석합니다.&lt;/li&gt;
  &lt;li&gt;또한, Linear Spectral GNN의 Universality 조건과 그래프 동형 테스트(Graph Isomorphism Test; GI Test)와의 연관성에 대해서도 분석합니다. 이런 GI Test를 활용한 GNN의 표현력 분석은 Spatial한 GNN에서 다뤄진 바 있습니다[5].&lt;/li&gt;
  &lt;li&gt;여러 Spectral GNN의 실험적인 성능 차이를 최적화 관점에서 분석하고, 이를 통해 그래프 신호 Density에 맞는 basis function으로 그래프 신호 필터를 구성하는 것이 중요함을 보여줍니다.&lt;/li&gt;
  &lt;li&gt;위의 분석을 기반으로 JacobiConv라는 Spectral GNN 모델을 제시합니다. JacobiConv는 비선형성 없이도 synthetic 및 real-world dataset에서 다른 Spectral GNN baseline들을 상회하는 성능을 보여줍니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(주) 본문에 들어가기에 앞서, 이 리뷰는 논문의 핵심적인 개념을 위주로 서술한 것임을 밝힙니다. 이 논문은 이론적인 분석이 주가 되는 논문이기에, 이 논문에 있는 모든 Theorem, Proposition 등을 충분히 이해하기 위해서는 Specral GNN에서 포괄하고 있는 많은 배경 지식을 필요로 합니다. 다만 이 리뷰를 작성하는 저도 그러한 배경 지식이 충분하지 않기에, 이 논문에서 말하고자 하는 essential한 부분에 대해서만 다루고자 합니다. 이 점 참고하여 읽어주시면 감사드리겠습니다.&lt;/em&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-preliminaries&quot;&gt;&lt;strong&gt;2. Preliminaries&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이 Section에서는 논문 본문에서 쓰인 Notation을 그대로 서술하도록 하겠습니다. 아래는 matrix의 행, 열에 대한 Notation입니다.&lt;/p&gt;

&lt;p&gt;$\forall M \in \mathbb{R}^{a\times b}: M_{i}=\mathrm{row_{i}}(M), M_{:i}=\mathrm{col_{i}}(M)$&lt;/p&gt;

&lt;p&gt;그리고, 주어진 node \(i\in\mathbb{V}\)에 대해서 그 이웃을 \(N(i)\)로 표기합니다.&lt;/p&gt;

&lt;p&gt;아래는 matrix의 condition number의 정의입니다. 이 개념은 전술했던 Contribution 3번에서의 분석과 관련이 있습니다. 여기서 \(\lambda_{max}\)는 matrix의 Maximum Eigenvalue, \(\lambda_{min}\)은 matrix의 Minimum Eigenvalue를 의미합니다.&lt;/p&gt;

&lt;p&gt;$\kappa(M)=\frac{\vert\lambda_{max}\vert}{\vert\lambda_{min}\vert}$&lt;/p&gt;

&lt;p&gt;이때, 주어진 matrix \(M\)이 singular(=not invertible; inverse가 존재하지 않는 경우)라면 \(\kappa(M)=+\infty\)이고, 이는 matrix의 모든 eigenvalue가 non-zero 값을 갖는 것이 matrix의 invertiblility와 동치이기 때문입니다. [6]&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(주) 다만 위 정의의 경우 오류가 있는 것 같습니다.&lt;/em&gt; \(\vert\lambda \vert _{max}\), \(\vert\lambda \vert _{min}\) &lt;em&gt;가 맞는 표기이지 않을까 싶습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;아래는 Graph와 관련된 Notation입니다. Undirected graph \(\mathcal{G}=(\mathbb{V}, \mathbb{E}, X)\)가 주어졌을 때, 여기서 \(\mathbb{V}=\{1,2,\cdots,n\},\ \mathbb{E}\subset \mathbb{V}\times\mathbb{V},\ X\in\mathbb{R}^{n\times d}\)는 각각 Node set, Edge set, node feature matrix입니다.&lt;/p&gt;

&lt;p&gt;\(A, D\)를 각각 Adjacency, Degree matrix라고 하면, normalized adjacency는 \(\hat{A}=D^{-1/2}AD^{-1/2}\)이고 symmetric normalized graph Laplacian은 \(\hat{L}=I-\hat{A}\)입니다. Graph Laplacian은 Real symmetric이기에 orthogonally diagonalizable하고, 따라서 아래와 같이 Eigen-decomposition할 수 있습니다.&lt;/p&gt;

&lt;p&gt;$\hat{L}=U\Lambda U^{T}$&lt;/p&gt;

&lt;p&gt;\(U\)는 \(i^{\mathrm{th}}\) column이 \(\hat{L}\)의 \(i^{\mathrm{th}}\) eigenvalue에 해당하는 eigenvector인 orthogonal matrix이고, \(\Lambda\)는 eigenvalue들을 diagonal entry들로 갖는 diagonal matrix입니다.&lt;/p&gt;

&lt;h3 id=&quot;21-graph-isomorphism&quot;&gt;&lt;strong&gt;2.1. Graph Isomorphism&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;이 Section에서는 Graph Isomorphism에 대해 간략하게 다룹니다.&lt;/p&gt;

&lt;p&gt;Graph Isomorphism은 중요한 개념이긴 하나, 이 리뷰에서는 Theorem, proposition의 증명을 상세히 다루지 않고 그 안에 담긴 의미에 대해서만 다룰 예정이기에 논문 본문에서 서술한 것 대신, 널리 알려진 정의[7]에 대해서 서술하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;두 graph \(\mathcal{G_1}=(\mathbb{V_1}, \mathbb{E_1}, X_1),\ \mathcal{G_2}=(\mathbb{V_2}, \mathbb{E_2}, X_2)\)에 대해 bijective mapping \(f:\mathbb{V_1}\rightarrow\mathbb{V_2}\)가 존재해서, \((i,j)\in\mathbb{E_1}\)인 임의의 두 node \(i, j\in\mathbb{V_1}\)의 mapped node \(f(i),f(j)\in\mathbb{V_2}\)가 \((f(i),f(j))\in\mathbb{E_2}\)일 때 두 graph \(\mathcal{G_1},\mathcal{G_2}\)를 &lt;strong&gt;isomorphic&lt;/strong&gt;하다고 하고, \(f\)를 &lt;strong&gt;isomorphism&lt;/strong&gt;이라고 부릅니다.&lt;/p&gt;

&lt;p&gt;간단하게 말하자면, 두 graph의 구조가 같은 것을 의미합니다.&lt;/p&gt;

&lt;h3 id=&quot;22-graph-signal-filter-and-spectral-gnns&quot;&gt;&lt;strong&gt;2.2. Graph Signal Filter and Spectral GNNs&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;이 Section에서는 Graph Signal Filter와 Spectral GNN의 개념, 그리고 논문에서 주로 다루는 Linear Spectral GNN(linear GNN)에 대해 서술합니다. 그리고 Filter의 표현력에 대한 개념인 &lt;em&gt;&lt;strong&gt;Polynomial-Filter-Most-Expressive&lt;/strong&gt;&lt;/em&gt;(PFME)와 &lt;em&gt;&lt;strong&gt;Filter-Most-Expressive&lt;/strong&gt;&lt;/em&gt;(FME)에 대해서도 소개하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Graph Fourier Transform&lt;/strong&gt;의 정의는 논문에서 정의된 바와 같이, (Shuman et al., 2013)[8]의 정의를 따릅니다.&lt;/p&gt;

&lt;p&gt;Signal \(X\in\mathbb{R}^{n\times d}\)의 Graph Fourier Transform은&lt;/p&gt;

&lt;p&gt;$\tilde{X}=U^{T}X\in\mathbb{R}^{n\times d}$&lt;/p&gt;

&lt;p&gt;로 정의하며, &lt;strong&gt;inverse transform&lt;/strong&gt;은&lt;/p&gt;

&lt;p&gt;$X=U^{T}\tilde{X}$&lt;/p&gt;

&lt;p&gt;와 같이 정의합니다. 여기서 \(U\)의 \(i^{\mathrm{th}}\) column은 eigenvalue \(\lambda_{i}\)에 해당하는 frequency component(eigenvector)입니다.&lt;/p&gt;

&lt;p&gt;Eigenvalue \(\lambda\)에 해당하는 eigenvector를 \(U_{:\lambda}^{T}\)라고 하면, frequency \(\lambda\)에 해당하는 \(X\)의 frequency component를 \(\tilde{X_{\lambda}}=U_{:\lambda}^{T}X\)로 정의합니다.&lt;br /&gt;
이때, \(\tilde{X_{\lambda}}\neq\mathbb{0}\)라면 \(X\)가 \(\lambda\) frequency component를 갖고 있다고 정의합니다. 그렇지 않은 경우, \(\lambda\) frequency component가 \(X\)에서 missing되었다고 정의합니다.&lt;/p&gt;

&lt;p&gt;Graph Fourier Transform과 원래 Fourier Transform의 연관성은 주어진 Signal(Graph에서는 Node feature \(X\))을 Frequency(Graph에서는 Laplacian \(\hat{L}\)의 Eigenvalue \(\lambda\)) domain으로 transform한다는 점에서 동일합니다.&lt;/p&gt;

&lt;p&gt;또한 Fourier Transform의 경우 주어진 signal을 Function space에서의 orthonormal basis를 이용해 변환하는데, Graph Fourier Transform의 경우 주어진 signal을 vector space의 orthonormal basis인 eigenvector를 이용해 변환한다는 점에서 연관성이 있습니다.&lt;/p&gt;

&lt;p&gt;이 이상의 Graph Fourier Transform에 대한 자세한 서술은 이 리뷰의 범위를 벗어나므로 생략하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(주) 이 리뷰에서 function space의 orthonormal basis에 대해서 자세히 다루는 것은 훨씬 심도깊은 논의가 필요하기 때문에 생략하도록 하겠습니다. 이와 관련하여 좀 더 알고 싶으신 분들은, Elias M. Stein and Rami Shakarchi의 Real Analysis: Measure Theory, Integration, and Hilbert Spaces (Princeton Lectures in Analysis)를 보시는 것이 좋을 것 같습니다. 또 Graph Fourier Transform에 대해서 더 자세히 알고 싶으시다면 (Shuman et al., 2013)[8]을 참고하시면 좋을 것 같습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이젠 Graph Signal Filter에 대해서 서술하도록 하겠습니다. Graph Signal Filter는 signal의 frequency component를 필터링하는 역할을 수행합니다.&lt;/p&gt;

&lt;p&gt;Filter \(g:[0,2]\rightarrow\mathbb{R}\)는 \(g(\lambda)\) 값을 각각의 frequency component에 곱해주는 방식으로 필터링을 수행합니다. Signal \(X\)에 spectral filter \(g\)를 적용하는 것은 다음과 같이 정의합니다.&lt;/p&gt;

&lt;p&gt;$Ug(\Lambda)U^{T}X$&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(주) filter의 정의역이 [0,2]인 것은 Normalized Graph Laplacian의 성질에 기인합니다.[9, Lemma 1.7.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;여기서 filter \(g\)는 \(\Lambda\)에 element-wise하게 적용됩니다. Filter를 parametrize하기 위해, \(g\)는 아래와 같이 degree \(K\)의 polynomial로 설정합니다.&lt;/p&gt;

&lt;p&gt;$g(\lambda):=\sum_{k=0}^{K}{\alpha_{k}\lambda^{k}}$&lt;/p&gt;

&lt;p&gt;여기서 \(g(\hat{L})\)을&lt;/p&gt;

&lt;p&gt;$g(\hat{L})=\sum_{k=0}^{K}{\alpha_{k}\hat{L}^{k}}$&lt;/p&gt;

&lt;p&gt;로 정의하면, 필터링 과정은 아래와 같이 표현 가능합니다.&lt;/p&gt;

&lt;p&gt;$Ug(\Lambda)U^{T}X=\sum_{k=0}^{K}{\alpha_{k}U\Lambda^{k}U^{T}X}=\sum_{k=0}^{K}{\alpha_{k}\hat{L}^{k}X}=g(\hat{L})X$&lt;/p&gt;

&lt;p&gt;ChebyNet 등과 같은 여러 널리 알려진 spectral GNN의 filter form은 아래 표를 통해 확인 가능합니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;700&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Table_5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;일반적으로, spectral-based GNN은 아래와 같은 form으로 정리할 수 있습니다.&lt;/p&gt;

&lt;p&gt;$Z=\phi(g(\hat{L}))\psi(X)$&lt;/p&gt;

&lt;p&gt;여기서 \(Z\)는 prediction, \(\phi, \psi\)는 Multi-Layer Perceptron(MLP)와 같은 함수입니다.&lt;/p&gt;

&lt;p&gt;이때, spectral GNN의 filter가 그 어떤 polynomial filter function이라도 근사할 수 있다면, 그 GNN이 &lt;strong&gt;Polynomial-Filter-Most-Expressive(PFME)&lt;/strong&gt; 하다라고 정의하고, arbitrary한 real-valued filter function을 근사할 수 있다면 &lt;strong&gt;Filter-Most-Expressive(FME)&lt;/strong&gt; 라고 정의합니다.&lt;/p&gt;

&lt;p&gt;이러한 PFME, FME property는 spectral GNN의 표현력에 있어서 중요한 성질인 것으로 보입니다. Frequency component를 scaling 함으로써 말 그대로 필터링을 해주는 Filter의 역할을 생각해봤을 때, arbitrary한 filter을 학습할 수 있느냐(=FME)는 spectral GNN의 표현력(주어진 두 node를 구별하는 능력)에 분명 큰 역할을 할 것이라고 생각할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 \(\phi, \psi\)가 linear한 경우에 초점을 두고 있기 때문에, ‘Linear GNN’, linear한 spectral GNN을 아래와 같이 정의합니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Definition_2_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아래의 Proposition 2.2는 Linear GNN이 PFME, 즉 충분히 강한 표현력을 갖고 있고, General한 spectral GNN의 표현력의 Lower bound가 됨을 서술하고 있습니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Prop_2_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;비록 길었지만, 이 논문의 중요 개념을 이해하는데에 필요한 부분은 모두 짚어보았습니다. 나머지는 분석에 앞서, 이 논문에서 가정하고 있는 부분에 대한 서술입니다.&lt;/p&gt;

&lt;p&gt;우선, 이 논문에서는 Fixed graph, fixed node features에서 오직 node property prediction task만 처리한다고 가정합니다.&lt;/p&gt;

&lt;p&gt;위와 같은 Setting에서는 PFME=FME가 성립하게 됩니다. 왜냐하면 PFME한 GNN이 비록 polynomial filter function만 표현할 수 있지만, fixed graph setting에서는 eigenvalue \(\lambda\)가 discrete하기 때문에 arbitrary filter function을 충분히 근사할 수 있는 interpolation polynomial을 얻을 수 있고[10, Theorem 3.1., 3.3.], 이 polynomial은 PFME GNN으로 표현 가능하기 때문입니다. 이를 위해, 추가적으로 Linear GNN의 Polynomial Filter가 충분히 큰 degree \(K\)를 가지도록 설정합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-analyses-the-expressive-power-of-linear-gnns&quot;&gt;&lt;strong&gt;3. Analyses: The Expressive Power of Linear GNNs&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이 Section에서는 세 가지 조건 아래에서 linear GNN이 Universal하다는 것을 증명합니다. 이어지는 3개의 sub-section에서는 세 가지 Universality 조건을 분석하여, spectral GNN이 얼마나 강력한 표현력을 가질 수 있는 지에 대해 다룹니다.&lt;/p&gt;

&lt;p&gt;나머지 sub-section에서는 Graph Isomorphism과의 연관성(3.4.), spectral GNN에서 Non-linearlity의 역할(3.5.)에 대해 분석합니다.&lt;/p&gt;

&lt;p&gt;본문에 들어가기에 앞서, Linear GNN \(Z=g(\hat{L})XW\)의 두 핵심 Component에 대해 다시 한 번 짚어보겠습니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Linear Transformation&lt;/strong&gt; \(W\): \(XW=U(\tilde{X}W)\)이기에, spatial domain에서의 선형 변환이 spectral domain에서의 선형 변환임을 의미합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Filter&lt;/strong&gt; \(g(\hat{L})\): \(g(\hat{L})X=U(g(\Lambda)\tilde{X})\)이기에, filter는 frequency component를 scaling해줍니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 논문의 핵심인, Linear GNN의 Universal Theorem은 아래와 같습니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Thm_4_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Theorem 4.1.을 통해 Universality를 얻기 위해서는 아래의 세 가지 조건이 필요하게 됩니다.
 1) 1-dimensional prediction
 2) Graph Laplacian has no multiple eigenvalues
 3) Node feature has no missing frequency components&lt;/p&gt;

&lt;p&gt;상기한 조건들은 linear GNN 표현력의 소위 ‘Bottleneck’이라 할 수 있습니다. 따라서 아래 sub-section들에서는 이 세 가지 Bottleneck이 되는 요소들에 대해서 자세하게 분석합니다.&lt;/p&gt;

&lt;h3 id=&quot;31-about-multi-dimensional-prediction&quot;&gt;&lt;strong&gt;3.1. About Multi-dimensional Prediction&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;아래 Proposition을 통해, 논문에서는 Linear GNN이 multi-dimensional prediction을 해내는 데에 있어서는 Universal하지 않다는 것을 서술하고 있습니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Prop_4_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Universal Theorem을 보면 Linear GNN은 1-dimensional prediction만을 산출하는 경우에는 충분히 강력하지만, 위의 Propsition 때문에 Multiple channel을 갖는 prediction을 산출하기 위해서는 각기 다른 polynomial filter를 필요로 하게 됩니다.&lt;/p&gt;

&lt;p&gt;이에 대해서는 Figure 1에 묘사되어 있는 Toy Example을 보도록 하겠습니다. (b), (c)를 보면, (a)에서 주어진 Node feature을 이용해 여러 dimension의 output을 만들기 위해서는 서로 다른(하나는 High-pass, 다른 하나는 Low-pass) filter가 필요하다는 것을 서술하고 있습니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;400&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Figure_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 Toy Example을 통해서 우리는 논문에서 서술하고 있는 위의 내용 이외에도, GNN의 표현력, Universality에 있어서 arbitary filter을 근사하는 능력인 FME property가 왜 중요한 지에 대해서 생각해볼 수 있습니다. 만약 Model에서 사용하는 filter가 특정 filter를 근사할 수 없다면, 이는 특정 prediction 값을 산출할 수 없다는 것이고 다시 말해 universal하지 못하게 된다는 것을 의미합니다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 이런 Multi-dimensional prediction 문제를 각 output channel마다 다른 polynomial coefficient parameter을 사용하는 것으로 해결할 수 있다고 서술하고 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;32-about-multiple-eigenvalue&quot;&gt;&lt;strong&gt;3.2. About Multiple Eigenvalue&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Graph Laplacian이 multiple eigenvalue을 갖는다는 것은 두 개의 frequency component가 같은 eigenvalue \(\lambda\)를 갖는 경우이며, 이는 다른 frequency component가 같은 scale \(g(\lambda)\)로 scaling 된다는 것을 의미합니다.&lt;/p&gt;

&lt;p&gt;다시 말해, 서로 다른 두 frequency component를 Model이 다르게 필터링할 수 없다는 것입니다. 이런 경우 우린 Linear GNN의 표현력이 낮아진다고 생각할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이러한 Multiple eigenvalue는 주어진 graph의 topology, 즉 구조와 연관되어 있습니다.&lt;/p&gt;

&lt;p&gt;하지만 우리는 후술된 Table 7의 데이터 통계를 통해, node feature을 갖는 real-world graph의 경우에는 이런 multiple eigenvalue가 유의미하게 적다는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;33-about-missing-frequency-components&quot;&gt;&lt;strong&gt;3.3. About Missing Frequency Components&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;전술했듯이, Filter는 frequency component를 scaling해주는 역할만을 수행합니다. 그렇기에 만약 node feature에서 어느 frequency component가 missing되었다면, prediction에 해당 frequency component가 반영되지 못하게 됩니다.&lt;/p&gt;

&lt;p&gt;아래 Figure 2에는 missing frequency component가 생기는 Toy graph를 다루고 있습니다.&lt;br /&gt;
 &lt;em&gt;(주) Figure 2에 있는 1-dim node feature와 graph structure을 이용해 계산해보면, 왼쪽의 node feature로는 frequency, 즉 eigenvalue=2에 해당하는 frequency component가 0이 됩니다.&lt;/em&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;400&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Figure_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 문제는 Graph structure(Laplacian eigenvector, 즉 frequency component에 영향)과 node feature(frequency component로 표현했을 때 없을 수 있음) 둘 다 영향을 끼치기에 다루기 어려운 문제입니다.&lt;/p&gt;

&lt;p&gt;하지만 Multiple eigenvalue 문제처럼 이 문제 역시 real-world graph에서는 보기 어렵습니다. 아래 Table 7은 benchmark dataset에서의 multiple eigenvalue 비율과 missing frequency component의 수를 정리한 것입니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;700&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Table_7.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;요약하자면, 각 output channel마다 다른 polynomial filter를 이용하는 방법과 real-world dataset의 특성을 통해 우리는 Linear GNN의 Universality를 위한 세 가지 조건이 실전에서 쉽게 만족될 수 있음을 알 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;34-about-the-connection-to-graph-isomorphism&quot;&gt;&lt;strong&gt;3.4. About the Connection to Graph Isomorphism&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Spatial GNN의 표현력에 대해 분석한 논문[5]에서는 GI test를 활용해 분석하였습니다. 이와 비슷하게 이 논문에서도 Universality 조건과 Graph Isomorphism의 연관성에 대해 분석합니다.&lt;/p&gt;

&lt;p&gt;Graph Isomorphism Test 기법으로 언급이 되는 것이 바로 1-dimensional Weisfeiler-Lehman(1-WL) test입니다. 1-WL test는 주어진 두 graph가 isomorphic한지 판별하는 알고리즘으로, 웬만한 non-isomorphic graph들을 구별할 수 있습니다. 보다 자세한 내용은 이 &lt;a href=&quot;https://davidbieber.com/post/2019-05-10-weisfeiler-lehman-isomorphism-test/&quot;&gt;링크&lt;/a&gt;를 참조하시면 좋을 것 같습니다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 먼저, \(K+1\) iteration 1-WL test가 구별할 수 없는 node pair는 degree $K$ polynomial filter를 갖는 Linear GNN도 구별할 수 없다는 것을 아래 Proposition을 통해 서술합니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Prop_4_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Proposition 4.3.은 Linear GNN의 표현력 역시 Spatial GNN 처럼[5] 1-WL test만큼이 한계라는 것을 의미합니다.&lt;/p&gt;

&lt;p&gt;하지만, 우리는 Universal Theorem을 통해 Linear GNN이 각기 다른 node들에 대해, 그 node들이 isomorphic한 지와 상관 없이 서로 다른 prediction을 산출할 수 있는 표현력을 갖고 있다는 것을 알고 있습니다.&lt;/p&gt;

&lt;p&gt;또한, 1) 1-WL test는 몇몇 non-isomorphic한 node들을 구별하지 못하며, 2) 1-WL test의 경우 isomorphic한 node들에 대해 같은 label을 산출한다는 것 역시 알려져 있는 바입니다.&lt;/p&gt;

&lt;p&gt;이렇듯 모순되어 보이는 두 사실은 Universality 조건 2와 3이 만족되면 1-WL test 역시 충분히 Powerful하다는 것(모든 non-isomorphic node를 구별할 수 있음)과 graph가 isomorphic한 node를 가질 수 없다는 것을 보여주는 결과릍 통해 해소되며, 그 결과는 아래 Corollary 4.4.와 Theorem 4.5., Theorem 4.6.에 정리되어 있습니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Corr_4_4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Corollary 4.4.는 Universal Theorem과 Proposition 4.3.을 통해 유도되는 결과입니다. 조건 2, 3 아래에서 1-WL test 역시 충분히 Powerful하다는 것을 보여줍니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Thm_4_5.png&quot; /&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Thm_4_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Theorem 4.5., 4.6.은 조건 2, 3이 만족되면 Graph와 node feature를 제약한다는 것을 보여줍니다.&lt;/p&gt;

&lt;p&gt;따라서 Universal Theorem의 조건을 만족한다는 것은 Graph Topology와 Node feature가 제약된다는 것을 의미하고, 1-WL test가 결국 linear GNN의 표현력의 한계라는 것을 확인할 수 있습니다. 위의 결과들을 통해서 우리는 Universality 측면에서의 spectral GNN의 표현력과 1-WL test 측면에서의 spatial GNN의 표현력 간 &lt;strong&gt;연결고리&lt;/strong&gt;를 얻게 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;35-about-the-role-of-non-linearlity&quot;&gt;&lt;strong&gt;3.5. About the Role of Non-linearlity&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;우리는 앞선 결과들을 통해서 Linear GNN이 충분히 강력한 표현력을 갖고 있음을 알게 되었습니다. 그럼에도 non-linearlity는 SOTA 성능의 GNN에서 활용되고 있습니다. 이 sub-section에서는 non-linearlity가 spectral GNN에서 어떤 역할을 하는지 분석합니다.&lt;/p&gt;

&lt;p&gt;Spectral GNN의 General form \(Z=\phi(g(\hat{L}))\psi(X)\)을 보면, Non-linearlity가 frequency component를 담고 있는 node feature를 변환하므로 node feature을 표현하는 frequency component가 바뀌게 된다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;아래 Figure 4를 보면 더 잘 이해할 수 있습니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;400&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Figure_4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또, \(\sigma\)를 spatial signal \(X\)에 적용되는 non-linearlity라고 하면 spectral signal \(\tilde{X}\)을 transform하는 \(\sigma &apos;\)는&lt;/p&gt;

&lt;p&gt;$\sigma ‘(\tilde{X})=U^{T}\sigma(U\tilde{X})$&lt;/p&gt;

&lt;p&gt;와 같습니다. 이를 자세히 보면, spectral signal \(\tilde{X}\)가 \(U\)를 통해 섞이게 된다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;이러한 Mixing이 multiple eigenvalue, missing frequency components와 같은 문제를 어느정도 완화할 수 있을지는 몰라도, 1-WL이 spectral GNN의 표현력의 한계이기에 충분히 강한 표현력을 가질 수는 없다고 저자들은 논문에서 언급합니다. 그렇기에 이 논문에서는 Universality condition들이 real-world에서 쉽게 만족될 수 있다는 점과 이에 따른 Linear GNN의 충분히 강한 표현력을 고려하여, non-linearlity가 없는 linear GNN을 기반으로 한 모델을 제안합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-methodology-jacobiconv&quot;&gt;&lt;strong&gt;4. Methodology-JacobiConv&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이 Section에서는 Polynomial Filter을 구성하는 Basis function 선택의 영향에 대해, Optimization 관점에서 분석합니다. 그리고 이를 바탕으로 논문에서 제안한 JacobiConv 모델에 대해 다룹니다.&lt;/p&gt;

&lt;p&gt;\(k=0,1,2,\cdots\)에 대해 Polynomial bases를 \(g_k\)라고 정의합니다. 이 section에서는 각 output dimension에 대해 개별적인 filter parameter를 갖는 linear GNN에 대해 다룹니다. 아래는 그 formulation입니다.&lt;/p&gt;

&lt;p&gt;$Z_{:l}=\sum_{k=0}^{K}{\alpha_{kl}g_{k}(\hat{L})XW_{:l}}$&lt;/p&gt;

&lt;p&gt;ChebyNet에서 활용하는 것과 같은 complete한 polynomial bases들은 PFME model을 만들 수 있습니다. 하지만, 다른 bases 선택이 다른 성능을 보여준다는 것을 논문에서는 Optimization 관점에서 다룹니다.&lt;/p&gt;

&lt;h3 id=&quot;41-preliminary-to-jacobiconv-hessian-matrix-and-polynomial-bases-choice&quot;&gt;&lt;strong&gt;4.1. Preliminary to JacobiConv: Hessian Matrix and Polynomial Bases choice&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;우선 아래와 같은 loss function으로 training한다고 가정합니다.&lt;/p&gt;

&lt;p&gt;$R=|Z-Y|_ {F}^{2}$&lt;/p&gt;

&lt;p&gt;추가적으로 Linear GNN이 global minimum으로 수렴할 수 있다고 가정합니다. 논문에서는 global minimum 근처에서의 수렴 속도를 분석합니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(주) 위와 같은 가정의 타당성은 논문의 Appendix J에 있으나, 이 리뷰에서는 다루지 않습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Linear GNN의 optimization의 경우, coefficient \(\alpha\), weight \(W\) 모두 learnable한 parameter입니다. 하지만, \(W\)의 optimization의 경우, 아래의 gradient를 보면 bases와 무관함을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;$\frac{\partial R}{\partial W_{jl}}=(g_{:l}(\hat{L})(XW)_ {:l} - Y_{:l})^{T}(g_{:l}(\hat{L})X_{:j})$&lt;/p&gt;

&lt;p&gt;\(W\)의 gradient는 filter function 전체에 dependent합니다. 충분히 표현력 있는 bases를 활용한다면 최적점 근처에서는 filter function이 비슷하게 학습되므로 bases 선택과 weight \(W\)를 최적화하는 것은 무관합니다. 하지만, 계수 \(\alpha\)의 경우는 이와 달리 bases 선택에 크게 의존합니다. 그렇기에 bases 선택에 따른 영향을 보려면, \(\alpha\)의 optimization에 초점을 맞춰야 합니다.&lt;/p&gt;

&lt;p&gt;Loss $R$는 convex합니다. 이때, Gradient Descent 알고리즘의 Convergence rate은 loss \(R\)의 Hessian Matrix \(H\)의 condition number \(\kappa(H)\)와 관련있다는 것[11]이 알려져 있습니다. Condition number \(\kappa(H)\)가 작을수록 수렴 속도는 빨라집니다.&lt;/p&gt;

&lt;p&gt;Loss function이 Frobenius norm의 형태이기에, 총 loss 값은 output dimension에 걸쳐 더해지고, 각 dimension에 따라 다른 coefficient \(\alpha_{kl}\)을 사용하므로 우리는 Hessian Matrix를 dimension마다 독립적으로 분석할 수 있습니다. 그래서 output dimension \(l\)을 무시하면 Hessian matrix의 \((k_{1}, k_{2})\) entry는 아래와 같이 계산할 수 있습니다.&lt;/p&gt;

&lt;p&gt;$\frac{\partial R}{\partial\alpha_{k_{1}}\partial\alpha_{k_{2}}}=X^{T}g_{k_{2}}(\hat{L})g_{k_{1}}(\hat{L})X=\sum_{i=1}^{n}{g_{k_{2}}(\lambda_{i})g_{k_{1}}(\lambda_{i})\tilde{X}_ {\lambda_{i}} ^{2}}$&lt;/p&gt;

&lt;p&gt;\(\lambda\)보다 작은 frequency를 갖는 signal의 accumulated amplitude를 \(F(\lambda):=\sum_{\lambda_{i}\leq\lambda}{\tilde{X}_ {\lambda_{i}} ^{2}}\)라고 하면, 위의 Hessian entry 값은 아래와 같이 Riemann sum으로 나타낼 수 있습니다.&lt;/p&gt;

&lt;p&gt;$\sum_{i=1}^{n}{g_{k_{2}}(\lambda_{i})g_{k_{1}}(\lambda_{i})\frac{F(\lambda_{i})-F(\lambda_{i-1})}{\lambda_{i}-\lambda_{i-1}}}(\lambda_{i}-\lambda_{i-1})$&lt;/p&gt;

&lt;p&gt;\(n \rightarrow +\infty\) 일 때, Frequency \(\lambda\)에서의 Signal density \(f(\lambda)=\Delta F(\lambda)/\Delta \lambda\)를 이용하면 아래와 같이 Hessian entry 값을 얻을 수 있습니다.&lt;/p&gt;

&lt;p&gt;$H_{k_{1}k_{2}}=\int_ {0} ^{2}{g_{k_{2}}(\lambda_{i})g_{k_{1}}(\lambda_{i})f(\lambda)d\lambda}$&lt;/p&gt;

&lt;p&gt;위에서 얻어낸 결과와 \(\mathrm{argmin}_ {H}\kappa(H)=I\)라는 사실을 함께 보면, polynomial bases \(g_{k}\)가 graph signal density \(f(\lambda)\)에 대해 orthonormal할 때 condition number가 최소화되어 가장 빠르게 수렴하게 된다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(주) bases가 graph signal density&lt;/em&gt; \(f(\lambda)\) &lt;em&gt;에 대해 orthonormal하다는 것은, inner product가&lt;/em&gt; \(&amp;lt;h,g&amp;gt;=\int_{0}^{2}{h(\lambda)g(\lambda)f(\lambda)d\lambda}\) &lt;em&gt;로 정의될 때 이 inner product를 갖는 함수 공간에서 orthonormal하다는 것을 말합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이러한 결과는, complete한 polynomial bases들이 비록 같은 표현력을 갖고 있더라도, graph density \(f(\lambda)\)에 대해 orthonormal한 bases를 사용하는 것이 linear GNN이 가장 빠르게 수렴할 수 있게 함을 의미합니다.&lt;/p&gt;

&lt;h3 id=&quot;42-jacobi-polynomial-bases&quot;&gt;&lt;strong&gt;4.2. Jacobi Polynomial Bases&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Jacobi basis는 가장 general한 형태의 polynomial bases이며, ChebyNet에서 활용하는 Chebyshev basis의 경우 이 Jacobi basis의 특수한 형태(\(P_{k}^{-1/2,-1/2} (1-\lambda)\))라고 합니다. Jacobi basis \(P_{k}^{a,b}\)는 아래와 같이 정의됩니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Jacobi.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 Jacobi basis는 weight function \((1-\lambda)^{a}(1+\lambda)^{b}\)에 대해, domain \([-1,1]\)에서 orthogonal합니다. Domain을 맞춰주기 위해, graph의 Jacobi basis는 아래와 같이 정의합니다.&lt;/p&gt;

&lt;p&gt;$g_{k}(\hat{L})=P_{k}^{a,b}(I-\hat{L})=P_{k}^{a,b}(\hat{A})$&lt;/p&gt;

&lt;h3 id=&quot;43-jacobiconv-architecture&quot;&gt;&lt;strong&gt;4.3. JacobiConv Architecture&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;이 sub-section에서는 논문에서 제안한 JacobiConv 모델의 Architecture에 대해 서술합니다. 먼저, node feature \(X\)의 dimension이 transformed features \(\hat{X}\)에 비해 아주 큰 경우가 많기 때문에, 먼저 \(\hat{X}=XW+b\)와 같이 Transform해주고 변환된 Signal \(\hat{X}\)를 필터링하게 됩니다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 filter에 아래의 세 가지 테크닉
 1) multiple filter functions
 2) Jacobi basis
 3) Polynomial Coefficient Decomposition(PCD)&lt;/p&gt;

&lt;p&gt;을 이용합니다.&lt;/p&gt;

&lt;p&gt;먼저 첫 번째 테크닉은 Section 3.1.을 바탕으로, multi-dimensional prediction을 위해 output dimension 각각에 filter를 이용하겠다는 것입니다. 이에 따라 JacobiConv는 아래와 같이 formulate 됩니다.&lt;/p&gt;

&lt;p&gt;$Z_{:l}=\sum_{k=0}^{K}{\alpha_{kl}P_{k}^{a,b}(\hat{A})\hat{X}_ {:l}}$&lt;/p&gt;

&lt;p&gt;두 번째 테크닉은 Section 4.2.에서 다룬 Jacobi basis의 점화식을 이용해 필터링 연산을 수행한다는 것입니다. Formulation은 아래와 같습니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Jacobi_calculations.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;저자의 서술에 따르면, 이는 \(K\)개의 message passing 연산을 수행한다고 합니다. Form을 보면 message passing framework과 유사한 모습입니다.&lt;/p&gt;

&lt;p&gt;세 번째 PCD 테크닉은 real-world dataset에서, \(k\)값이 커질수록 계수 \(\alpha_{kl}\)의 값이 작아진다는 observation에 기반하고 있습니다. 이렇게 계수들의 크기에 편차가 생기면 최적화가 어려워진다고 하며, 따라서 coefficient를 다음과 같이 decomposition합니다.&lt;/p&gt;

&lt;p&gt;$\alpha_{kl}=\beta_{kl}\prod_{i=1}^{k}\gamma_{i}$&lt;/p&gt;

&lt;p&gt;이때 \(\gamma_{i}\)는 모든 output channel $l$에서 공유되는 값입니다. \(\gamma_{i}=\gamma &apos;\mathrm{tanh}(\eta_{i})\)로 놓으면, \(\gamma_{i}\)는 \([-\gamma &apos;,\gamma &apos;]\) 사이의 값을 갖게 됩니다.&lt;/p&gt;

&lt;p&gt;이러한 parameter decomposition 테크닉을 PCD라고 부르고, 이를 기반으로 한 JacobiConv의 점화식은 아래와 같습니다.&lt;/p&gt;

&lt;p&gt;$P_{k}^{a,b}(\hat{A})\hat{X}=\gamma_{k}\theta_{k}\hat{A}P_{k-1}^{a,b}(\hat{A})\hat{X} + \gamma_{k}\theta’_ {k}P_{k-1}^{a,b}(\hat{A})\hat{X} - \gamma_{k}\gamma_{k-1}\theta’‘_ {k}P_{k-2}^{a,b}(\hat{A})\hat{X}$&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-experiment&quot;&gt;&lt;strong&gt;5. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이 Section에서는 논문 본문에 공유된 실험 결과에 대해 소개합니다. 논문에서는 이미지로 만든 Synthetic grid graph에서 Filter 표현력(filter를 잘 학습할 수 있는지)을 비교하는 실험과, Real-world dataset에서의 성능을 비교한 실험을 수행했습니다.&lt;/p&gt;

&lt;h3 id=&quot;51-experimental-setup&quot;&gt;&lt;strong&gt;5.1. Experimental setup&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Dataset&lt;br /&gt;
Filter 학습 능력을 평가하는 실험에서는 이전 연구인 BernNet[12]의 실험 세팅을 따라, 50개의 이미지를 grid graph로 변환한 Synthetic graph dataset을 사용합니다. Task는 original graph signal을 이용해 filtered signal에 fit하여, 5가지 filter function(Low, High, Band, Reject, Comb)을 잘 배울 수 있는 지를 평가하는 Regression Task입니다.&lt;br /&gt;
Real-world dataset의 경우, Homogeneous Graph로는 널리 쓰이는 Citation network Cora, CiteSeer, Pubmed와 2개의 Amazon co-purchase graph를 사용합니다. 추가적으로 Heterogeneous graph인 Wikipedia graph Chameleon과 Squirrel 2개, 그리고 Actor co-occurence graph, webpage graph Texas, Cornell 2개를 사용합니다. Task는 node classification이며, train/valid/test split은 60%/20%/20%입니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;baseline&lt;br /&gt;
Synthetic dataset을 활용한 실험에서는 filter 학습 능력을 평가하므로, PFME GNN들인 GPRGNN[14], ARMA[15], BernNet[12], ChebyNet[4]을 Baseline model로 사용해 JacobiConv와 비교합니다. 또한, Jacobi bases가 아닌 다른 Chebyshev, Monomial, Bernstein 등의 bases들을 이용한 linear GNN 모델과도 비교합니다. 이때, JacobiConv를 포함한 Linear GNN들은 PCD technique를 사용하지 않습니다.&lt;br /&gt;
Real-world dataset 실험에서는 baseline으로 다른 spectral GNN들인 GCN[2], APPNP, ChebyNet, GPRGNN, BernNet을 사용합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Evaluation Metric&lt;br /&gt;
Synthetic Dataset에서는 실질적으로 Regression Task이기 때문에 총 50개 graph에서의 실험 결과의 평균 MSE 값을 metric으로 활용합니다.&lt;br /&gt;
Real-world Dataset에서는 accuracy가 metric입니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;52-result&quot;&gt;&lt;strong&gt;5.2. Result&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;원래 논문에서는 아래 소개할 실험 결과 이외에도 Ablation Study, Scalability 관련 실험을 포함하고 있으나, 이 리뷰에서는 다루지 않도록 하겠습니다.&lt;/p&gt;

&lt;h4 id=&quot;52a-synthetic-dataset-result-evaluating-model-on-learning-filters&quot;&gt;&lt;strong&gt;5.2.a. Synthetic Dataset Result: evaluating model on learning filters&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;JacobiConv가 다른 PFME GNN이나 다른 Bases를 사용한 linear GNN에 비해 Filter를 잘 학습할 수 있는지를 보여주는 실험입니다. 아래 Table 1은 다른 모델과 비교했을 때 JacobiConv의 우수성을 보여주고 있습니다. 이 실험 결과는 Section 4.1.에서의 Analysis, basis 선택이 실제 성능에 영향을 미친다는 분석을 뒷받침합니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;400&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Table_1.png&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;52b-real-world-dataset&quot;&gt;&lt;strong&gt;5.2.b Real-world Dataset&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;아래 Table 2의 결과에서 JacobiConv의 우수한 성능은 표현력이 강한 Linear Spectral GNN을 사용하는 것으로도 충분히 강력한 성능을 얻을 수 있음을 보여줍니다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;600&quot; src=&quot;/images/How_Powerful_are_Spectral_Graph_Neural_Networks/Table_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;6-conclusion&quot;&gt;&lt;strong&gt;6. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이 논문은 Spectral GNN의 Expressive Power, 표현력에 대해 이론적인 분석을 제시한 첫 연구입니다. 이미 있었던 Spatial GNN의 표현을 분석한 연구와는 다르게 주로 Universality 측면에서 표현력을 분석했지만, 이를 Spatial GNN 표현력 분석 연구에서 쓰인 Graph Isomorphism Test 측면과의 연결성 역시 제시했습니다. 또한 Spectral filter를 어떻게 구성하는 지가 실제 성능에 어떤 영향을 주는 지도 분석하였습니다.&lt;/p&gt;

&lt;p&gt;이런 표현력에 대한 분석을 바탕으로 이 논문에서 저자들은 새로운 Spectral GNN 모델 ‘JacobiConv’를 제시하였고, 실험적으로도 우수한 성능을 보임을 광범위한 실험을 통해 입증하였습니다.&lt;/p&gt;

&lt;p&gt;이 논문은 AI/ML 분야에서 최고 중 하나로 인정받는 학회인 ICML의 Spotlght paper로 선정된 논문입니다. 그만큼의 기대를 충족시킬만한 정말 좋은 논문이었다고 생각합니다. Problem Formulation, Theoretical Background &amp;amp; Analysis, Extensive Experiments 등 좋은 논문을 만드는 요소는 다 포함하고 있는 연구인 것 같습니다. 만약 Spectral GNN에 대해 관심이 있으시거나 어느정도의 배경지식을 갖고 계신 분이라면 많은 것을 얻어갈 수 있는 논문이라고 생각합니다.&lt;/p&gt;

&lt;p&gt;가장 마음에 들었던 부분은 핵심인 Universality보다도, 최적화 측면에서 표현력이 같은 기존 spectral GNN들의 실험적 성능에 차이가 생길 수밖에 없는 이유를 분석하고 JacobiConv를 motivate한 부분이었습니다. Gradient Descent의 알려진 성질을 이용해서 왜 Filter을 구성하는 Polynomial Bases가 중요한 지에 대해 분석하고 해답을 제시한 부분에서 깊은 인상이 남았습니다.&lt;/p&gt;

&lt;p&gt;그렇지만 이 논문에서도 아쉬웠던 부분이 없지는 않았습니다.&lt;/p&gt;

&lt;p&gt;이 논문에서 가장 아쉬운 부분은 PFME/FME property에 대해 자세히 서술하지 않은 점입니다. 앞의 Section에서 전술했듯 Spectral GNN의 표현력은 spatial GNN에서 표현력 분석[5]에서 그랬던 것처럼 주어진 두 node를 구별할 수 있느냐 없느냐로 서술되는데(linear spectral GNN이 Universal하다는 것을 통해), 위에서 정의된 PFME, FME 성질들이 이러한 GNN의 표현력과 어떻게 연관되어 있는지에 대해서는 논문에서 직접적인 이론을 통해서 설명하지는 않았습니다.&lt;/p&gt;

&lt;p&gt;다만, Polynomial Filter의 basis 선택이 Empirical한 성능에 중요하다는 부분을 지적하는 부분이나, &lt;a href=&quot;https://icml.cc/virtual/2022/spotlight/17796&quot;&gt;링크&lt;/a&gt;의 발표자료에 있는 ‘same expressive power’과 같은 맥락을 통해서 간접적으로는 PFME, FME property가 표현력과 연관이 있다고 추측해볼 수 있습니다. 그럼에도, 이 논문이 spectral GNN의 표현력을 분석하는 첫 논문이라는 점을 생각해보면 아쉬운 대목입니다. Non-PFME/non-FME spectral GNN의 표현력이 약하다와 같은 분석이 있었다면 논문의 컨텐츠가 더더욱 풍성했을 것 같아 더더욱 아쉬움이 남습니다.&lt;/p&gt;

&lt;p&gt;이런 아쉬운 점도 있었지만, 그래도 이 논문이 갖는 가치는 엄청나다고 생각하고, Spectral GNN이라는 분야가 발전함에 있어 중요한 분기점 중 하나가 될 연구라고 생각합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;-paper-author-information&quot;&gt;** Paper Author Information**&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Xiyuan Wang
    &lt;ul&gt;
      &lt;li&gt;Institute for Artificial Intelligence, Peking University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Muhan Zhang
    &lt;ul&gt;
      &lt;li&gt;Institute for Artificial Intelligence, Peking University&lt;/li&gt;
      &lt;li&gt;Beijing Institute for General Artificial Intelligence&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-review-writer-information-&quot;&gt;** Review Writer Information **&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;정지형 (Jihyeong Jung)
    &lt;ul&gt;
      &lt;li&gt;Master student, Department of Industrial &amp;amp; Systems Engineering, KAIST&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;7-reference--additional-materials&quot;&gt;&lt;strong&gt;7. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The Official Implementation은 &lt;a href=&quot;https://github.com/GraphPKU/JacobiConv&quot;&gt;여기&lt;/a&gt;에서 확인 가능합니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Xiyuan Wang and Muhan Zhang. &lt;a href=&quot;https://arxiv.org/abs/2205.11172&quot;&gt;&lt;em&gt;How Powerful are Spectral Graph Neural Networks&lt;/em&gt;&lt;/a&gt;. ICML, 2022.&lt;/li&gt;
  &lt;li&gt;Thomas N. Kipf and Max Welling. &lt;em&gt;Semi-Supervised Classification with Graph Convolutional Networks&lt;/em&gt;. ICLR, 2017.&lt;/li&gt;
  &lt;li&gt;Petar Veličković et al. &lt;em&gt;Graph Attention Networks&lt;/em&gt;. ICLR, 2018.&lt;/li&gt;
  &lt;li&gt;Michaël Defferrard et al. &lt;em&gt;Convolutional neural networks on graphs with fast localized spectral filtering&lt;/em&gt;. NeurIPS, 2016.&lt;/li&gt;
  &lt;li&gt;Keyulu Xu et al. &lt;em&gt;How Powerful are Graph Neural Networks?&lt;/em&gt; ICLR, 2019.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors&quot;&gt;&lt;em&gt;Eigenvalues and eigenvectors&lt;/em&gt;&lt;/a&gt;. Wikipedia, 2022.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Graph_isomorphism&quot;&gt;&lt;em&gt;Graph Isomorphism&lt;/em&gt;&lt;/a&gt;. Wikipedia, 2022.&lt;/li&gt;
  &lt;li&gt;David I Shuman et al. &lt;a href=&quot;https://ieeexplore.ieee.org/document/6494675&quot;&gt;&lt;em&gt;The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains&lt;/em&gt;&lt;/a&gt;. IEEE Signal Process Magazine, 2013.&lt;/li&gt;
  &lt;li&gt;Fan R. K. Chung. &lt;em&gt;Spectral Graph Theory&lt;/em&gt;. Americal Mathematical Society, 1996.&lt;/li&gt;
  &lt;li&gt;Richard Burden and J. Douglas Faires. &lt;em&gt;Numerical Analysis&lt;/em&gt;. Cengage Learning, 2005.&lt;/li&gt;
  &lt;li&gt;Stephen Boyd and Lieven Vandenberghe. &lt;em&gt;Convex Optimization&lt;/em&gt;. Cambridge University Press, 2009.&lt;/li&gt;
  &lt;li&gt;Mingguo He et al. &lt;em&gt;BernNet: Learning Arbitrary Graph Spectral Filters via Bernstein Approximation&lt;/em&gt;. NeurIPS, 2021.&lt;/li&gt;
  &lt;li&gt;Johannes Gasteiger et al. &lt;em&gt;Predict then Propagate: Graph Neural Networks meet Personalized PageRank&lt;/em&gt;. ICLR, 2019.&lt;/li&gt;
  &lt;li&gt;Eli Chien et al. &lt;em&gt;Adaptive Universal Generalized PageRank Graph Neural Network&lt;/em&gt;. ICLR, 2021.&lt;/li&gt;
  &lt;li&gt;Filippo Maria Bianchi et al. &lt;em&gt;Graph neural networks with convolutional ARMA filters&lt;/em&gt;. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021.&lt;/li&gt;
&lt;/ol&gt;
</description>
            <pubDate>Sun, 16 Oct 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/How_Powerful_are_Spectral_Graph_Neural_Networks.html</link>
            <guid isPermaLink="true">http://localhost:4000/How_Powerful_are_Spectral_Graph_Neural_Networks.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICML 2020] Generalization and Representation Limits of Graph Nueral Networks</title>
            <description>&lt;h1 id=&quot;generalization-and-representational-limits-of-graph-neural-networks&quot;&gt;Generalization and Representational Limits of Graph Neural Networks&lt;/h1&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Graph Neural Network (GNN) 은 graph-structured data 를 학습하기 위한 모델로 등장하여, molecular structures, knowledge graph, social networks 등 다양한 domain 에서 사용되고 있다. 본 논문에서는 GNN 의 한계와 generalization properites 에 대하여 깊게 탐구하였다. 저자는 간단한 구조의 graph 라도 GNN 이 구분하지 못할 것이라는 가정하에, 간단한 예시를 보여주며 이를 입증하였다. 또한, binary classification 에서 GNN 이 graph 의 label 을 얼마나 잘 구분할 수 있는지, 즉 graph 의 generalization bound 에 대하여 계산하고 이를 분석하였다.&lt;br /&gt;
Graph Neural Network (GNN) 은 graph-structured data 를 학습하기 위한 모델로 등장하여, molecular structures, knowledge graph, social networks 등 다양한 domain 에서 사용되고 있다. 본 논문에서는 GNN 의 한계와 generalization properites 에 대하여 깊게 탐구하였다. 저자는 간단한 구조의 graph 라도 GNN 이 구분하지 못할 것이라는 가정하에, 간단한 예시를 보여주며 이를 입증하였다. 또한, binary classification 에서 GNN 이 graph 의 label 을 얼마나 잘 구분할 수 있는지, 즉 graph 의 generalization bound 에 대하여 계산하고 이를 분석하였다.&lt;br /&gt;&lt;br /&gt;
저자가 GNN 을 분석한 내용은 크게 두 가지로 나눌 수 있다.&lt;br /&gt;
a) GNN 모델들이 특정한 graph property 에 대하여 graph 를 구분할 수 있는가?&lt;br /&gt;
b) GNN 모델들이 graph 의 label 을 얼마나 잘 구분해낼 수 있는가?
&lt;br /&gt;
a) 의 경우 아주 간단한 graph 들이 주어진 상황에서 graph의 성질 (i.e., longest or shortest cycle, diameter, clique information) 을 구분하지 못하는 경우가 있음을 보여준다.
&lt;br /&gt;&lt;br /&gt;
a) 의 경우 아주 간단한 graph 들이 주어진 상황에서 graph의 성질 (i.e., longest or shortest cycle, diameter, clique information) 을 구분하지 못하는 경우가 있음을 보여준다.&lt;br /&gt;
b) 의 경우 간단한 binary prediction 으로 graph 모델의 performance limitation 을 설명하고자 한다.&lt;/p&gt;

&lt;p&gt;본 논문의 contribution 은 다음과 같다.
&lt;br /&gt;&lt;br /&gt;
본 논문의 contribution 은 다음과 같다.&lt;br /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;간단한 graph 지만, GNN 이 local information 만 사용하여 만든 embedding 으로는 구분할 수 없을 수 있음을 보인다. 또한 powerful 한 node information 을 얻어내기 위하여 “port numbering” 을 적용한 “CPNGNN” 과 “geometric information”을 사용하는 “DimeNet” 역시 해당 graph 들을 구분할 수 없음을 보인다.&lt;/li&gt;
  &lt;li&gt;CPNGNN 을 graph theoretic 관점에서 분석하여, GNN 의 효과에 대한 insight 를 얻는다.&lt;/li&gt;
  &lt;li&gt;GNN 의 message passing 에 관한 data dependent generalization bounds 를 제시한다. 또한, 기존 연구보다 더 tight 한 bound 임을 입증한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;저자는 Graph 가 가지고 있는 여러 Properties 중에서, 직관적으로 이해할 수 있는 Graph Isomorphism 을 통하여, 기존 연구(LU-GNN, CPNGNN, DimeNet) 가 isomorphism 을 구분할 수 없는 Graph 가 있음을 지적한다.&lt;br /&gt;&lt;br /&gt;
즉, 간단한 예시들로 기존 연구들이 Graph Properties 를 완전히 표현할 수 없다는 한계를 보여준다.&lt;br /&gt;&lt;br /&gt;
  또한, 기존 연구의 한계점을 해결하기 위한 아주 간단한 model 을 제시한다.&lt;br /&gt;
이 간단한 model 은 DimeNet 에 geometric information 을 추가한 것으로, Novel method 를 제안한 것이 아니라,
기존연구의 (graph isomorphism에서의) 한계를 해결하기 위한 간단한 예시를 든 것으로 이해하면 된다.&lt;br /&gt;
&lt;br /&gt;
  뿐만 아니라, Empirical Rademacher Complexity 로 GNN 의 bound  기존 연구보다 tight 하게 도출하는 방법을 증명하였다.&lt;/p&gt;

&lt;h2 id=&quot;preliminaries&quot;&gt;Preliminaries&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Locally Unordered GNNs (LU-GNNs): spatial information 을 사용하지 않고 각 node 의 neighbors 에서 오는 message 로 node embedding 을 updata 하는 model (e.g., GraphSAGE, GCN, GIN and GAT).
    &lt;ol&gt;
      &lt;li&gt;Locally Unordered GNNs (LU-GNNs): spatial information 을 사용하지 않고 각 node 의 neighbors 에서 오는 message 로 node embedding 을 updata 하는 model (e.g., GraphSAGE, GCN, GIN and GAT).&lt;br /&gt;&lt;br /&gt;
LU-GNNs 에서 aggregation 과 conbine operation 은 다음과 같이 표기한다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/formula_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서, N(v) 는 node v 의 neighbor set 을 의미한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Consistent port numbering GNNs (CPNGNNs): node 의 neighbors 에 port number 를 부여함으로써 local structure information 을 더 잘 뽑아내게 하는 model.&lt;/li&gt;
  &lt;li&gt;DimeNet: molecular graphs 에서 directional message passing alogirhtm 을 사용한 model. Message passing 을 node 간의 angle 정보를 바탕으로 transform 하여 directional information 을 전달하는 model.
    &lt;ol&gt;
      &lt;li&gt;Consistent port numbering GNNs (CPNGNNs): node 의 neighbors 에 port number 를 부여함으로써 local structure information 을 더 잘 뽑아내게 하는 model.&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
      &lt;li&gt;DimeNet: molecular graphs 에서 directional message passing alogirhtm 을 사용한 model.&lt;br /&gt;Message passing 을 node 간의 angle 정보를 바탕으로 transform 하여 directional information 을 전달하는 model.&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/formula_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 e^(uv) 는 노드 u 에서 노드 v 까지의 distance 를 의미하며, a^(wu,uv) 는 w 에서 u 까지의 거리에 wuv 의 각도를 합친 정보를 의미한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Graph Property (P): Q 라는 GNN model과 서로 다른 property (P) 를 보이는 graph G_1 과 G_2 가 있을 때, 만약 f(g_Q(G_1) != f(g_Q(G_2)) 라면 model Q 는 P 를 분별할 수 있다.
또한, P 즉 graph properties 의 종류로 저자는 다음과 같은 property 를 예시로 들었다.&lt;br /&gt;
위의 수식은 DimeNet 의 학습 구조이며, e^(uv) 는 노드 u 에서 노드 v 까지의 distance 를 의미하며, a^(wu,uv) 는 w 에서 u 까지의 거리에 wuv 의 각도를 합친 정보를 의미한다.&lt;br /&gt;&lt;br /&gt;
    &lt;ol&gt;
      &lt;li&gt;Graph Property (P): Q 라는 GNN model과 서로 다른 property (P) 를 보이는 graph G_1 과 G_2 가 있을 때, 만약 f(g_Q(G_1) != f(g_Q(G_2)) 라면 model Q 는 P 를 분별할 수 있다.&lt;br /&gt;&lt;br /&gt;
또한, P 즉 graph properties 의 종류로 저자는 다음과 같은 property 를 예시로 들었다.&lt;br /&gt;&lt;br /&gt;
1) grith (length of shortest cycle),&lt;br /&gt;
2) circumference (length of longest cycle),&lt;br /&gt;
3) diameter (maximum distance between any pair of nodes in graph),&lt;br /&gt;
@@ -45,94 +54,105 @@ LU-GNNs 에서 aggregation 과 conbine operation 은 다음과 같이 표기한&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;representation-limits-of-gnns&quot;&gt;Representation limits of GNNs&lt;/h2&gt;
&lt;h4 id=&quot;limitation-of-lu-gnns&quot;&gt;Limitation of LU-GNNs&lt;/h4&gt;
&lt;p&gt;저자는 LU-GNNs 을 CPNGNNs 과 비교하여, LU-GNNs 의 한계를 보여준다.&lt;br /&gt;
저자는 LU-GNNs 을 CPNGNNs 과 비교하여, LU-GNNs 의 한계를 보여준다.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Proposition_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;위의 Proposition 1. 을 조금 더 자세히 설명하면, LU-GNN 이 특정 property 에 대하여 구분할 수 없는 두 graph 가 존재한다고 할 때, CPNGNN 은 port numbering 덕분에 구분할 수 있다.&lt;br /&gt; 구분하고자하는 property 를 “Isomorphic” 으로 가정하고, 이를 그림으로 표현하면 아래의 그림처럼 표현할 수 있다.
위의 Proposition 1. 을 조금 더 자세히 설명하면, LU-GNN 이 특정 property 에 대하여 구분할 수 없는 두 graph 가 존재한다고 할 때, CPNGNN 은 port numbering 덕분에 구분할 수 있다.&lt;br /&gt;&lt;br /&gt; 구분하고자하는 property 를 “Isomorphic” 으로 가정하고, 이를 그림으로 표현하면 아래의 그림처럼 표현할 수 있다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Figure_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;여기서 같은 색깔로 표현된 node 는 같은 feature vector 를 가지고 있다. 또한, edge 에 있는 숫자는 각 node 의 port number 를 나타낸다.&lt;br /&gt;
Graph G 와 &lt;em&gt;G&lt;/em&gt; 는 isomorphic 관점에서 서로 다름을 알 수 있다. Graph G에서 structure 정보는 (B1 - C1 - D1 - B1 - C1 - D1 - B1 - …), (B2 - C2 - D2 - B2 - C2 - D2 - B2 - …) 으로 이루어져 있으며, Graph &lt;em&gt;G&lt;/em&gt; 의 경우 (&lt;em&gt;B1&lt;/em&gt; - &lt;em&gt;C1&lt;/em&gt; - &lt;em&gt;D1&lt;/em&gt; - &lt;em&gt;B2&lt;/em&gt; - &lt;em&gt;C2&lt;/em&gt; - &lt;em&gt;D2&lt;/em&gt; - &lt;em&gt;B1&lt;/em&gt; - … ) 으로 이루어져있다.
하지만 LU-GNN 은 단순히 feature vector 만 사용하기 때문에, (보라색 - 빨간색 - 파란색 - 보라색 - 빨간색 - … ) 과 같은 순서로 node 가 연결되어있다는 정보만을 알 수 있다. 즉, Graph G를 (보라색 - 빨간색 - 파란색 - 보라색 - 빨간색 - …) 으로 인식하게 되며, Graph &lt;em&gt;G&lt;/em&gt; 의 경우도 (보라색 - 빨간색 - 파란색 - 보라색 - 빨간색 - … ) 으로 인식하게 된다. 따라서, LU-GNN 의 경우 위의 그림과 같은 Graph 들의 isomorphism 을 분별하지 못한다. &lt;br /&gt;
CPNGNN 의 경우, port number 를 사용하기에, Graph G 에서 D2 는 port 2 를 사용하여 B2 와 연결되었다는 정보와, Graph &lt;em&gt;G&lt;/em&gt; 에서는 &lt;em&gt;D2&lt;/em&gt; 가 port 1 을 사용하여 &lt;em&gt;B1&lt;/em&gt; 과 연결되었음을 알 수 있다. 따라서, CPNGNN 은 Graph G 와 &lt;em&gt;G&lt;/em&gt; 를 isomorphism property 에서 구별할 수 있다. &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;여기서 같은 색깔로 표현된 node 는 같은 feature vector 를 가지고 있다.&lt;br /&gt; 또한, edge 에 있는 숫자는 각 node 의 port number 를 나타낸다.&lt;br /&gt;&lt;br /&gt;
Graph G 와 &lt;em&gt;G&lt;/em&gt; 는 isomorphic 관점에서 서로 다름을 알 수 있다. Graph G에서 structure 정보는 (B1 - C1 - D1 - B1 - C1 - D1 - B1 - …), (B2 - C2 - D2 - B2 - C2 - D2 - B2 - …) 으로 이루어져 있으며, Graph &lt;em&gt;G&lt;/em&gt; 의 경우 (&lt;em&gt;B1&lt;/em&gt; - &lt;em&gt;C1&lt;/em&gt; - &lt;em&gt;D1&lt;/em&gt; - &lt;em&gt;B2&lt;/em&gt; - &lt;em&gt;C2&lt;/em&gt; - &lt;em&gt;D2&lt;/em&gt; - &lt;em&gt;B1&lt;/em&gt; - … ) 으로 이루어져있다.&lt;br /&gt;&lt;br /&gt;
하지만 LU-GNN 은 단순히 feature vector 만 사용하기 때문에, (보라색 - 빨간색 - 파란색 - 보라색 - 빨간색 - … ) 과 같은 순서로 node 가 연결되어있다는 정보만을 알 수 있다. 즉, Graph G를 (보라색 - 빨간색 - 파란색 - 보라색 - 빨간색 - …) 으로 인식하게 되며, Graph &lt;em&gt;G&lt;/em&gt; 의 경우도 (보라색 - 빨간색 - 파란색 - 보라색 - 빨간색 - … ) 으로 인식하게 된다. 따라서, LU-GNN 의 경우 위의 그림과 같은 Graph 들의 isomorphism 을 분별하지 못한다. &lt;br /&gt;&lt;br /&gt;
CPNGNN 의 경우, port number 를 사용하기에, Graph G 에서 D2 는 port 2 를 사용하여 B2 와 연결되었다는 정보와, Graph &lt;em&gt;G&lt;/em&gt; 에서는 &lt;em&gt;D2&lt;/em&gt; 가 port 1 을 사용하여 &lt;em&gt;B1&lt;/em&gt; 과 연결되었음을 알 수 있다. 따라서, CPNGNN 은 Graph G 와 &lt;em&gt;G&lt;/em&gt; 를 isomorphism property 에서 구별할 수 있다. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;limitations-of-cpngnns&quot;&gt;Limitations of CPNGNNs&lt;/h4&gt;
&lt;p&gt;CPNGNN 이 LU-GNN 이 구분하지 못하는 Graph 들을 구별할 수 있음을 보여주었다. 하지만, CPNGNN 역시 구분할 수 없는 Graph 들이 존재하며, 저자는 LU-GNN 의 limitation 을 보여주었던 것과 같은 방식으로, CPNGNN 의 limitation 을 보여준다.
CPNGNN 이 LU-GNN 이 구분하지 못하는 Graph 들을 구별할 수 있음을 보여주었다. 하지만, CPNGNN 역시 구분할 수 없는 Graph 들이 존재하며, 저자는 LU-GNN 의 limitation 을 보여주었던 것과 같은 방식으로, CPNGNN 의 limitation 을 보여준다.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Proposition_2.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Proposition 1. 과 동일하게, 색깔은 node 의 feature vector 를 edge 의 숫자는 port number 를 나타낸다. &lt;br /&gt;
Proposition 1. 과 동일하게, 색깔은 node 의 feature vector 를 edge 의 숫자는 port number 를 나타낸다. &lt;br /&gt;&lt;br /&gt;
Graph 의 isomorphism property 를 구분하는 task 에서 다음 그림과 같은 Graph 들이 주어졌을 때, CPNGNN 은 isomorphism 을 구분할 수 없다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Figure_2.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;그림의 Graph 들은 Proposition 1. 에서 보인 예시에서 Port number 를 변경한 Graphs 이다.&lt;br /&gt;
그림의 Graph 들은 Proposition 1. 에서 보인 예시에서 Port number 를 변경한 Graphs 이다.&lt;br /&gt;&lt;br /&gt;
CPNGNN 을 사용할 때, Graph G 의 D1과 D2 와 Graph &lt;em&gt;G&lt;/em&gt; 의 &lt;em&gt;D2&lt;/em&gt; 가 보라색, 빨간색 feature vector 와 연결된 port number 가 같음을 알 수 있다. 따라서, CPNGNN 은 해당 그래프에서 해당 node 들을 구분할 수 없다. 따라서, 두 그래프의 isomorphism 을 구분하는데 실패하게 된다.&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Proposition_4.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;저자는 Proposition 4. 에서 isomorphism task 이외에 다른 task 에 대하여 일반화하였다.
저자는 Proposition 4. 에서 isomorphism task 이외에 다른 task 에 대하여 일반화하였다.&lt;br /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Figure_3.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Graph S4 와 S8 은 girth, circumference, diameter, radius 를 가지고 있음에도 CPNGNN 이나 LU-GNN 으로 구분할 수 없다. 하지만, DimeNets 의 경우 node 간의 angle 을 사용하므로, Graph S4 의 A1-B1-C1 이 이루는 angle 과 Graph S8 의 &lt;em&gt;A1&lt;/em&gt;-&lt;em&gt;B1&lt;/em&gt;-&lt;em&gt;C1&lt;/em&gt; 의 angle 이 다르기에 두 graph 를 여러 properties 에 대하여 구분 할 수 있다.&lt;br /&gt;
Graph S4 와 S8 은 girth, circumference, diameter, radius 를 가지고 있음에도 CPNGNN 이나 LU-GNN 으로 구분할 수 없다.&lt;br /&gt;&lt;br /&gt;
하지만, DimeNets 의 경우 node 간의 angle 을 사용하므로, Graph S4 의 A1-B1-C1 이 이루는 angle 과 Graph S8 의 &lt;em&gt;A1&lt;/em&gt;-&lt;em&gt;B1&lt;/em&gt;-&lt;em&gt;C1&lt;/em&gt; 의 angle 이 다르기에 두 graph 를 여러 properties 에 대하여 구분 할 수 있다.&lt;br /&gt;&lt;br /&gt;
Graph G1, G2 의 경우 역시, CPNGNN 과 LU-GNN 으로 구분 할 수 없으나, DimeNets 의 경우 node 의 angle 정보를 사용함으로 graph 를 구분할 수 있다.
&lt;br /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;limitations-of-dimenets&quot;&gt;Limitations of DimeNets&lt;/h4&gt;
&lt;p&gt;DimeNets 이 CPNGNN 과 LU-GNN 이 구분할 수 없는 Graphs 들을 분별할 수 있을지라도, DimeNets 역시 구분 할 수 없는 상황이 존재한다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Figure_4.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Graph G3 의 A1 과 G4 의 &lt;em&gt;A1&lt;/em&gt; 을 비교하면 node 의 angle 정보로 G3 와 G4 를 구분할 수 없음을 알 수 있다. 따라서, DimeNets 역시 graph properties 를 구별할 수 없는 경우가 존재할 수 있다.
Graph G3 의 A1 과 G4 의 &lt;em&gt;A1&lt;/em&gt; 을 비교하면 node 의 angle 정보로 G3 와 G4 를 구분할 수 없음을 알 수 있다. 따라서, DimeNets 역시 graph properties 를 구별할 수 없는 경우가 존재할 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;more-powerful-gnns&quot;&gt;More powerful GNNs&lt;/h4&gt;
&lt;p&gt;지금까지, LU-GNN, CPNGNN 그리고 DimeNet 의 한계점에 대하여 간단한 예시를 통하여 알아보았다. 그렇다면, 이 graph models 들이 구분하지 못하는 properties 를 해결할 수 있는 model 을 구성할 필요가 있다. 저자는 이러한 model 을 아주 간단한 방식으로 구성하였다.
지금까지, LU-GNN, CPNGNN 그리고 DimeNet 의 한계점에 대하여 간단한 예시를 통하여 알아보았다.&lt;br /&gt;
그렇다면, 이 graph models 들이 구분하지 못하는 properties 를 해결할 수 있는 model 을 구성할 필요가 있다. 저자는 이러한 model 을 아주 간단한 방식으로 구성하였다.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/formula_3.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;여기서 $\Phi_{uv}$ node u와 v 사이의 angle 이외의 additional geometric information 을 뜻한다. 여기서 저자는, u와 v 이외의 다른 node w, z 를 사용하여, $\Phi_{uv}$ 는 node (w,u,v) 가 이루는 plane 과 node (u,v,z) 가 이루는 plane 간의 distance 를 의미한다. 따라서 저자는 이러한 DimeNet 에서 사용하는 node angle 이외의 geometric information 사용하여 해결할 수 있다고 주장하였다.
여기서 $\Phi_{uv}$ node u와 v 사이의 angle 이외의 additional geometric information 을 뜻한다.&lt;br /&gt;
저자는, u와 v 이외의 다른 node w, z 를 사용하였으며, $\Phi_{uv}$ 는 node (w,u,v) 가 이루는 plane 과 node (u,v,z) 가 이루는 plane 간의 distance 를 의미한다.&lt;br /&gt;&lt;br /&gt;
따라서 저자는 이러한 DimeNet 에서 사용하는 node angle 이외의 geometric information 사용하여 해결할 수 있다고 주장하였다.&lt;/p&gt;

&lt;h3 id=&quot;generalization-bounds-for-gnns&quot;&gt;Generalization bounds for GNNs&lt;/h3&gt;
&lt;p&gt;지금까지 GNNs 의 Limitation 에 관하여 분석하였다. 본 단락부터는 저자가 GNN 의 generalization ability 에 관하여 분석한 내용을 설명하도록 하겠다.&lt;br /&gt;
지금까지 GNNs 의 Limitation 에 관하여 분석하였다.&lt;br /&gt;&lt;br /&gt;
본 단락부터는 저자가 GNN 의 generalization ability 에 관하여 분석한 내용을 설명하도록 하겠다.&lt;br /&gt;&lt;br /&gt;
Generalization ability 는 binary classification 에 집중하여 분석을 진행하였다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/formula_4.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;저자는 기본적인 GNN 의 embedding updata 수식 (aggretation, combine) 에서 다음과 같은 결과를 해석할 수 있다고 하였다.&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;각 node 는 각자의 embedding 을 사용하여 각자의 binary prediction 을 진행한다.&lt;/li&gt;
  &lt;li&gt;Graph classification 에서는 node 들 각자의 binary prediction 에서로부터 majority 를 취하여 graph label 로 사용하게 된다. (average readout 때문)&lt;/li&gt;
  &lt;li&gt;각 node 는 각자의 embedding 을 사용하여 각자의 binary prediction 을 진행한다.&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Graph classification 에서는 node 들 각자의 binary prediction 에서로부터 majority 를 취하여 graph label 로 사용하게 된다. (average readout 때문)&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;empirical-risk--rademacher-complexity&quot;&gt;Empirical Risk &amp;amp; Rademacher Complexity&lt;/h4&gt;
&lt;p&gt;이전의 연구에서 GNNs 의 bound 에 관하여 진행된 연구가 있다. 해당 연구는 empirical risk (\(\hat{R}\))를 사용하여, bound 를 계산하였다.
이전의 연구에서 GNNs 의 bound 에 관하여 진행된 연구가 있다. 해당 연구는 empirical risk ($\hat{R}$)를 사용하여, bound 를 계산하였다.&lt;br /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/formula_7.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;여기서 y 는 0과 1 의 binary value 를 가진다.&lt;br /&gt;
여기서 y 는 0과 1 의 binary value 를 가진다.&lt;br /&gt;&lt;br /&gt;
위의 식을 바탕으로, 기존 연구에 따르면 다음과 같은 GNN 의 bound 를 구할 수 있게 된다. 여기서, p 가 음수가 되는 확률이므로, population risk 의 bound (error bound) 를 의미하게 된다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Lemma_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;따라서, Rademacher complexity 라고 불리는 \(\hat{R}_{\mathcal{T}}(\mathcal{J}_{\gamma})\) 의 bound 를 계산하여, GNNs 의 bound 를 계산할 수 있다. &lt;br /&gt;
하지만, Graph 의 Rademacher complexity 를 직접 구할 수 없기에, 저자는 GNN 을 tree 형태로 표현하며 tree의 Rademacher complexity 로 Graph 의 Rademacher complexity 를 bound 할 수 있음을 보였다.
따라서, Rademacher complexity 라고 불리는 \(\hat{R}_{\mathcal{T}}(\mathcal{J}_{\gamma})\) 의 bound 를 계산하여, GNNs 의 bound 를 계산할 수 있다. &lt;br /&gt;&lt;br /&gt;
하지만, Graph 의 Rademacher complexity 를 직접 구할 수 없기에, 저자는 GNN 을 tree 형태로 표현하며 tree의 Rademacher complexity 로 Graph 의 Rademacher complexity 를 bound 할 수 있음을 보였다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;analyzing-gnn-generalization-via-trees&quot;&gt;Analyzing GNN generalization via trees&lt;/h4&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Figure_5.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;위의 그림에 따라, Graph 를 tree 로 표현할 수 있으며, 이를 통하여 몇개의 insight 를 알 수 있다.&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;subtree 의 관점에서, tree node 에 대한 embedding 을 재귀적으로 표현할 수 있다.&lt;/li&gt;
  &lt;li&gt;Shared weights 에 조그마한 변화를 주어도, tree root 의 embedding 은 거의 변하지 않는다. (individual prediction 이 거의 변하지 않는다.)&lt;/li&gt;
  &lt;li&gt;subtree 의 관점에서, tree node 에 대한 embedding 을 재귀적으로 표현할 수 있다.&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Shared weights 에 조그마한 변화를 주어도, tree root 의 embedding 은 거의 변하지 않는다. (individual prediction 이 거의 변하지 않는다.)&lt;br /&gt;&lt;br /&gt;
GNN 을 tree 로 표현한 구조로부터 약간의 notation abuse 를 사용하여, 다음과 같이 표현할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/formula_5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 f(G;\(\theta\)) 를 tree 에 적용된 모든 function 의 expactation 으로 표기하고, T_1, T_2, … T_n 이 depth L 인 computation tree 의 모든 possible set 이라고 할때,
여기서 f(G;$\theta$) 를 tree 에 적용된 모든 function 의 expactation 으로 표기하고, T_1, T_2, … T_n 이 depth L 인 computation tree 의 모든 possible set 이라고 할때,&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/formula_6.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;위의 식과 같이 표현할 수 있다. 즉 “GNN 의 complexity 는 computation tree 의 complexity 에 bound 될 수 있다”.
위의 식과 같이 표현할 수 있다.&lt;br /&gt;
즉 “GNN 의 complexity 는 computation tree 의 complexity 에 bound 될 수 있다”.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;따라서, Proposition 6 을 통하여, tree 의 Rademacher complextiy 로 graph 의 Rademacher complexity 를 bound 할 수 있다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Proposition_6.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Proposition 6 과 Lemma 1 을 사용하면 Graph 의 bound 를 알 수 있게된다. 다음 section 에서 저자는 tree 의 Rademacher complexity 를 계산하고, Graph 의 bounds 를 보여준다.
Proposition 6 과 Lemma 1 을 사용하면 Graph 의 bound 를 알 수 있게된다. 다음 section 에서 저자는 tree 의 Rademacher complexity 를 계산하고, Graph 의 bounds 를 보여준다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;generalization-bound-for-gnns&quot;&gt;Generalization Bound for GNNs&lt;/h4&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Proposition_7.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Proposition 7 을 통하여 tree 의 Rademacher Complexity 를 계산할 수 있다. 여기서 C 는 percolation complexity 를 의미하며, B_1 과 B_2 의 경우 단순하게 W1, W2 의 spectral norm 을 사용한다. Lemma 1, Proposition 6, Proposition 7 을 사용하여, 드디어 GNN 의 generalization bound 를 계산할 수 있다.
Proposition 7 을 통하여 tree 의 Rademacher Complexity 를 계산할 수 있다.&lt;br /&gt;
여기서 C 는 percolation complexity 를 의미하며, B_1 과 B_2 의 경우 단순하게 W1, W2 의 spectral norm 을 사용한다.&lt;br /&gt;
Lemma 1, Proposition 6, Proposition 7 을 사용하여, 드디어 GNN 의 generalization bound 를 계산할 수 있다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Figure_6.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;위의 표는 GNN 과 RNN 의 generalization error bound 를 C 의 값에 따라 계산한 결과이다. GNN 의 bound 를 계산할 때, tree 구조를 사용하여 계산하였기에, branching factor d 가 GNN에 추가된 모습을 확인할 수 있다. 또한, r: dependence on dimension, L: depth (in RNN length), m: sample size 를 나타낸다.
위의 표는 GNN 과 RNN 의 generalization error bound 를 C 의 값에 따라 계산한 결과이다.&lt;br /&gt;
GNN 의 bound 를 계산할 때, tree 구조를 사용하여 계산하였기에, branching factor d 가 GNN에 추가된 모습을 확인할 수 있다.&lt;br /&gt;
또한, r: dependence on dimension, L: depth (in RNN length), m: sample size 를 나타낸다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;additional-analysis&quot;&gt;Additional Analysis&lt;/h4&gt;
&lt;p&gt;이 외에 저자는 VC-bounds 와 저자가 계산한 GNN 을 비교하여, VC-bounds (O(r^6 N^2) , 저자 (O(r^3 N / (m^(1/2))) 로 저자의 bound 가 더 tight 함을 보였다.&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&quot;additional-analysis-1&quot;&gt;Additional Analysis&lt;br /&gt;&lt;/h4&gt;
&lt;p&gt;이 외에 저자는 VC-bounds 와 저자가 계산한 GNN 을 비교하여, VC-bounds (O(r^6 N^2) , 저자 (O(r^3 N / (m^(1/2))) 로 저자의 bound 가 더 tight 함을 보였다.&lt;br /&gt;&lt;br /&gt;
또한, shared weight parameter 와 classifier parameter 가 변경될 때의 영향에 대한 분석을 기술하였다.&lt;br /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Lemma_2.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;$\nabla_{L}$ 는 Weight (W1, W2) 에서 도출된 embedding 과 (W’1, W’2) 에서 도출된 embedding 의 l2-norm difference 를 보여준다.
&lt;br /&gt;
또한, shared weight parameter (W1,W2) 와 classifier parameter (\(\beta\)) 가 변경될 때의 probability 변화를 계산하면 다음과 같다.
또한, shared weight parameter (W1,W2) 와 classifier parameter ($\beta$) 가 변경될 때의 probability 변화를 계산하면 다음과 같다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/Generalization_and_Representational_Limits_of_Graph_Neural_Networks/Lemma_4.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Lemma 4 를 통하여 충분히 수렴이 되는 조건 하에서, “change in probability” 는 매우 작은 값을 가질 수 있음을 알 수 있다. &lt;br /&gt;
즉, Shared weights 에 조그마한 변화를 주어도, tree root 의 embedding 은 거의 변하지 않는다. (individual prediction 이 거의 변하지 않는다.)&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;본 논문은 단순 GNN 모델 (LU-GNN), CPNGNN, DimeNet 의 한계에서 대하여 직관적인 예시를 보여주며 설명하였다.&lt;br /&gt;
또한, GNN 의 generalization bound 를 이전의 연구 (VC-bounds) 보다 더 tight 한 결과를 얻어, GNN 의 효용을 보여주었다. &lt;br /&gt;
마지막으로, Shared weight parameter 의 변화가 충분히 수렴되는 상황 속에서는 model performance 에 영향을 거의 주지 않음을 증명하였다. &lt;br /&gt;
또한, Graph Isomorphism 에 대하여, 기존 연구가 가지고 있는 한계점을 해결하기 위한 간단한 model 예시를 보여주었다.&lt;br /&gt;&lt;br /&gt;
Graph Generalization 측면에서는, GNN 의 generalization bound 를 이전의 연구 (VC-bounds) 보다 더 tight 한 결과를 얻어, GNN 의 효용을 보여주었다. &lt;br /&gt;&lt;br /&gt;
마지막으로, Shared weight parameter 의 변화가 충분히 수렴되는 상황 속에서는 model performance 에 영향을 거의 주지 않음을 증명하였다. &lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

</description>
            <pubDate>Sun, 16 Oct 2022 00:00:00 +0900</pubDate>
            <link>http://localhost:4000/Generalization_and_Representation_Limits_of_Graph_Nueral_Networks.html</link>
            <guid isPermaLink="true">http://localhost:4000/Generalization_and_Representation_Limits_of_Graph_Nueral_Networks.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
    </channel>
</rss>
