<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>DSAILatKAIST.github.io</title>
        <description>Intended as a documentation theme based on Jekyll for technical writers documenting software and other technical products, this theme has all the elements you would need to handle multiple products with both multi-level sidebar navigation, tags, and other documentation features.</description>
        <link>http://dsailatkaist.github.io/</link>
        <atom:link href="http://dsailatkaist.github.io/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Mon, 16 Oct 2023 17:35:34 +0900</pubDate>
        <lastBuildDate>Mon, 16 Oct 2023 17:35:34 +0900</lastBuildDate>
        <generator>Jekyll v3.9.2</generator>
        
        <item>
            <title>[RecSys 2023] Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation</title>
            <description>&lt;h1 id=&quot;a-review-on-fairllm&quot;&gt;A Review on FaiRLLM&lt;/h1&gt;

&lt;h3 id=&quot;summary&quot;&gt;SUMMARY&lt;/h3&gt;
&lt;p&gt;This is a scientific review on the paper â€œIs Chat GPT fair for Recommendation? Evaluating Fairness in Large Language
Model Recommendationâ€ by Jizhi Zhang, Keqin Bao, Yan Zhang, Wenjoe Wang, Fuli Feng, and Xiangnan He.
The paper was accepted not long ago in July 2023 by the RecSys conference and has been since then already cited 22 times
(October 14th on Google Scholar).&lt;br /&gt;
Within this work, the paper is analysed according to its completeness and the methods that were used. The significance
and impact of the work is easily recognizable considering search result using the indicated keywords by the authors.
Without doubt, their approach has been conducted scientifically clean and added great value to the RecSys community. Yet,
this analysis points out limitations and minor issues, that are necessary to consider in future work in order to showcase
the broad bandwidth in which unfairness exists.&lt;/p&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;In recent years, the realm of recommender systems has witnessed a burgeoning trend in the adoption of generative models
to augment the efficacy of recommendations. With the ascent of Large Language Models (LLMs) such as ChatGPT by OpenAI
and Bard by Google, the allure of leveraging these powerful models for recommendation tasks has surged. &lt;br /&gt;
However, as LLMs gain prominence in recommendation systems, concerns regarding recommendation fairness have surfaced.
These concerns are not limited to traditional recommendation systems and are equally pertinent to LLM-based 
recommendation systems. Notably, traditional fairness metrics are often inapplicable in this novel context 
(Zhang et al.), necessitating the emergence of a research domain centered around LLM fairness and bias.&lt;/p&gt;

&lt;p&gt;The persistence of unfairness in LLM-based recommendation systems is of paramount concern, given its potential to 
significantly impact the user experience of marginalized groups. In response to this pressing issue, Zhang et al. 
have introduced the benchmarking method known as FaiRLLM. This method seeks to evaluate the fairness of LLMs in the 
context of recommendations, particularly for the top-k recommendation task. Notably, this method has been rigorously 
tested on ChatGPT, demonstrating the existence of unfairness in LLM-based recommendations and highlighting the metricsâ€™
resilience to prompt modification.&lt;/p&gt;

&lt;p&gt;Given the authorsâ€™ assertion of being pioneers in developing a fairness metric for LLM-based recommender systems, 
a comprehensive review of this paper is imperative to assess its efficacy, comprehensiveness, and accuracy.
A preliminary examination of the paperâ€™s impact reveals that it has already garnered 22 citations, underscoring its 
influence on subsequent research and the significance of this work. &lt;br /&gt;
Moreover, in light of the rapid evolution and advancements within the LLM community, it is incumbent upon LLM-based 
recommender systems to keep pace with ongoing developments in fairness and bias mitigation. Consequently, the primary 
objective of this paper review is to contribute to the acceleration of research progress in this dynamic field.&lt;/p&gt;

&lt;h2 id=&quot;2-summary&quot;&gt;2. Summary&lt;/h2&gt;

&lt;p&gt;The authors of the paper â€œIs ChatGPT fair for Recommendation? Evaluating Fairness in Large Language Model Recommendationâ€
introduce the purpose and motivation of their work in a thorough introduction paragraph. There, they underline the
fairness concerns in LLMs due to the bias in the training corpus and that it is necessary to reduce those in the
context of recommendations, since the traditional metrics to measure fairness in recommender systems can not be applied
for LLMs. This is due to the fact, that those metrics require the scores of the model prediction results, which are 
difficult to obtain in a LLM. In addition, the fairness needs to be computed on a fixed candidate set based on a
specific dataset, which would limit the recommendation ability of Recommendations via LLM (RecLLM) significantly.&lt;/p&gt;

&lt;p&gt;In order to set a proper starting point in the fairness evaluation of RecLLMs, the authors have decided to consider the
user-side group-fairness for a top-k recommendation task on the music and movie domain. They reason their choice for
the scope setting according to the nature of conversational recommendation tasks and the complexity reduction. For
instance, music or movie items consist of way less and explicit features compared to fashion items.&lt;/p&gt;

&lt;p&gt;After setting the scope, the authors proceed on explaining the evaluation method, the metrics they constructed to 
compute fairness, and finally document how they have generated the benchmarking dataset.  &lt;br /&gt;
For the evaluation method, the authors have chosen to compare neutral instructions against sensitive instructions, which
are instructions that consist additional user information in addition to the expressed preference and task. For the 
additional user information added in the sensitive prompt, the authors decided on testing the eight most discussed attributes
in the area of recommendation system fairness: &lt;em&gt;age, continent, country, occupation, gender, religion, race, physics&lt;/em&gt;.  &lt;br /&gt;
The values for injection they have considered are depicted in the following extraction of the paper:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img.png&quot; alt=&quot;img.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Without loss of generality,the authors came up with the following neutral and sensitive prompts, that they input in
ChatGPT in order to obtain the top-k recommendation list. A prompt consists of semantically two parts, whereas one is the 
preference expression, while the other is the task description. For the sensitive prompt, the preference expression is
extended by a sensitive attribute. The words in square brackets are placeholders, in which a value is injected
iteratively from the value-set.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Neutral&lt;/strong&gt;: &lt;em&gt;â€œI am a fan of [names]. Please provide me with a list of ğ¾ song/movie titlesâ€¦â€&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sensitive&lt;/strong&gt;: &lt;em&gt;â€œI am a/an [sensitive feature] fan of [names]. Please provide me with a list of ğ¾ song/movie titlesâ€¦â€&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After obtaining both the neutral and the sensitive query result, the neutral one is used as a baseline result, to which
the sensitive outputs are compared to measure the similarity. &lt;br /&gt;
While the attributes and values for the sensitive features have been well-defined, the choice of the values for the 
&lt;em&gt;[names]&lt;/em&gt;-placeholder, representing a user preference, needed to be known by the RecLLM.
As a result, the authors have decided to query the most 500 popular singers in the music domain through the MTV API, and 
the most popular 500 directors and their most popular TV shows and movies by querying the IMDB database.&lt;br /&gt;
Thus, the resulting two benchmark databases, one for each domain, consist of neutral and sensitive instructions in form
of natural language. In order to ensure reproducibility of the query outputs, the authors have decided on fixing
the hyperparameters of ChatGPT accordingly, such as &lt;em&gt;temperature, top_p, and frequency_penalty&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;For the purpose of similarity computation of the sensitive recommendation set with the neutral output, the authors have 
designed three metrics:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Jaccard&lt;/strong&gt;   &lt;br /&gt;
Computes the ratio between common elements, but does not consider the ranking.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SERP&lt;/strong&gt;*   &lt;br /&gt;
Is a modification of the &lt;strong&gt;Search Result Page Misinformation Score&lt;/strong&gt;, which computes the similarity between two
recommendation lists. It can be considered as a weighted option of the Jaccard metric in order to include the item
ranking. The relative item ranking in this metric is nevertheless neglected.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;PRAG&lt;/strong&gt;*  &lt;br /&gt;
Is a modification of Pairwise Ranking Accuracy Gap metric to include the importance of relative rankings. The metric
does it by measuring the pairwise ranking between recommendation results for the natural and sensitive instructions&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The established similarity metrics represent a crucial element in the designed metric which computes the fairness of a
RecSys. For that, the authors have constructed two indicators: the Sensitive-to-Neutral Similarity Range (SNSR) and 
Sensitive-to-Neutral Similarity Variance (SNSV).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SNSR&lt;/strong&gt;   &lt;br /&gt;
It measures the similarities between the most advantaged and the most disadvantaged group.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SNSV&lt;/strong&gt;  &lt;br /&gt;
Computes the divergence across all possible attribute values using the Standard Deviation.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;(Note: For a detailed mathematical formulation of the metrics please refer to Appendix A)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In consideration with the similarity metrics, there are therefore three options to compute the fairness score.
For the analysis, all possible fairness metrics were computed and presented in a table, which is added as an excerpt
below. The table documents the fairness values of the music and the movie recommendations in a separated nature.
Aside from the &lt;em&gt;SNSR&lt;/em&gt; and &lt;em&gt;SNSV&lt;/em&gt; metrics, the authors have decided on adding the Min/Max value for each attribute,
which denote the minimum and maximum similarity value among all values for one attribute. The sensitive attributes
are listed in decreasing SNSV-score from left to right.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_1.png&quot; alt=&quot;img_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, the scores are used for an analysis of the developed metrics by setting two research questions (RQ1 and RQ2).
By formulating these two questions, the authors attempt to proof the validity and robustness of their benchmarking
method. To facilitate the data interpretation, the authors visualized the most crucial data points by plotting for each
attribute the similarity score for the top-k recommendations against the number of k, setting k from 1 to 20. By
using the collected data as an argumentative foundation, the authors have shown that both research questions could be 
answered in favor of their developed benchmarking method:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RQ1:&lt;/strong&gt; &lt;em&gt;How unfair is the LLM when serving as a recommender on various sensitive user attributes?&lt;/em&gt;    &lt;br /&gt;
For evaluating the overall unfairness in ChatGPT as a RecLLM, the authors performed a thorough analysis on the collected
data and determined three major findings:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The unfairness is present in both, the music and the movie domains. The SNSV and SNSR score show clear varying values
across  the different attributes and thus proof the preference of some groups over others.&lt;/li&gt;
  &lt;li&gt;The recommendation unfairness does not depend on the recommendation length, as truncating the lists lead to the same results.&lt;/li&gt;
  &lt;li&gt;The unfairness in regard to the attribute values align with real world disadvantages. For example, African groups
receive a recommendation list which diverges more from the neutral recommendation, than Americans.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;RQ2:&lt;/strong&gt; &lt;em&gt;Is the unfairness phenomenon for using LLM as a recommender robust across different cases?&lt;/em&gt;   &lt;br /&gt;
The authors produced additional recommendation lists in order to test the confidence of their metrics and the
existing bias in RecLLM by 1) replacing the sensitive attribute values through typos and 2) by inserting the prompts
in a different language. Due to resource limitations, the authors tested the robustness only on the &lt;em&gt;country&lt;/em&gt;
attribute and on the values &lt;em&gt;African&lt;/em&gt; and &lt;em&gt;American&lt;/em&gt;. While, typos were generated by randomly adding and removing letters,
the language robustness was tested by using Chinese instructions. &lt;br /&gt;
For both parts, the results have shown that the unfairness shown in RQ1 persisted and therefore confirmed the authorâ€™s
contribution.&lt;/p&gt;

&lt;p&gt;The paper is then concluded with a brief summary about the findings within the paper and an outlook on future work
in regard to the authorâ€™s goal. They state, that it is in their interest to evaluate other RecLLMs, such as LLaMA for
fairness and develop methods that mitigate the unfairness score in RecLLMs.&lt;/p&gt;

&lt;h2 id=&quot;3-analysis-on-the-paper&quot;&gt;3. Analysis on the Paper&lt;/h2&gt;

&lt;p&gt;The paper â€œIs Chat GPT fair for Recommendation? Evaluating Fairness in Large Language Model Recommendationâ€ by
Zhang et al. is a solid academic foundation in the area of fairness evaluation for RecLLMs. Additional research on
fairness metrics for RecLLMs has confirmed the authorâ€™s claim of providing the first contribution to a benchmarking method 
in this field. For that reason alone, the academic significance of this work should be recognized. Even though a paper 
with a similar research goal by Hua et al. was published a few months before the paper of Zhang et al., it is noticeable 
that the target and scope by Hua et al. differs significantly from Zhang et al. While Hua et al. also developed methods
to probed unfairness in a LLM-based recommendation system, they limited the methods to the used model and the trained
dataset. Thus, their approach is not applicable for unfairness probing on other LLMs.&lt;/p&gt;

&lt;p&gt;In addition, the scientific methods used in this paper coherently align with the basics of scientific principles, as
described by W.S. Jevons. Considering that following these standards, such as following the formalities of correct
citation, proof-based argumentation, and the empirical and experimental approach, are the status quo for published papers,
their details shall not be further elaborated within this review. &lt;br /&gt;
Nevertheless, it is to note that the authors have taken the requirement for benchmarking robustness into account and
fulfilled by addressing different recommendation domains and crucial varieties of the prompts, by testing their method
for typos and for the language of the prompt. &lt;br /&gt;
Furthermore, the instrumentalization of similarity metrics that are used in traditional recommendation systems are 
effective for the fairness metrics and provide an easy-to-understand transfer, allowing for adaptivity of the fairness
metrics without the need for additional hard-to-obtain data.
The persuasive nature of the paper is also supported by the paper structure, in which knowledge is transferred to the
reader in a reasonable order, so that the more complex topics are easy to follow and understand.&lt;/p&gt;

&lt;p&gt;Finally, with their pragmatic and experimental-based reasoning, the authors manage to propose their benchmarking method in a 
convincing manner through their well-thought-out metrics that underline their statements about existing unfairness in 
RecLLM and their robustness. In general, they always provided immediate reasoning for any choice of methodology aside from
a few exceptions. For example, the authors did not specify their choice on the sensitive attribute values. Aside from 
that, other minor research gaps have been identified during the paper review, leaving room for future improvement or
initiating some adjustments to their work.&lt;/p&gt;

&lt;p&gt;Structurally, the analysis of the experiment results have validated the usefulness of FaiRLLM. Yet, for a proper
360-degree view on their work, the paper is missing a section listing their limitations of their approach and the
discussion of their findings. Even though the limitations have been mentioned in places of the paper, such as when
the authors stated to focus only on the top-k recommendation task, an explicit paragraph about the limitations would
have provided more clearance after reading the results. Missing the discussion paragraph is pretty crucial though, as 
the interim results of the authorâ€™s findings have not been discussed in other parts of the paper. As a result, it leaves
the impression as if he authors did not try to put their findings into question.&lt;/p&gt;

&lt;p&gt;Within the analysis of the benchmarking robustness to changes in the prompts, typos have only been tested on the attribute
&lt;em&gt;continent&lt;/em&gt; and the values &lt;em&gt;African&lt;/em&gt; and &lt;em&gt;American&lt;/em&gt;. Since the authors did not argue that this small set on experiment
suffices, a broader consideration should have been shown. Especially an analysis on whether the unfairness still holds
when considering attribute values, that are already close to each other. Evaluating the recommendation lists with typos
could provide additional insights, that could either strengthen or weaken the authorâ€™s points. An example would be to
consider typos for the attribute &lt;em&gt;occupation&lt;/em&gt; for &lt;em&gt;writer&lt;/em&gt; and &lt;em&gt;worker&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_2.png&quot; alt=&quot;img_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Moreover, the language robustness has been tested solely for Chinese prompts. Since it is noticeable, that the similarity
score between Africans and Asians have switched after querying for movies, a RecLLM might show cultural bias based on the
language in which the user queries the prompt. Thus, testing language robustness in multiple languages should is
necessary.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_3.png&quot; alt=&quot;img_3.png&quot; /&gt; 
&lt;img src=&quot;img_4.png&quot; alt=&quot;img_4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, the authors did not provide any reasoning for their choice of the sensitive attribute values.
Looking at those in more detail, some values should have been included in order to properly cross-check the unfairness
of the RecLLM. Since the attributes &lt;em&gt;continet&lt;/em&gt; and &lt;em&gt;country&lt;/em&gt; have a hierarchical order, the consistency of the fairness
probing should have been applied as well. Due to the lack of fitting values though, this is not clear. For example, 
for the attribute &lt;em&gt;country&lt;/em&gt;, there are European and South American countries, but Europe and South America are not 
included as values in the &lt;em&gt;continent&lt;/em&gt; attribute. At the same time, there is no African country listed in the &lt;em&gt;country&lt;/em&gt;
attribute, making it question, whether a user from Ghana might end up with the same ranking distribution when considering
the &lt;em&gt;continent&lt;/em&gt; attribute.&lt;/p&gt;

&lt;h2 id=&quot;4-open-questions&quot;&gt;4. Open Questions&lt;/h2&gt;

&lt;p&gt;The work of Zhang et al. is in its own very thorough and provides a solid instrument to benchmark LLMs as recommender
systems in regard to their fairness attribute. Yet, there are still few open questions that have not been dealt with
within the scope of their work, which are nevertheless important to include in follow-up work on that matter.&lt;/p&gt;

&lt;p&gt;First, users can be described through a set of sensitive attributes and not only one. Even though the analysis of the
sensitive attributes as their own provides the recognition on the most discriminated ones, the group-fairness should be
extended by a set of sensitive attributes for additional insight.&lt;/p&gt;

&lt;p&gt;Second, another popular task with RecLLMs are sequential recommendations. Since LLMs provide the power of iteratively 
refining their outputs based on user interactions, the question is on how the benchmarking method by Zhang et al. can
be transferred to this task. Since it is way more complex in the data format, as in recommendation representation,
sequential representation, and data load, it might require a different benchmarking method to bve developed. Considering
the popularity and customization of this task, sequential recommendations in LLMs, when containing bias, could run into 
the danger of reinforcing the bias and unfairness (Shu et al.). Zhang et al. have not made a statement on a 
benchmarking approach in that regard since the publication of this paper.&lt;/p&gt;

&lt;p&gt;Lastly, the authors have introduced three similarity scores which are all used in order to probe a model for fairness.
Yet, for the overall and robustness analysis, only the Jaccard similarity was referenced. Within the second part of the
work, the other metrics, SERP* and PRAG* were not mention anymore. Even though their differences were explained
during their mathematical definition, it is still questionable which of those metrics should be used for a proper 
indicator in which scenarios and why the consideration of all of them are significant. In regard to the performed 
analysis by Zhang et al., it would have sufficed to solely compute the SNSR and SNSV score based on the Jaccard similarity
only. One therefore wonders: so why needing to do all the work in computing the similarities with the other two metrics?&lt;/p&gt;

&lt;h2 id=&quot;4-conclusion&quot;&gt;4. Conclusion&lt;/h2&gt;

&lt;p&gt;All in all the work of Zhang et al. is a crucial milestone in the context of fairness probing for RecLLMs. FaiRLLM 
is a solid benchmarking tool in order to probe for RecLLM fairness and compare existing LLMs against each other.
Even though minor gaps have been detected during this paper review, those are issues that can be easily extended with
a rework on the analysis part of the paper. The curves of the plotted results look promising, so that an extension of
the attribute values might not affect the overall result of the paper.
While FaiRLLM has not yet been applied except for ChatGPT within the context of the authorâ€™s work, it represents a
promising start to create an incentive for mitigating discrimination in LLMs. Even though itâ€™s downside requires 
computational effort, the gained insights by using FaiRLLM represent a solid foundation to improve user experience and
do not only leverage the development of recommender-based LLMs, but also LLMs themselves. &lt;br /&gt;
For LLM-developers, using FaiRLLM can become a key performance indicator in development improvements and for users a
decisive factor on which LLM to use. Since developing methods to mitigate unfairness in LLMs is a research area in 
itself, FaiRLLM is a helpful metric to design such a method using a standardized benchmarking metric, which can then
be compared against others easily.
The open questions defined during this paper review are future work topics that are to be further defined. Especially
the inclusion of sequential recommendation benchmarking can set another new milestone in this area. Even though Zhang et
al. have stated to work on benchmarking other LLMs and developing methods to mitigate discrimination, it would be
exciting to see them pioneering in developing a benchmarking for framework for sequential recommendations with user-item
interactions.&lt;/p&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;

&lt;h3 id=&quot;a-mathemtiacal-definition-of-the-similarity-and-fairness-metrices&quot;&gt;A) Mathemtiacal Definition of the Similarity and Fairness Metrices&lt;/h3&gt;
&lt;p&gt;Due to the limitations in writing for mathematical expressions in Markdown, the mathematical representations of the
deefined metrics by Zhang et al. are added as excerpts from the original paper.&lt;/p&gt;

&lt;p&gt;For the metrics, the following mathematical notations are to be considered:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_7.png&quot; alt=&quot;img_7.png&quot; /&gt; is the set of neutral instructions&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_5.png&quot; alt=&quot;img_5.png&quot; /&gt; is the set of top-k recommendations for a neutral instruction &lt;img src=&quot;img_6.png&quot; alt=&quot;img_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_8.png&quot; alt=&quot;img_8.png&quot; /&gt; denotes a sensitive attribute where ğ‘ is a specific value of the attribute. ğ‘ is a word or a
phrase.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_17.png&quot; alt=&quot;img_17.png&quot; /&gt; denotes the number of all possible values in a studied attribute&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_9.png&quot; alt=&quot;img_9.png&quot; /&gt; is a set of sensitive instructions for each value of attribute &lt;img src=&quot;img_10.png&quot; alt=&quot;img_10.png&quot; /&gt; by injecting the value ğ‘&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_12.png&quot; alt=&quot;img_12.png&quot; /&gt; is the recommendation list for a sensitive attribute &lt;img src=&quot;img_10.png&quot; alt=&quot;img_10.png&quot; /&gt; and the value ğ‘&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_13.png&quot; alt=&quot;img_13.png&quot; /&gt; computes the similarity between &lt;img src=&quot;img_14.png&quot; alt=&quot;img_14.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_15.png&quot; alt=&quot;img_15.png&quot; /&gt; is the aggregated similarity value across all M instructions&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_16.png&quot; alt=&quot;img_16.png&quot; /&gt; is the level of unfairness in RecLLM as the divergence of these aggregated similarities 
across different values of the sensitive attribute&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_21.png&quot; alt=&quot;img_21.png&quot; /&gt; denotes the number of common items between the two recommendation lists&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ğ‘£&lt;/strong&gt; represents an item in a sensitive recommendation list&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_24.png&quot; alt=&quot;img_24.png&quot; /&gt; represents the rank of the item ğ‘£&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_25.png&quot; alt=&quot;img_25.png&quot; /&gt; is 1 if ğ‘£ is in the neutral recommendation list, else 0&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_27.png&quot; alt=&quot;img_27.png&quot; /&gt; denote two different recommended items in the sensitive recommendation list&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img_28.png&quot; alt=&quot;img_28.png&quot; /&gt; or &lt;img src=&quot;img_29.png&quot; alt=&quot;img_29.png&quot; /&gt; is the rank in the recommendation list &lt;img src=&quot;img_30.png&quot; alt=&quot;img_30.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SNSR&lt;/strong&gt;
&lt;img src=&quot;img_19.png&quot; alt=&quot;img_19.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SNSV&lt;/strong&gt;  &lt;br /&gt;
&lt;img src=&quot;img_18.png&quot; alt=&quot;img_18.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Jaccard&lt;/strong&gt; &lt;br /&gt;
&lt;img src=&quot;img_20.png&quot; alt=&quot;img_20.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SEREP&lt;/strong&gt;*  &lt;br /&gt;
&lt;img src=&quot;img_22.png&quot; alt=&quot;img_22.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PRAG&lt;/strong&gt;*
&lt;img src=&quot;img_26.png&quot; alt=&quot;img_26.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;sources&quot;&gt;Sources&lt;/h2&gt;

&lt;p&gt;Asia J. Biega, Krishna P. Gummadi, and Gerhard Weikum. 2018. Equity of
Attention: Amortizing Individual Fairness in Rankings. In SIGIR â€™18: The
41st International ACM SIGIR Conference on Research and Development in
Information Retrieval, July 8â€“12, 2018, Ann Arbor, MI, USA. ACM, New York,
NY, USA, 10 pages. https://doi.org/10.1145/3209978.3210063&lt;/p&gt;

&lt;p&gt;Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023.
Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. arXiv preprint
arXiv:2305.07609.&lt;/p&gt;

&lt;p&gt;Jevons, W. S. 1958. Principles of Science. Daedalus, 87(4), 148-154.&lt;/p&gt;

&lt;p&gt;Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Zhen Wen, Fei Wang, Xiangyu Zhao, 
Jiliang Tang, and Qing Li. 2023. Recommender Systems in the Era of Large Language Models (LLMs). arXiv.
https://arxiv.org/pdf/2307.02046.pdf&lt;/p&gt;

&lt;p&gt;Wenyue Hua, Yingqiang Ge, Shuyuan Xu, Jianchao Ji, and Yongfeng Zhang. 2023.
UP5: Unbiased Foundation Model for Fairness-aware Recommendation. arXiv. https://arxiv.org/abs/2305.12090&lt;/p&gt;

&lt;p&gt;Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, Ning Gu. 2023. 
RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models.
arXiv. https://doi.org/10.48550/arXiv.2308.09904&lt;/p&gt;

&lt;p&gt;Yunqi Li, Hanxiong Chen, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2021. 
User-oriented Fairness in Recommendation. In Proceedings of the Web Conference 2021 (WWW â€™21), 
April 19â€“23, 2021, Ljubljana, Slovenia. ACM, New York, NY, USA, 9 pages. 
https://doi.org/10.1145/3442381.3449866&lt;/p&gt;

</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/Is_ChatGPT_Fair_For_Recommendation_Evaluating_Fairness_in_Large_Language_Model_Recommendation.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/Is_ChatGPT_Fair_For_Recommendation_Evaluating_Fairness_in_Large_Language_Model_Recommendation.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[CIKM 2022] Temporal and Heterogeneous Graph Neural Network for Financial Time Series Prediction</title>
            <description>&lt;h1 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;ì£¼ì‹ì˜ ê°€ê²© ì›€ì§ì„ì€ ë‹¤ì–‘í•œ ì¸¡ë©´ì— ì˜í•´ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ê³  ì•Œë ¤ì ¸ ìˆë‹¤. ì„ í–‰ ì—°êµ¬ì—ì„œëŠ” ê°€ê²© ì›€ì§ì„ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ê¸°ìˆ ì  ì§€í‘œ, factor, ì¬ë¬´ìƒíƒœ, ë‰´ìŠ¤, sns ë“±ì„ inputìœ¼ë¡œ êµ¬ì„±í•˜ì˜€ë‹¤. ì£¼ì‹ì‹œì¥ì˜ ì‹œê·¸ë„ì„ stock fundamentalê³¼ ê¸°ìˆ ì  ì§€í‘œë¥¼ ì‚¬ìš©í•´ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ê±°ë‚˜ ë‰´ìŠ¤ ê¸°ì‚¬ì™€ ê´€ë ¨ëœ ê¸°ì—… ê°„ì˜ ì—°ê²°ê³ ë¦¬ë¥¼ êµ¬ì¶•í•˜ì—¬ ì£¼ê°€ ì›€ì§ì„ì„ ì˜ˆì¸¡í•˜ëŠ” ë“± ì„ í–‰ ì—°êµ¬ì—ì„œëŠ” LSTMê³¼ GRU ë“±ì„ í™œìš©í•˜ì—¬ ê³¼ê±° ì •ë³´ë¥¼ í•™ìŠµí•˜ê³  ì´ë¥¼ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì˜ˆì¸¡ ì‘ì—…ì— í™œìš©í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ ê¸°ì¡´ í•™ìŠµ ë°©ë²•ì€ ê° ì£¼ì‹ì˜ ì‹œê³„ì—´ ì •ë³´ë¥¼ ë…ë¦½ì ì´ê³  ë™ì¼í•˜ê²Œ ë¶„í¬ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼í•˜ê³  ê° ë¶„ì„ì„ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰í•œë‹¤. ì´ëŸ¬í•œ ê³¼ì •ì€ ê° ì£¼ì‹ ê°„ì˜ ë‚´ë¶€ê´€ê³„ë¥¼ ë¬´ì‹œí•  ë°–ì— ì—†ëŠ” ê²°ê³¼ë¥¼ ë‚´ê³  ì´ëŠ” í•„ì—°ì ìœ¼ë¡œ ìµœì ì˜ ì„±ëŠ¥ì„ ë‚´ì§€ ëª»í•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•œë‹¤.&lt;/p&gt;

&lt;h1 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;ì£¼ì‹ì˜ ê°€ê²© ë³€ë™ì€ ê·¸ ìì²´ì˜ ê³¼ê±° ê°€ê²©ê³¼ ê´€ë ¨ì´ ìˆì„ ë¿ë§Œ ì•„ë‹ˆë¼ ê³µê¸‰ì—…ì²´, ê³ ê°, ì£¼ì£¼, íˆ¬ìì, ì—°ê²°ëœ ê¸°ì—… ë“±ê³¼ë„ ê´€ë ¨ì´ ìˆë‹¤. ì´ëŸ¬í•œ ê´€ê³„ë¥¼ ì €ì¥í•˜ê³  í‘œí˜„í•˜ê¸° ìœ„í•´ knowledge graphë¥¼ í™œìš©í•˜ì˜€ê³  ìµœê·¼ì—ëŠ” ê·¸ë˜í”„ êµ¬ì¡°ì˜ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆëŠ” GNNì´ ë°©ë²•ë¡ ìœ¼ë¡œ ì œì‹œë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ê¸°ì¡´ì˜ ë°©ì‹ëŒ€ë¡œ êµ¬ì¶•ëœ ê·¸ë˜í”„ëŠ” ìˆ˜ì‘ì—…ìœ¼ë¡œ ë§Œë“  ë¼ë²¨ë§ê³¼ NLPë¥¼ í™œìš©í•˜ì˜€ê³  ì´ëŠ” ê¸°ì—…ê°„ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ê¸°ì— ì œí•œë˜ë©° ë§ì€ ë¦¬ì†ŒìŠ¤ ë¼ë²¨ë§ê³¼ ë‚®ì€ ì •í™•ë„ê°€ ë‚®ì€ ì–´ë ¤ì›€ì´ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì‹¤ì œ ê¸°ì—… ê´€ê³„ëŠ” ì‹œê°„ì— ë”°ë¼ ìœ ë™ì ìœ¼ë¡œ ë³€í™”í•œë‹¤. ë˜í•œ ê¸°ì—…ê°„ì˜ ê´€ê³„ëŠ” heterogenousí•˜ì—¬ ê¸°ì—… ê°„ì˜ ê´€ê³„ ìœ í˜•ì€ ë‹¤ì–‘í•˜ê²Œ ë‚˜íƒ€ë‚œë‹¤. ë”°ë¼ì„œ ê¸°ì¡´ ë°©ë²•ìœ¼ë¡œëŠ” ì‹¤ì œë¡œ ê¸°ì—… ê´€ê³„ ê·¸ë˜í”„ì˜ ëª¨ë“  ì •ë³´ë¥¼ í‘œí˜„í•  ìˆ˜ ì—†ë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‹¤ì œ ì£¼ì‹ê°€ê²© ì‹œí€€ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ relation graphë¥¼ êµ¬ì„±í•˜ê³  sequential featuresì™€ relational featuresë¥¼ í•¨ê»˜ í•™ìŠµí•˜ì—¬ ì£¼ê°€ë¥¼ ì˜ˆì¸¡ì„ í•˜ëŠ” temporal and heterogenous graph neural network(THGNN) ë°©ë²•ë¡ ì„ ì œì‹œí•œë‹¤.&lt;/p&gt;

&lt;h1 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://github.com/hynacin121/ML_Paper_Review/blob/main/img/3MethodAlgorithm.png?raw=true&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;THGNNëª¨ë¸ì€ historical price sequenceë¥¼ inputìœ¼ë¡œ ë°›ê³  probability of stock movementë¥¼ outputìœ¼ë¡œ í•œë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;a-stock-correlation-graph-generation&quot;&gt;&lt;strong&gt;(a) Stock Correlation Graph Generation&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;ëª¨ë¸ì˜ ì²« íŒŒíŠ¸ëŠ” ì£¼ì‹ê°„ì˜ ìƒê´€ê´€ê³„ ê·¸ë˜í”„ë¥¼ ìƒì„± í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ ê° ê±°ë˜ì¼ì˜ ì£¼ì‹ê°„ì˜ ë™ì ê´€ê³„ë¥¼ êµ¬ì¶•í•œë‹¤. ì£¼ì‹ê°„ì˜ ìƒê´€ê´€ê³„ëŠ” ê° ì£¼ì‹ì˜ ê³¼ê±° ì£¼ì‹ë°ì´í„°ë¥¼ í™œìš©í•´ ìƒê´€í–‰ë ¬ì„ ê³„ì‚°í•˜ê³ , í–‰ë ¬ì˜ ê° ìš”ì†Œ ê°’ì— ë”°ë¼ ê¸°ì—…ê°„ì˜ ê´€ê³„ë¥¼ ê²°ì •í•œë‹¤.&lt;/p&gt;

&lt;p&gt;ê¸°ì—…ê°„ì˜ ê´€ê³„ëŠ” postiveì™€ negative ë‘ ê°€ì§€ë¡œ ë¶„ë¥˜í•œë‹¤. ì´ë•Œ ê·¸ë˜í”„ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ correlationì˜ ì ˆëŒ“ê°’ì´ thresholdë³´ë‹¤ í° ê°’ë§Œ í™œìš©í•˜ê³ , correlation &amp;gt; threshold ì¼ ë•Œ positive, correlation &amp;lt; threshold ì¼ ë•Œ negativeë¡œ ì •ì˜í•œë‹¤. ê·¸ë˜í”„ì˜ edgeëŠ” ì•ì„œ ì„¤ëª…í•œ relationìœ¼ë¡œ ìƒì„±ë˜ê³ , ê° íšŒì‚¬ê°„ì˜ heterogenous graphë¥¼ ì•ì„œ ì„¤ëª…í•œ ë‘ê°œì˜ ê´€ê³„ë¡œ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•œë‹¤. $G = (V, (E_ {r_1}, E_ {r_2}, \dots) \ \; r \in (pos, neg)$.&lt;/p&gt;

&lt;p&gt;íšŒì‚¬ê°„ì˜ ê´€ê³„ëŠ” ë™ì ê´€ê³„ì´ë¯€ë¡œ, ê¸°ì—…ê°„ì˜ ê´€ê³„ ê·¸ë˜í”„ë¥¼ temporal formatìœ¼ë¡œ ìƒì„±í•˜ì˜€ë‹¤. T ê±°ë˜ì¼ì˜ ê·¸ë˜í”„ëŠ” $ \tilde{G} = (\tilde{V}, (\tilde{E}_ {pos},\tilde{E}_ {neg} ))$ë¡œ í‘œê¸°í•œë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;b-historical-price-encoding&quot;&gt;&lt;strong&gt;(b) Historical Price Encoding&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Inputì¸ të²ˆì§¸ ê±°ë˜ì¼ì˜ price sequenceëŠ” $X^t \in \mathbb{R}^{n \times T \times d_ {feat}}$ ìœ¼ë¡œ ì •ì˜í•œë‹¤. TëŠ” të²ˆì§¸ ê±°ë˜ì¼ ì´ì „ì˜ ê±°ë˜ì¼ ìˆ«ìë¥¼ ì˜ë¯¸í•˜ê³ , $d_ {feat}$ ì€ ê³¼ê±° ì£¼ì‹ê°€ê²©ì˜ dimensionì„ ì˜ë¯¸í•œë‹¤. $X^t$ëŠ” linear transformationê³¼ positional encoding ê³¼ì •ì„ ê±°ì¹œë‹¤.&lt;/p&gt;

&lt;p&gt;$\hat{H}^t = W_ {in}X^t + b_ {in}$&lt;br /&gt;
$H^t = \hat{H}^t + PE$&lt;/p&gt;

&lt;p&gt;$PE(p,2i) = \sin(p/10000^{2i/d_ {in}})$&lt;br /&gt;
$PE(p,2i +  1) = \cos(p/10000^{2i/d_ {in}})$&lt;/p&gt;

&lt;p&gt;ìœ„ ì‹ì—ì„œ pëŠ” ê±°ë˜ì¼ì˜ ì˜ë¯¸í•˜ê³ , iëŠ” dimension, ê·¸ë¦¬ê³  $d_ {in}$ì€ input featureì˜ dimensionì„ ì˜ë¯¸í•˜ê³  $W_ {in} \in \mathbb{R}^{d_ {feat} \times d_ {in}}$ê³¼ $b_ {in} \in \mathbb{R}^{d_ {in}}$ì€ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë‹¤.&lt;/p&gt;

&lt;p&gt;$Q_i^t =H^tW_i^Q, \; K_i^t = H^tW_i^K, V_i^t = H^tW_i^V$&lt;br /&gt;
$Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_ {in}}})V$&lt;br /&gt;
$EncHead_i^t = Attention(Q_i^t, K_i^t, V_i^t)$&lt;br /&gt;
$H^t_ {enc} = Concat(EncHead_1^t, \dots, EncHead^t_ {h_ {enc}})W_o$&lt;/p&gt;

&lt;p&gt;ì•ì„œ Linear transformationê³¼ PE ê³¼ì •ì„ ê±°ì¹œ í›„, Multi-head attentional transformerë¥¼ í™œìš©í•˜ì—¬ ì£¼ì‹ì˜ ê° input featureë¥¼ ì¸ì½”ë”©í•œë‹¤. $H^t$ë¥¼ ê°ê° $W_ i^Q \in \mathbb{R}^{d_ {in} \times d_ {hidden}}, W_ i^K \in \mathbb{R}^{d_ {in} \times d_ {hidden}}, W_ i^V \in \mathbb{R}^{d_ {in} \times d_ {hidden}}$ì™€ ê³±í•˜ì—¬ Q(Query), K(Key), V(Value)ë¥¼ ê³„ì‚°í•œ í›„ softmaxí•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ $EncHead_i^T$ë¥¼ êµ¬í•œë‹¤. concatì€ Encoder headë“¤ì„ concatenationí•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. $W_o \in \mathbb{R}^{h_ {enc}d_v \times d_ {enc}} $ëŠ” output projection matrixë¡œ concatenated matrixì— ê³±í•˜ì—¬ inputìœ¼ë¡œ ë“¤ì–´ì˜¬ ë•Œì˜ ì‚¬ì´ì¦ˆì™€ ë™ì¼í•˜ê²Œ ìœ ì§€ë˜ê²Œ í•œë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;c-temporal-graph-attention-mechanism&quot;&gt;&lt;strong&gt;(c) Temporal Graph Attention Mechanism&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Historical Price Encodingì˜ outputì¸ $H^t_ {enc}$ì™€ Temporal relation Graphì¸ $\tilde{G}$ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ì¸ temporal attention mechanismì„ ì§„í–‰í•œë‹¤. $H^t_ {enc}$ì˜ ëª¨ë“  ë…¸ë“œë¥¼ 1ì°¨ì›ìœ¼ë¡œ flattení•˜ê³  2ë‹¨ê³„ì˜ temporal attention mechanismì„ í™œìš©í•œë‹¤. ê°ê°ì˜ relationshipì¸ $r \in (pos, neg)$ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ ì—°ì‚°ì„ ì§„í–‰í•œë‹¤.&lt;/p&gt;

&lt;p&gt;$\alpha^i_ {u^t, v^t} = \frac{exp(LeakyReLU(a^T_ {r,i}[h_ {u_t}  \vert h_ {v_t}]))}{\sum_ {k^t \in N_ r(v^t)}exp(LeakyReLU(a^T_ {r,i}[h_ {k^t}  \vert h_ {v_t}]))}$&lt;/p&gt;

&lt;p&gt;$h_ {u_t}$ëŠ” $H_ {enc}^t$ì˜ $u_t$ë²ˆì§¸ ì—´ì„ ì˜ë¯¸í•˜ê³ , $a_ {r,i}  \in \mathbb{R}^{2Td_ {enc}}$ëŠ” ië²ˆì§¸ headì˜ rë²ˆì§¸ relationì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ë²¡í„°ë¥¼ ì˜ë¯¸í•œë‹¤. $\alpha^i_ {u_t, v_t}$ëŠ” ë…¸ë“œ$u_t$ì— ëŒ€í•œ ë…¸ë“œ$v_t$ì˜ ì¤‘ìš”ë„ë¥¼ ì˜ë¯¸í•œë‹¤. LeakyReLU activationì„ í™œìš©í•˜ì—¬ ê³„ì‚°ëœ Normalized Attention ScoreëŠ” ì•„ë˜ì™€ ê°™ì´ ië²ˆì§¸ ë…¸ë“œì˜ neighbor importanceë¥¼ ê²°ì •í•˜ì—¬ input ë°ì´í„°ë¥¼ ì¬ì •ì˜ í•œë‹¤.&lt;/p&gt;

&lt;p&gt;$TgaHead_i = \sum_ {v^t \in \tilde{V}}  \sigma(\sum_ {u^t \in N_ r(v^t)}\alpha^i_ {u^t, v^t}h_ {u^t})&lt;br /&gt;
H^t_r = Concat(TgaHead_1, \dots, TgaHead_ {h_ {tga}})W_ {o,r}$&lt;/p&gt;

&lt;p&gt;$\sigma$ ëŠ” activate functionìœ¼ë¡œ sigmoidí•¨ìˆ˜ë¥¼ í™œìš©í•œë‹¤. $W_ {o,r}  \in \mathbb{R}^{h_ {tga}Td_ {enc}  \times d_ {att}}$ ëŠ” output projection matrixë¥¼ ì˜ë¯¸í•œë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;d-heterogeneous-graph-attention-mechanism&quot;&gt;&lt;strong&gt;(d) Heterogeneous Graph Attention Mechanism&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;ì•„í‚¤í…ì³ë¥¼ ì„¤ëª…í•˜ê¸°ì— ì•ì„œ Heterogeneous Graphì— ëŒ€í•´ ì„¤ëª…í•˜ìë©´,  ê¸°ì¡´ Graph(Homogeneous Graph)ì˜ ê²½ìš° nodeì™€ edgeì˜ ì¢…ë¥˜ëŠ” í•œ ê°€ì§€ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.  ë°˜ë©´ì— Heterogeneous Graphì˜ ê²½ìš° nodeì™€ edgeì˜ ì¢…ë¥˜ê°€ ì—¬ëŸ¬ê°€ì§€ì¸ ê·¸ë˜í”„ë¥¼ ì˜ë¯¸í•œë‹¤. ì¦‰ Heterogenous GrapëŠ” nodeì˜ ì¢…ë¥˜ëŠ” ê°™ì§€ë§Œ ë‹¤ì–‘í•œ ê´€ê³„ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆê³ , ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ Nodeë¡œ ì´ì›ƒì„ ë‹¤ì–‘í•˜ê²Œ ì •ì˜ í•  ìˆ˜ë„ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì•ì„  ê³¼ì •ì„ í†µí•´ 3ê°œì˜ ì¢…ë¥˜ì˜ ì„ë² ë”©($H^t_ {self}, H^t_ {pos}, H^t_ {neg}$)ì„ ì •ì˜ í•˜ì˜€ë‹¤. $H^t_ {self} = W_ {self}H^t_ {enc}  + b_ {self}$ë¡œ $H^t_ {self}$ë¡œ ë¶€í„° ë„ì¶œë˜ì—ˆê³ , $H^t_ {pos}, H^t_ {neg}$ëŠ” ì•ì„  Temporal Graph Attention Mechanismì„ í†µí•´ ë„ì¶œë˜ì—ˆë‹¤. $(\beta_ {self}, \beta_ {pos}, \beta_ {neg})$ ëŠ” 3ê°œì˜ ì„ë² ë”©ì„ inputìœ¼ë¡œ í•˜ì—¬ ì•„ë˜ì™€ ê°™ì€ ê³¼ì •ì„ í†µí•´ ê³„ì‚°ëœë‹¤.&lt;/p&gt;

&lt;p&gt;$w_r = \frac{1}{\vert \tilde{V}  \vert}  \sum_ {v^t \in \tilde{V}}q^T \tanh(Wh_ {v^t,r}+b)$&lt;br /&gt;
$\beta_r = \frac{exp(w_r)}{\sum_ {r \in (self, pos, neg)}exp(w_r)}$&lt;br /&gt;
$Z^t = \sum_ {r \in (self, pos, neg)}  \beta_r \cdot H^t_r$&lt;/p&gt;

&lt;p&gt;3ê°œì˜ ì„ë² ë”©ì„ MLPë¥¼ í†µí•´ ê°ê° transformí•˜ê³  heterogeneous attention vectorì¸ &lt;strong&gt;q&lt;/strong&gt; ë¥¼ ê³±í•œ í›„ í‰ê· ì„ êµ¬í•´ $w_r$ ë¥¼ ê³„ì‚°í•˜ì˜€ë‹¤. $w_r$ ì„ í™œìš©í•˜ì—¬ 3ê°€ì§€ ê´€ê³„ì˜ ê°€ì¤‘ì¹˜ì¸ ($\beta_r$)ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ê°€ì¤‘ì¹˜ì¸ $\beta_r$ ì„ í™œìš©í•˜ì—¬ ìµœì¢… ì„ë² ë”©ì¸ $Z_t$ ë¥¼ êµ¬í•œë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;e-optimzation-objectives&quot;&gt;&lt;strong&gt;(e) Optimzation Objectives&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;ëª©ì í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ í†µí•´ ê³„ì‚°ëœë‹¤. ìƒìœ„ 100ê°œì™€ í•˜ìœ„ 100ê°œì— ì†í•˜ëŠ” 200ê°œì˜ ì£¼ì‹ì„ ì„ íƒí•˜ê³  í•´ë‹¹ ë…¸ë“œì— ê°ê° 1ê³¼ 0ìœ¼ë¡œ ë ˆì´ë¸”ì„ ì§€ì •í•œë‹¤. ê·¸ í›„ë¡œ í•œ ê³„ì¸µì˜ MLPë¥¼ ë¶„ë¥˜ê¸°ë¡œ ì‚¬ìš©í•˜ì—¬ ë¼ë²¨ë§ëœ ë…¸ë“œì˜ ë¶„ë¥˜ê²°ê³¼ë¥¼ ì–»ëŠ”ë‹¤. Binary cross-entropyë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ëª©ì í•¨ìˆ˜ Lì„ êµ¬í•  ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;$\hat{Y}_ l = \sigma(WZ^t_ l + b)$&lt;br /&gt;
$\mathcal L = \sum_ {l \in \mathcal Y_ t}[Y^t_ l \log(\hat{Y}_ l)  +  (1- Y_ l^t)log(1-  \hat{Y}_ l)]$&lt;/p&gt;

&lt;p&gt;$Y_l^t, Z_l^t$ëŠ” ë¼ë²¨ë§ëœ ë…¸ë“œ $l$ì˜ ì„ë² ë”©ê³¼ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ê°’ì„ ì˜ë¯¸í•œë‹¤. ê³„ì‚°ì„ ìœ„í•´ Adam Optimizerë¥¼ í™œìš©í•œë‹¤.&lt;/p&gt;

&lt;h1 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;experimental-settings&quot;&gt;&lt;strong&gt;Experimental Settings&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;dataset&quot;&gt;&lt;strong&gt;Dataset&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;SP500ê³¼ CSI300ì˜ 2016ë…„ë¶€í„° 2021ë…„ê¹Œì§€ì˜ ì£¼ì‹ë°ì´í„°ë¥¼ í™œìš©í•˜ì˜€ë‹¤. ê¸°ì—…ê°„ì˜ ê´€ê³„ ê·¸ë˜í”„ ë¥¼ êµ¬ì„±í•˜ê¸° ìœ„í•´ í™œìš©ëœ correlation matrixì˜ ê²½ìš°, ê¸°ì¤€ì¼ë¡œ ë¶€í„° 20 ê±°ë˜ì¼ ì „ê¹Œì§€ì˜ ì£¼ê°€ë¥¼ í™œìš©í•˜ì—¬ ê³„ì‚°í•˜ì˜€ë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;parameter-settings&quot;&gt;&lt;strong&gt;Parameter Settings&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;$\tilde{G}$ì˜ ê²½ìš° 20 ê±°ë˜ì¼ë™ì•ˆì˜ ê¸°ì—…ê°„ì˜ ê´€ê³„ë¥¼ ë‹´ê³  ìˆë‹¤. $d_ {feat}$ì€ 6ê°œì˜ encoding layerë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , $d_ {in}$ê³¼ $d_ {enc}$ëŠ” ëª¨ë‘ 128ê°œì˜ encoding layerë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. Attention functionì—ì„œ í™œìš©ëœ $d_ {hidden}$ì˜ ê²½ìš° 512ê°œì˜ layer, $d_ {v}$ëŠ” 128ê°œ $h_ {enc}$ëŠ” 8ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. Temporal graph attention layerì—ì„œëŠ” $d_ {att}$ì€ 256ê°œ, $h_ {tga}$ëŠ” 4ê°œ, ê·¸ë¦¬ê³  heterogeneous graph attention layerì˜ $d_q$ëŠ” 256ê°œì˜ encoding layerë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;compared-baselines&quot;&gt;&lt;strong&gt;Compared Baselines&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Non-graph-based approachì¸ LSTM, GRU, Transformer, eLSTMê³¼ Graph-based approachì¸ LSTM-GCN, LSTM-RGCN, TGC, MAN-SF, HATS, REST, AD-GATê°€ ë¹„êµêµ°ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;evaluating-metrics&quot;&gt;&lt;strong&gt;Evaluating Metrics&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;ACC(prediction accuracy, ì˜ˆì¸¡ì •í™•ë„), ARR(annual return rate, ì—°ê°„ ìˆ˜ìµë¥ ), AV(annual volatility, ì—°ê°„ ë³€ë™ì„±), MDD(Maximum DrawDown), ASR(Annual Sharpe Ratio, $ARR/AV$), CR(Calmar Ratio, $ARR/\vert MDD \vert$), IR(Information Ratio) ì´ 7ê°€ì§€ì˜ ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¤€ì„ ê³¼ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê¸°ë¡í•œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;financial-prediction&quot;&gt;&lt;strong&gt;Financial Prediction&lt;/strong&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://github.com/hynacin121/ML_Paper_Review/blob/main/img/4ResultTable.png?raw=true&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;ë…¼ë¬¸ì—ì„œ í™œìš©ëœ ëª¨ë¸ì¸ THGNNì˜ ê²½ìš° ëª¨ë“  í‰ê°€ì§€í‘œì—ì„œ ëŒ€ë¶€ë¶„ì˜ Baselineë³´ë‹¤ ìš°ìˆ˜í•œ ì§€í‘œë¥¼ ë³´ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ë¥¼ í†µí•´ ê¸ˆìœµ ì‹œê³„ì—´ ì˜ˆì¸¡ì—ì„œ THGNNì˜ ìš°ìˆ˜ì„±ì„ ì…ì¦í•˜ì˜€ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;ablation-study&quot;&gt;&lt;strong&gt;Ablation Study&lt;/strong&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://github.com/hynacin121/ML_Paper_Review/blob/main/img/4AblationTable.png?raw=true&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Ablation StudyëŠ” 3ì—ì„œ ì§„í–‰ëœ ê° ì„¹ì…˜ë“¤ì„ í•˜ë‚˜ì”© ì œê±°í•´ë³´ë©° ì„±ëŠ¥ì„ í‰ê°€í•˜ì˜€ë‹¤. ìœ„ì—ì„œë¶€í„° ê°ê° Historical Price Encoding, Temporal Graph Attention, Heterogeneous Graph attentionì„ ì œê±°í•˜ì˜€ë‹¤. ëª¨ë“  í‰ê°€ì§€í‘œì—ì„œ ì–´ë– í•œ ê³¼ì •ë„ ì œê±°í•˜ì§€ ì•Šì•˜ì„ ë•Œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì˜´ì„ ì•Œ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;interpretability-of-graph-neural-network&quot;&gt;&lt;strong&gt;Interpretability of Graph Neural Network&lt;/strong&gt;&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://github.com/hynacin121/ML_Paper_Review/blob/main/img/4GraphAttention.png?raw=true&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;ëª¨ë¸ì˜ í•´ì„ê°€ëŠ¥ì„±ì„ ì‚´í´ë³´ê¸° ìœ„í•´ ëª¨ë¸ ì˜ˆì¸¡ê³¼ì •ì—ì„œ ê·¸ë˜í”„ì˜ ê´€ì‹¬ê°€ì¤‘ì¹˜ë¥¼ ì¶”ì¶œí•˜ì˜€ë‹¤. Relational graphì˜ ë©”ì‹œì§€ ì „ë‹¬ê³¼ì •ì—ì„œ ëª¨ë“  ë…¸ë“œì— ëŒ€í•œ attention weightë¥¼ ê³„ì‚°í•˜ì—¬ ê°ê°ì˜ ì¼ì¼ ìˆ˜ìµë¥ ê³¼ node degreesì— ë”°ë¼ attention weightì˜ í‰ê· ì„ êµ¬í•˜ê³  ì‹œê°í™” í•˜ì˜€ë‹¤. Pos relationshipì˜ ê²½ìš°, ë…¸ë“œì˜ degreeê°€ ë†’ì„ ê²½ìš° attention weightê°€ ë†’ìŒì„ ë³´ì—¬ì¤€ë‹¤. ì¦‰ ì´ì›ƒì´ ë§ì€ ë…¸ë“œê°€ ì£¼ë³€ì— ë” ë§ì€ ë©”ì‹œì§€ë¥¼ ê¸°ì—¬í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ë˜í•œ ì¼ì¼ ìˆ˜ìµë¥  ë³€ë™ì´ í° ê¸°ì—…ì˜ attention weightê°€ ë†’ìŒì„ ë³´ì˜€ë‹¤. ì´ëŠ” ê°€ê²© ë³€ë™ì„±ì´ í´ìˆ˜ë¡ ì£¼ë³€ì— ë” ë§ì€ ì •ë³´ë¥¼ ì œê³µí•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ë©°, ê°€ê²©ë³€ë™ì´ momentum spillover effectë¥¼ ì¼ìœ¼í‚¨ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë°˜ë©´ Neg relationshipëŠ”, ë°˜ëŒ€ë¡œ degreeê°€ ë‚®ì€ ë…¸ë“œì—ì„œ ë†’ì€ attention weightë¥¼ ë³´ì¸ë‹¤.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://github.com/hynacin121/ML_Paper_Review/blob/main/img/4ACC.png?raw=true&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;ì´ëŠ” ì•ì„  ê²°ê³¼ì— ë” ë‚˜ì•„ê°€ ê° relationì˜ attention weightsë¥¼ ì‹œê°í™”í•˜ì—¬ í•˜ë‚˜ì˜ relationë§Œ ì‚¬ìš©í–ˆì„ ë•Œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤. ê¸°ì¡´ê³¼ ê°™ì´ 2ê°œì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ í•™ìŠµì‹œí‚¤ê³  í•˜ë‚˜ì˜ relationshipì˜ ë©”ì‹œì§€ë¥¼ inputìœ¼ë¡œ í™œìš©í•˜ì—¬ ìœ„ì™€ ê°™ì€ ê²°ê³¼ë¥¼ ë³´ì˜€ë‹¤. selfì™€ posê°€ negë³´ë‹¤ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ìš°ìˆ˜í•¨ì„ ë³´ì˜€ë‹¤. ë˜í•œ pos ë©”ì‹œì§€ì˜ ë¦¬ì†ŒìŠ¤ê°€ ì˜ˆì¸¡ ëª¨ë¸ì— ëŒ€í•œ ê¸°ì—¬ë„ê°€ ë†’ìŒì„ ë³¼ ìˆ˜ ìˆë‹¤. ê·¸ ì´ìœ ëŠ” ë¹„ìŠ·í•œ ê°€ê²© ì›€ì§ì„ì„ ë³´ì´ëŠ” ê¸°ì—…ê°„ì˜ ì˜í–¥ë ¥ì´ í–¥í›„ ê°€ê²© ì›€ì§ì„ì„ ì˜ˆì¸¡í•˜ëŠ”ë° ìƒëŒ€ì ìœ¼ë¡œ ìœ ìš©í•˜ê¸° ë•Œë¬¸ì´ë‹¤. Temporal graph attention layerê°€ ê° ë…¸ë“œì™€ ê°€ì¤‘ì¹˜ ê°„ì˜ ì°¨ì´ë¥¼ ì ì ˆíˆ ë³´ì—¬ì£¼ê³ , Heterogeneous graph attentionì€ ê° ë©”ì‹œì§€ì˜ ê¸°ì—¬ë„ë¥¼ ì ì ˆíˆ ì¡°ì •í•  ìˆ˜ ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;h1 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;ê¸ˆìœµ ì‹œê³„ì—´ ì˜ˆì¸¡ì„ ìœ„í•´ Temporal and Heterogeneous graph neural network modelì„ ì œì‹œí•œë‹¤. ê°€ì¥ íš¨ê³¼ì ì¸ ê·¸ë˜í”„ ê¸°ë°˜ê³¼ ë¹„ê·¸ë˜í”„ ê¸°ë°˜ baselineê³¼ ë¹„êµí•˜ì—¬ ì œì‹œí•œ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ì˜€ë‹¤. ë˜í•œ ì‹¤ì œ íˆ¬ì ì „ëµì—ì„œ THGNNì´ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì˜€ë‹¤. ê¸°ì—…ê°„ì˜ ê´€ê³„ë¥¼ Heteoreneous dynamic graphë¡œ ëª¨ë¸ë§ í•˜ê³  GNNì„ í†µí•´ ê¸ˆìœµ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸ì„ ê°œì„ í•˜ì˜€ë‹¤. ì¶”í›„ ì—°êµ¬ì—ì„œëŠ” ì˜ˆì¸¡ ëª¨ë¸ì´ ë³´ë‹¤ ì •í™•í•œ training input graph ë°ì´í„°ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡œ corporate relation modelingì„ ê°œì„ í•  ì˜ˆì •ì´ë‹¤.&lt;/p&gt;
</description>
            <pubDate>Thu, 20 Apr 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/Temporal_and_Heterogeneous_Graph_Neural_Network_for_Financial_Time_Series_Prediction.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/Temporal_and_Heterogeneous_Graph_Neural_Network_for_Financial_Time_Series_Prediction.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICLR 2023] Temporal 2D-Variation Modeling for General Time Series Analysis2</title>
            <description>&lt;p&gt;&lt;strong&gt;ì‘ì„±ì : ìœ ê¸°ì„ &lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;1introduction&quot;&gt;&lt;strong&gt;1.Introduction&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;ì‹œê³„ì—´ ë¶„ì„ì€ ê¸°ìƒ ì˜ˆì¸¡ , ëª¨ë‹ˆí„°ë§ ë°ì´í„°ì˜ ì´ìƒ ê°ì§€ ë° í–‰ë™ ì¸ì‹ì„ ìœ„í•œ ê¶¤ì  ë¶„ë¥˜ ì™€ ê°™ì€ ë‹¤ì–‘í•œ ì‹¤ì œ ì‘ìš© ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ë©°, ì´ëŸ¬í•œ ë„“ì€ ì‹¤ìš©ì  ê°€ì¹˜ ë•Œë¬¸ì— ì‹œê³„ì—´ ë¶„ì„ì€ í° ê´€ì‹¬ì„ ë°›ê³  ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì¼ë°˜ì ìœ¼ë¡œ ì–¸ì–´ë‚˜ ë¹„ë””ì˜¤ì™€ ê°™ì€ ë‹¤ë¥¸ ìœ í˜•ì˜ ìˆœì°¨ ë°ì´í„°ì™€ ë‹¬ë¦¬ ì‹œê³„ì—´ì€ ì—°ì†ì ìœ¼ë¡œ ê¸°ë¡ë˜ë©° ê° ì‹œê°„ ì§€ì ì€ ì¼ë¶€ ìŠ¤ì¹¼ë¼ë§Œ ì €ì¥í•œë‹¤. ê·¸ëŸ¬ë‚˜  í•˜ë‚˜ì˜ ë‹¨ì¼ ì‹œê°„ ì§€ì ìœ¼ë¡œëŠ” ë³´í†µ ë¶„ì„ì— ì¶©ë¶„í•œ ì˜ë¯¸ì  ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì—, ë§ì€ ê²½ìš° ë” ë§ì€ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì‹œê³„ì—´ì˜ ë‚´ì¬ì ì¸ íŠ¹ì„±ì¸ ì—°ì†ì„±, ì£¼ê¸°ì„±, ì¶”ì„¸ ë“±ì„ ë°˜ì˜í•  ìˆ˜ ìˆëŠ” ì‹œê°„ì  ë³€í™”ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œ ì‹œê³„ì—´ì˜ ë³€ë™ì€ í•­ìƒ ë³µì¡í•œ ì‹œê°„ íŒ¨í„´ì„ í¬í•¨í•˜ë©°, ì—¬ëŸ¬ ë³€ë™(ìƒìŠ¹, í•˜ê°•, ë³€ë™ ë“±)ì´ ì„œë¡œ ì„ì´ê³  ì¤‘ì²©ë˜ì–´ ëª¨ë¸ë§ì„ ë§¤ìš° ì–´ë µê²Œ ë§Œë“ ë‹¤.  íŠ¹íˆ ë”¥ëŸ¬ë‹ ì»¤ë®¤ë‹ˆí‹° ì—ì„œëŠ” ì´ëŸ° ë³µì¡í•œ ì‹œê³„ì—´ Data ì˜ ì‹œê°„ì  ë³€í™”ë¥¼ í¬ì°©í•˜ê¸° ìœ„í•´, (RNN), (TCN), Attention ë©”ì»¤ë‹ˆì¦˜ ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ë§ì„ ì§„í–‰í•˜ê³  ìˆìœ¼ë‚˜,  ê° ëª¨ë¸ë“¤ì˜ í•œê³„ë¡œ ì¸í•´ íš¨ìœ¨ì ì¸ ëª¨ë¸ë§ì„ ì§„í–‰í•˜ëŠ”ë° í•œê³„ê°€ ì¡´ì¬í•œë‹¤.&lt;/p&gt;

&lt;p&gt;ë³¸ ë…¼ë¬¸ì—ì„œëŠ”, ë³µì¡í•œ ì‹œê°„ì  ë³€ë™ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ ì£¼ê¸°ì„±ì—ì„œ ë¶„ì„í•œë‹¤. ì‹¤ì œ í˜„ì‹¤ì„¸ê³„ì˜ ì‹œê³„ì—´ ë°ì´í„°ëŠ” ì¼ì¼,  ì£¼ê°„,  ì—°ê°„ ê°™ì€ ì£¼ê¸°ì„±ì„ ê´€ì°°í•  ìˆ˜ ìˆìœ¼ë©°,  ì´ëŸ° ì£¼ê¸°ì„±ì´ ì„œë¡œ ìƒí˜¸ì‘ìš©í•˜ì—¬ ë³€ë™ ëª¨ë¸ë§ì„ ì–´ë µê²Œ í•œë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ê´€ì ì—ì„œ í•´ë‹¹ ë…¼ë¬¸ì˜ í•µì‹¬ì€ ì´ëŸ° ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì£¼ê¸°ë‚´ì—ì„œì˜ ë³€ë™ì„± (intraperiod-variation) ê³¼ ì£¼ê¸° ê°„ ë³€ë™ì„±(interperiod-variation) ìœ¼ë¡œ ê°ê° ë‚˜ëˆ ,  ê¸°ì¡´ Temporal Variation ì„ Intraperiod - , Interperiod â€“ variation ìœ¼ë¡œ í™•ì¥í•˜ì—¬ Multi â€“ periodicity íŠ¹ì„±ì„ ë°˜ì˜í•˜ëŠ” ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ëŸ° Multi â€“ periodicity íŠ¹ì„±ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´, 1D ì‹œê³„ì—´ì„ 2D ê³µê°„ìœ¼ë¡œ í™•ì¥í•œë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ê·¸ë¦¼ 1ì²˜ëŸ¼, 1D ì‹œê³„ì—´ì„ ê° ì—´ì´ ì£¼ê¸° ë‚´ ì‹œê°„ ì ì„ í¬í•¨í•˜ê³  ê° í–‰ì´ ì„œë¡œ ë‹¤ë¥¸ ì£¼ê¸°ì—ì„œ ë™ì¼í•œ ìœ„ìƒì˜ ì‹œê°„ ì ì„ í¬í•¨í•˜ëŠ” 2D í…ì„œë¡œ ì¬êµ¬ì„± í•œë‹¤. ë”°ë¼ì„œ 1D ì‹œê³„ì—´ì„ 2D í…ì„œ ì§‘í•©ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì›ë˜ì˜ 1D ê³µê°„ì—ì„œ í‘œí˜„ ëŠ¥ë ¥ ë³‘ëª© í˜„ìƒì„ ê¹¨ê³  2D ê³µê°„ì—ì„œ intra-period- ë° inter-period-variationsë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ì—¬ ì‹œê°„ì  2D-variationsì„ ì–»ì„ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/XLt18hp/fig-1.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë˜í•œ ê¸°ìˆ ì ìœ¼ë¡œ, ìœ„ì™€ ê°™ì€ ë™ê¸°ì— ê¸°ë°˜í•˜ì—¬, ì´ì „ ë°±ë³¸(backbone)ì„ ë„˜ì–´ì„œ ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ ìƒˆë¡œìš´ íƒœìŠ¤í¬-ì¼ë°˜ ëª¨ë¸ë¡œ TimesNetì„ ì œì•ˆí•œë‹¤.&lt;/p&gt;

&lt;p&gt;êµ¬ì²´ì ìœ¼ë¡œ, TimesBlockì€ í•™ìŠµëœ ì£¼ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 1D ì‹œê³„ì—´ì„, 2D í…ì„œ  SET ìœ¼ë¡œ ë³€í™˜í•˜ê³ , íŒŒë¼ë¯¸í„° íš¨ìœ¨ì ì¸ inception block ì„ í†µí•´ 2D ê³µê°„ì—ì„œ intra-period ë° inter-period ë³€í™”ë¥¼ í¬ì°©í•  ìˆ˜ ìˆë‹¤. ì‹¤í—˜ì ìœ¼ë¡œ, TimesNet ì€ ë‹¨ê¸° ë° ì¥ê¸° ì˜ˆì¸¡, ëŒ€ì²´, ë¶„ë¥˜ ë° ì´ìƒ íƒì§€ë¥¼ í¬í•¨í•œ 5 ê°€ì§€ ì£¼ìš” ë¶„ì„ ì‘ì—…ì—ì„œ ì¼ê´€ëœ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;2related-work&quot;&gt;&lt;strong&gt;2.RELATED WORK&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;ì‹œê³„ì—´ ë¶„ì„ì˜ ì£¼ìš” ë¬¸ì œì¸ ì‹œê°„ì  ë³€í™” ëª¨ë¸ë§ì€, ARIMA(Anderson &amp;amp; Kendall, 1976), Holt-Winter(Hyndman &amp;amp; Athanasopoulos, 2018) ë° Prophet(Taylor &amp;amp; Letham, 2018) ê°™ì€ ê³ ì „ì  ëª¨ë¸ ê¸°ë°˜ì˜ ì—°êµ¬ê°€ ì§„í–‰ë˜ì—ˆìœ¼ë‚˜,  ì‹œê³„ì—´ì˜ ë³€í™”ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë¯¸ë¦¬ ì •ì˜ëœ íŒ¨í„´ìœ¼ë¡œëŠ” ì¶©ë¶„íˆ ì„¤ëª…í•˜ê¸° ì–´ë µê¸° ë•Œë¬¸ì— ì‹¤ìš©ì„±ì€ ì œí•œë˜ëŠ” í•œê³„ê°€ ì¡´ì¬í–ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ìµœê·¼ ì—ëŠ” MLP, TCN, RNN ê¸°ë°˜ì˜ ë‹¤ì–‘í•œ Deep ëª¨ë¸ë“¤ì´ ì‹œê³„ì—´ ëª¨ë¸ë§ì— ì ìš©ë˜ ì™”ë‹¤.  ìš°ì„  MLP ê¸°ë°˜ì˜ ë°©ë²•ë“¤ (Oreshkin et al., 2019; Challu et al., 2022; Zeng et al., 2023; Zhang et al., 2022)ì€ MLPì„ ì‹œê°„ ì¶•ìœ¼ë¡œ ì‚¬ìš©í•˜ë©°, ì‹œê°„ ì˜ì¡´ì„±ì„ MLP ë ˆì´ì–´ì˜ ê³ ì •ëœ íŒŒë¼ë¯¸í„°ë¡œ ì¸ì½”ë”© í•œë‹¤. TCN ê¸°ë°˜ì˜ ë°©ë²• (2019)ì€ ì‹œê°„ ì¶•ì„ ë”°ë¼ ì´ë™í•˜ëŠ” ì»¨ë³¼ë£¨ì…˜ ì»¤ë„ë¡œ ì‹œê°„ ë³€í™”ë¥¼ ìº¡ì³í•˜ë©°, RNN ê¸°ë°˜ì˜ ë°©ë²• (Hochreiter &amp;amp; Schmidhuber, 1997; Lai et al., 2018; Gu et al., 2022)ì€ ì¬ê·€ êµ¬ì¡°ë¥¼ í™œìš©í•˜ë©°, ì‹œê°„ ë‹¨ê³„ ê°„ ìƒíƒœ ì „ì´ë¥¼ í†µí•´ ì‹œê°„ ë³€í™”ë¥¼ ìº¡ì³í•œë‹¤. íŠ¹íˆ ìµœê·¼ ë”¥ëŸ¬ë‹ ë¶„ì•¼ì—ì„œ ì „ë°˜ì ìœ¼ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” TransformerëŠ” ì‹œê³„ì—´ ì˜ˆì¸¡ì—ì„œë„ í° ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìœ¼ë©° (Zhou et al., 2021; Liu et al., 2021a; Wu et al., 2021; Zhou et al., 2022), ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ í¬ì¸íŠ¸ ê°„ì˜ ì‹œê°„ì  ì¢…ì†ì„±ì„ íŒŒì•…í•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ, Wu et al.ì€ í•™ìŠµëœ ì£¼ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìê¸° ìƒê´€ ë©”ì»¤ë‹ˆì¦˜ì„ ê°–ì¶˜ Autoformerë¥¼ ì œì‹œ í–ˆìœ¼ë©°. ê·¸ í›„, FEDformer (Zhou et al., 2022)ëŠ” ê³„ì ˆì„±-ì¶”ì„¸ ë¶„í•´ë¥¼ ê°•í™”í•˜ê³  ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ë‚´ì—ì„œ sparse ì–´í…ì…˜ì„ ì œì‹œí–ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë³¸ ë…¼ë¬¸ì˜ ê²½ìš° ì´ì „ ë°©ë²•ê³¼ ë‹¬ë¦¬, ì‹œê³„ì—´ì˜ ë‹¤ì¤‘ ì£¼ê¸°ì„±ì„ íƒìƒ‰í•˜ì—¬ ë³µì¡í•œ ì‹œê°„ì  íŒ¨í„´ì„ í•´ê²°í•˜ê³ , ì´ë¯¸ ì¸ê³µì§€ëŠ¥ ì»´í“¨í„° ë¹„ì „ì—ì„œ ì˜ ì•Œë ¤ì§„ ë°±ë³¸ì„ ì‚¬ìš©í•˜ì—¬ ì²˜ìŒìœ¼ë¡œ 2D ê³µê°„ì—ì„œ ì‹œê°„ì  2D-ë³€í™”ë¥¼ í¬ì°©í•œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;3timesnet&quot;&gt;&lt;strong&gt;3.TIMESNET&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;í•´ë‹¹ ë…¼ë¬¸ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œ ìš°ì„  Multi periodicity ë¥¼ ì´í•´í•´ì•¼ í•œë‹¤. Multi periodicity ëŠ” ìœ„ì—ì„œ ê°„ë‹¨íˆ ì–¸ê¸‰í–ˆì§€ë§Œ, í•´ë‹¹ ë…¼ë¬¸ì€ Intraperiod Variationê³¼ Intreperiod Variation ì„ êµ¬ë¶„í•˜ì—¬ ë¶„ì„í•˜ì˜€ë‹¤. ìš°ì„  Intraperiod Variation ì€ Period ë‚´ì—ì„œ ë°œìƒí•˜ëŠ” Variation ìœ¼ë¡œ Short Term Temporal pattern ì„ ë°˜ì˜í•˜ë©°,  ì¼ë°˜ì ìœ¼ë¡œ 1D Time Series data ë¥¼ Input ìœ¼ë¡œ ëª¨ë¸ë§ ì§„í–‰ì‹œ ê³ ë ¤í•˜ëŠ” Variation ì´ë‹¤.  ë˜í•œ ì¶”í›„ 2D Tensor ë¡œ ë³€í™˜í•  ë•Œ ê° Column ìœ¼ë¡œ í‘œí˜„ë˜ì–´ ê°™ì€ Period ë‚´ time Point ê°„ì˜ Variation ì„ ì˜ë¯¸í•œë‹¤.  ë°˜ë©´ Interperiod Variation ì€ ì„œë¡œ ë‹¤ë¥¸ Period ì—ì„œ ë°œìƒí•˜ëŠ” Variation ìœ¼ë¡œ Long Term Temporal Pattern ì„ ë°˜ì˜í•œë‹¤.  ì´ëŠ” 2D  Tensor ë¡œ ë³€í™˜ì‹œ ê° row ë¡œ í‘œí˜„ë˜ì–´ ë‹¤ë¥¸ Period ì— ì¡´ì¬í•˜ì§€ë§Œ,  ê°™ì€ Phase ë¥¼ ê°€ì§€ëŠ” time points ê°„ Temporal Variation ì„ ì˜ë¯¸í•œë‹¤.  ì´ ë…¼ë¬¸ì€ ì´ ë‘˜ì„  ì¡°í•©í•˜ì—¬ ì‚¬ìš© í•˜ëŠ” ê²ƒì´ key idea ì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ Interperiod ì˜ ê¸°ì¤€ì„ ë‚˜ëˆ„ê¸° ìœ„í•´ì„œ ê·¸ë¦¼ 1ê³¼ ê°™ì´ í•´ë‹¹ Data ì—ì„œ ë‹¤ì–‘í•œ Period ë¥¼ ì–»ì–´ì•¼ í•œë‹¤.  ì´ë¥¼ ìœ„í•˜í•´ì„œ í•´ë‹¹ ë…¼ë¬¸ì€ ì•„ë˜ ê·¸ë¦¼ê³¼ ì‹ì²˜ëŸ¼ Fast Fourier Transform ì„ ì‚¬ìš©í•œë‹¤.
&lt;img src=&quot;https://i.ibb.co/sV7HDkg/fig-2.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/ph2FGQW/fig-3.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/p&gt;

&lt;p&gt;FFT ë¥¼ ì ìš©í•´ì„œ Sequence ì— ëŒ€í•œ Amplitude ë° Frequency ë¥¼ ë„ì¶œ í•˜ê³ , Frequency ì¤‘ Amplitude ê°’ì´ ê°€ì¥ ë†’ì€ Top K ê°œì˜ Frequency ë¥¼ ì„ ì •í•˜ì—¬, Frequency ì— ìƒì‘í•˜ëŠ” Period ë¥¼ êµ¬í•œë‹¤.  ì—¬ê¸°ì„œ top K ê°œì˜ Frequency ë¥¼ ì„ ì •í•˜ëŠ” ì´ìœ ëŠ” Frequency ì˜ì—­ì˜ sparse í•¨ì„ ê³ ë ¤í–ˆì„ë•Œ,  ìœ¼ë¯¸ ì—†ëŠ” high Frequency ì— ì˜í•œ Nosie ë¥¼ í”¼í•˜ê¸° ìœ„í•œê²ƒì´ë‹¤.
&lt;img src=&quot;https://i.ibb.co/JzfM3cw/fig-4.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ ì„ ì •ëœ Top Kê°œì˜ Frequency ì— í•´ë‹¹í•˜ëŠ” Period ëŠ” ìœ„ ìˆ˜ì‹ì—ì„œ pi ë¡œ ì„¤ì •í•œë‹¤.  ì´ë ‡ê²Œ êµ¬í•´ì§„ Frequency {f1, â€¦, fk} ì™€Period  {p1, â€¦, pk} ë¥¼ ì´ìš©í•˜ì—¬ 1D Time series data 
&lt;img src=&quot;https://i.ibb.co/FBm7rPm/fig-5.png &quot; width=&quot;101&quot; height=&quot;20&quot; /&gt; ë¥¼ 2D Tensor ë¡œ ë³€í™˜ í•œë‹¤.
&lt;img src=&quot;https://i.ibb.co/qn0hS2d/fig-6.png&quot; width=&quot;300&quot; height=&quot;30&quot; /&gt; 
ì—¬ê¸°ì„œ Padding ì€ 2D tensor ë¡œ ì¬êµ¬ì„± í•˜ê¸° ìœ„í•´ ì‹œê³„ì—´ì„ ì‹œê°„ ì¶•ì„ ë”°ë¼ 0ìœ¼ë¡œ íŒ¨ë”©í•˜ëŠ” ì‘ì—…ì¸ë°,  ì•„ë˜ ìˆ˜ì‹ ì—ì„œ T/fi ê°’ì„ ë§ì¶°ì£¼ê¸° ìœ„í•´ ì§„í–‰í•œë‹¤.
&lt;img src=&quot;https://i.ibb.co/b1ZxjGp/fig-7.png&quot; width=&quot;150&quot; height=&quot;30&quot; /&gt;
(piì™€ fiëŠ” ê°ê° ië²ˆì§¸ ë³€í™˜ëœ 2D í…ì„œì˜ í–‰ê³¼ ì—´ì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.)
ì´ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì„ íƒëœ ì£¼íŒŒìˆ˜ì™€ ì¶”ì •ëœ ì£¼ê¸°ì— ê¸°ë°˜í•˜ì—¬ kê°œì˜ ë‹¤ë¥¸ 2D ë³€ë™ì„ ë‚˜íƒ€ë‚´ëŠ” 2D í…ì„œ ì§‘í•©  &lt;img src=&quot;https://i.ibb.co/VYpv3nK/fig-8.png&quot; width=&quot;101&quot; height=&quot;20&quot; /&gt;  ì„ ì–»ê²Œ ëœë‹¤.
ì´ëŸ¬í•œ ë³€í™˜ì€ ë³€í™˜ëœ 2D í…ì„œì— ë‘ ê°€ì§€ ìœ í˜•ì˜ ì§€ì—­ì„±(locality)ì„ ê°€ì ¸ë‹¤ ì¤€ë‹¤ëŠ” ì ë„ ì£¼ëª©í•  ë§Œí•˜ë‹¤. ì¦‰, ì—°ì†ëœ ì‹œê°„ì (ì—´, intra-period variation)ê³¼ ì¸ì ‘í•œ ì£¼ê¸°(í–‰, inter-period variation) ì‚¬ì´ì˜ ì§€ì—­ì„±ì´ë‹¤. ë”°ë¼ì„œ, ì‹œê³„ì—´ 2D-ë³€ë™ì„±ì€ 2D ì»¤ë„ì— ì˜í•´ ì‰½ê²Œ ì²˜ë¦¬ë  ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;32timesblock&quot;&gt;&lt;strong&gt;3.2.TIMESBLOCK&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/wQkhLbk/fig-9.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;
Capturing temporal 2D-variation&lt;/p&gt;

&lt;p&gt;ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ Reshape ëœ ê²°ê³¼ë¥¼ í†µí•´ pi, fi ì— ëŒ€í•œ Representation ì„ ì¶”ì¶œí•œë‹¤.  ì—¬ê¸°ì„œ input ì€ &lt;img src=&quot;https://i.ibb.co/HdhBC5K/fig-10.png&quot; width=&quot;120&quot; height=&quot;25&quot; /&gt; ì´ê³  output ì€ &lt;img src=&quot;https://i.ibb.co/gMkhr4J/fig-11.png&quot; width=&quot;120&quot; height=&quot;30&quot; /&gt; ì´ë‹¤.  ë˜í•œ ìœ„ì˜ ê·¸ë¦¼ì²˜ëŸ¼ Reshape Back ì´ë¼ëŠ” ê³¼ì •ì„ í†µí•´ Convolution ê³¼ì •ì„ í†µí•´ ì¶”ì¶œí•œ Representation ì„ ë‹¤ì‹œ ê¸°ì¡´ í˜•íƒœë¡œ Reshape ì„ í•˜ê²Œ ëœë‹¤.&lt;/p&gt;

&lt;p&gt;ë§ˆì§€ë§‰ìœ¼ë¡œ ì•„ë˜ ì‹ì²˜ëŸ¼ Adaptive Aggregation ì„ ìˆ˜í–‰í•˜ê²Œ ë˜ëŠ”ë°,
&lt;img src=&quot;https://i.ibb.co/cXsM4Np/fig-12.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;
ì´ëŠ” ì´ì „ ê³¼ì •ì„ í†µí•´ ë§Œë“¤ì–´ì§„ 1D time series data ë¥¼ Aggregation í•˜ëŠ” ê³¼ì •ì´ë‹¤. Amplitude A ëŠ” ì„ íƒëœ Top K ê°œì˜ Frequency ì™€ Period ê°„ ìƒëŒ€ì  ì¤‘ìš”ë„ë¥¼ ë°˜ì˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, Transform ëœ Tensor ì˜ ì¤‘ìš”ë„ ì—­ì‹œ ë°˜ì˜í•  ìˆ˜ ìˆë‹¤.  ì´ë¡œë¶€í„° ì²˜ìŒ FFT ê³¼ì •ì„ í†µí•´ êµ¬í•´ì§„ Amplitude ê°’ì„ ë°”íƒ•ìœ¼ë¡œ Aggregation í•˜ê²Œ ëœë‹¤.  ì´ë¡œë¶€í„° ë‚˜ì˜¨ ê²°ê³¼ëŠ” ì„œë¡œ ë‹¤ë¥¸ Period ê°„ Interperiod, Intraperiod variation ì„ ê³ ë ¤í•œ Temporal 2D Variation ì„ ë™ì‹œì— ìº¡ì³í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;4experiments&quot;&gt;&lt;strong&gt;4.EXPERIMENTS&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;TimesNetì˜ ì¼ë°˜ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´, ì¥/ë‹¨ê¸° ì˜ˆì¸¡, ë³´ì™„, ë¶„ë¥˜ ë° ì´ìƒ íƒì§€ì˜ ë‹¤ì„¯ ê°€ì§€ ì£¼ìš” ë¶„ì„ ì‘ì—…ì— ëŒ€í•œ ì‹¤í—˜ì„ ì§„í–‰í•¨.&lt;br /&gt;
&lt;img src=&quot;https://i.ibb.co/YNP1rS9/fig-13.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ìœ„ í‘œ 1ì€ ë²¤ì¹˜ë§ˆí¬ì˜ í‰ê°€ ê²°ê³¼ Summary-&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;-baseline&quot;&gt;&lt;strong&gt;-BaseLine&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;ì´ì—ëŠ” RNN ê¸°ë°˜ ëª¨ë¸ì¸ LSTM (1997), LSTNet (2018) ë° LSSL (2022); CNN ê¸°ë°˜ ëª¨ë¸ì¸ TCN (2019); MLP ê¸°ë°˜ ëª¨ë¸ì¸ LightTS (2022) ë° DLinear (2023); Transformer ê¸°ë°˜ ëª¨ë¸ì¸ Reformer (2020), Informer (2021), Pyraformer (2021a), Autoformer (2021), FEDformer (2022), Non-stationary Transformer (2022a) ë° ETSformer (2022) ë“±ì´ í¬í•¨ë¨. ë˜í•œ ê°ê°ì˜ íŠ¹ì • ì‘ì—…ì— ëŒ€í•´ ìµœì‹  ê¸°ë²•ì¸ N-HiTS (2022)ì™€ N-BEATS (2019)ë¥¼ ì‚¬ìš©í•œ ë‹¨ê¸° ì˜ˆì¸¡, ì´ìƒ íƒì§€ë¥¼ ìœ„í•œ Anomaly Transformer (2021), ë¶„ë¥˜ë¥¼ ìœ„í•œ Rocket (2020)ê³¼ Flowformer (2022) ë“±ê³¼ ê°™ì€ ìµœì‹  ëª¨ë¸ë“¤ê³¼ë„ ë¹„êµí•¨. ì¢…í•©ì ì¸ ë¹„êµë¥¼ ìœ„í•´ 15ê°œ ì´ìƒì˜ ê¸°ì¤€ ëª¨ë¸ì„ í¬í•¨í•˜ì˜€ìŒ.
&lt;img src=&quot;https://i.ibb.co/FmBr4Qj/fig-14.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;-41-ì£¼ìš”ê²°ê³¼&quot;&gt;&lt;strong&gt;-4.1 ì£¼ìš”ê²°ê³¼&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;TimesNetì€ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´  5ê°œ Mainstream Task ì—ì„œ ë‹¤ë¥¸  ëª¨ë¸ë“¤ ëŒ€ë¹„ ëª¨ë“  ë°©ë©´ì—ì„œ SOTA ë¥¼ ë‹¬ì„±í•˜ì˜€ë‹¤.  ë˜í•œ ì¸ì…‰ì…˜ ë¸”ë¡ì„ ë” ê°•ë ¥í•œ ë¹„ì „ ë°±ë³¸ìœ¼ë¡œ ëŒ€ì²´í•¨ìœ¼ë¡œì¨ TimesNetì˜ ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë³´ì¸ë‹¤. (ìœ„ ê·¸ë¦¼ì˜ ì˜¤ë¥¸ìª½)&lt;/p&gt;

&lt;h4 id=&quot;-41-ë‹¨ê¸°-ë°-ì¥ê¸°-ì˜ˆì¸¡-ì„¤ì •-&quot;&gt;**-4.1 ë‹¨ê¸° ë° ì¥ê¸° ì˜ˆì¸¡ ì„¤ì • **&lt;/h4&gt;

&lt;p&gt;ì‹œê³„ì—´ ì˜ˆì¸¡ì€ ë‚ ì”¨ ì˜ˆë³´, êµí†µ ë° ì—ë„ˆì§€ ì†Œë¹„ ê³„íšì— í•„ìˆ˜ì ì´ë©°, ì´ëŸ¬í•œ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´, ì¥/ë‹¨ê¸° ì˜ˆì¸¡ì„ í¬í•¨í•œ ë‘ ê°€ì§€ ìœ í˜•ì˜ ë²¤ì¹˜ë§ˆí¬ë¡œ ë¹„êµí•¨.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ì¥ê¸° ì˜ˆì¸¡: Autoformer (2021)ì—ì„œ ì‚¬ìš©í•œ ë²¤ì¹˜ ì‚¬ìš©.&lt;/li&gt;
  &lt;li&gt;ë‹¨ê¸° ì˜ˆì¸¡: M4 (Spyros Makridakis, 2018)ë¥¼ ì±„íƒ
    &lt;ul&gt;
      &lt;li&gt;ì—°ê°„, ë¶„ê¸° ë° ì›”ë³„ë¡œ ìˆ˜ì§‘ëœ ë‹¨ì¼ ë³€ìˆ˜ ë§ˆì¼€íŒ… ë°ì´í„° í¬í•¨.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.esdrop.com/d/f/uD7EquG4pF/0TfhSU820p.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.esdrop.com/d/f/uD7EquG4pF/bJ0Q1DcKw5.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;--ê²°ê³¼&quot;&gt;&lt;strong&gt;- ê²°ê³¼&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;TimesNetì€ ì¥ê¸° ë° ë‹¨ê¸° ì„¤ì •ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤ (í‘œ 2-3). í‘œ13 ì—ì„œ TimesNetì˜ ì¥ê¸° ì˜ˆì¸¡ì˜ ê²½ìš° 80% ì´ìƒì˜ ê²½ìš°ì—ì„œ SoTA ë‹¬ì„±í•¨. M4 ë°ì´í„°ì…‹ì˜ ê²½ìš°, ì‹œê³„ì—´ì´ ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘ë˜ê¸° ë•Œë¬¸ì— ì‹œê°„ì  ë³€ë™ì´ ë§¤ìš° ì»¤ì ¸, ì´ë¡œ ì¸í•´ ì˜ˆì¸¡ì´ í›¨ì”¬ ì–´ë ¤ì§ˆ ìˆ˜ ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ TimesNet ëª¨ë¸ì€ ì´ ì‘ì—…ì—ì„œ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©°, ê³ ê¸‰ MLP ê¸°ë°˜ ë° Transformer ê¸°ë°˜ ëª¨ë¸ì„ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤€ë‹¤.&lt;/p&gt;

&lt;h4 id=&quot;--43-imputation&quot;&gt;&lt;strong&gt;- 4.3 IMPUTATION&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Missing Valueë¡œ ì¸í•´ Imputation ì‘ì—…ì€ ëª¨ë¸ì´ ë¶ˆê·œì¹™í•˜ê³  ë¶€ë¶„ì ìœ¼ë¡œ ê´€ì¸¡ëœ ì‹œê³„ì—´ì—ì„œ ì ì¬ì ì¸ ì‹œê°„ì  íŒ¨í„´ì„ ë°œê²¬í•´ì•¼ í•˜ëŠ” ì–´ë ¤ìš´ ì‘ì—…ì„ì—ë„, í‘œ 4ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, TimesNetì€ ì´í•´ë‹¹ ì‘ì—…ì—ì„œë„ SOTAë¥¼ ë‹¬ì„±í•˜ì—¬, ë³µì¡í•œ ì‹œê°„ì  ë³€ë™ì„ í¬ì°©í•˜ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ ë˜í•œ ê²€ì¦í•¨.&lt;/p&gt;

&lt;h4 id=&quot;--44-classification&quot;&gt;&lt;strong&gt;- 4.4 CLASSIFICATION&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;ì‹œê³„ì—´ ë¶„ë¥˜ì˜ ê²½ìš° ì¸ì‹ ë° ì˜ë£Œ ì§„ë‹¨ì— ì‚¬ìš©ë  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ ê²€ì¦í•˜ê¸° ìœ„í•´, UEA ì‹œê³„ì—´ ë¶„ë¥˜ ì•„ì¹´ì´ë¸Œ (Bagnall et al., 2018)ì—ì„œ, ì˜ë£Œ ì§„ë‹¨ ë° ê¸°íƒ€ ì‹¤ì œ ì‘ì—…ì„ í¬í•¨í•˜ëŠ” 10ê°œì˜ ë‹¤ë³€ëŸ‰ ë°ì´í„°ì…‹ì„ ì „ì²˜ë¦¬ í•˜ì—¬ ì‚¬ìš©í•¨.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.esdrop.com/d/f/uD7EquG4pF/Xr832xCRpQ.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.esdrop.com/d/f/uD7EquG4pF/vQG8qjHpcg.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;--44-classification-1&quot;&gt;&lt;strong&gt;- 4.4 CLASSIFICATION&lt;/strong&gt;&lt;/h4&gt;
&lt;h4 id=&quot;--ê²°ê³¼-1&quot;&gt;&lt;strong&gt;- ê²°ê³¼&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Figure 5ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, TimesNetì€ í‰ê·  ì •í™•ë„ 73.6%ë¡œ ìµœê³ ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì—¬ ì´ì „ì˜ SOTA ë°©ë²•ì¸ Rocket (72.5%)ê³¼ ë”¥ ëª¨ë¸ì¸ Flowformer (73.0%)ë¥¼ ëŠ¥ê°€í•¨. íŠ¹íˆ MLP ê¸°ë°˜ ëª¨ë¸ì¸ DLinearì€ ì´ dataset ì—ì„œ ì˜ ë™ì‘í•˜ì§€ ì•ŠëŠ”ë°, (67.5%) ì´ëŠ”  DLinearì˜ ê²½ìš° ì‹œê°„ì  ì˜ì¡´ì„±ì´ ê³ ì •ëœ ìê¸°íšŒê·€ ì‘ì—…ì— ì í•©í•œ í•œ ê³„ì¸µì˜ MLP ëª¨ë¸ë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, ê³ ìˆ˜ì¤€ í‘œí˜„ì„ í•™ìŠµí•˜ëŠ” ë° ì•½ì ì´ ìˆì„ê²ƒìœ¼ë¡œ ë³´ì„. ë°˜ë©´ì— TimesNetì€ 2D ê³µê°„ì—ì„œ ì‹œê°„ì ì¸ 2D ë³€ë™ì„ í†µí•©í•˜ì—¬ 2D ì»¤ë„ì„ í†µí•´ ì •ë³´ë¥¼ í•™ìŠµí•˜ê¸° ìš©ì´í•˜ê²Œ ë§Œë“¤ì–´ì§€ë¯€ë¡œ, ê³„ì¸µì  í‘œí˜„ì„ í•„ìš”ë¡œ í•˜ëŠ” ë¶„ë¥˜ ì‘ì—…ì— ìœ ë¦¬í•´ ë³´ì„.&lt;/p&gt;

&lt;h4 id=&quot;--45-anomaly-detection&quot;&gt;&lt;strong&gt;- 4.5 ANOMALY DETECTION&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;ëª¨ë‹ˆí„°ë§ ë°ì´í„°ì—ì„œ ì´ìƒì¹˜ íƒì§€ëŠ” ë§¤ìš° ì¤‘ìš”í•˜ë‚˜, ì¼ë°˜ì ìœ¼ë¡œ ë°ì´í„° ë ˆì´ë¸”ë§ì´ ì–´ë ¤ì›Œ, unsupervised Leaning ë°©ì‹ìœ¼ë¡œ í•´ë‹¹ Point ë¥¼ Detection í•¨. ë¹„êµ ë¶„ì„ì„ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ì…‹ì€: SMD (Su et al., 2019), MSL (Hundman et al., 2018), SMAP (Hundman et al., 2018), SWaT (Mathur &amp;amp; Tippenhauer, 2016), PSM (Abdulaal et al., 2021).&lt;/p&gt;

&lt;h4 id=&quot;--ê²°ê³¼-2&quot;&gt;&lt;strong&gt;- ê²°ê³¼&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://i.esdrop.com/d/f/uD7EquG4pF/IGTAd9lmKI.png&quot; alt=&quot;ëŒ€ì²´&quot; /&gt;
 Table 5ë¥¼ ë³´ë©´, TimesNetì´ ì´ìƒ íƒì§€ì—ì„œ ë˜í•œ SOTAë¥¼ ë‹¬ì„±í•˜ë©°, ê³ ê¸‰ Transformer ê¸°ë°˜ ëª¨ë¸ì¸ FEDformer (2022)ì™€ Autoformer (2021)ë³´ë‹¤ ë›°ì–´ë‚¨ì„ ë³´ì—¬ì¤Œ. ì´ëŠ” ì´ìƒ íƒì§€ê°€ ë“œë¬¼ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì´ìƒì ì¸ ì‹œê°„ íŒ¨í„´ì„ ì°¾ì•„ì•¼ í•˜ëŠ”ë° ë¹„í•´, ì¼ë°˜ì ì¸ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì€ ê° ì‹œê°„ ì§€ì  ìŒ ê°„ì˜ ìœ ì‚¬ì„±ì„ ê³„ì‚°í•˜ë¯€ë¡œ ì£¼ìš” ì •ìƒ ì‹œê°„ ì§€ì ì— ì˜í•´ ë°©í•´ë¥¼ ë°›ê¸° ë•Œë¬¸ìœ¼ë¡œ ë³´ì—¬ì§. ë˜í•œTimesNet, FEDformer ë° AutoformerëŠ” ëª¨ë‘ íœ¼ë¥­í•œ ì„±ëŠ¥ì„ ê³µí†µì ìœ¼ë¡œ ë³´ì—¬ ì£¼ëŠ”ë° ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ì£¼ê¸°ì„± ë¶„ì„ì˜ ì¤‘ìš”ì„±ì„ ë³´ì—¬ì£¼ë©°, ì£¼ê¸°ì„±ì„ ìœ„ë°˜í•˜ëŠ” ë³€ë™ì„ ì•”ì‹œì ìœ¼ë¡œ ê°•ì¡°í•˜ì—¬ ì´ìƒ íƒì§€ì— ë„ì›€ì„ ì£¼ëŠ”ê²ƒìœ¼ë¡œ ë³´ì„.&lt;/p&gt;

&lt;h2 id=&quot;5conclusion-and-future-work&quot;&gt;&lt;strong&gt;5.CONCLUSION AND FUTURE WORK&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;í•´ë‹¹ ë…¼ë¬¸ì˜ novelty ëŠ” ë‹¤ìŒê³¼ ê°™ì´ 3ê°€ì§€ë¡œ ìš”ì•½ëœë‹¤.&lt;/p&gt;

&lt;p&gt;-ë‹¤ì–‘í•œ ì£¼ê¸°ì„±ê³¼ ì£¼ê¸°ë³„ ë‚´/ì™¸ë¶€ì  ìƒí˜¸ì‘ìš©ì— ëŒ€í•œ ë™ê¸°ë¶€ì—¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì‹œê°„ì  ë³€í™” ëª¨ë¸ë§ì„ ìœ„í•œ ëª¨ë“ˆí™”ëœ ë°©ë²•ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. 1ì°¨ì› ì‹œê³„ì—´ì„ 2ì°¨ì› ê³µê°„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬, ì£¼ê¸° ë‚´/ì™¸ë¶€ì ì¸ ë³€í™”ë¥¼ ë™ì‹œì— ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;-TimesNetì€ TimesBlockì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ì£¼ê¸°ë¥¼ ì°¾ê³ , parameter-efficient inception blockìœ¼ë¡œ ë³€í™˜ëœ 2D tensorì—ì„œ temporal 2D-variationsì„ í¬ì°©í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ task-general ëª¨ë¸ë¡œ ì œì•ˆëœë‹¤.&lt;/p&gt;

&lt;p&gt;-TimesNetì€ ë‹¨ê¸° ë° ì¥ê¸° ì˜ˆì¸¡, ëŒ€ì¹˜, ë¶„ë¥˜ ë° ì´ìƒ íƒì§€ë¥¼ í¬í•¨í•œ ë‹¤ì„¯ ê°€ì§€ì˜ ì£¼ìš” ì‹œê³„ì—´ ë¶„ì„ ì‘ì—…ì—ì„œ ì¼ê´€ëœ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆë‹¤.&lt;/p&gt;

</description>
            <pubDate>Thu, 20 Apr 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/Temporal_2D_Variation_Modeling_for_General_Time_Series_Analysis2.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/Temporal_2D_Variation_Modeling_for_General_Time_Series_Analysis2.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICLR 2023] Temporal 2D-Variation Modeling for General Time Series Analysis</title>
            <description>&lt;h1 id=&quot;temporal-2d-variation-modeling-for-general-time-series-analysis&quot;&gt;Temporal 2D-Variation Modeling for General Time Series Analysis&lt;/h1&gt;

&lt;h1 id=&quot;1-problem-definition&quot;&gt;1. Problem Definition&lt;/h1&gt;
&lt;p&gt;ì‹œê³„ì—´ ë¶„ì„ì€ ì¼ê¸° ì˜ˆë³´, ì´ìƒì¹˜ íƒì§€, í–‰ë™ ì¸ì‹ ë“± ë§ì€ ì‘ìš© ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì‹œê³„ì—´ ë°ì´í„°ëŠ” ì–¸ì–´ë‚˜ ì˜ìƒê³¼ ê°™ì€ ìˆœì°¨ì  ë°ì´í„°ì™€ ë‹¬ë¦¬ ì—°ì†ì ìœ¼ë¡œ ê¸°ë¡ë˜ë©°, ê° ì‹œì ì€ ì¼ë¶€ ê°’ë§Œ ì €ì¥í•©ë‹ˆë‹¤. í•˜ë‚˜ì˜ ë‹¨ì¼ ì‹œì ì€ ì¶©ë¶„í•œ ì˜ë¯¸ë¥¼ ê°–ì§€ ì•Šê¸° ë•Œë¬¸ì—, ì—°ì†ì„±, ì£¼ê¸°ì„±, ì¶”ì„¸ ë“±ê³¼ ê°™ì€ ì‹œê³„ì—´ì˜ ê³ ìœ í•œ ì†ì„±ì„ ë°˜ì˜í•˜ë„ë¡ ì‹œê°„ì  ë³€í™”ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h1 id=&quot;2-motivation&quot;&gt;2. Motivation&lt;/h1&gt;
&lt;p&gt;ê·¸ëŸ¬ë‚˜ ì‹¤ì œ ì‹œê³„ì—´ ë°ì´í„°ëŠ” ì—¬ëŸ¬ ë³€í™”(ìƒìŠ¹, í•˜ë½, ë³€ë™ ë“±)ê°€ ë³µí•©ì ìœ¼ë¡œ ì„ì—¬ ë³µì¡í•œ íŒ¨í„´ì„ í¬í•¨í•˜ê¸° ë•Œë¬¸ì— ëª¨ë¸ë§ì´ ì–´ë µìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë…¼ë¬¸ì€, ë‹¤ì¤‘ ì£¼ê¸°ì„±(multi periodicity)ë¼ëŠ” ê´€ì ì—ì„œ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ë‚ ì”¨ ê´€ì¸¡ì„ ì˜ˆë¥¼ ë“¤ë©´, ê¸°ì˜¨ì€ í•˜ë£¨ì—ë„ ì£¼ê¸°ì„±ì„ ê°–ì§€ë§Œ ì£¼ê°„, ì›”ê°„, ë¶„ê¸°ê°„, ì—°ê°„ ì£¼ê¸°ì„±ë„ ì¡´ì¬í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‘ë²ˆì§¸ë¡œ, ê° ì£¼ê¸° ë‚´ì—ì„œ ì‹œê³„ì—´ ë°ì´í„°ëŠ” ì¸ì ‘í•œ ì˜ì—­ ë¿ë§Œ ì•„ë‹ˆë¼ ì¸ì ‘í•œ ì£¼ê¸°ì˜ ë³€ë™ê³¼ë„ ìƒê´€ê´€ê³„ê°€ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì´ìš©í•©ë‹ˆë‹¤. ì €ìë“¤ì€ ì´ë¥¼ ê°ê° ê¸°ê°„ ë‚´ ë³€ë™(intraperiod-variation)ê³¼ ê¸°ê°„ ê°„ ë³€ë™(interperiod-variation)ì´ë¼ ë¶€ë¦…ë‹ˆë‹¤.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;ê¸°ê°„ ë‚´ ë³€ë™(intraperiod-variation): ê¸°ê°„ ë‚´ì˜ ì§§ì€ ì£¼ê¸°ì„±ì„ íŒŒì•…í•¨.&lt;/p&gt;

  &lt;p&gt;ê¸°ê°„ ê°„ ë³€ë™(interperiod-variation): ê¸°ê°„ ê°„ì˜ ì¥ê¸° ì¶”ì„¸ë¥¼ íŒŒì•…í•¨.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_multiperiodicy.png?raw=true&quot; alt=&quot;Multi-Periodicity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê³ ì „ì ì¸ ë°©ë²•ë¡ ì€ ì‹œê°„ì  ë³€ë™ì´ ë¯¸ë¦¬ ì •ì˜ëœ íŒ¨í„´ì„ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. ì´ëŸ° ë°©ë²•ë¡ ì´ ì ìš©ëœ ëª¨ë¸ì€ ARIMA, Holt-Winter, Prophetì´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œ ì‹œê³„ì—´ì˜ ë³€í™”ëŠ” ë„ˆë¬´ ë³µì¡í•˜ì—¬ ì´ëŸ¬í•œ ì‚¬ì „ ì •ì˜ëœ íŒ¨í„´ìœ¼ë¡œ ë‹¤ë£¨ê¸° ì–´ë µê¸°ì— ì‹¤ì œ ì ìš©ì€ ë§¤ìš° ì œí•œì ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ìµœê·¼ì—ëŠ”ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ë°©ë²•ë¡ ì´ ì œì•ˆë˜ì—ˆê³ , í¬ê²Œ MLP, RNN, TCN ê¸°ë°˜ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MLP-based: ì‹œê°„ì°¨ì›ì„ ê³ ì •ëœ layerë¡œ ì¸ì½”ë”©&lt;/li&gt;
  &lt;li&gt;TCN-based: ì‹œê°„ì  ë³€í™”ë¥¼ convolution-kernelì„ ì´ìš©í•˜ì—¬ í¬ì°©&lt;/li&gt;
  &lt;li&gt;RNN-based: time step ë‹¹ ìƒíƒœ ì „í™˜ì„ í†µí•´ ì‹œê°„ì  ë³€í™”ë¥¼ í¬ì°©&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ê·¸ëŸ¬ë‚˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì—­ì‹œ ì£¼ê¸°ì„±ì— ì˜í•´ íŒŒìƒë˜ëŠ” ì‹œê°„ì  ë³€ë™ì„ ê³ ë ¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” Transformer ì—­ì‹œ ì‹œê³„ì—´ì—ì„œë„ ì„±ëŠ¥ì´ ì¢‹ìŠµë‹ˆë‹¤. attention-mechanismì„ ì´ìš©í•˜ì—¬ ì‹œì ê°„ì˜ ì‹œê°„ì  ì˜ì¡´ì„±ì„ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Autoformer: auto-correlationì„ ì´ìš©í•˜ì—¬ ì‹œê°„ì  ì˜ì¡´ì„±ì„ í¬ì°©í•˜ê³ &lt;/li&gt;
  &lt;li&gt;FEDformerëŠ” ê³„ì ˆì„±-ì¶”ì„¸ ë¶„í•´ë¥¼ ì´ìš©í•˜ì—¬ frequency ì˜ì—­ì—ì„œ attentionì„ í¬ì°©í•©ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì´ ë…¼ë¬¸ì€ ì´ì „ ì—°êµ¬ì™€ ë¹„êµí•˜ì—¬ 3ê°€ì§€ Contributionì´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Multi-periodicityë¥¼ í¬ì°©í•˜ê¸° ìœ„í•´ 1D time seriesë¥¼ 2D tensorë¡œ ë³€í™˜í•˜ì—¬, intraperiodì™€ interperiod-variation ëª¨ë‘ í¬ì°©&lt;/li&gt;
  &lt;li&gt;TimesNet ëª¨ë¸ ì•„í‚¤í…ì²˜ ì œì•ˆ. ì´ë•Œ parameter-efficientí•œ inception blockì´ ì ìš©ëœ TimesBlock ëª¨ë“ˆ ì´ìš©&lt;/li&gt;
  &lt;li&gt;Foundation modelë¡œì¨, 5ê°€ì§€ ì£¼ìš” taskì—ì„œ SOTA ë‹¬ì„± ë° ì‹œê°í™” ì œê³µ&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;3-method&quot;&gt;3. Method&lt;/h1&gt;
&lt;p&gt;ì €ìë“¤ì´ ì œì•ˆí•œ TimesNetì€ í¬ê²Œ 2ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ í•™ìŠµí•©ë‹ˆë‹¤. ì²«ë²ˆì§¸ ë‹¨ê³„ëŠ” í‘¸ë¦¬ì— ë³€í™˜ì„ ì´ìš©í•˜ì—¬ multi-periodicityë¥¼ í¬ì°©í•˜ê³ , ë‘ë²ˆì§¸ ë‹¨ê³„ëŠ” ì•ì„œ ì–»ì€ periodë§ˆë‹¤ 2D-tensorë¡œ ë³€í™˜í•˜ì—¬ 2D-variationì„ í¬ì°©í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;31-fft-analysis&quot;&gt;3.1 FFT Analysis&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;$T$: ì‹œê³„ì—´ ë°ì´í„°ì˜ ê¸¸ì´&lt;/li&gt;
  &lt;li&gt;$C$: ì‹œê³„ì—´ ì±„ë„ ìˆ˜. univariateì´ë©´ $C = 1$ì´ë‹¤&lt;/li&gt;
  &lt;li&gt;$\mathbf{X}_ {\text{1D}} \in \mathbb{R}^{T \times C}$: ì „ì²´ ì‹œê³„ì—´ ë°ì´í„°&lt;/li&gt;
  &lt;li&gt;$\text{FFT}(\cdot)$ëŠ” ê³ ì† í‘¸ë¦¬ì— ë³€í™˜ìœ¼ë¡œ ì£¼íŒŒìˆ˜ $f_i$ë¥¼ ì°¾ëŠ”ë‹¤&lt;/li&gt;
  &lt;li&gt;$\text{Amp}(\cdot)$: ì£¼íŒŒìˆ˜ $f_i$ì˜ ì§„í­ì„ ì°¾ëŠ” í•¨ìˆ˜&lt;/li&gt;
  &lt;li&gt;$\text{Avg}(\cdot)$: $C$ì°¨ì› ì‹œê³„ì—´ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ì§„í­ì˜ í‰ê·  ê³„ì‚°&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì•„ë˜ ì¼ë ¨ì˜ ê³¼ì •ì„ ê±°ì³ ê°•ë„(indensity) $\mathbf{A}$ë¥¼ ì–»ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\mathbf{A} = \text{Avg}\Bigl( \text{Amp}(\text{FFT}(\mathbf{X}_ {\text{1D}})) \Bigr), \quad \mathbf{A} \in \mathbb{R}^T$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_FFT.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì´ë•Œ $\mathbf{A}_ j$ëŠ” ì£¼íŒŒìˆ˜ê°€ $j$(ì£¼ê¸°ê°€ $\lceil T/j \rceil$ì´ë‹¤.)ì˜ intensityê°€ ëœë‹¤. ì£¼íŒŒìˆ˜ ì˜ì—­ì—ì„œ ì˜ë¯¸ì—†ëŠ” ê³ ì£¼íŒŒëŠ” noiseì´ë¯€ë¡œ ì´ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ top-$k$ì˜ ì§„í­ë§Œ ì‚¬ìš©í•˜ê¸°ë¡œ í•©ë‹ˆë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;${ f_1, \cdots, f_k} = \underset{f_* \in {1, \cdots , [\frac{T}{2}]}}{\text{argTopK}(\mathbf{A})}, \quad p_i = \Biggl\lceil\cfrac{T}{f_i} \Biggr\rceil, \quad i \in { 1, \cdots, k }$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ìœ„ ê³¼ì •ì„ ìš”ì•½í•˜ë©´, $\mathbf{X}_ {\text{1D}}$ë¡œë¶€í„° FFTë¥¼ ì´ìš©í•˜ì—¬ $k$ê°œì˜ ìœ ì˜ë¯¸í•œ ì§„í­($\mathbf{A}$), ì£¼íŒŒìˆ˜($f_i$), ì£¼ê¸°($p_i$)ë¥¼ ì–»ìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\mathbf{A}, {f_1, \cdots, f_k}, {p_1, \cdots, p_k} = \text{Period}(\mathbf{X}_ {\text{1D}})$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_convert2D.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;32-reshape-1d-time-series-to-2d-tensors&quot;&gt;3.2 Reshape 1D time series to 2D tensors&lt;/h2&gt;
&lt;p&gt;FFTë¡œ ì–»ì€ $f$ì™€ $p$ë¥¼ ì´ìš©í•˜ì—¬ $\mathbf{X}_ {\text{1D}}$ë¡œë¶€í„° $k$ê°œì˜ 2D-tensor $\mathbf{X}_ {\text{2D}}$ ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ $\text{Reshape}$ ê²°ê³¼ê°€ $p_i \times f_i$ ëª¨ì–‘ì´ ë˜ë„ë¡ zero-padding $\text{Padding}(\cdot)$ì´ í•„ìš”í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;$\mathbf{X}_ {\text{2D}}^i = \underset{p_i, f_i}{\text{Reshape}}(\text{Padding}(\mathbf{X}_ {\text{1D}})), \quad i \in { 1, \cdots, k }$&lt;/p&gt;

&lt;h2 id=&quot;33-timesblock&quot;&gt;3.3 TimesBlock&lt;/h2&gt;
&lt;p&gt;TimesBlock êµ¬ì¡°ëŠ” computer visionì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ResNetì˜ residual wayë¥¼ ì ìš©í•˜ì˜€ë‹¤. ë¨¼ì € raw data $\mathbf{X}_ {\text{1D}} \in  \mathbf{R}^{T \times C}$ë¥¼ ëª¨ë¸ ì°¨ì›ì— ë§ê²Œ ì„ë² ë”©í•˜ì—¬ $\mathbf{X}_ {\text{1D}}^0 \in \mathbb{R}^{T \times d_{\text{model}}}$ë¥¼ ì–»ê²Œë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\mathbf{X}_ {\text{1D}}^0 = \text{Embed}(\mathbf{X}_ {\text{1D}}). \quad \mathbf{X}_ {\text{1D}} \in  \mathbf{R}^{T \times C}, \ \mathbf{X}_ {\text{1D}}^0 \in \mathbb{R}^{T \times d_{\text{model}}}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ê·¸ ì´í›„ $l$ ë²ˆì§¸ layerë§ˆë‹¤ deep feature $\mathbf{X}_ {\text{1D}}^{l}$ë¥¼ êµ¬í•œë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\mathbf{X}_ {\text{1D}}^l = \text{TimesBlock}(\mathbf{X}_ {\text{1D}}^{l-1}) + \mathbf{X}_ {\text{1D}}^{l-1}$
TimesBlockì€ í¬ê²Œ 2ê°€ì§€ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    &lt;ol&gt;
      &lt;li&gt;2D-variation í¬ì°©&lt;/li&gt;
      &lt;li&gt;Adaptively aggregating representations&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Capturing temporal 2D-variations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;TimesNetì€ $\text{Reshape}(\cdot)$ë¡œ ë³€í™˜í•œ 2D-tensorë¥¼ multi-scale 2D kernelë¡œ í•™ìŠµí•©ë‹ˆë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\mathbf{X}_ {\text{2D}}^i = \underset{p_i, f_i}{\text{Reshape}}(\text{Padding}(\mathbf{X}_ {\text{1D}})), \quad i \in {1, \cdots, k}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì´ë•Œ ë‹¤ì–‘í•œ vision backboneì„ ì´ìš©í•  ìˆ˜ ìˆëŠ”ë°, ì €ìë“¤ì€ parameter-efficientí•œ inception blockì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\widehat{\mathbf{X}}_ {\text{2D}}^{l, i} = \text{Inception}(\mathbf{X}_ {\text{2D}}^{l, i}), \quad i \in {1, \cdots, k}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\text{Inception}(\cdot)$ì„ í†µí•´ í‘œí˜„ëœ $\widehat{\mathbf{X}}_ {\text{2D}}^{l, i}$ì€ ë‹¤ì‹œ 1Dë¡œ reshapeí•˜ê³  ê¸¸ì´ $T$ë¥¼ ë³´ì¡´í•˜ë„ë¡ $\text{Trunc}(\cdot)$ë¡œ íŒ¨ë”©ì„ ì œê±°í•©ë‹ˆë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\widehat{\mathbf{X}}_ {\text{1D}}^{l, i} = \text{Trunc}(\underset{1, \ (p_i \times f_i)}{\text{Reshape}}(\widehat{\mathbf{X}}_ {\text{2D}}^{l, i})), \quad i \in {1, \cdots, k }$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ê° $l$ë²ˆì§¸ layerë¥¼ í†µê³¼í•œ í›„ $k$ê°œì˜ 1D-representation ${\widehat{\mathbf{X}}_ {\text{1D}}^{l, 1}, \cdots, \widehat{\mathbf{X}}_ {\text{1D}}^{l, k}}$ì„ ì–»ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_TimesBlock_1.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Adaptive aggregateion&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Autoformer ëª¨ë¸ì´ ì œì•ˆëœ ë…¼ë¬¸ì—ì„œ, Auto-Correlationì€ ì§„í­ $\mathbf{A}$ëŠ” ì„ íƒëœ ì£¼íŒŒìˆ˜ì™€ ì£¼ê¸° $f, p$ì˜ ìƒëŒ€ì  ì¤‘ìš”ì„±ì„ ë°˜ì˜í•œë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œì•„ëƒˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì§„í­ì„ ê¸°ë°˜ìœ¼ë¡œ 1D-representationì„ ì§‘ê³„í•©ë‹ˆë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\widehat{\mathbf{A}}_ {f_1}^{l-1}, \cdots, \widehat{\mathbf{A}}_ {f_k}^{l-1} = \text{Softmax}\left(\mathbf{A}_ {f_1}^{l-1}, \cdots, \mathbf{A}_ {f_k}^{l-1} \right)$&lt;/li&gt;
  &lt;li&gt;$\mathbf{X}_ {\text{1D}}^l = \sum_{i=1}^{k} \widehat{\mathbf{A}}_ {f_i}^{l-1} \times \widehat{\mathbf{X}}_ {\text{1D}}^{l, i}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_TimesBlock_2.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Generality in 2D vision backbones&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ì €ìë“¤ì€ ë‹¤ì–‘í•œ computer vision backboneì¸ ResNet, ResNeXt, ConvNeXt ë“±ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë” ì¢‹ì€ 2D backboneì¼ ìˆ˜ë¡ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤. ì €ìë“¤ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ inception blockì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_cmp_backbones.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-experiment&quot;&gt;4. Experiment&lt;/h1&gt;
&lt;p&gt;ì €ìë“¤ì€ ì‹œê³„ì—´ ë¶„ì„ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” 5ê°€ì§€ ì£¼ì œì— ëŒ€í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ í‘œëŠ” 5ê°œ taskì— ëŒ€í•˜ì—¬ ì‚¬ìš©ëœ ë°ì´í„°ì…‹, í‰ê°€ì§€í‘œ ê·¸ë¦¬ê³  ì‹œê³„ì—´ ë°ì´í„° ê¸¸ì´ë¥¼ ë‚˜íƒ€ë‚¸ ê²ƒì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_exp_benchmarks.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;41-main-results&quot;&gt;4.1 Main Results&lt;/h2&gt;
&lt;p&gt;TimesNetì€ ì¥ê¸° ì˜ˆì¸¡, ë‹¨ê¸° ì˜ˆì¸¡, ê²°ì¸¡ì¹˜ ë³´ê°•, ë¶„ë¥˜, ì´ìƒì¹˜ íƒì§€ 5ê°œì˜ ì˜ì—­ì—ì„œ ëª¨ë‘ SOTAë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_5tasks_SOTA.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;42-shortlong-term-forecasting&quot;&gt;4.2 Short/Long-term Forecasting&lt;/h2&gt;
&lt;p&gt;TimesNet ì¥ê¸° ì˜ˆì¸¡ê³¼ ë‹¨ê¸° ì˜ˆì¸¡ ëª¨ë‘ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ ì¥ê¸° ì˜ˆì¸¡ì˜ ê²½ìš° 80%ì˜ ë°ì´í„°ì…‹ì—ì„œ SOTAë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë‹¨ê¸° ì˜ˆì¸¡ì— ì‚¬ìš©ëœ M4 ë°ì´í„°ì…‹ì˜ ê²½ìš° ë‹¤ì–‘í•œ ì¶œì²˜ì—ì„œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì–´ ì‹œê°„ì  ë³€ë™ì´ í¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ë‹¤ë¥¸ ëª¨ë¸ë“¤ ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_longterm.png?raw=true&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_shortterm.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;43-imputation&quot;&gt;4.3 Imputation&lt;/h2&gt;
&lt;p&gt;ê²°ì¸¡ì¹˜ ë•Œë¬¸ì—, ëª¨ë¸ì€ ë¶ˆê·œì¹™í•˜ê³  ë¶ˆì™„ì „í•œ ë°ì´í„° ì†ì—ì„œ ì‹œê°„ì  íŒ¨í„´ì„ ì°¾ì•„ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì–´ë ¤ìš´ ë¬¸ì œì…ë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  TimesNetì€ SOTAë¥¼ ë‹¬ì„±í•˜ì—¬ ê·¹ë‹¨ì ìœ¼ë¡œ ë³µì¡í•œ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì‹œê°„ì  ë³€ë™ì„ ì˜ í¬ì°©í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_imputation.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;44-classification&quot;&gt;4.4 Classification&lt;/h2&gt;
&lt;p&gt;ì‹œê³„ì—´ ë°ì´í„°ì˜ ë¶„ë¥˜ëŠ” ì¸ì§€ ë° ì˜ë£Œ ì§„ë‹¨ì— ì‚¬ìš©ë©ë‹ˆë‹¤. ì €ìë“¤ì€ UEA Time Series Classification Archiveì—ì„œ í–‰ë™, ë™ì‘ ë° ìŒì„± ì¸ì‹, ì‹¬ì¥ ë°•ë™ ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ì˜ë£Œ ì§„ë‹¨ ë“±ì˜ ì‹¤ì œ ì‘ì—…ì´ í¬í•¨ëœ ë‹¤ë³€ëŸ‰ ë°ì´í„°ì…‹ 10ê°œë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ëŸ° ë°ì´í„°ì…‹ì˜ í‘œì¤€ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•œ í›„ ì‹¤í—˜í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_clf.png?raw=true&quot; alt=&quot;image&quot; /&gt;
ê²°ê³¼ ì—­ì‹œ TimesNetì€ SOTAë¥¼ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤. ì£¼ëª©í•  ì ì€ ì¥ë‹¨ê¸° ì˜ˆì¸¡ì—ì„œ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ MLP-based ëª¨ë¸ë“¤ì€ ë¶„ë¥˜ì—ì„œëŠ” ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” TimesNetì´ ë³´ë‹¤ ë” ë†’ì€ ìˆ˜ì¤€ì˜ ì •ë³´ë¥¼ í‘œí˜„í•˜ê¸° ë•Œë¬¸ì— ê³„ì¸µ í‘œí˜„ì´ ìš”êµ¬ë˜ëŠ” ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì„±ëŠ¥ì´ ì¢‹ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;45-anomaly-detection&quot;&gt;4.5 Anomaly Detection&lt;/h2&gt;
&lt;p&gt;ì´ìƒì¹˜ íƒì§€ì—ì„œë„ TimesNetì€ SOTAë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ìƒì¹˜ íƒì§€ëŠ” ì´ìƒí•œ ì‹œê°„ì  ë³€ë™ì„ ì°¾ëŠ” ê²ƒì´ ìš”êµ¬ë˜ì§€ë§Œ, TransformerëŠ” attention-mechanism íŠ¹ì„±ìƒ ì •ìƒ ë°ì´í„°ê°€ ì˜í–¥ì„ ë§ì´ ë°›ê¸° ë•Œë¬¸ì— ì„±ëŠ¥ì´ ê·¸ë‹¤ì§€ ë†’ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_anomalydet.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;46-model-analysis&quot;&gt;4.6 Model Analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Representation analysis&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;TimesNetì€ ì˜ˆì¸¡ê³¼ ì´ìƒì¹˜ íƒì§€ì—ì„œ CKA ìœ ì‚¬ë„ê°€ ë†’ê³ , ê²°ì¸¡ì¹˜ ë³´ê°•ê³¼ ë¶„ë¥˜ì—ì„œ CKA ìœ ì‚¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. CKA ìœ ì‚¬ë„ê°€ ë‚®ë‹¤ëŠ” ê²ƒì€ ê° layerë¼ë¦¬ êµ¬ë³„ëœë‹¤ëŠ” ëœ»ì´ê³  ê³§ ê³„ì¸µì  í‘œí˜„(hierarchical representation)ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” TimesNetì´ imputationê³¼ classificationì—ì„œ ì„±ëŠ¥ì´ ë†’ì€ ì´ìœ ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë°˜ë©´ì—, FEDformerëŠ” ê³„ì¸µì  í‘œí˜„ í•™ìŠµì— ì‹¤íŒ¨í•˜ì—¬ ê²°ì¸¡ì¹˜ ë³´ê°•ê³¼ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•ŠìŒì´ ì„¤ëª…ë©ë‹ˆë‹¤.
&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_CKA_sim.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Temporal 2D-variations&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ê¸°ê°„ ê°„ ë³€ë™ì€ ì‹œê³„ì—´ì˜ ì¥ê¸° ì¶”ì„¸ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ëª…í™•í•œ ì£¼ê¸°ê°€ ì—†ëŠ” ì‹œê³„ì—´ì˜ ê²½ìš°ì—ë„ 2D-tensorëŠ” ì—¬ì „íˆ ìœ ìš©í•©ë‹ˆë‹¤. Exchange ë°ì´í„°ì…‹ì€ ëª…í™•í•œ ì£¼ê¸°ê°€ ì—†ì§€ë§Œ 2D-tensorì—ì„œ ì¥ê¸° ì¶”ì„¸ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ê° ì—´(ê¸°ê°„ ë‚´ ë³€ë™)ì˜ ì¸ì ‘í•œ ê°’ì€ ê°€ê¹Œìš´ ì‹œì ì˜ ì§€ì—­ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ê° í–‰(ê¸°ê°„ ê°„ ë³€ë™)ì˜ ì¸ì ‘í•œ ê°’ì€ ê¸°ê°„ ë¼ë¦¬ì˜ ì§€ì—­ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ëŸ¬í•œ ì§€ì—­ì„±ì€ í‘œí˜„ í•™ìŠµì— 2D-kernelì„ ì´ìš©í•˜ëŠ” ë™ê¸°ê°€ ë©ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2D-tensorë¥¼ ì‹œê°í™”ë©´ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ìŠµë‹ˆë‹¤.
&lt;img src=&quot;https://github.com/ahj1592/CourseMaterials/blob/main/DS503/Paper%20Review/images/TimesNet_temporal_2D_vars.png?raw=true&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;TimesNetì€ ì‹œê³„ì—´ ë¶„ì„ ì˜ì—­ì—ì„œ task-general foundation modelì…ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ë‹¤ì¤‘ ì£¼ê¸°ì„±ì„ ì´ìš©í•˜ì—¬ TimesNetì€ ì£¼ê¸°ë‚´ ë³€í™”ì™€ ì£¼ê¸°ê°„ ë³€í™” ëª¨ë‘ í¬ì°©í•©ë‹ˆë‹¤. (ë‹¤ì–‘í•œ ì‹œê°„ì  ë³€í™” í¬ì°©)&lt;/li&gt;
  &lt;li&gt;ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ ì‹¤í—˜ì—ì„œ TiemsNetì€ 5ê°€ì§€ taskì— SOTAë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Thu, 20 Apr 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/Temporal_2D_Variation_Modeling_for_General_Time_Series_Analysis.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/Temporal_2D_Variation_Modeling_for_General_Time_Series_Analysis.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[AAAI 2021] TabNet: Attentive Interpretable Tabular Learning</title>
            <description>&lt;h1 id=&quot;tabnet-attentive-interpretable-tabular-learning&quot;&gt;TabNet: Attentive Interpretable Tabular Learning&lt;/h1&gt;

&lt;p&gt;ë³¸ ë…¼ë¬¸ì˜ ì €ìëŠ” &lt;strong&gt;íŠ¸ë¦¬ ê¸°ë°˜ ì•™ìƒë¸” ëª¨ë¸&lt;/strong&gt;ë“¤ì´ ë”¥ëŸ¬ë‹ì— ë¹„í•´ &lt;strong&gt;ì •í˜• ë°ì´í„°&lt;/strong&gt;ì—ì„œ í•™ìŠµì— ë³´ë‹¤ ë…¼ë¦¬ì ì´ê³  í•©ë¦¬ì ì¸ ì ‘ê·¼ ë°©ë²•ì´ë¼ê³  ì†Œê°œí•©ë‹ˆë‹¤.   ì¼ë°˜ì ìœ¼ë¡œ ê´€ì¸¡ë˜ëŠ” ì •í˜• ë°ì´í„°ëŠ” ëŒ€ëµì ì¸ ì´ˆí‰ë©´(hyperplane) ê²½ê³„ë¥¼ ì§€ë‹ˆê³  ìˆëŠ” ë§¤ë‹ˆí´ë“œ(manifolds)ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©° ì´ ê³µê°„ì—ì„œëŠ” íŠ¸ë¦¬ ê¸°ë°˜ ì•™ìƒë¸” ëª¨ë¸ì˜ ê²°ì • ë°©ì‹ì´ ì´í•´(representation)í•˜ëŠ”ë° ë” ê°•ì ì„ ì§€ë‹ˆê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.   &lt;br /&gt;
 ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ TabNetì€ &lt;strong&gt;decision tree-based gradient boosting&lt;/strong&gt;ì˜ ì¥ì ì„ ì‚´ë¦° ì¸ê³µì‹ ê²½ë§ ì•„í‚¤í…ì³ì´ë©°, &lt;strong&gt;feature engineering&lt;/strong&gt;ê³¼ &lt;strong&gt;selection&lt;/strong&gt;ê¹Œì§€ í•¨ê»˜ í™œìš©í•  ìˆ˜ ìˆëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ &lt;strong&gt;í•´ì„ê°€ëŠ¥í•œ(interpretability)&lt;/strong&gt;, ì„¤ëª…ê°€ëŠ¥í•œ XAI(eXplainable Artificial Intelligence)ë¼ëŠ” ì ì—ì„œ í° ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;ë‘ê´„ì‹ìœ¼ë¡œ &lt;strong&gt;TabNetì˜ ì»¨ì…‰&lt;/strong&gt;ì„ ê°„ëµí•˜ê²Œ ì„¤ëª…í•˜ìë©´ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë©ë‹ˆë‹¤.&lt;br /&gt;
 â€œì…ë ¥ëœ ì •í˜•ë°ì´í„°(tabular data)ì—ì„œ Featureë¥¼ maskingí•˜ë©° ì—¬ëŸ¬ stepì„ ê±°ì³ì„œ í•™ìŠµâ€
      &lt;ul&gt;
        &lt;li&gt;ê° stepë³„ &lt;strong&gt;featureë“¤ì˜ importance&lt;/strong&gt; íŒŒì•… (ì„¤ëª…ë ¥ í™•ë³´)&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;masking ìœ¼ë¡œ ì¤‘ìš”í•œ feature ë“¤ë§Œ ì„ ì¶œ&lt;/strong&gt;í•´ì„œ í•™ìŠµí•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ (ëª¨ë¸ ê³ ë„í™”)&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;ì €í¬ ë¶„ì•¼ì—ì„œëŠ” ì •í˜•ë°ì´í„°ì¸ tabular dataë¥¼ í™œìš©í•œ ì—°êµ¬ê°€ ë§ì´ ì§„í–‰ë˜ëŠ” í¸ì´ì–´ì„œ, ë³¸ ë…¼ë¬¸ì„ í¥ë¯¸ë¡­ê²Œ ì½ì—ˆëŠ”ë°ìš”. ì •í˜•ë°ì´í„°ë¥¼ ë§ì´ í™œìš©í•˜ì‹œëŠ” ë¶„ì´ë¼ë©´ ë„ì›€ì´ ë  ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;1. Problem Definition&lt;/h2&gt;
&lt;p&gt;ê³¼ê±° ì •í˜• ë°ì´í„°ë¥¼ í™œìš©í•œ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ë¹„êµë¥¼ í–ˆì„ ë•Œ, &lt;strong&gt;&lt;em&gt;LightGBM&lt;/em&gt;&lt;/strong&gt;ì˜ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ë‹¤ê³  ì•Œë ¤ì ¸ìˆê³ , í˜¹ì€ ì•™ìƒë¸”ì„ ê³ ë ¤í•œ &lt;strong&gt;&lt;em&gt;Extreme Gradient Boosting&lt;/em&gt;&lt;/strong&gt; (&lt;strong&gt;&lt;em&gt;XGBoost&lt;/em&gt;&lt;/strong&gt;)ë‚˜ &lt;strong&gt;&lt;em&gt;Catboost&lt;/em&gt;&lt;/strong&gt;ì„ ë– ì˜¬ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”í•˜ì—¬ &lt;strong&gt;&lt;em&gt;Neural Network&lt;/em&gt;&lt;/strong&gt;ë¥¼ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì´ ìˆëŠ”ë°, ì •í˜• ë°ì´í„°ì˜ ê²½ìš°ì— &lt;em&gt;Neural Network&lt;/em&gt;ëŠ” ë³µì¡í•˜ê±°ë‚˜ ê¹Šì€ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì§€ ì•ŠëŠ” í¸ì´ë©°, ë” ê¹Šê±°ë‚˜ ë³µì¡í•˜ë‹¤ê³  ì„±ëŠ¥ì´ ëˆˆì— ë„ê²Œ ì¢‹ì•„ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;ì—¬ê¸°ì„œ ì ê¹!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;[&lt;strong&gt;LightGBMê³¼ ê¸°ì¡´ì˜ íŠ¸ë¦¬ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•œ ì¶”ê°€ ì„¤ëª…&lt;/strong&gt;]&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/82039869/237000522-a78be61f-9848-4031-9ed2-b03c61bf6e00.jpg&quot; alt=&quot;lightgbm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê¸°ì¡´ì˜ íŠ¸ë¦¬ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì€ &lt;strong&gt;&lt;em&gt;level wise&lt;/em&gt;&lt;/strong&gt;(ex : XGBoost) ë°©ì‹ì„ ì‚¬ìš©í–ˆê³ , ìµœëŒ€í•œ ê· í˜•ì´ ì¡íŒ íŠ¸ë¦¬ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë¶„í• í•˜ê¸° ë•Œë¬¸ì— treeì˜ ê¹Šì´ê°€ ìµœì†Œí™” ë  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆì—ˆì§€ë§Œ, ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•œ ì‹œê°„ì´ í•„ìš”í–ˆë‹¤. 
LightGBMì˜ &lt;strong&gt;&lt;em&gt;leaf wise&lt;/em&gt;&lt;/strong&gt; ë°©ì‹ì€ treeì˜ ê· í˜•ì„ ê³ ë ¤í•˜ì§€ ì•Šê³  ìµœëŒ€ ì†ì‹¤ê°’ì„ ê°€ì§€ëŠ” leaf nodeë¥¼ ì§€ì†ì ìœ¼ë¡œ ë¶„í• í•˜ë©´ì„œ ë¹„ëŒ€ì¹­ì ì¸ treeê°€ ìƒì„±ëœë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì€ level wise tree ë¶„í•  ë°©ì‹ë³´ë‹¤ ì˜ˆì¸¡ ì˜¤ë¥˜ ì†ì‹¤ì„ ìµœì†Œí™” í•  ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;PCA&lt;/em&gt;&lt;/strong&gt;ë¥¼ í™œìš©í•˜ì—¬ &lt;strong&gt;ì°¨ì›ì¶•ì†Œ&lt;/strong&gt;ë¥¼ í•˜ê±°ë‚˜, &lt;strong&gt;&lt;em&gt;autoencoder&lt;/em&gt;&lt;/strong&gt;ë¥¼ ê¸°ë°˜ìœ¼ë¡œ &lt;strong&gt;ë…¸ì´ì¦ˆë¥¼ ì œê±°&lt;/strong&gt;í•˜ëŠ” ë“±ì˜ ë°©ì‹ì— í™œìš©ì´ ë˜ëŠ” ê²ƒì´ ì£¼ ì˜€ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. &lt;br /&gt;
ë˜í•œ, &lt;strong&gt;&lt;em&gt;CNN, MLP&lt;/em&gt;&lt;/strong&gt;ì™€ ê°™ì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ì ì ˆí•œ ê·€ë‚©ì  í¸í–¥(&lt;em&gt;inductive bias&lt;/em&gt;)ì˜ ë¶€ì¡±ìœ¼ë¡œ ì§€ë‚˜ì¹˜ê²Œ &lt;strong&gt;&lt;em&gt;Overparametrized&lt;/em&gt;&lt;/strong&gt; ë˜ì–´ ì •í˜• ë°ì´í„° ë‚´ ë§¤ë‹ˆí´ë“œì—ì„œ ì¼ë°˜í™”ëœ í•´ê²°ì±…ì„ ì°¾ëŠ”ë° ì–´ë ¤ì›€ì„ ë°œìƒì‹œê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì´ëŸ° ë”¥ëŸ¬ë‹ í•™ìŠµ ë°©ë²•ë¡ ì„ ì •í˜• ë°ì´í„° í•™ìŠµì— ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” ì´ìœ ëŠ” ì´ë¯¸ì§€ë‚˜ ë‹¤ë¥¸ ì¢…ë¥˜ì— ë°ì´í„°ì™€ ì •í˜•ë°ì´í„°ë¥¼ í•¨ê»˜ í•™ìŠµ(&lt;em&gt;Multi-Modal&lt;/em&gt;)í•  ìˆ˜ ìˆìœ¼ë©° íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ ì„±ëŠ¥ì˜ í•µì‹¬ì¸ Feature Engineeringê³¼ ê°™ì€ ì‘ì—…ì´ í¬ê²Œ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë˜í•œ, ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° í•™ìŠµì´ ìš©ì´í•˜ê³  ì¢…ë‹¨ê°„(&lt;em&gt;end-to-end&lt;/em&gt;) ëª¨ë¸ì€ Domain adaptation, Generative modeling, Semi-supervised learningê³¼ ê°™ì€ ê°€ì¹˜ìˆëŠ” ì‘ìš© ëª¨ë¸ê³¼ ê°™ì€ í‘œí˜„ í•™ìŠµ(&lt;em&gt;representation learning&lt;/em&gt;)ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;2. Motivation&lt;/h2&gt;
&lt;p&gt;ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ìƒˆë¡œìš´ ê³ ì„±ëŠ¥ ë° í•´ì„ ê°€ëŠ¥í•œ í‘œì¤€ ì‹¬ì¸µ í…Œì´ë¸” í˜•ì‹ ë°ì´í„° í•™ìŠµ ì•„í‚¤í…ì²˜ ì¸ TabNetì„ ì œì•ˆí•©ë‹ˆë‹¤. TabNetì€ ì›ìë£Œì˜ ë‹¤ë¥¸ ì „ì²˜ë¦¬ ì—†ì´ ì…ë ¥í•  ìˆ˜ ìˆê³  ê²½ì‚¬í•˜ê°•ë²• ìµœì í™” ë°©ë²•ì„ í†µí•´ ìœ ì—°í•œ í†µí•©(flexible integration)ì´ ê°€ëŠ¥í•œ ì¢…ë‹¨ê°„(end-to-end) í•™ìŠµì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë˜í•œ, ìˆœì°¨ì ì¸ ì–´í…ì…˜(Sequential Attention)ì„ ì‚¬ìš©í•˜ì—¬ ê° ì˜ì‚¬ ê²°ì • ë‹¨ê³„ì—ì„œ ì¶”ë¡ í•  featureë“¤ì„ ì„ íƒí•©ë‹ˆë‹¤. ì´ë¡œì¸í•´ ë” ë‚˜ì€ í•´ì„ ëŠ¥ë ¥ê³¼ í•™ìŠµì´ ê°€ëŠ¥í•˜ë©° ìˆ¨ê²¨ì§„ íŠ¹ì§•ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì‚¬ì „ ë¹„ì§€ë„ í•™ìŠµì„ ì‚¬ìš©í•˜ì—¬ ì •í˜• ë°ì´í„°ì— ì¤‘ìš”í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤(&lt;em&gt;Self-supervised learning&lt;/em&gt;).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ TabNetì˜ ì°¨ë³„í™”ëœ ì•„ì´ë””ì–´ì™€ contributionì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
 1) ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì¹˜ì¹˜ ì•Šì€ &lt;strong&gt;raw dataë¡œë„ end-to-end í•™ìŠµì´ ê°€ëŠ¥&lt;/strong&gt;
 2) &lt;strong&gt;sequantial attention&lt;/strong&gt; ê³¼ì •ì—ì„œ &lt;strong&gt;ê° stepë§ˆë‹¤ ì¤‘ìš”í•œ featureë¥¼ ì„ ë³„&lt;/strong&gt;í•˜ë©´ì„œ ê° ê³¼ì •ì˜ ëª¨ë¸ í•´ì„ê³¼ ì„±ëŠ¥ í–¥ìƒì´ ê°€ëŠ¥ 
 3) &lt;strong&gt;ë‹¤ì–‘í•œ ë„ë©”ì¸ì˜ ë°ì´í„°&lt;/strong&gt;ì—ì„œ ë‹¤ë¥¸ í…Œì´ë¸” í•™ìŠµ ëª¨ë¸ê³¼ ë¹„êµ í–ˆì„ ë•Œ &lt;strong&gt;ë¶„ë¥˜/íšŒê·€ ë¬¸ì œì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥&lt;/strong&gt;ì„ ë³´ì„ 
 4) &lt;strong&gt;masking ëœ featureë¥¼ ì˜ˆì¸¡í•˜ëŠ” tabnet decoder ë¹„ì§€ë„ í•™ìŠµì„ í†µí•œ ìš°ìˆ˜í•œ ì„±ëŠ¥&lt;/strong&gt;ì„ ë³´ì„&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;3-method&quot;&gt;3. Method&lt;/h2&gt;
&lt;p&gt;ë³¸ê²©ì ìœ¼ë¡œ TabNet architectureë¥¼ ì‚´í´ë³´ê¸° ì „ì—, TabNetì˜ feature selection ë°©ë²•ê³¼, encoder, decoderì— ëŒ€í•œ ì„¤ëª…ì„ ê°„ëµíˆ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/82039869/237002064-d235dd1b-7c9e-4566-8fb3-fce2beedc122.jpg&quot; alt=&quot;image_revise1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê¸°ì¡´ì˜ Feature seletionì€ Lasso Regularization, Instance-wise feature selectionë“±ì˜ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì„ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Hard feature selectionìœ¼ë¡œ í‘œí˜„í•˜ê³  ìˆìœ¼ë©°, TabNetì€ Soft feature selectionì„ êµ¬í˜„í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ë©´, &lt;strong&gt;TabNetì€ masking&lt;/strong&gt;ì„ ì´ìš©í•˜ì—¬, ì¢Œì¸¡ì—ì„œ ìš°ì¸¡ìœ¼ë¡œ &lt;strong&gt;sequentialí•˜ê²Œ feature selection&lt;/strong&gt;ì„ í•˜ë©° í”¼ë“œë°±ì„ ì£¼ê³  í•™ìŠµí•´ë‚˜ê°€ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤ (&lt;em&gt;figure 1 ê·¸ë¦¼ ì°¸ì¡°&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/82039869/237002151-316bc441-2b50-44fd-b71b-1bc8b4f5d7e2.jpg&quot; alt=&quot;image_revise2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë”í•˜ì—¬ tabnet encoderë¥¼ í†µí•´ì„œ &lt;strong&gt;feature engineering&lt;/strong&gt;íš¨ê³¼ë¥¼ ë‚´ê³ , decision making ë¶€ë¶„ì„ í†µí•´ &lt;strong&gt;feature selection&lt;/strong&gt;ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. encoderëŠ” &lt;em&gt;fine-tuning&lt;/em&gt;í•˜ë©´ì„œ taskì— ë§ê²Œ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼œ ë§ì¶°ê°‘ë‹ˆë‹¤. &lt;br /&gt;
encoderì— decoder êµ¬ì¡° ê²°í•©í•˜ë©´ autoencoder ê°™ì€ ìê¸° í•™ìŠµ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆê³ , decoder ì—ì„œëŠ” ?(ë¬¼ìŒí‘œ) ë¡œ ëœ &lt;em&gt;missing value&lt;/em&gt; ë¥¼ ì±„ì›Œë„£ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;TabNet encoderì™€ decoderì˜ architectureë¥¼ ì¢€ ë” ìì„¸íˆ ì‚´í´ë³´ë©´ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/82039869/237002504-8ad61c75-433a-4376-b84d-a1de9464984d.jpg&quot; alt=&quot;image_revise3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìš°ì„  &lt;em&gt;Encoder&lt;/em&gt;ì™€ &lt;em&gt;Decoder&lt;/em&gt;ë¥¼ ê±°ì‹œì ìœ¼ë¡œ ì„¤ëª…í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;&lt;em&gt;Encoder&lt;/em&gt;&lt;/strong&gt;  &lt;br /&gt;
&lt;em&gt;Encoder&lt;/em&gt;ëŠ” ì—¬ëŸ¬ Desicion Stepìœ¼ë¡œ êµ¬ì„±ë˜ë©°, Step ë‚´ì˜ ë‘ê°€ì§€ ë¸”ë¡ì´ ì¡´ì¬í•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Feature transformer ë¸”ë¡ : ì„ë² ë”© ìˆ˜í–‰&lt;/li&gt;
    &lt;li&gt;Attentive transformer ë¸”ë¡ : trainable Mask ìƒì„±&lt;/li&gt;
    &lt;li&gt;Masked FeatureëŠ” ë‹¤ìŒ Stepì˜ Input featureê°€ ë˜ë©°, ì´ì „ stepì—ì„œ ì‚¬ìš©ë˜ì—ˆë˜ Maskì˜ ì •ë³´ë¥¼ í”¼ë“œë°±í•˜ê¸°ì— Featureì˜ ì¬ì‚¬ìš© ë¹ˆë„ë¥¼ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;&lt;strong&gt;&lt;em&gt;Decoder&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;em&gt;Decoder&lt;/em&gt;ì˜ ê° stepì€ feature transformer ë¸”ë¡ì—ì„œ FC layerë¡œ ì´ë£¨ì–´ì§€ê³  ê° step í•©ì‚°í•´ì„œ reconstructed feature ê²°ê³¼ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤. ë””ì½”ë” êµ¬ì¡°ë¥¼ í†µí•´ ê²°ì¸¡ì¹˜ ë³´ê°„ íš¨ê³¼ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;ì¶”ê°€ì ìœ¼ë¡œ &lt;em&gt;Encoder&lt;/em&gt;ì™€ &lt;em&gt;Decoder&lt;/em&gt;ì— ëŒ€í•´ ìì„¸íˆ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;(a) : TabNet encoder&lt;/strong&gt; ì˜ ê²½ìš°, ê° decision stepì— ëŒ€í•´ì„œ &lt;strong&gt;&lt;em&gt;1)feature transformer, 2)attentive transformer, 3)feature masking&lt;/em&gt;&lt;/strong&gt;ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  &lt;br /&gt;
ì²« ì˜ì‚¬ê²°ì • ë‹¨ê³„ì—ì„œ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ë‹¤ìŒ ì˜ì‚¬ê²°ì • ë‹¨ê³„ì—ì„œ ë³´ì™„í•˜ëŠ” ë°©ì‹ì´ë©°, íŠ¸ë¦¬ê¸°ë°˜ ë¶€ìŠ¤íŒ… ëª¨ë¸ë“¤ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.
ëª¨ë¸ì˜ ìš©ì–´ë¥¼ ì¢€ ë” êµ¬ì²´ì ì„ ì„¤ëª…í•˜ë©´, BN : ìµœì´ˆ Featureì— ëŒ€í•´ ë°°ì¹˜ ì •ê·œí™”ë¥¼ ì ìš©
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;&lt;em&gt;Feature transformer&lt;/em&gt;&lt;/strong&gt; : ì´í›„ì— ì•„ë˜ì˜ ë‹¨ê³„ ë°˜ë³µ.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;&lt;em&gt;Attentive transformer&lt;/em&gt;&lt;/strong&gt; : (d)ì—ì„œ ì„¤ëª…&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;&lt;em&gt;Mask&lt;/em&gt;&lt;/strong&gt; : Attentive transformerì—ì„œ ë‚˜ì˜¨ &lt;strong&gt;&lt;em&gt;Mask&lt;/em&gt;&lt;/strong&gt;(&lt;strong&gt;&lt;em&gt;M[i]&lt;/em&gt;&lt;/strong&gt;)ì— ëŒ€í•´ feature &lt;strong&gt;&lt;em&gt;f&lt;/em&gt;&lt;/strong&gt;ë¥¼ ê³±í•˜ì—¬ ì´í›„ stepì˜ &lt;em&gt;Feature transformer&lt;/em&gt;ì— ë“¤ì–´ê°€ëŠ” inputì„ ì¡°ì ˆ. Maskë¥¼ í†µí•´ ë³€ìˆ˜ë¥¼ soft selection í•¨.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;&lt;em&gt;Feature transformer&lt;/em&gt;&lt;/strong&gt; : (c)ì—ì„œ ì„¤ëª…&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;&lt;em&gt;Split&lt;/em&gt;&lt;/strong&gt; : Feature transformerì˜ outputì„ ë‘ ê°œë¡œ ë³µì œí•˜ì—¬ í•˜ë‚˜ëŠ” &lt;em&gt;relu&lt;/em&gt;ë¡œ, í•˜ë‚˜ëŠ” &lt;em&gt;Attentive transformer&lt;/em&gt;ë¡œ ë³´ëƒ„&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;&lt;strong&gt;(b) : TabNet decoder&lt;/strong&gt;ëŠ” ê° ë‹¨ê³„ì—ì„œ feature transformer ë¸”ë¡ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì¼ë°˜ í•™ìŠµì—ì„œëŠ” Decoderë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , self-supervised í•™ìŠµì„ ì§„í–‰í•  ë•Œ, ì¸ì½”ë” ë‹¤ìŒì— ë¶™ì—¬ì ¸ì„œ ê¸°ì¡´ì˜ ê²°ì¸¡ê°’ì„ ë³´ì™„í•˜ê³  í‘œí˜„í•™ìŠµì„ ì§„í–‰í•˜ê²Œ ë©ë‹ˆë‹¤.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;(c) Feature Transformer&lt;/strong&gt;ëŠ” 4ê°œì˜ ë„¤íŠ¸ì›Œí¬ ë¬¶ìŒìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;&lt;em&gt;Fully Connected Layer&lt;/em&gt;&lt;/strong&gt; (&lt;strong&gt;FC&lt;/strong&gt;) - &lt;strong&gt;&lt;em&gt;Batch Normalization&lt;/em&gt;&lt;/strong&gt; (&lt;strong&gt;BN&lt;/strong&gt;) - &lt;strong&gt;&lt;em&gt;Gated Linear Unit Activation&lt;/em&gt;&lt;/strong&gt; (&lt;strong&gt;GLU&lt;/strong&gt;)ë¡œ êµ¬ì„±ëœ ë¸”ëŸ­ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ í†µê³¼í•˜ëŠ” êµ¬ì¡°ë¥¼ ìŒ“ê³ , ë¸”ëŸ­ê°„ì˜ &lt;em&gt;residual skip connecion&lt;/em&gt;ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.&lt;/li&gt;
        &lt;li&gt;ê·¸ë¦¬ê³  &lt;em&gt;residual output&lt;/em&gt;ì˜ &lt;em&gt;normalization&lt;/em&gt;ì„ ìœ„í•´ &lt;strong&gt;&lt;em&gt;sqrt&lt;/em&gt;&lt;/strong&gt;(&lt;strong&gt;&lt;em&gt;0.5&lt;/em&gt;&lt;/strong&gt;)ë¥¼ ê³±í–ˆìŠµë‹ˆë‹¤. ì´ë•Œ, ë‘ ë ˆì´ì–´ëŠ” ëª¨ë“  &lt;em&gt;decision&lt;/em&gt; ë‹¨ê³„ì—ì„œ ê³µìœ ë˜ë©°, ë‚˜ë¨¸ì§€ ë‘ ë ˆì´ì–´ëŠ” &lt;em&gt;decision&lt;/em&gt; ë‹¨ê³„ì— ì˜ì¡´í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì• 2ê°œì˜ ë„¤íŠ¸ì›Œí¬ëŠ” ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ê³µìœ í•˜ë©° &lt;strong&gt;ê¸€ë¡œë²Œ ì„±í–¥&lt;/strong&gt;ì„ í•™ìŠµí•˜ê³ , ë’¤ì— 2ê°œì˜ ë„¤íŠ¸ì›Œí¬ ê·¸ë£¹ì€ &lt;strong&gt;ë¡œì»¬ ì„±í–¥&lt;/strong&gt;ì„ í•™ìŠµí•©ë‹ˆë‹¤. 
ì´ì–´ì„œ &lt;strong&gt;D&lt;/strong&gt;ê°œì˜ ë³€ìˆ˜ë¥¼ ê°–ëŠ” ê°’ë“¤ì„ ì…ë ¥ë°›ì€ &lt;em&gt;feature transformer&lt;/em&gt;ëŠ” &lt;strong&gt;&lt;em&gt;split&lt;/em&gt;&lt;/strong&gt;í•  ê°’ë“¤ì„ ë‚´ë³´ëƒ…ë‹ˆë‹¤. ì´(&lt;strong&gt;B,N&lt;/strong&gt;)ì˜ &lt;em&gt;output&lt;/em&gt;ì„ ë‚´ë³´ëƒˆì„ ë•Œ, ë…¼ë¬¸ì—ì„œëŠ” &lt;em&gt;split&lt;/em&gt; ê³¼ì •ì„ í†µí•´ &lt;em&gt;d&lt;/em&gt;[&lt;em&gt;i&lt;/em&gt;]ì™€ &lt;em&gt;a&lt;/em&gt;[&lt;em&gt;i&lt;/em&gt;]ë¡œ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;(d) Attnetive transformer&lt;/strong&gt; ë¸”ë¡ìœ¼ë¡œ, í˜„ì¬ ì˜ì‚¬ê²°ì • ë‹¨ê³„ì—ì„œ ê° ë³€ìˆ˜ë“¤ì´ ì–¼ë§ˆë‚˜ ë§ì€ ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ ì‚¬ì „ ì •ë³´ëŸ‰(&lt;em&gt;prior scale information&lt;/em&gt;)ì„ í†µí•´ ì§‘ê³„í•©ë‹ˆë‹¤. ë‹¤ì‹œë§í•´, í˜„ì¬ decision step ì „ì— ê° featureê°€ ì–¼ë§ˆë‚˜ ë§ì´ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ë¥¼ ì§‘ê³„í•œ ì •ë³´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ê²ƒì€ ë‹¨ì¼ ë ˆì´ì–´ì— ë§µí•‘í•˜ì—¬ ì‚¬ìš©ë˜ë©°, ê³„ìˆ˜ì˜ ì •ê·œí™”ëŠ” ê° decision stepì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§„ íŠ¹ì§•ì„ &lt;strong&gt;&lt;em&gt;sparse&lt;/em&gt;&lt;/strong&gt;í•˜ê²Œ ì„ íƒí•˜ê³ , ê³„ìˆ˜ê°’ë“¤ì„ ì¼ë°˜í™”(&lt;em&gt;normalization&lt;/em&gt;)í•˜ê¸° ìœ„í•´ &lt;strong&gt;&lt;em&gt;sparsemax&lt;/em&gt;&lt;/strong&gt;ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµë˜ì–´ì§‘ë‹ˆë‹¤.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;4. Experiment&lt;/h2&gt;
&lt;p&gt;ë³¸ ë…¼ë¬¸ì—ì„œëŠ” regression, classification taskë¡œ ì„±ëŠ¥ì„ í‰ê°€í•˜ì˜€ê³ , ë°ì´í„° ì…‹ì˜ ëª¨ë“  categorical value ë“¤ì€ ì„ë² ë”©ë˜ì—ˆê³ , numerical valueë“¤ì€ ì „ì²˜ë¦¬ ì—†ì´ inputìœ¼ë¡œ í™œìš©ë˜ì—ˆìŠµë‹ˆë‹¤. TabNetì€ ëŒ€ë¶€ë¶„ì˜ &lt;em&gt;hyperparameter&lt;/em&gt;ì— ëŒ€í•´ ê·¸ë¦¬ ì˜ˆë¯¼í•˜ì§€ ì•Šë‹¤ëŠ” íŠ¹ì§•ì„ ê°€ì§‘ë‹ˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Instance-wise feature selection&lt;/strong&gt; (synthetic dataset - ì„ì˜ë¡œ ìƒì„±í•œ ë°ì´í„°ì…‹ í™œìš©)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/82039869/237002742-68b8810f-fd98-4077-81c3-799524d74314.jpg&quot; alt=&quot;image_revise4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Table 1ì˜ ê²°ê³¼ë¥¼ ê°„ëµíˆ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;6ê°œ ì„ì˜ë¡œ ìƒì„±ëœ ë°ì´í„°ë¡œ ì„±ëŠ¥ì„ í‰ê°€&lt;/strong&gt; â€“&amp;gt; syn1 ~ syn 6 ë°ì´í„°&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;syn 1~3 ì—ì„œëŠ” ê° ì¸ìŠ¤í„´ìŠ¤(data row) ë³„ë¡œ ì¤‘ìš”í•œ í”¼ì³ê°€ ê°™ìŒ&lt;/strong&gt; â€“&amp;gt; ë”°ë¼ì„œ syn 1~3 ì—ì„œëŠ” Tabnet ì˜ ì„±ëŠ¥ì´ global feature selection í•˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ë“¤ê³¼ ì„±ëŠ¥ì´ ë¹„ìŠ·&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;syn 4~6 ì—ì„œëŠ” ê° ì¸ìŠ¤í„´ìŠ¤(data row) ë³„ë¡œ ì¤‘ìš”í•œ í”¼ì³ê°€ ë‹¤ë¦„&lt;/strong&gt; â€“&amp;gt; ë”°ë¼ì„œ ë¶ˆí•„ìš”í•œ featureë“¤ì„ instance wiseë¡œ ì œê±°í•´ì„œ ì„±ëŠ¥ì„ í–¥ìƒ&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Performance on real-world datasets&lt;/strong&gt; (ì‹¤ì œ ë°ì´í„°ì…‹ í™œìš©)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/82039869/237004066-0d97d137-2837-47c2-8357-128642572409.jpg&quot; alt=&quot;image_revise5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Forest cover type dataset&lt;/em&gt;&lt;/strong&gt;  : ë‚˜ë¬´ ë¶„ë¥˜ ë¬¸ì œ / &lt;strong&gt;&lt;em&gt;Poker Hand&lt;/em&gt;&lt;/strong&gt; : ì¹´ë“œ ë¶„ë¥˜ ë¬¸ì œ / &lt;strong&gt;&lt;em&gt;Sarcos&lt;/em&gt;&lt;/strong&gt; : ë¡œë´‡ íŒ” ê´€ë ¨ ë°ì´í„° / &lt;strong&gt;&lt;em&gt;Higgs Boson&lt;/em&gt;&lt;/strong&gt; : ì´ì§„ ë¶„ë¥˜ ë¬¸ì œ /&lt;strong&gt;&lt;em&gt;Rossman Store Sales&lt;/em&gt;&lt;/strong&gt; : ìƒì  ë§¤ì¶œ ì˜ˆì¸¡&lt;/p&gt;

&lt;p&gt;ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ &lt;em&gt;XGBoost, LightGBM, Random forest, MLP&lt;/em&gt; ë“± ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ì˜ ë¹„êµ ê²°ê³¼, &lt;strong&gt;Test accuracy, MSE ë“±ì˜ í‰ê°€ì§€í‘œ&lt;/strong&gt;ì—ì„œ TabNetì´ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì— ë¹„í•´ &lt;strong&gt;ì¢‹ì€ ì„±ëŠ¥&lt;/strong&gt;ì„ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë˜í•œ ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ ê·¸ë¦¼(&lt;em&gt;Figure 5&lt;/em&gt;)ì„ í†µí•´ ì•Œ ìˆ˜ ìˆë“¯ì´, ê° ìŠ¤í…ì—ì„œ í™œì„±í™”ëœ &lt;strong&gt;feature ë¥¼ ì‹œê°í™”&lt;/strong&gt;ë¡œ í™•ì¸í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆê³ , &lt;strong&gt;instance ë³„ ì¤‘ìš”ë„&lt;/strong&gt; ë˜í•œ í™•ì¸ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/82039869/237004512-34c5c360-5f8f-423a-8de5-a5d2f700ae5c.jpg&quot; alt=&quot;image_revise6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ë¦¼ì˜ í•˜ì–€ìƒ‰ ë¶€ë¶„ì´ ëª¨ë¸ í•™ìŠµì— ì‚¬ìš© featureë¼ê³  í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. &lt;br /&gt;
ê°„ë‹¨íˆ ì„¤ëª…í•´ë³´ìë©´, &lt;em&gt;Syn2 dataset&lt;/em&gt;ì—ì„œëŠ” &lt;strong&gt;&lt;em&gt;feature X3-X6&lt;/em&gt;&lt;/strong&gt; ë§Œ í™œìš© ë˜ì—ˆìœ¼ë©° &lt;strong&gt;&lt;em&gt;Magg&lt;/em&gt;&lt;/strong&gt; ëŠ” ê° ìŠ¤í…ì˜ &lt;strong&gt;feature importanceë¥¼ ê²°í•©&lt;/strong&gt; í–ˆì„ ë•Œ ë‚˜ì˜¤ëŠ” ê²°ê³¼ë¥¼ &lt;strong&gt;ì‹œê°í™”&lt;/strong&gt; í•œ ê²ƒì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;ì €ìëŠ” &lt;em&gt;tabular learning&lt;/em&gt;ì„ ìœ„í•œ ì°¸ì‹ í•œ ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ì¸ &lt;strong&gt;&lt;em&gt;TabNet&lt;/em&gt;&lt;/strong&gt;ì„ ì œì‹œí–ˆìœ¼ë©°, TabNetì€ ê° ê²°ì • ë‹¨ê³„ì—ì„œ ì²˜ë¦¬í•  ì˜ë¯¸ ìˆëŠ” ë³€ìˆ˜ì˜ subsetì„ ì„ íƒí•˜ê¸° ìœ„í•´ &lt;strong&gt;&lt;em&gt;sequential attention mechanism&lt;/em&gt;&lt;/strong&gt;ì„ í™œìš©í–ˆìŠµë‹ˆë‹¤. ì„ íƒëœ íŠ¹ì§•ë“¤ì€ &lt;em&gt;representation&lt;/em&gt;ìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ì„œ ë‹¤ìŒ ê²°ì • ë‹¨ê³„ì—ì„œ ì •ë³´ë¥¼ ë³´ë‚´ê³  ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. &lt;strong&gt;&lt;em&gt;Instance-wise feature selection&lt;/em&gt;&lt;/strong&gt;ì€ &lt;em&gt;model capacity&lt;/em&gt;ë¡œì¨ íš¨ìœ¨ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤ê³  ì •ë¦¬í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ì €ì˜ ê°œì¸ì ì¸ ì†Œê²¬ìœ¼ë¡œëŠ”, ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰ëœ ê²ƒê³¼ ê°™ì´ &lt;strong&gt;ì •í˜• ë°ì´í„°ë³´ë‹¤ëŠ” ë¹„ì •í˜• ë°ì´í„°ì— ë§ì´ ì§‘ì¤‘&lt;/strong&gt;ë˜ì–´ ê°œë°œë˜ì–´ ìˆëŠ” ìƒíƒœë¼ê³  ìƒê°í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë¹„ì •í˜•ë°ì´í„°ì—ì„œ ì„±ëŠ¥ì„ ë†’ì¸ ëª¨ë¸ì„ ì •í˜•ë°ì´í„°ì— ì ìš©í•˜ê¸°ì—ëŠ” ì´ë¡ ì´ ë§ì§€ ì•Šë‹¤ê³  ìƒê°í–ˆëŠ”ë°, ë³¸ ëª¨ë¸ì—ì„œ ëŒ€ì•ˆìœ¼ë¡œ &lt;strong&gt;&lt;em&gt;attention mechanism&lt;/em&gt;&lt;/strong&gt;ì´ë¼ê³  í•˜ëŠ” ë°©ë²•ì´ ì œì‹œë˜ì–´ ë„ˆë¬´ ì¢‹ì•˜ìŠµë‹ˆë‹¤. ë˜í•œ ë³¸ ëª¨ë¸ì„ í™œìš©í•œë‹¤ë©´ ì „ì²˜ë¦¬ì˜ í•„ìš”ì„±ì´ ì¤„ì–´ë“¤ê³ , &lt;strong&gt;&lt;em&gt;tree-based model&lt;/em&gt;&lt;/strong&gt;ì²˜ëŸ¼ í™œìš©í•  ìˆ˜ ìˆëŠ” ê²ƒì´ ë˜ í•˜ë‚˜ì˜ ì¥ì ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.  &lt;br /&gt;
ë§ˆì§€ë§‰ìœ¼ë¡œ ë³´í†µì€ ë”¥ëŸ¬ë‹ì„ í•´ì„í•˜ê³  í‰ê°€í•˜ê¸° ìœ„í•´ &lt;em&gt;surrogate model&lt;/em&gt;ë¡œ ëŒ€ì²´í•˜ëŠ”ë°, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” &lt;strong&gt;í•´ì„ê°€ëŠ¥ì„± ë°©ì‹&lt;/strong&gt;ì„ í™œìš©í•˜ì—¬ êµ¬í˜„í•œ ê²ƒì´ ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤. ì•„ì£¼ ì‘ì€ ì½”ë©˜íŠ¸ë¡œëŠ”, ì‹ ê²½ë§ëª¨ë¸ ì¹˜ê³ ëŠ” ì¡°ì ˆí•´ì•¼í•  íŒŒë¼ë¯¸í„°ê°€ ì¡°ê¸ˆ ë§ì•„ &lt;em&gt;parameter search&lt;/em&gt;í•˜ëŠ”ë° ì‹œê°„ì´ ì†Œìš” ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤. &lt;br /&gt;
í•˜ì§€ë§Œ ì •í˜• ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ ì—°êµ¬ë‚˜ ë°©ë²•ë¡ ì´ í•œì •ì ì´ë¼ê³  ìƒê°í–ˆì—ˆëŠ”ë° ëì—†ì´ ë°œì „í•˜ê³  ìˆë‹¤ëŠ” ìƒê°ì´ ë“œëŠ” ë…¼ë¬¸ì´ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ &lt;strong&gt;&lt;em&gt;tabular data&lt;/em&gt;&lt;/strong&gt;ë¥¼ í™œìš©í•œ ì—°êµ¬ë¥¼ ë§ì´ ì§„í–‰í•˜ê³  ìˆëŠ” ì…ì¥ìœ¼ë¡œ TabNetì„ ì €í¬ ì—°êµ¬ë¶„ì•¼ì— ì ìš©í•˜ê¸° ìœ„í•´ ì½”ë“œ ë° êµ¬ì¡°ë¥¼ ë”ìš±ë” ê¼¼ê¼¼íˆ ë°°ì›Œì•¼ ê² ë‹¤ëŠ” ìƒê°ì„ í–ˆìŠµë‹ˆë‹¤.
ëª¨ë‘ í•œë²ˆ ì½ì–´ë³´ì„¸ìš”~! :)&lt;/p&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;6. Reference &amp;amp; Additional materials&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;TabNet ë…¼ë¬¸íŒŒì¼ê³¼, Github - tensorflow, torchë¡œ êµ¬í˜„ëœ ì½”ë“œ ë§í¬ë¥¼ í•¨ê»˜ ì²¨ë¶€ë“œë¦½ë‹ˆë‹¤.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1908.07442&quot;&gt;TabNet ë…¼ë¬¸&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/google-research/google-research/tree/master/tabnet&quot;&gt;TabNet tensorflow code&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/qlib/blob/main/qlib/contrib/model/pytorch_tabnet.py&quot;&gt;TabNet torch code&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Thu, 20 Apr 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/TabNet_Attentive_Interpretable_Tabular_Learning.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/TabNet_Attentive_Interpretable_Tabular_Learning.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[Nature Machine Intelligence 2022] Super-resolution generative adversarial networks of randomly-seeded fields</title>
            <description>&lt;h1 id=&quot;paper-title--super-resolution-generative-adversarial-networks-of-randomly-seeded-fields&quot;&gt;Paper title : Super-resolution generative adversarial networks of randomly-seeded fields&lt;/h1&gt;

&lt;h2 id=&quot;1introdcution&quot;&gt;1.introdcution&lt;/h2&gt;
&lt;h3 id=&quot;11-problem-definition&quot;&gt;1.1 Problem definition&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;ê¸°ê³„&quot;ëŠ” ì¢…ì¢… ì‚¶ì„ ì¢€ ë” í¸ë¦¬í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì‚´ì•„ê°ˆ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë°©ë²• í˜¹ì€ ë„êµ¬ë¡œ ì •ì˜ëœë‹¤. ë§ì€ ê³µí•™ (engineering) ë¶„ì•¼ì—ì„œ ì´ëŸ¬í•œ ë„êµ¬ë¥¼ ìµœì í™”í•˜ê¸° ìœ„í•´ ë§ì€ ì—°êµ¬ë“¤ì´ ìˆ˜í–‰ë˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ, ë”¥ëŸ¬ë‹ ë°©ë²•ë¡ ì´ ê³µí•™ ë¶„ì•¼ì— ì–´ë–¤ ì‹ìœ¼ë¡œ ë”ìš± íš¨ìœ¨ì ì¸ ë„êµ¬ë¥¼ ê°œë°œí•˜ê¸° ìœ„í•´ ì ìš©ë˜ëŠ”ì§€ ë³¸ ë¦¬ë·° ë…¼ë¬¸ì„ í†µí•´ ì†Œê°œí•˜ë ¤ê³  í•œë‹¤.

ë³¸ ìˆ˜ì—…ì„ ìˆ˜ê°•í•˜ëŠ” ëŒ€ë¶€ë¶„ì˜ data scienctistsì˜ peer reviewerë“¤ ìœ„í•´, ê³µí•™ ë¶„ì•¼ì— ì‚¬ìš©ë˜ëŠ” ë¬¼ë¦¬ì ì¸ ë°©ì •ì‹ì— ëŒ€í•œ ì„¸ë¶€ì ì¸ ë‚´ìš©ì€ ìµœëŒ€í•œ ì¤„ì´ê³ , &quot;ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì˜ ê³µí•™ ë¶„ì•¼ì— ì ìš© ê°€ëŠ¥ì„±&quot;ì„ ì¤‘ì ìœ¼ë¡œ ë³¸ ë¦¬ë·°ë¥¼ ì´ì–´ê°€ë ¤ê³  í•œë‹¤. ìš°ì„ , í˜„ì‹¤ì ìœ¼ë¡œ ê°€ì¥ ì™€ë‹¿ëŠ” ì˜ˆì‹œë¡œì¨, ì•„ë˜ ê·¸ë¦¼ 1ê³¼ ê°™ì´, ëŒ€ë¶€ë¶„ì˜ ì‚¬ëŒë“¤ì€ í•˜ë£¨ë¥¼ ì‹œì‘í•˜ê¸° ì „ì— ê¸°ìƒ, ë‚ ì”¨ í˜¹ì€ ë¯¸ì„¸ë¨¼ì§€ê°€ ì–¼ë§ˆë‚˜ ë†’ì€ì§€ ê²€ìƒ‰ì„ í•´ë³´ê³¤ í•œë‹¤. ì´ëŠ” íŠ¹ì • ì§€ì—­ì—ì„œ ê¸°ê³„ ì¥ë¹„ (sensor)ì˜ ì¸¡ì • (measurement)ì„ í†µí•´ ì–»ì–´ì§„ í’ëŸ‰, ì˜¨ë„, ê¸°ì••ê³¼ ê°™ì€ ë°ì´í„° ì •ë³´ë“¤ì„ ì¢…í•©í•œ ì˜ˆë³´ë¥¼ í†µí•´ ì¸ê°„ì˜ ì‚¶ì„ ìì—° ì¬í•´ë¡œ ë¶€í„° ëŒ€ë¹„í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ì¤€ë‹¤.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/images_DS503/figure_1.gif&quot; alt=&quot;example image&quot; width=&quot;500&quot; height=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;center&gt;ê·¸ë¦¼ 1. ì„¼ì„œ ì¥ë¹„ì— ì˜í•´ ì¸¡ì •ëœ ë°ì´í„° ì •ë³´ ì˜ˆì‹œ &lt;/center&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;í•˜ì§€ë§Œ, ì´ëŸ¬í•œ ê¸°ê³„ ì¥ë¹„ëŠ” ì •í™•ë„ê°€ ë†’ê³  ì •ë°€í•œ ë°ì´í„°ë¥¼ ì–»ê¸° ìœ„í•´ ë‹¤ì–‘í•˜ê³  ë³µì¡í•œ ì „ì ì¥ë¹„ë¥¼ ë™ë°˜í•˜ê¸° ë•Œë¬¸ì— í° ì„¤ì¹˜ ë¹„ìš©ì´ ë°œìƒí•œë‹¤. ì´ì— ë”°ë¼, ê´€ì‹¬ ìˆëŠ” ì§€ì—­ì— ê³µê°„ì ìœ¼ë¡œ ê±°ë¦¬ê°€ ë¨¼ (Sparse) ì„¼ì„œ ì¥ë¹„ ì„¤ì¹˜ë¥¼ í•˜ê³ , íŠ¹ì • ìœ„ì¹˜ì—ì„œ ì¸¡ì •ëœ ê°’ì„ ë„“ì€ ì˜ì—­ì„ ëŒ€í‘œí•˜ëŠ” ë°©ì‹ì„ ì±„íƒí•˜ì—¬ í•´ìƒë„ê°€ ì ì€ (low-resolution) ê²°ê³¼ë¥¼ ì œê³µí•œë‹¤. ì¦‰, ì‚¬ëŒì´ í™œë™í•˜ê³  ìˆëŠ” í•´ìƒë„ê°€ ë†’ì€ (high-resolution) ë‹¤ì–‘í•œ ê³µê°„ ë‚´ ì •ë³´ë¥¼ ì¡°ë°€í•˜ê²Œ ë°°ì¹˜ëœ ì„¼ì„œ ì¥ë¹„ë¥¼ í†µí•´ ì–»ëŠ” ê²ƒì€ í˜„ì‹¤ì ìœ¼ë¡œ í° ë¹„ìš© ë¬¸ì œê°€ ë°œìƒí•œë‹¤.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;12-neural-network-methodology&quot;&gt;1.2 Neural network methodology&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ì´ëŸ¬í•œ ë¹„ìš©-ê³µê°„ í•´ìƒë„ ì‚¬ì´ ì ˆì¶© (trade-off) ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì¸ê³µì‹ ê²½ë§ (neural-network) ê¸°ë°˜ ë°©ë²•ë¡ ì´ ì €í•´ìƒë„ ë°ì´í„°ì™€ ê³ í•´ìƒë„ ë°ì´í„° ì‚¬ì´ ë¹„ì„ í˜• (nonlinear) ê´€ê³„ì„±ì„ ì—°ê²°í•˜ëŠ”ë° íš¨ìœ¨ì ì´ê³  ì„±ê³µì ì¸ ê²°ê³¼ë¥¼ ë³´ì´ëŠ” ë„êµ¬ë¡œ ì¦ëª…ë˜ê³  ìˆë‹¤. ë”¥ëŸ¬ë‹ ë°©ë²•ë¡ ì´ ì €í•´ìƒë„ì™€ ê³ í•´ìƒë„ ì‚¬ì´ ëª¨ë¸ë§ì— ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€ ì„¤ëª…í•˜ê¸° ìœ„í•´ ì•„ë˜ ê·¸ë¦¼ 2ì„ í†µí•´ ë‚˜íƒ€ë‚´ê³ ì í•œë‹¤. ëŒ€í‘œì ìœ¼ë¡œ, ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì…ë ¥ì€ ê´€ì‹¬ ìˆëŠ” ì§€ì—­ì— ê³µê°„ì ìœ¼ë¡œ ê±°ë¦¬ê°€ ë¨¼ (Sparse) ì„¼ì„œ ì¥ë¹„ ì •ë³´ì´ê³  ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì¶œë ¥ì€ í•´ìƒë„ê°€ ë†’ì€ (high-resolution) ë‹¤ì–‘í•œ ê³µê°„ ë‚´ ì •ë³´ë¡œ ì„¤ì •í•˜ì—¬ ë‘ ì‚¬ì´ ê°„ ë¹„ì„ í˜•ì  ê´€ê³„ë¥¼ ë…¸ë“œì™€ ë ˆì´ì–´ë¥¼ ê°–ëŠ” ë³µì¡í•œ neural network ì¡°í•©ì„ í†µí•´ í•™ìŠµí•˜ê³  ìƒˆë¡œìš´ ì €í•´ìƒë„ ì •ë³´ë¡œ ë¶€í„° ê³ í•´ìƒë„ ì„¼ì„œ ì •ë³´ë¥¼ ì˜ˆì¸¡í•œë‹¤ [1].
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/images_DS503/figure_2.jpeg&quot; alt=&quot;example image&quot; width=&quot;700&quot; height=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;center&gt;ê·¸ë¦¼ 2. ì¸ê³µì‹ ê²½ë§ ê¸°ë²•ì„ ê¸°ë°˜í•œ ì €í•´ìƒë„&lt;/center&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ë”ìš± êµ¬ì²´ì ìœ¼ë¡œ, ì €í•´ìƒë„-ê³ í•´ìƒë„ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´, ê·¸ë¦¼ê³¼ ê°™ì´ í¬ê²Œ (1) residual blockì™€ (2) super-resolution block ë¥¼ ê°–ëŠ”Deep learning architecture [2]ë¥¼ ì œì•ˆí•œë‹¤. ì €í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ deep learning modelì— ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , Residual blockì„ ë°˜ë³µì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì…ë ¥ ë° ì¶œë ¥ ì‚¬ì´ ê³µê°„ì  ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•œë‹¤. ì´ í›„, í•™ìŠµ ë³€ìˆ˜ë¥¼ ê°–ëŠ” up-sampling convolutional operationì„ residual block ì„ êµ¬ì¡° ëë‹¨ í™œìš©í•˜ì—¬ ê³ í•´ìƒë„ output ì°¨ì›ê¹Œì§€ ë³µêµ¬í•˜ëŠ” ê¸°ë²•ì´ ì´ìš©ë˜ê³  ìˆë‹¤. 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/images_DS503/figure_3.png&quot; alt=&quot;example image&quot; width=&quot;800&quot; height=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;center&gt;ê·¸ë¦¼ 3. ì €í•´ìƒë„-ê³ í•´ìƒë„ ë§µí•‘ì„ ìœ„í•œ ë‰´ëŸ´ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°&lt;/center&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ì´ëŠ” ê¸°ì¡´ ì €í•´ìƒë„ì—ì„œ ê³ í•´ìƒë„ë¡œ ë³µêµ¬í•˜ëŠ” ì¼ë°˜ì ì¸ ì„ í˜• interpolation ê¸°ë²•ì— ë¹„êµí•˜ì—¬ convolution ì—°ì‚°ì„ í†µí•´ ë¹„ì„ í˜•ì„±ì„ ë§µí•‘í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ë†€ë¼ìš´ ê³ í•´ìƒë„ ë³µêµ¬ ê²°ê³¼ë¥¼ ì•„ë˜ ê·¸ë¦¼ 3ê³¼ ê°™ì´ ë³´ì¸ë‹¤.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/images_DS503/figure_4.png&quot; alt=&quot;example image&quot; width=&quot;800&quot; height=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;center&gt;ê·¸ë¦¼ 4. ì¼ë°˜ì ì¸ ì €í•´ìƒë„-ê³ í•´ìƒë„ ë§µí•‘ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ë° ê¸°ì¡´ ë³´ê°„ ì•Œê³ ë¦¬ì¦˜ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ&lt;/center&gt;

&lt;h3 id=&quot;13-challenges-of-the-exsiting-deep-learning-approachs-for-engineering-application&quot;&gt;1.3 Challenges of the exsiting deep learning approachs for engineering application&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ì„¼ì„œ ì €í•´ìƒë„-ê³ í•´ìƒë„ ë¬¸ì œì— ëŒ€í•´ ë”¥ëŸ¬ë‹ ë°©ë²•ë¡ ì´ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ê³  ìˆì§€ë§Œ, ì•ì„œ ì„¤ëª…í•œ ê¸°ìƒ ì˜ˆë³´ì™€ ê°™ì€ ì„¼ì„œ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ë”¥ëŸ¬ë‹ ë°©ë²•ë¡ ì„ ì ìš©í•˜ê¸°ì—” ë‹¤ìŒê³¼ ê°™ì€ ë‘ ê°€ì§€ í•œê³„ì ì´ ì—¬ì „íˆ ì¡´ì¬í•œë‹¤.

 (1) ë”¥ëŸ¬ë‹ í•™ìŠµì„ ìœ„í•œ ê³ í•´ìƒë„ ë°ì´í„° íšë“ ë¬¸ì œ: ë‹¤ëŸ‰ì˜ ë°ì´í„°ê°€ ì¡´ì¬í•œë‹¤ë©´, ì•ì„œ ì„¤ëª…í•œ ë”¥ëŸ¬ë‹ ë°©ë²•ë¡ ì´ ì„±ê³µì ìœ¼ë¡œ ë‹¤ì–‘í•œ ì €í•´ìƒë„-ê³ í•´ìƒë„ ë¬¸ì œ (ë¯¸ì„¸ í˜„ë¯¸ê²½ ì •í™•ë„ ë³´ì •, í•´ìˆ˜ë©´ ì˜¨ë„ ì¸¡ì • ë° ìœ ì²´ ë‚œë¥˜ í•´ìƒë„ ë¬¸ì œ ë“±)ì— ì ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ê³µí•™ ë¶„ì•¼ì— ì´ìš©ë˜ê³  ìˆëŠ” ì„¼ì„œë“¤ì„ í†µí•´ ì¡°ë°€í•œ ê³ í•´ìƒë„ ë”¥ëŸ¬ë‹ í•™ìŠµ ë°ì´í„°ë¥¼ í™•ë³´ í•˜ëŠ” ê²ƒì€ ë§¤ìš° í° ë¹„ìš©ì´ ë°œìƒí•œë‹¤.
   
 (2) ë”¥ëŸ¬ë‹ í•™ìŠµì„ ìœ„í•œ ê³ í•´ìƒë„ ë°ì´í„° ê´€ë¦¬ ë¬¸ì œ: (1)ì˜ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë”ë¼ë„, ê³ í•´ìƒë„ë¡œ êµ¬ì¶•ëœ ì„¼ì„œë“¤ì€ ì˜ˆê¸°ì¹˜ ëª»í•œ ë‹¤ì–‘í•œ í™˜ê²½ ì¡°ê±´ìœ¼ë¡œ ì¸í•´ ê¸°ê¸°ê°€ ë¬´ì‘ìœ„ë¡œ On-offë˜ê±°ë‚˜ ì›€ì§ì„ì´ í•„ìš”í•œ ì„¼ì„œë¡œ ì¸í•´ ì¼ê´€ì„± ìˆê³  ì •í™•í•œ ê³ í•´ìƒë„ ë°ì´í„°ë¥¼ í™•ë³´í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì–´ë ¤ìš´ ë¬¸ì œë¥¼ ì œê³µí•œë‹¤.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2-deep-learning-framework-to-solve-these-limitations&quot;&gt;2. Deep learning framework to solve these limitations&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë”¥ëŸ¬ë‹ í•™ìŠµ ê³¼ì •ì—ì„œ ê³ í•´ìƒë„ì˜ ì¸¡ì • ë°ì´í„° í•„ìš”ì—†ì´ ì €í•´ìƒë„-ê³ í•´ìƒë„ ì¸¡ì • ë°ì´í„° ê´€ê³„ë¥¼ ëª¨ë¸ë§ ê°€ëŠ¥í•œ íšê¸°ì ì¸ ë”¥ëŸ¬ë‹ í”„ë ˆì„ ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. ì œì•ˆëœ ë°©ë²•ë¡ ì˜ ì£¼ëœ ì¥ì ì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ í•™ìŠµ ê³¼ì •ì—ì„œ ì˜¤ì§ ê³µê°„ì— ë¬´ì‘ìœ„ë¡œ spaseí•˜ê²Œ ë¶„í¬í•œ ì„¼ì„œë§Œì„ ì´ìš©í•˜ì—¬ ì €í•´ìƒë„-ê³ í•´ìƒë„ ê°„ ê´€ê³„ë¥¼ ëª¨ë¸ë§ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. í•´ë‹¹ í”„ë ˆì„ ì›Œí¬ëŠ” ë¬´ì‘ìœ„ë¡œ ë¶„í¬í•œ ë°ì´í„°ë§Œì„ í™œìš©í•˜ì—¬ ì•ì„œ ì„¤ëª…í•œ ë°ì´í„° ê´€ë ¨ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ë•Œë¬¸ì— randomly seeded super-resolution GAN (RaSeedGAN)ì´ë¼ê³  ëª…ì¹­ë˜ê³ , ì œì•ˆí•˜ëŠ” í”„ë ˆì„ ì›Œí¬ì˜ ìš°ìˆ˜ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ 3ê°€ì§€ ì˜ˆì¸¡ task (ìœ ì²´ ìœ ì† ì‹œë®¬ë ˆì´ì…˜, ì§€êµ¬ í•´ìˆ˜ë©´ ì˜¨ë„ ë° ìœ ì²´ ìœ ì† ì¸¡ì • ë¬¸ì œ)ë¥¼ ì±„íƒí•œë‹¤. ìì„¸í•œ ë”¥ëŸ¬ë‹ êµ¬ì¡°ì— ëŒ€í•œ ì„¤ëª…, ë©”ì»¤ë‹ˆì¦˜ ë° ì˜ˆì¸¡ ê²°ê³¼ë“¤ì€ ì•„ë˜ì™€ ê°™ì´ ì„¤ëª…í•˜ê³ ì í•œë‹¤.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;21-deep-learning-architecture-for-raseedgan&quot;&gt;2.1 Deep learning architecture for RaSeedGAN&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/images_DS503/figure_5.jpeg&quot; alt=&quot;example image&quot; width=&quot;1000&quot; height=&quot;500&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;center&gt;ê·¸ë¦¼ 5. ë³¸ ë¦¬ë·° ë…¼ë¬¸ì—ì„œ ì œì•ˆëœ ë”¥ëŸ¬ë‹ êµ¬ì¡° ì„¸ë¶€ì‚¬í•­&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Main acrchitecture and idea&lt;/strong&gt; : GANsì€ â€œgeneratorâ€ ê·¸ë¦¬ê³  â€œdiscriminatorâ€ë¼ëŠ” ë‘ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ neural networkë¥¼ êµ¬ì„±í•˜ê³  ìˆë‹¤.â€generatorâ€ëŠ” ì°¸ê°’ (target data)ì„ ëª¨ë°©í•˜ì—¬ ì¸ê³µì ì¸ ì˜ˆì¸¡ ê°’ì„ (generated data) ìƒì„±í•˜ëŠ” networkì´ê³ , â€œdiscriminatorâ€ëŠ” ì¸ê³µì ìœ¼ë¡œ ìƒì„±ëœ ì˜ˆì¸¡ ê°’ê³¼ ì°¸ê°’ ì‚¬ì´ ë‹¤ë¥¸ ì ì„ êµ¬ë³„í•˜ëŠ” networkì´ë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ì „ ì—°êµ¬ë“¤ì˜ í•œê³„ì¸ í•™ìŠµ ë°ì´í„°ì— high-resolution full fields íšë“ì— ëŒ€í•œ ì œí•œì ì„ í•´ê²°í•˜ëŠ” generatorë¥¼ ì œì•ˆí•˜ì—¬ GANì„ ì´ìš©í•˜ì—¬ ë³´ë‹¤ ìš°ìˆ˜í•œ ìƒì„± ëŠ¥ë ¥ì„ ê°–ë„ë¡ í•™ìŠµì‹œí‚¨ë‹¤ (ê·¸ë¦¼5)
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Generator network&lt;/strong&gt; : ë³¸ ì—°êµ¬ì—ì„œ ì´ìš©ë˜ëŠ” generatorì˜ ì…ë ¥ê³¼ ì¶œë ¥ì€ ê¸°ì¡´ ì €í•´ìƒë„-ê³ í•´ìƒë„ ê´€ê³„ë¥¼ í•´ê²°í•˜ëŠ” ë”¥ëŸ¬ë‹ ì—°êµ¬ë“¤ê³¼ ë‹¤ë¥´ê²Œ í• ë‹¹í•˜ì—¬ í•´ë‹¹ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤. ë”ìš± êµ¬ì²´ì ìœ¼ë¡œ, ê³ í•´ìƒë„ì˜ ëª¨ë“  ê³µê°„ ë°ì´í„°ë¥¼ ì´ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ê³ í•´ìƒë„ì˜ ì„¼ì„œ ë°ì´í„°ì—ì„œ ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œí•œ sparseí•œ ë°ì´í„°ë¥¼ &lt;strong&gt;generator ì¶œë ¥&lt;/strong&gt;ìœ¼ë¡œ ì„¤ì •í•˜ê³  (ê·¸ë¦¼ 5a), ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œëœ sparseí•œ ê³ í•´ìƒë„ ë°ì´í„° (ê·¸ë¦¼ 5b ì™¼ìª½)ë¡œ ë¶€í„° íŠ¹ì • ì§ì‚¬ê°í˜• í¬ê¸° í”½ì…€ë§ˆë‹¤ í‰í˜•í•˜ê²Œ ì´ë™í•˜ì—¬ 10ê°œì˜ ì„¼ì„œë¥¼ í‰ê· í™” ì‘ì—…ì„ í†µí•´ &lt;strong&gt;ì €í•´ìƒë„ì˜ generator ì…ë ¥ feature&lt;/strong&gt;ë¥¼ ìƒì„±í•œë‹¤ (ê·¸ë¦¼ a ì™¼ìª½). ì¦‰, ê³ ê°€ ì„¼ì„œ ì¥ë¹„ë¥¼ sparseí•˜ê²Œ ë¶„í¬ì‹œì¼œ ë°ì´í„°ë¥¼ ì–»ê³ , ì´ë¥¼ convolutions strideì²˜ëŸ¼ ì´ë™í•˜ì—¬ í‰ê·  ê°’ì„ ì‚°ì •í•˜ì—¬ low-resolution5 ì…ë ¥ì„ ì–»ëŠ”ë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ ì¡ìŒ ë¿ë§Œ ì•„ë‹ˆë¼ ê³µê°„ì  í•´ìƒë„ì— ëŒ€í•œ ê· ì¼ì„±ì„ ì¦ê°€í•˜ëŠ” ì¥ì ì„ ê°–ëŠ”ë‹¤. generatorëŠ” ê¸°ì¡´ baseline neural network architecture [2]ì— ë¹„í•´ ë³€í˜•ëœ êµ¬ì¡°ë¥¼ ê°–ëŠ”ë° ì´ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(1) Initial layer : ë¨¼ì € low-resolution fieldsê°€ generatorë¡œ ì…ë ¥ë˜ëŠ”ë°, filter size 9 Ã— 9 ê·¸ë¦¬ê³  64 feature mapsì„ ê°–ëŠ” convolutional layerê°€ ì´ìš©ë˜ê³ , parametric rectified linear unit (ReLU) í™œì„±í™” í•¨ìˆ˜ê°€ convolutional operationì— ì˜í•´ ì¶”ì¶œëœ ì •ë³´ë¥¼ í¬ì°©í•œë‹¤. &amp;lt;br&amp;gt;
   
(2) Medium layer : ì´ˆê¸° ë ˆì´ì–´ì— ì˜í•´ ì¶”ì¶œëœ ì •ë³´ëŠ” 16ê°œì˜ residual blocks [2] ì„ í†µí•´ ë³´ë‹¤ ë†’ì€ ë¹„ì„ í˜•ì  ê´€ê³„ì— ëŒ€í•´ ëª¨ë¸ë§í•œë‹¤. ì´ë–„ residual blockì€ 3x3 kernelì„ ë™ë°˜í•œ 64ê°œì˜ feature map ì„ ì´ìš©í•œë‹¤. ì—¬ê¸°ì„œ, ì €í•´ìƒë„ë¥¼ ì¦ê°€ì‹œí‚¤ê¸° ì „ì—, skip-connection sum ë ˆì´ì–´ê°€ residual blocksì˜ ì¶œë ¥ ë¶€ë¶„ ê·¸ë¦¬ê³  initialization layersì˜ ì¶œë ¥ ë¶€ë¶„ ì‚¬ì´ì— ì ìš©ëœë‹¤. ì´ í›„ì• , [2]ì— ì œì•ˆëœ subpixel convolution layer ê°€ generator ì¶œë ¥ ë§Œí¼ ì¦ê°€ ì‹œí‚¤ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤. ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ë˜ëŠ” spase-high resolution ouputì€ ë¹„ì„ í˜• ë³´ê°„ ê¸°ë²•ì„ ì´ìš©í•˜ì—¬ sparse sampleê³¼ sample ì‚¬ì´ ë°ì´í„°ë¥¼ ê³µê°„ì ìœ¼ë¡œ ë³´ê°„í•˜ì—¬ ê´€ì‹¬ ìˆëŠ” ìµœì¢…ì  ê³ í•´ìƒë„ ë°ì´í„°ë¥¼ ë³µêµ¬í•  ìˆ˜ ìˆë‹¤.
&amp;lt;br&amp;gt; &amp;lt;br&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;3. Discriminator network&lt;/strong&gt; : spase-high resolution target ê·¸ë¦¬ê³  generated fields ì‚¬ì´ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ ìœ„í•´, ì•„ë˜ì™€ ê°™ì€ discriminator networkë¥¼ ì´ìš©í•˜ì—¬ generated fieldsë¥¼ ì…ë ¥ìœ¼ë¡œ ì—°ê²°í•œë‹¤ (ê·¸ë¦¼ 5b). Discriminator networkëŠ” ì´ˆê¸°ì— filter size 3 Ã— 3 ê·¸ë¦¬ê³  64 feature mapsë¥¼ ì´ìš©í•˜ì—¬ ì¤‘ìš” ê³µê°„ì  ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , 7ê°œì˜ discriminator blocksì´ ì—°ì†ì ìœ¼ë¡œ ì ìš©ëœë‹¤. ì´ë•Œ, í™€ìˆ˜ block ë§ˆë‹¤ stride ì‚¬ì´ì¦ˆë¥¼ ë†’ì—¬ ì°¨ì›ì„ ì¤„ì´ê³ , ì¤„ì—¬ì§„ feature-map tensorê°€ í•˜ë‚˜ì˜ vectorë¡œ ë³€í™˜ëœë‹¤. ì´ë•Œ 1,024ê°œì˜ fully connected layerë¥¼ ì´ìš©í•˜ì—¬ ë³€í™˜ëœ vectorë¥¼ discriminator ì¶œë ¥ ê°’ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê³ , ê·¸ ì¶œë ¥ê°’ì´ sigmoid functionì„ í†µí•´ í™•ë¥ ì ìœ¼ë¡œ ì°¸ (0s)ì¸ì§€ ê±°ì§“ (1s)ì¸ì§€ ì ëŒ€ì ìœ¼ë¡œ í•™ìŠµì‹œì¼œ generatorì˜ ìƒì„± ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤. discriminatorì˜ ì†ì‹¤ í•¨ìˆ˜ (loss function)ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤.
&lt;br /&gt;
\(\mathcal{L}_{\text{D}} = -\mathbb{E}[\log D(H_R)] - \mathbb{E}[\log(1 - D(F_v  \odot G(L_R)))]\)
    ì—¬ê¸°ì„œ ğ”¼[]ëŠ” mini-batch ë‚´ í‰ê· ì— ëŒ€í•œ ì—°ì‚°ìì´ê³ , H_R ë° L_Rì€ ê°ê° ê³ í•´ìƒë„ ë° ì €í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ë©°, D()ëŠ” ì €í•´ìƒë„ ì…ë ¥ìœ¼ë¡œ ë¶€í„° ìƒì„±ëœ ê³ í•´ìƒë„ ì´ë¯¸ì§€ì— ëŒ€í•œ lossë¥¼ ê³„ì‚°í•˜ëŠ” discriminator networkë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. F_v ëŠ” í•˜ë‚˜ì˜ ì—°ì‚°ì ê³„ìˆ˜ë¡œì¨ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë‚´ ì„¼ì„œê°€ ì¡´ì¬í• ë•Œ 1 ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° 0ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ì„ í•œë‹¤. ì—¬ê¸°ì„œ, generator networkì˜ loss functionì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤.
\(\mathcal{L}_{\text{G}} = -\sum_{i=1}^{Nx}\sum_{i=1}^{Nz}| H_R - F_v \odot G(L_R)_i,_j |^2 + \lambda  \mathcal{L}_A\)
    ì—¬ê¸°ì„œ G()ëŠ” generator networkê°€ ì‹¤ì œ ì°¸ê°’ê³¼ ìƒì„±í•˜ëŠ” sparse high-resolutional ê°’ ì‚¬ì´ ê²©ìë³„ ì˜¤ì°¨ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
\(\mathcal{L}_A  =  -\mathbb{E}[\log D(F_v \odot G(L_R))]\)
    GANsì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´, ìœ„ì˜ adversarial lossê°€ ìƒì„±ëœ spase-high resolution fieldë¥¼ binary cross-entropyë¡œ ë ˆì´ë¸”ë§í•œë‹¤. ì—¬ê¸°ì„œ, discriminatorëŠ” ìƒì„±ëœ spase-high resolution fieldê°€ â€˜fakeâ€™ ì¸ì§€ ì§„ìœ„ ì—¬ë¶€ë¥¼ í•´ë‹¹ 1ê°’ìœ¼ë¡œ í• ë‹¹í•œ binary cross-entropyë¥¼ í†µí•´ ê²°ì •í•œë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;22-prediction-results&quot;&gt;2.2 Prediction results&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ê°’ë¹„ì‹¼ ê³ í•´ìƒë„ ë°ì´í„°ë¥¼ í•™ìŠµê³¼ì •ì—ì„œ ìš”êµ¬í•˜ì§€ ì•ŠëŠ” RaSeedGANì˜ ìš°ìˆ˜ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´, ë¹„ì„ í˜•ì„±ê³¼ ë³€ë™ì„±ì„ í¬í•¨í•˜ê³  ìˆëŠ” 3ê°€ì§€ ì‹¤í—˜ ë° ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì´ìš©í•œë‹¤. ìš°ìˆ˜ì„± ê²€ì¦ì„ ìœ„í•´, ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ (1) Pinball flow numerical simulation, (2) NOAA sea surface temperature database (3) particle-image velocimetry (PIV) experiment ì™€ ê°™ì€ ì„¸ ê°€ì§€ ì˜ˆì‹œì— ëŒ€í•´ ê²€ì¦í•˜ê³ , ë³´ë‹¤ ìì„¸í•œ numerical simulation ì¡°ê±´ì€ í•´ë‹¹ ë¦¬ë·°ì—ì„œ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•œ high-quality ì •ë³´ë¥¼ ì§‘ì¤‘í•˜ê¸° ìœ„í•´ ìƒëµí•œë‹¤. ì„¸ ê°€ì§€ ì˜ˆì‹œëŠ” ì„œë¡œ ë‹¤ë¥¸ image ì°¨ì›ì„ ê°–ëŠ”ë‹¤. (1),(2),(3)ì€ ê°ê°, 512 x 512, 720 Ã— 1,440, 128 Ã— 128 í¬ê¸°ë¡œ ì„œë¡œ ë‹¤ë¥¸ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ ê°–ê³  í•´ë‹¹ ì˜ˆì¸¡ taskì— ë§ˆë‹¤ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ ì„±ëŠ¥ì— ëŒ€í•´ ê²€ì¦í•œë‹¤. ë˜í•œ, ì„œë¡œ ë‹¤ë¥¸ taskì´ì§€ë§Œ ë³¸ ì•Œê³ ë¦¬ì¦˜ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œëœ sparseí•œ ê³ í•´ìƒë„ ë°ì´í„°ë¡œ ë¶€í„° íŠ¹ì • ì§ì‚¬ê°í˜• í¬ê¸° í”½ì…€ë§ˆë‹¤ í‰í˜•í•˜ê²Œ ì´ë™í•˜ì—¬ ì§ì‚¬ê°í˜• ê³µê°„ ë‚´ 10ê°œì˜ ì„¼ì„œë¥¼ í‰ê· í™”í•˜ëŠ” ì‘ì—…ì„ í†µí•´ 32 x 32 bin sizeë¥¼ ê°–ë„ë¡ input featureë¥¼ ê°€ê³µí•œë‹¤. 

ê·¸ë¦¼ 6ì€ ì„¸ ê°€ì§€ ì˜ˆì¸¡ taskì— ëŒ€í•´ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ê³ í•´ìƒë„ ë°ì´í„°ë¥¼ í•™ìŠµì— ì´ìš©í•˜ì§€ ì•Šê³ , ì €í•´ìƒë„-ê³ í•´ìƒë„ ì‚¬ì´ ê´€ê³„ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•´ ë¹„êµí•œ ê²°ê³¼ì´ë‹¤. ê·¸ë¦¼ 6ì˜ ì²«ë²ˆì§¸ ì—´ì—ëŠ” í‰ê· í™” ì‘ì—…ì„ ê±°ì¹œ ì…ë ¥ ì €í•´ìƒë„ í•„ë“œ, ë‘ë²ˆì§¸ ì—´ì€ &quot;Sparse HR reference&quot;ë¼ê³  í•˜ëŠ” íŠ¹ì§•í™”ëœ ê³ í•´ìƒë„ í•„ë“œ, ì„¸ë²ˆì§¸ ê·¸ë¦¬ê³  ë„¤ë²ˆì§¸ ì—´ì€ RaSeed GANì´ ì´ë¥¼ ì˜ˆì¸¡í•˜ê³  ë³€í™˜í™˜ ê²°ê³¼ì™€ íƒ€ê²Ÿ í•„ë“œë“¤ì„ ë‚˜íƒ€ë‚¸ë‹¤. ì—¬ê¸°ì„œ ì£¼ëª©í•  ì ì€, ì „ì²´ ê³ í•´ìƒë„ ë°ì´í„°ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê·¸ë¦¼ 6ì˜ ë§ˆì§€ë§‰ ì—´ì— í¬í•¨ë˜ì–´ ìˆì§€ë§Œ í›ˆë ¨ ì¤‘ ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ëŠ” ì•Šì•˜ë‹¤ëŠ” ì ì´ë‹¤. ê·¸ë¦¼ 6ì˜ ê° taskì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´, RaSeedGANì€ ì›ê¸°ë‘¥ ì£¼ë³€ê³¼ ì›ê¸°ë‘¥ ë¶€ê·¼ì˜ ë‚œë¥˜ ë°œë‹¬ ì§€ì—­ì„ ì •í™•í•˜ê²Œ ë³µêµ¬í•  ìˆ˜ ìˆì„ ë¿ë§Œ ì•„ë‹ˆë¼, ë†’ì€ ìˆ˜ì¤€ì˜ ë””í…Œì¼ë¡œ ì˜¨ë„ ì‹¤í—˜ ë°ì´í„°ë¥¼ ë³µêµ¬í•  ìˆ˜ ìˆë‹¤.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;task-1-pinball-flow-numerical-simulation&quot;&gt;Task 1: Pinball flow numerical simulation&lt;/h4&gt;
&lt;center&gt;&lt;img src=&quot;/images_DS503/figure6_1.jpeg&quot; alt=&quot;example image&quot; width=&quot;1000&quot; height=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;task-2-noaa-sea-surface-temperature-database&quot;&gt;Task 2: NOAA sea surface temperature database&lt;/h4&gt;
&lt;center&gt;&lt;img src=&quot;/images_DS503/figure6_2.jpeg&quot; alt=&quot;example image&quot; width=&quot;1000&quot; height=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;task-3-particle-image-velocimetry-piv-experiment&quot;&gt;Task 3: particle-image velocimetry (PIV) experiment&lt;/h4&gt;
&lt;center&gt;&lt;img src=&quot;/images_DS503/figure6_3.jpeg&quot; alt=&quot;example image&quot; width=&quot;1000&quot; height=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;center&gt;ê·¸ë¦¼ 6. RaSeedGAN ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ&lt;/center&gt;

&lt;h3 id=&quot;3-conclusion&quot;&gt;3 Conclusion&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ë³¸ ì—°êµ¬ì—ì„œëŠ” ë¬´ì‘ìœ„ë¡œ ê³µê°„ì— ë°°ì¹˜ëœ ì„¼ì„œ ë°ì´í„°ë¡œë¶€í„° ê´€ì‹¬ ìˆëŠ” ì˜ì—­ì˜ ê³ í•´ìƒë„ ì„¼ì„œ ì¸¡ì • ê²°ê³¼ë“¤ì„ ì¶”ì •í•˜ê¸° ìœ„í•œ RaSeedGAN í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. í•´ë‹¹ í”„ë ˆì„ ì›Œí¬ì˜ ê°€ì¥ í° ì¥ì ì´ì ë°©ë²•ë¡ ì  ì ‘ê·¼ ìš”ì•½ì€ (1) ë¬´ì‘ìœ„ë¡œ ê³µê°„ì— ë°°ì¹˜ëœ ì„¼ì„œ ë°ì´í„°ë“¤ì„ íŠ¹ì • êµ¬ê°„ ì„¼ì„œ ê°œìˆ˜ë§ˆë‹¤ í‰ê· í™”í•˜ì—¬ ì €í•´ìƒë„ ì…ë ¥ featureë¥¼ ë§Œë“œëŠ” ê²ƒ. (2) ì €í•´ìƒë„ ì…ë ¥ featureë¡œ ë¶€í„° ë“¬ì„±ë“¬ì„± ë°°ì¹˜ëœ í•´ë‹¹ ì„¼ì„œ ë°ì´í„°ë¥¼ ë³µêµ¬í•˜ëŠ” ê²ƒ. (3) ì˜ˆì¸¡ëœ ê²°ê³¼ë¥¼ ë³´ê°„í•˜ì—¬ ë‹¤ì‹œ ê³µê°„ì ìœ¼ë¡œ ë§¤ìš° ì„¸ë¶€ì ìœ¼ë¡œ ê¸°ìˆ ëœ ì˜¨ë„/ìœ ì† ê³ í•´ìƒë„ ë°ì´í„°ë¥¼ ì–»ëŠ” ê²ƒì— ìˆë‹¤. ì—¬ê¸°ì„œ GANì€ ë“¬ì„±ë“¬ì„± ë°°ì¹˜ëœ í•´ë‹¹ ì„¼ì„œ ë°ì´í„°ë“¤ì„ ì˜ˆì¸¡í•˜ëŠ” generatorì— ëŒ€í•´ ì‹¤ì œ ê²°ê³¼ì™€ ë§¤ìš° ìœ ì‚¬í•œ ìƒì„± fieldë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆê²Œ í–ˆë‹¤. íŠ¹íˆ, ë³¸ ì—°êµ¬ëŠ” ìœ ì²´ íë¦„ ì‹œë®¬ë ˆì´ì…˜, í•´ì–‘ í‘œë©´ ì˜¨ë„ ë¶„í¬ ì¸¡ì • ë° ì…ì-ì´ë¯¸ì§€ ì†ë„ì¸¡ì • ë°ì´í„°ì—ì„œ ê²€ì¦ë˜ì—ˆë‹¤. ì´ëŸ¬í•œ í”„ë ˆì„ ì›Œí¬ëŠ” ê³ í•´ìƒë„ì˜ ë°ì´í„°ë¥¼ í›ˆë ¨ ìì²´ì— í•„ìš”í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë¹„ìš©-íš¨ìœ¨ì ìœ¼ë¡œ ë§ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì ìš©ë  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ìƒê°í•œë‹¤.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4-reference&quot;&gt;4 Reference&lt;/h3&gt;

&lt;p&gt;[1]Adversarial super-resolution of climatological wind and solar data, &lt;strong&gt;&lt;em&gt;Proceedings of the National Academy of Sciences of the United States of America&lt;/em&gt;&lt;/strong&gt;,July 6, 2020,117 (29) 16805-16815
https://doi.org/10.1073/pnas.1918964117
&lt;br /&gt;
[2]Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network, &lt;strong&gt;&lt;em&gt;arXiv&lt;/em&gt;&lt;/strong&gt;:1609.0480&lt;/p&gt;
</description>
            <pubDate>Thu, 20 Apr 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/Super_resolution_generative_adversarial_networks_of_randomly_seeded_fields.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/Super_resolution_generative_adversarial_networks_of_randomly_seeded_fields.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[NIPS 2021] Subgraph Federated Learning with Missing Neighbor Generation</title>
            <description>&lt;h1 id=&quot;neurips-21-subgraph-federated-learning-with-missing-neighbor-generation-ë¦¬ë·°&quot;&gt;[NeurIPS-21] Subgraph Federated Learning with Missing Neighbor Generation ë¦¬ë·°&lt;/h1&gt;

&lt;h1 id=&quot;1-motivation&quot;&gt;1. Motivation&lt;/h1&gt;

&lt;p&gt;ë³¸ ë…¼ë¬¸ì€ Graph domainì—ì„œ &lt;strong&gt;Subgraph Federating Learning&lt;/strong&gt; ì„ ì²˜ìŒ ì‹œë„í•œ ë…¼ë¬¸ì´ë‹¤. ì´ ì—°êµ¬ê°€ ì™œ í•„ìš”í•œì§€ ì•Œì•„ë³´ë ¤ë©´ ìš°ì„  Federated Learningì´ ë¬´ì—‡ì¸ì§€ ê°„ëµí•œ ê°œë…ì„ ì•Œì•„ì•¼í•œë‹¤. &lt;strong&gt;Federated Learning&lt;/strong&gt;ì´ë€ privacyë“±ì˜ ì´ìœ ë¡œ ë‹¤ì–‘í•œ local systemë“¤ë¡œ ë¶€í„° dataë¥¼ ëª¨ì„ ìˆ˜ ì—†ëŠ” ìƒí™©ì—ì„œ ëª¨ë¸ì„ í•¨ê»˜ í•™ìŠµì‹œì¼œ ê°ìì˜ local system ë‚´ì˜ dataë¡œë§Œ í•™ìŠµì‹œì¼°ì„ ë•Œ ë³´ë‹¤ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ê¸° ìœ„í•œ ë°©ë²•ì´ë‹¤. ì˜ˆë¥¼ë“¤ì–´ Computer Vision (CV) ë„ë©”ì¸ ì—ì„œëŠ” íœ´ëŒ€í° ì‚¬ì§„ì²©ë‚´ì˜ ì‚¬ì§„ë“¤ì„ ëª¨ë‘ ì¤‘ì•™ ì„œë²„ë¡œ ëª¨ì•„ì„œ Machine Learningëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ë ¤ í•œë‹¤ë©´ ê°ìì˜ ì–¼êµ´ ë“±ì˜ privacyê°€ ì¹¨í•´ ë  ìš°ë ¤ê°€ ìˆì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë°ì´í„°ë¥¼ ê³µìœ í•˜ì§€ ì•Šê³  Convolution Neural Network (CNN)ì„ í•™ìŠµ ì‹œí‚¤ë ¤ê³  í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ CVì™€ NLPë„ë©”ì¸ì—ì„œëŠ” Federated Learningì—°êµ¬ê°€ ë§ì´ ì§„í–‰ë˜ì–´ ì™”ëŠ”ë° Graph ë„ë©”ì¸ì—ì„œëŠ” ì™œ Federated Learningì´ í•„ìš”í• ê¹Œ?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1SygClT33EqcEuDLVZbLYWeQyjEu7oxHh&quot; alt=&quot;Motivation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Graph ë„ë©”ì¸ì—ì„œ Graph Neural Networks (GNNs)ë¥¼ ì´ìš©í•œ ë§ì€ ì ìš©ì‚¬ë¡€ê°€ ìˆì§€ë§Œ ê·¸ ì¤‘ í•˜ë‚˜ë¡œ ìœ ì‚¬í•œ íŠ¹ì„±ì„ ê°€ì§„ í™˜ìê°„ì— edgeë¥¼ ì—°ê²°ì‹œì¼œì„œ ë§Œë“  Patient Graphë¥¼ ì´ìš©í•˜ì—¬ í™˜ìì˜ ì§ˆë³‘ ìœ ë¬´ ë“±ì„ ì˜ˆì¸¡í•˜ëŠ” taskê°€ ìˆë‹¤. ì´ ê²½ìš° í™˜ìì˜ ê°œì¸ ì •ë³´ ë° ê²€ì‚¬ ê²°ê³¼ ì‚¬ì§„ ë“±ì„ Medical Centerë¡œ ë³´ë‚´ì„œ GNNì„ í•™ìŠµ ì‹œì¼œì•¼ í•˜ëŠ”ë° real-worldì—ì„œì˜ ìƒí™©ì„ ìƒê°í•´ë³´ë©´ ë³‘ì›ì—ì„œ í™˜ì ê°œì¸ì •ë³´ëŠ” ë§¤ìš° ë¯¼ê°í•œ privacy ë¬¸ì œê°€ ìˆê¸° ë•Œë¬¸ì— ì‚¬ì‹¤ìƒ í•˜ë‚˜ì˜ Centerì— ì—¬ëŸ¬ ë³‘ì›ì˜ í™˜ì ì •ë³´ë¥¼ ì·¨í•©í•˜ê¸°ê°€ í˜ë“¤ë‹¤. ê·¸ëŸ¬ë‹¤ë³´ë‹ˆ ìœ„ì˜ ê·¸ë¦¼ì²˜ëŸ¼ Hospital A, B, C, Dì—ì„œ ë°ì´í„°ë¥¼ Moedical Administration Centerë¡œ ëª¨ì•„ì„œ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ &lt;strong&gt;â€˜Joint training without sharing graph dataâ€™&lt;/strong&gt; ê°€ í•„ìš”í•œ ê²ƒì´ë‹¤. ê·¸ë ‡ë‹¤ë©´ CVì™€ NLPì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ë¡ ë“¤ì„ ê·¸ëŒ€ë¡œ ì ìš©í•˜ì§€ ì•Šê³  ìƒˆë¡œìš´ ì—°êµ¬ê°€ í•„ìš”í•œ ê²ƒì¼ê¹Œ?&lt;/p&gt;

&lt;p&gt;ìœ„ì˜ ì˜ˆì‹œì²˜ëŸ¼ Hospitalê°„ì— dataë¥¼ shareí•˜ì§€ ì•ŠëŠ” ê²½ìš° Hospital Aì™€ Bì— ìˆëŠ” í™˜ì ê°„ì—ëŠ” edgeë¥¼ ì—°ê²° ì‹œí‚¬ ìˆ˜ ì—†ê²Œ ëœë‹¤. ë”°ë¼ì„œ GNNì—ì„œ ê²°ê³¼ê°’ì„ ë‚¼ ë•Œ ì „ì²´ Graphë¥¼ ë‹¤ í™œìš©í•˜ì§€ ëª»í•˜ê³  ë³‘ì› ë³„ &lt;strong&gt;Subgraph&lt;/strong&gt; ë§Œì„ í™œìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— missing edgeê°€ ë°œìƒí•˜ì—¬ ì´ë¡œ ì¸í•œ ì •ë³´ ì†ì‹¤ì´ ì¼ì–´ë‚œë‹¤. ì´ëŸ¬í•œ í˜„ìƒì€ ê¸°ì¡´ ë‹¤ë¥¸ ë„ë©”ì¸ì—ì„œëŠ” ì—†ëŠ” ë¬¸ì œì´ê¸° ë•Œë¬¸ì— ì´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë°©ë²•ì´ í•„ìš”í•˜ê³  ë”°ë¼ì„œ &lt;strong&gt;Subgraph Federated Learning&lt;/strong&gt; ì— íŠ¹í™”ëœ ë°©ë²•ë¡ ì„ ì—°êµ¬í•  í•„ìš”ê°€ ìˆë‹¤.&lt;/p&gt;

&lt;h1 id=&quot;2-method&quot;&gt;2. Method&lt;/h1&gt;

&lt;p&gt;ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ìœ„ì˜ ì„¤ëª…ê³¼ ê°™ì´ ì—¬ëŸ¬ ê°œì˜ Subgraphê°„ì— dataë¥¼ ê³µìœ í•˜ì§€ ì•Šê³  jointly trainingí•˜ëŠ” Federated Learningì„ ìœ„í•œ ë°©ë²•ë¡ ì„ ì œì‹œí•˜ì˜€ë‹¤. ê·¸ë˜ì„œ ì²«ë²ˆì§¸ë¡œ 1) ê°€ì¥ ê¸°ë³¸ì ì¸ Federated Learning ë°©ë²•ì¸ FedAvgë¥¼ Graphsage ì¸ì½”ë”ë¥¼ í™œìš©í•˜ì—¬ ì ìš©í•´ë³¸ &lt;strong&gt;Fedsage&lt;/strong&gt;ì„ ì œì‹œí•˜ì˜€ê³  2) Missing Edgeë¥¼ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì´ Linkë¥¼ ë‹¤ì‹œ ë³µì›ì‹œì¼œì£¼ëŠ” Generative Modelì„ ê²°í•©ì‹œí‚¨ &lt;strong&gt;Fedsage+&lt;/strong&gt; ë¥¼ ì¶”ê°€ì ìœ¼ë¡œ ì œì‹œí•˜ì˜€ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;2-1-fedsage&quot;&gt;2-1) Fedsage&lt;/h2&gt;

&lt;p&gt;ë¨¼ì € FedsageëŠ” ì¼ë°˜ì ì¸ GNNì—ì„œ Node classification modelì„ í•™ìŠµì‹œí‚¤ë“¯ì´ ê°ê°ì˜ labelì— ëŒ€í•œ prediction ê°’ì„ ê³„ì‚°í•œ ë’¤ ì•„ë˜ Cross Entropy Lossë¥¼ ê³„ì‚°í•˜ê³  gradient descentë¥¼ í†µí•˜ì—¬ í•™ìŠµì‹œí‚¨ë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1rZ4fhaWnSMNTqxtcpMapl9tWeM6OI2kt&quot; alt=&quot;CE&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ë¦¬ê³  FedAvgë¥¼ ì ìš©í•˜ëŠ”ë° FedavgëŠ” 1) Roundë§ˆë‹¤ local systemì„ í•™ìŠµ 2) í•™ìŠµëœ local systemì˜ weightë¥¼ serverì—ì„œ average 3) serverì—ì„œ weightë¥¼ ê°ê°ì˜ local systemìœ¼ë¡œ ë°°í¬ ì˜ ìˆœì„œë¥¼ ë°˜ë³µí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. ì´ëŠ” ê°€ì¥ ëŒ€í‘œì ì´ê³  ê°„ë‹¨í•˜ì—¬ ë„ë¦¬ ì“°ì´ëŠ” ë°©ë²•ë¡ ì´ê³  ì•„ë˜ Fedavgë…¼ë¬¸ì—ì„œì˜ ìˆ˜ë„ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1TXPt7ESV5qanZHAZpQW8vnrJisC3Wq4s&quot; alt=&quot;Fedavg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-2-fedsage&quot;&gt;2-2) Fedsage+&lt;/h2&gt;

&lt;p&gt;ìœ„ FedsageëŠ” Subgraph Federated Learning ì„¸íŒ…ì—ì„œ ì²˜ìŒìœ¼ë¡œ Federated Learningì„ ì‹œë„í•´ë´¤ë‹¤ëŠ” ì˜ë¯¸ê°€ ìˆì§€ë§Œ ì´ ë°©ë²•ì€ ì´ì „ Motivation ì„¹ì…˜ì—ì„œ ë§í•œ Missing Linkë¡œ ì¸í•œ ë¬¸ì œë¥¼ ì „í˜€ ë‹¤ë£¨ì§€ ì•Šê³  ìˆë‹¤. ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Generative Modelì„ í™œìš©í•˜ì—¬ Missing ìƒì–´ë²„ë¦° ì—°ê²°ê´€ê³„ë¥¼ ë³µì›ì‹œì¼œì£¼ëŠ” ë°©ë²•ì„ ì œì•ˆí•œë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1meNAOF25mBHTH6A0yoztAX62jT6Vy0jo&quot; alt=&quot;Fedavg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ë˜ì„œ ëª¨ë¸ Architectureë¥¼ í¬ê²Œ ë³´ë©´ Missing Neighbor Generator (NeighGen)ì„ í†µí•˜ì—¬ Missing ëœ Nodeë“¤ì„ ë‹¤ì‹œ ë§Œë“¤ì–´ì„œ Observeëœ Graphì—ì„œ ë¶™ì—¬ì£¼ê³  (Graph mending) ë³µì›ëœ Graphë¥¼ í†µí•˜ì—¬ downstream taskì¸ node classificationì„ ìˆ˜í–‰í•œë‹¤. Node classification ë¶€ë¶„ì€ ìœ„ fedsageì™€ ë™ì¼í•˜ê¸° ë•Œë¬¸ì— ì¤‘ìš”í•œ ë¶€ë¶„ì€ NeighGenì„ ì–´ë–»ê²Œ êµ¬ì„±í•˜ëŠ”ì§€ ì¸ë° ìš°ì„  missingëœ linkë¥¼ Subgraphë‚´ì—ì„œ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•´ì„œëŠ” ê°ê°ì˜ Subgraph ë‚´ì˜ nodeë§ˆë‹¤ ëª‡ê°œì˜ nodeê°€ dropë˜ì—ˆëŠ”ì§€ë¥¼ ì•Œì•„ì•¼ í•˜ê¸° ë•Œë¬¸ì— missingëœ node ê°œìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” dGenì„ í•™ìŠµì‹œí‚¤ê³  ê·¸ ì˜ˆì¸¡ëœ node ê°œìˆ˜ì— ë§ê²Œ ìƒˆë¡œìš´ nodeì˜ featureë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” fGenì„ í•™ìŠµì‹œí‚¨ë‹¤.&lt;/p&gt;

&lt;p&gt;êµ¬ì²´ì ìœ¼ë¡œ ë³´ë©´ í•™ìŠµë‹¨ê³„ì—ì„œëŠ” Ground Truthê°’ì„ ì•Œì•„ì•¼ modelì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê´€ì¸¡ëœ Graphì—ì„œ ëª‡ëª‡ nodeë¥¼ ë” ìˆ¨ê²¨ (hide) missing linkë¥¼ ë°œìƒì‹œí‚¨ë‹¤. ê·¸ë¦¬ê³  NeighGenì„ ìœ„í•œ GNNì„ í†µí•´ nodeë§ˆë‹¤ì˜ representationì„ ë½‘ì•„ ë‚¸ë’¤ dGenì„ í†µí•˜ì—¬ ëª‡ê°œì˜ nodeê°€ ìˆ¨ê²¨ì¡ŒëŠ”ì§€ ì˜ˆì¸¡í•œë‹¤. ì—¬ê¸°ì„œ dGenëŠ” $\theta^d$ë¼ê³  í‘œê¸°ë˜ëŠ” parameterë¥¼ ê°€ì§„ linear regression ëª¨ë¸ì´ë‹¤. ê·¸ë˜ì„œ ë…¼ë¬¸ì—ëŠ” ì•„ë˜ ìˆ˜ì‹ìœ¼ë¡œ missing neighbor ìˆ˜ì¸ $\tilde{n_v}$ ë¥¼ predictionì„ í•œë‹¤ê³  í•˜ëŠ”ë° ë…¼ë¬¸ì˜ $n_v$ëŠ” typoì¸ ê²ƒ ê°™ê³  node representationì„ íƒ€ë‚˜ë‚´ëŠ” $z_v$ë¡œ ëŒ€ì²´ ë˜ì–´ì•¼ í•  ê²ƒ ê°™ë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1wgW8ENe9ArVcUcWsN3C5cdB0T2u4sYuu&quot; alt=&quot;dGen&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ë¦¬ê³  fGenì—ì„œëŠ” ì˜ˆì¸¡ëœ missing neighborìˆ˜ ë§Œí¼ nodeë¥¼ ë§Œë“¤ì–´ ì¤˜ì•¼ í•˜ëŠ”ë° ë‹¤ì–‘ì„±ì„ ìœ„í•˜ì—¬ Gaussian noiseì™€ node representatinoì„ ë”í•´ì£¼ê³  fGenì˜ parameter $\theta^f$ì™€ ê³±í•´ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ìƒˆë¡œìš´ node featureë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤. ì´ ë•Œ dGenì—ì„œ ì˜ˆì¸¡í•œ missing neighbor ê°œìˆ˜ì¸ $\tilde{n_v}$ê°œ ë§Œí¼ ìƒì„±í•˜ê³  ìˆ˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤. (ì—¬ê¸°ì„œ Rì€ Random Samplerë¥¼ ì˜ë¯¸í•œë‹¤)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1U8_7sHEpJIO9IsuPGfEku-IjK4kvmeAk&quot; alt=&quot;fGen&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ë˜ì„œ ì „ë°˜ì ì¸ NeighGenì— ê´€í•œ í•™ìŠµì€ ìœ„ ì˜ˆì¸¡ê°’ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ìˆ˜ì‹ê³¼ ê°™ì´ ì‹¤ì œ missing neighborì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ëŠ” dGenì— ê´€í•œ loss ê·¸ë¦¬ê³  Generateí•œ Neighborì™€ holdingëœ Neighborì˜ feature differenceë¥¼ ê³„ì‚°í•˜ëŠ” ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ëœë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1IZIcwK_5nJ3wDtDSLZC3AhglMBENGhfo&quot; alt=&quot;Graph_mending&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Downstream taskì¸ node classification (fedsageì™€ ë™ì¼)ì— ëŒ€í•œ lossì™€ balance parameterì¸ $\lambda$ì™€ í•¨ê»˜ ê²°í•©í•˜ì—¬ ì•„ë˜ ìµœì¢… loss functionì´ ë„ì¶œëœë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=13YbmbMAiP28gAwae_MA7Q94H8FXlobp5&quot; alt=&quot;overall&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;federated-learning-of-graphsage-and-neighgen&quot;&gt;Federated Learning of GraphSage and NeighGen&lt;/h3&gt;

&lt;p&gt;Federated Learningì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ìœ„ Loss functionì„ ë°”íƒ•ìœ¼ë¡œ Graphsageì¸ì½”ë”ì™€ NeighGenì„ ê°ê°ì˜ local systemì—ì„œ í•™ìŠµì‹œí‚¤ê³  Fedavgë¥¼ í•˜ëŠ” ê²ƒì´ ê°€ì¥ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ ë°©ë²•ì¼ ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ì €ìëŠ” ì‹¤í—˜ì ìœ¼ë¡œ NeighGenì˜ weightë¥¼ averagingì„ í–ˆì„ ê²½ìš° diverseí•œ neighborhood nodeê°€ ë§Œë“¤ì–´ì§€ì§€ ì•Šì•˜ë‹¤ê³  í•œë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1a2BnNEAHL4ZVVqzRdlwh_me5uuJ7fqjQ&quot; alt=&quot;fGen_local&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë”°ë¼ì„œ NeighGenì€ ê³µí†µëœ í•˜ë‚˜ì˜ modelì„ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ localí•œ modelì„ ê°ì í•™ìŠµì‹œí‚¤ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ” techniqueì„ ì´ìš©í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ ë‹¤ë¥¸ nodeì˜ ì •ë³´ë¥¼ ë™ì‹œì— ì´ìš©í•˜ê¸° ìœ„í•´ì„œ ìœ„ì˜ ìˆ˜ì‹ê³¼ ê°™ì´ ë³€ê²½í•˜ì˜€ëŠ”ë° ì‚´í´ë³´ë©´ ì•ìª½ termì€ ê¸°ì¡´ì— local systemë‚´ì—ì„œ minimizeí•˜ë˜ lossì™€ ë™ì¼í•œë° ë’¤ìª½ termì€ ë‹¤ë¥¸ clientì— ìˆëŠ” nodeì™€ì˜ distanceë¥¼ minimizeí•˜ëŠ” termì´ ìˆë‹¤. ì´ lossë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ë¥¸ nodeì˜ ì •ë³´ë¥¼ ë°›ì•„ì™€ì•¼ í•˜ëŠ”ë° ì´ëŠ” Federated Learningì˜ ì„¸íŒ…ê³¼ ë§ì§€ ì•Šê¸° ë•Œë¬¸ì— ê°ìì˜ modelì˜ weightì™€ node representationì„ serverë¡œ ë³´ë‚´ì„œ serverì—ì„œ í•´ë‹¹ termì„ ê³„ì‚°í•˜ê³  gradientë¥¼ ë³´ë‚´ì£¼ëŠ” ë°©ì‹ì˜ trickì„ ì´ìš©í–ˆë‹¤ê³  í•œë‹¤. ê·¸ë ‡ë‹¤ê³  í•´ë„ node representationì„ serverë¡œ ì „ì†¡í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— privacyë¬¸ì œê°€ ì „í˜€ ì—†ë‹¤ê³  í•  ìˆ˜ëŠ” ì—†ì„ ê²ƒì´ê³  ì´ ë¶€ë¶„ì´ ì´ ë…¼ë¬¸ì˜ ê°€ì¥ í° limitationì´ë¼ê³  ìƒê°í•œë‹¤. ì„¤ëª…í•œ ë¶€ë¶„ì— ê´€í•œ ìˆ˜ë„ ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1IH_yPZmVmgwwI_AsGckqN7Xgovq5iDZH&quot; alt=&quot;fedsage+&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-experiments&quot;&gt;3. Experiments&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1XHx8BVUdSfdgpmCiKqr77BZjUZyVqweU&quot; alt=&quot;statistics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìœ„ ë…¼ë¬¸ì—ì„œëŠ” Subgraph Federated Learningì‹¤í—˜ì„ ìœ„í•´ ì „ì²´ graphë¥¼ Louvain methodë¥¼ í†µí•´ì„œ ì—¬ëŸ¬ partitionìœ¼ë¡œ ë‚˜ëˆˆ ë’¤ Silo ìˆ˜ (Subgraph ìˆ˜)ì¸ Mê°œ ë§Œí¼ ë‚˜ëˆ ì„œ ê°ê°ì˜ siloì— ë°°ë¶„í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‹¤í—˜ ì„¸íŒ…ì„ í•˜ì˜€ë‹¤. Benchmark datasetì¸ Cora, Citeseer, Pubmed, MSAcademicì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í–ˆê³  $\Delta E$ê°€ í•´ë‹¹ ê°¯ìˆ˜ë¡œ partitioní–ˆì„ ë•Œ ë°œìƒí•˜ëŠ” missing linkê°œìˆ˜ë¥¼ ì˜ë¯¸í•˜ëŠ”ë° Siloìˆ˜ê°€ ë§ì•„ ì§ˆìˆ˜ë¡ ë‹¹ì—°íˆ ë” Missing linkê°€ ë§ì•„ ì§€ëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1fasj0podN9FZ0oU5aG4BomJYim2UyNFY&quot; alt=&quot;statistics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìœ„ Benchmark ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ ì‹¤í—˜í•œ ê²°ê³¼ Federated Learningì„ ì´ìš©í•œ FedSageê°€ ê°ê°ì˜ local modelì—ì„œ GNNì„ í•™ìŠµí•œ LocSageì— ë¹„í•´ì„œ í° ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ Subgraph Federated Learningì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤¬ë‹¤. ë˜í•œ FedSage+ ì¦‰ Missing Neighborë¥¼ ë§Œë“¤ì–´ ì¤€ ëª¨ë¸ì´ ëª¨ë“  ì„¸íŒ…ì—ì„œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ í•´ë‹¹ Missing linkì˜ ì¤‘ìš”ì„±ì„ ë³´ì—¬ì¤Œê³¼ í•¨ê»˜ ì œì•ˆëœ ëª¨ë¸ì˜ ìš°ìˆ˜ì„±ì„ ì…ì¦í•˜ì˜€ë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?export=download&amp;amp;id=1fJa1HsP9ArosVH0a50_-By6dDtmlao7Z&quot; alt=&quot;statistics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ë¦¬ê³  ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ë•Œ ë‹¤ë¥¸ Siloì˜ node ì •ë³´ë¥¼ ì´ìš©í•œ portionì¸ $\alpha$ì™€ í•™ìŠµ ì‹œ ì–´ëŠì •ë„ì˜ nodeë¥¼ hide ì‹œí‚¬ì§€ì— ëŒ€í•œ hyper-parameterì¸ hì— ëŒ€í•œ Sensitivity anlaysisë¥¼ í•˜ì˜€ë‹¤. ìœ„ ì‹¤í—˜ì„ í†µí•´ ë‹¤ë¥¸ siloì˜ ì •ë³´ë¥¼ ì ì •ëŸ‰ ê°€ì ¸ ì˜¤ëŠ” ê²ƒì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ ì™œ ìœ„ì˜ lossë¥¼ fedavgí•˜ì§€ ì•Šê³  NeighGenì„ ê°ê¸° í•™ìŠµì‹œì¼°ëŠ”ì§€ ë³´ì—¬ì£¼ì—ˆë‹¤.&lt;/p&gt;

&lt;h1 id=&quot;4-conlcusion&quot;&gt;4. Conlcusion&lt;/h1&gt;

&lt;p&gt;í•´ë‹¹ ë…¼ë¬¸ì„ ì¢…í•©í•´ë³´ë©´ &lt;strong&gt;Subgraph Federated Learning&lt;/strong&gt;ì˜ í•„ìš”ì„±ì„ ì¢‹ì€ ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•´ì£¼ì—ˆê³  ê·¸ì— ë”°ë¼ Missing Linkë¼ëŠ” Graph domainë§Œì˜ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ì œê¸°í•˜ì˜€ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Neighborhood generatorë¼ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•˜ì˜€ëŠ”ë° methodì ìœ¼ë¡œ ì•„ì£¼ íšê¸°ì ì¸ ë…¼ë¬¸ì€ ì•„ë‹ˆì˜€ì§€ë§Œ ì—°êµ¬ë¥¼ í•  ë•Œ ìƒˆë¡œìš´ ë¬¸ì œë¥¼ ì˜ ì •ì˜í•´ë³´ê³  ì‹¤ì œë¡œ ê·¸ëŸ°ì§€ ì‹¤í—˜ì„ í†µí•´ì„œ ì˜ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ëŠ” êµí›ˆì„ ì£¼ëŠ” ë…¼ë¬¸ì´ë¼ê³  ìƒê°í•œë‹¤.&lt;/p&gt;

&lt;h1 id=&quot;reviewer-information&quot;&gt;Reviewer Information&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Name : Junseok Lee&lt;/li&gt;
  &lt;li&gt;Affilitation : DSAIL in KAIST&lt;/li&gt;
  &lt;li&gt;Research Topic : Graph Mining, Bioinformatics&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Thu, 20 Apr 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/Subraph_Federated_Learning_with_Missing_Neighbor_Generation.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/Subraph_Federated_Learning_with_Missing_Neighbor_Generation.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICML 2022] Structure-Aware Transformer for Graph Representation Learning</title>
            <description>&lt;h1 id=&quot;structure-aware-transformer-for-graph-representation-learning&quot;&gt;&lt;strong&gt;Structure-Aware Transformer for Graph Representation Learning&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Background before reading this review.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Graphêµ¬ì¡°ì— ë§ê²Œ Transformerë¥¼ ì ìš©í•˜ì—¬ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ SATë¥¼ ì œì‹œí•œ ë…¼ë¬¸ &lt;a href=&quot;https://arxiv.org/abs/2202.03036&quot;&gt;Structure-Aware Transformer for Graph Representation Learning&lt;/a&gt;ë¥¼ ì½ê¸°ì „ì— ì•Œê³  ë„˜ì–´ê°€ì•¼í•  Graph Notation, Transformerì— ëŒ€í•œ ì„¤ëª… ë“± ê°„ë‹¨í•˜ê²Œ ì§šê³  ë„˜ì–´ê°€ë©´ ì¢‹ì€ ë‚´ìš©ë“¤ì…ë‹ˆë‹¤. ì‚¬ì „ ì§€ì‹ì´ ìˆìœ¼ì‹  ê²½ìš°, ë°”ë¡œ ë³¸ë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;*Notation&lt;/p&gt;

&lt;p&gt;$G = (V, E, \mathbf X)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;node $u \in V$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;node attribute $x_u \in  \mathcal X \subset  \mathbb R^d$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\mathbf X \in  \mathbb R^{n \times d}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Transformer êµ¬ì„± ìš”ì†Œ&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Self-attention module&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;input node feature $\mathbf X$ê°€ linear projectionì„ í†µí•´ Query($\mathbf Q$), Key($\mathbf K$), Value($\mathbf V$)ë¡œ íˆ¬ì˜ë˜ê³ , ì´ë¥¼ í™œìš©í•˜ì—¬ self-attentionì„ ê³„ì‚°í•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;multi-head attention : self-attentionì˜ initializeë¥¼ ë‹¤ì–‘í•˜ê²Œ í•˜ì—¬ í‘œí˜„ë ¥ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;feed-forward NN&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;self-attentionì˜ outputì´ skipconnectionì´ë‚˜ FFNë“±ì„ ê±°ì¹˜ë©´ í•˜ë‚˜ì˜ transforemer layerë¥¼ í†µê³¼í•œ ê²ƒ ì…ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Absolute encoding&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;ê·¸ë˜í”„ì˜ ìœ„ì¹˜ì /êµ¬ì¡°ì ì¸ representationì„ input node featureì— ë”í•˜ê±°ë‚˜ concatenateí•˜ì—¬ Transformerì˜ inputìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. (Vanilla transformerì˜ PEì™€ ê°™ì€ ì—­í• )&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Graph Transformerì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” Positional encoding methodë“¤&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ìì£¼ ì‚¬ìš©ë˜ëŠ” PEë¡œëŠ” ë‹¤ìŒ ë‘ê°€ì§€ë¥¼ ê¼½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ Positional Encodingë“¤ì˜ ë¬¸ì œëŠ” ë…¸ë“œì™€ ê·¸ ì´ì›ƒë“¤ ì‚¬ì´ì˜ structural similarityë¥¼ ë°˜ì˜í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ê°ê°ì— ëŒ€í•œ ì„¤ëª…ì€ ë§í¬ë¥¼ íƒ€ê³  ë“¤ì–´ê°€ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://paperswithcode.com/method/laplacian-pe&quot;&gt;Laplacian PE&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2110.07875.pdf&quot;&gt;Random Walk PE&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Self-attention and kernel smoothing&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$\operatorname{Attn}\left(x_v\right)=\sum_ {u \in V} \frac{\kappa_ {\exp }\left(x_v, x_u\right)}{\sum_ {w \in V} \kappa_ {\exp }\left(x_v, x_w\right)} f\left(x_u\right), \forall v \in V$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;linear value function $f(x) = \mathbf W_ {\mathbf V}x$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\kappa_ {\exp }$ (non-symmetric) exponential kernel parameterized by $\mathbf W_ {\mathbf Q}, \mathbf W_ {\mathbf K}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\kappa_ {\exp }\left(x, x^{\prime}\right):=\exp  \left(\left\langle\mathbf{W}_ {\mathbf{Q}} x, \mathbf{W}_ {\mathbf{K}} x^{\prime}\right\rangle / \sqrt{d_ {\text {out }}}\right)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$\langle  \cdot, \cdot\rangle$ : dotproduct&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;í•™ìŠµê°€ëŠ¥í•œ exponential kernel&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(-) only position-aware, not structure-aware encoding&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;limitations-of-gnn&quot;&gt;&lt;em&gt;&lt;strong&gt;Limitations of GNN&lt;/strong&gt;&lt;/em&gt;&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;limited expressiveness : GNNì€ message passingê³¼ì •ì—ì„œì˜ aggregation operationì˜ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ìµœëŒ€ 1-WL testì˜ í‘œí˜„ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤. GNNì˜ WL-testì™€ expressionì— ëŒ€í•œ ë¶„ì„ì€ GINì„ ì œì‹œí•œ ë…¼ë¬¸ì¸ &lt;a href=&quot;https://arxiv.org/abs/1810.00826&quot;&gt;How Powerful are Graph Neural Networks?&lt;/a&gt; ì—ì„œ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Over-smoothing problem : GNN layerì˜ ìˆ˜ê°€ ì¶©ë¶„íˆ ì»¤ì§€ë©´ ëª¨ë“  node representationì´ ìƒìˆ˜ë¡œ ìˆ˜ë ´í•˜ê²Œë©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Over-squashing problem : ê·¸ë˜í”„ì˜ ìˆ˜ë§ì€ ë©”ì„¸ì§€ë“¤ì´ ê³ ì •ëœ ê¸¸ì´ì˜ ë²¡í„° í•˜ë‚˜ë¡œ ì••ì¶•ë˜ì–´ ë°œìƒí•˜ëŠ” ê·¸ë˜í”„ â€œbottleneckâ€ìœ¼ë¡œ ì¸í•´ ë©€ë¦¬ ìœ„ì¹˜í•œ ë…¸ë“œì˜ ë©”ì„¸ì§€ê°€ íš¨ìœ¨ì ìœ¼ë¡œ ì „íŒŒë˜ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;â‡’ Beyond neighborhood aggregation!&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;transformer&quot;&gt;&lt;em&gt;&lt;strong&gt;Transformer&lt;/strong&gt;&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;Transformerë¥¼ ì ìš©í–ˆì„ ë•Œì˜ ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;í•˜ë‚˜ì˜ self-attention layerë¥¼ í†µí•´ ê·¸ë˜í”„ë‚´ì˜ ì–´ë–¤ ë…¸ë“œìŒì´ë“ ì§€ ê·¸ ì‚¬ì´ì˜ ìƒí˜¸ì‘ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GNNê³¼ ë‹¬ë¦¬ ì¤‘ê°„ ê³„ì¸µì—ì„œ structural inductive biasê°€ ë°œìƒí•˜ì§€ ì•Šì•„ GNNì˜ í‘œí˜„ë ¥ í•œê³„ë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

    &lt;p&gt;ë°˜ë©´, ë‹¨ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;graph structure infoë¥¼ ì–¼ë§ˆë‚˜ í•™ìŠµí•˜ëŠ”ì§€ input node featureì—ë§Œ structural, positional ì •ë³´ë¥¼ ì¸ì½”ë”©í•˜ì—¬ ë„£ê¸° ë•Œë¬¸ì— ì œí•œì ì…ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ë…¸ë“œì— ëŒ€í•œ structural, positional ì •ë³´ë§Œ input node featureë¡œ ì¸ì½”ë”©í•˜ê¸° ë•Œë¬¸ì—, ê·¸ë˜í”„ êµ¬ì¡° ìì²´ì—ì„œ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì •ë³´ì˜ ì–‘ì´ ì œí•œì ì…ë‹ˆë‹¤.&lt;/p&gt;

    &lt;p&gt;ë”°ë¼ì„œ ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ê³ ì í•˜ëŠ” Graph Transformerì˜ Goalì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;ğŸ’¡ Goal : ê·¸ë˜í”„ ë°ì´í„°ì— Transformerë¥¼ ì ì ˆíˆ ë³€í˜•í•´ ì ìš©í•˜ì—¬ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì˜ ë°˜ì˜í•˜ê³  ë†’ì€ í‘œí˜„ë ¥ì„ ê°€ì§€ëŠ” Achitectureë¥¼ ë””ìì¸í•˜ëŠ” ê²ƒ&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;message-passing-graph-neural-networks&quot;&gt;&lt;em&gt;&lt;strong&gt;Message passing graph neural networks.&lt;/strong&gt;&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;ìµœëŒ€ 1-WL testë¡œ ì œí•œëœ í‘œí˜„ë ¥, over-smoothing, over-quashing&lt;/p&gt;

&lt;h2 id=&quot;limitations-of-existing-approaches&quot;&gt;&lt;em&gt;&lt;strong&gt;Limitations of existing approaches&lt;/strong&gt;&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;ê¸°ì¡´ì— Graphêµ¬ì¡°ì— Transformerë¥¼ ì ìš©í•˜ëŠ” ì‹œë„ê°€ ì—†ì—ˆë˜ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì–´ë–¤ê²ƒì´ ë¬¸ì œê°€ ë˜ì—ˆì„ê¹Œìš”?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ë…¸ë“œë“¤ ì‚¬ì´ positional relationshipë§Œ ì¸ì½”ë”©í•˜ê³ , strucutral relationshipì„ ì§ì ‘ ì¸ì½”ë”©í•˜ì§€ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ì— ë”°ë¼ ë…¸ë“œë“¤ ì‚¬ì´ structural similarityë¥¼ í™•ì¸í•˜ê¸°ê°€ ì–´ë µê³ , ë…¸ë“œë“¤ ì‚¬ì´ì˜ structural interactionì„ ëª¨ë¸ë§í•˜ëŠ”ë° ì‹¤íŒ¨í•œê²ƒìœ¼ë¡œ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ë‹¤ìŒì˜ ê·¸ë¦¼ ì˜ˆì‹œë¥¼ ë³´ë©´ ì´í•´ê°€ ë” ì‰½ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ex.
&lt;img src=&quot;https://github.com/sujinyun999/LearningOnGraph/assets/69068083/4472bb78-65cc-43bf-90be-8dcd203616d8&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;G1ê³¼ G2ì—ì„œ ìµœë‹¨ê±°ë¦¬ë¥¼ í™œìš©í•œ positional encodingì„ í• ê²½ìš° node uì™€ vê°€ ë‹¤ë¥¸ ë…¸ë“œë“¤ì— ëŒ€í•´ ëª¨ë‘ ê°™ì€ representationì„ ê°€ì§€ê²Œë˜ì§€ë§Œ, ê·¸ë˜í”„ì˜ ì‹¤ì œ êµ¬ì¡°ëŠ” ë‹¤ë¦…ë‹ˆë‹¤. 
â†’ ì´ ì§€ì ì´ ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ëŠ” ê¸°ì¡´ Graph Transformerì˜ ë¬¸ì œ, ì¦‰, strucure awareì— ì‹¤íŒ¨í•œ ê²ƒ ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ğŸ’¡ Message-passing GNNê³¼ Transformer architecture ê°ê°ì˜ ì¥ì ì„ ì‚´ë ¤ local, global infoë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ëŠ” transformer architectureë¥¼ ì œì•ˆ&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;contribution-of-this-paper&quot;&gt;&lt;em&gt;&lt;strong&gt;Contribution of this paper&lt;/strong&gt;&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;Q. ê·¸ë ‡ë‹¤ë©´ ë…¼ë¬¸ì—ì„œ í•´ê²°í•˜ê³ ìí•˜ëŠ” Structure-Awareë¥¼ ìœ„í•´ Transformerêµ¬ì¡°ì— structural infoë¥¼ ì–´ë–»ê²Œ ì¸ì½”ë”©í• ê¹Œìš”?&lt;/p&gt;

&lt;p&gt;ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ë‹µí•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;A. Structure-aware self attentionë¥¼ ë„ì…í•œ Structre-Aware Transformer(SAT)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;reformulate the self-attention mechanism&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;kernel smoother&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ì›ë˜ ë…¸ë“œ featureì— ì ìš©í•˜ëŠ” exponential ì»¤ë„ì„ í™•ì¥í•˜ì—¬ ê° ë…¸ë“œê°€ ì¤‘ì‹¬ì¸ subgraph representationì„ ì¶”ì¶œí•˜ì—¬ local structureì—ë„ ì ìš©í•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;subgraph representationë“¤ì„ ìë™ì ìœ¼ë¡œ ë§Œë“¤ì–´ë‚´ëŠ” ë°©ë²•ë¡  ì œì•ˆ&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;ì´ë¥¼ í†µí•´ kernel smootherê°€ êµ¬ì¡°ì /íŠ¹ì„±ì  ìœ ì‚¬ì„±ì„ í¬ì°©í•  ìˆ˜ ìˆê²Œë©ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;GNNìœ¼ë¡œ ê·¸ë˜í”„ì˜ subgraph infoë¥¼ í¬í•¨í•˜ëŠ” node representationì„ ë§Œë“¤ì–´ ê¸°ì¡´ GNNì— ì¶”ê°€ì ì¸ êµ¬ì¡° ê°œì„  ì—†ì´ë„ ë” ë†’ì€ ì„±ëŠ¥ì„ ëƒ…ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Transformerì˜ ì„±ëŠ¥í–¥ìƒì´ structure-awareí•œ ì¸¡ë©´ì—ì„œ ì¼ì–´ë‚œ ê²ƒì„ ì¦ëª…í•˜ê³  absolute encodingì´ ì¶”ê°€ëœ transfoemrë³´ë‹¤ SATê°€ ì–¼ë§ˆë‚˜ interpretableí•œì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;structure-aware-transformer&quot;&gt;&lt;em&gt;&lt;strong&gt;Structure-Aware Transformer&lt;/strong&gt;&lt;/em&gt;&lt;/h2&gt;

&lt;h3 id=&quot;1-structure-aware-self-attention&quot;&gt;&lt;em&gt;1. &lt;strong&gt;Structure-Aware Self-attention&lt;/strong&gt;&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;position-awareí•œ structural encodingì— ë…¸ë“œë“¤ ì‚¬ì´ structural similarityë¥¼ í¬í•¨í•˜ê¸° ìœ„í•´ ê° ë…¸ë“œì˜ local structureì— ê´€í•œ generalized kernelì„ ì¶”ê°€í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ê° ë…¸ë“œê°€ ì¤‘ì‹¬ì´ë˜ëŠ” subgraph setì„ ì¶”ê°€í•¨ìœ¼ë¡œì¨ structure-aware attentionì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;$\operatorname{SA-Attn}\left(v\right):=\sum_ {u \in V} \frac{\kappa_ {\text{graph} }\left(S_G(v), S_G(u)\right)}{\sum_ {w \in V} \kappa_ {\text{graph}}\left(S_G(v), S_G(u)\right)} f\left(x_u\right)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$S_G(v)$ : node feature $\mathbf X$ì™€ ì—°ê´€ëœ $v$ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œí•˜ëŠ” subgraph&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\kappa_ {\text{graph} }$ : subgraphìŒì„ ë¹„êµí•˜ëŠ” kernel&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;â‡’ attribute &amp;amp; structural similarity ëª¨ë‘ í‘œí˜„ ê°€ëŠ¥í•œ expressive node representationì„ ìƒì„± â†’ table 1&lt;/p&gt;

&lt;p&gt;â‡’ ë™ì¼í•œ subgraph êµ¬ì¡°ë¥¼ ê°€ì§€ëŠ” ê²½ìš°ì—ë§Œ permutation equivariantí•œ ì„±ì§ˆì„ ê°–ê²Œë¨&lt;/p&gt;

&lt;p&gt;$\kappa_ {\text {graph }}\left(S_G(v), S_G(u)\right)=\kappa_ {\exp }(\varphi(v, G), \varphi(u, G))$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$\varphi(v, G)$ : feature $\mathbf X$ë¥¼ ê°€ì§€ëŠ” node $v$ê°€ ì¤‘ì‹¬ì— ìˆëŠ” subgraphì˜ vector representationì„ ë§Œë“¤ì–´ë‚´ëŠ” structure extractor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GNNì´ë‚˜ differentiable Graph kernelë“± subgraphì˜ representationì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì–´ëŠ ëª¨ë¸ì´ë“  ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Task/data íŠ¹ì„±ì— ë”°ë¼ Edge attributeì„ í™œìš©í•  í•„ìš”ê°€ ìˆëŠ” ê²½ìš° ê·¸ì— ë§ëŠ”GNNì„ ì„ íƒí•˜ëŠ” ë””ìì¸ ì´ˆì´ìŠ¤ê°€ ìƒê¹ë‹ˆë‹¤. edge attributeì„ ë”°ë¡œ í™œìš©í•˜ì§€ëŠ” ì•Šê³  subgraph extractorì—ì„œ í™œìš©í•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;k-subtree GNN extractor.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;$\varphi(u, G) = \operatorname{GNN}_G^{(k)}(u)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;node uì—ì„œ ì‹œì‘í•˜ëŠ” k-subtree structureì˜ representationì„ ìƒì„±í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;at most 1-WL test : ìœ„ì—ì„œ ì§€ì í•œ GNNì˜ í•œê³„ì™€ ê°™ì´, ìµœëŒ€ 1WL Testì˜ í‘œí˜„ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ë…¼ë¬¸ì—ì„œëŠ” ì‹¤í—˜ì„ í†µí•´ ì‘ì€ k ê°’ì´ë”ë¼ë„ over-smoothing, over-squashing issueì—†ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ”ê²ƒì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;k-subgraph GNN extractor.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;$\varphi(u, G) = \sum_ {v \in  \mathcal N_k(u)} \operatorname{GNN}_G^{(k)}(v)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;node uì˜ representationë§Œì„ ì‚¬ìš©í•˜ëŠ”ë°ì„œ ë‚˜ì•„ê°€ node uê°€ ì¤‘ì‹¬ì´ ë˜ëŠ” k-hop subgraphì „ì²´ì˜ representationì„ ìƒì„±í•˜ê³  í™œìš©í•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;node u ì˜ k-hopì´ì›ƒ $\mathcal N_k(u)$ì— ëŒ€í•´ ê° ë…¸ë“œì— GNNì„ ì ìš©í•œ node representationì„ pooling(ë…¼ë¬¸ì—ì„œëŠ” summation)í•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;More powerful than 1-WL test!&lt;/strong&gt; ìœ„ì—ì„œ k-subtree GNN extractorì™€ì˜ ê°€ì¥ í° ì°¨ì´ì…ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;original node representationê³¼ì˜ concatenationì„ í†µí•´ structural similarityë¿ë§Œ ì•„ë‹ˆë¼ attributed similarityë„ ë°˜ì˜í•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì´ì™¸ì— ë‹¤ë¥¸ structure extractorë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê²ƒë“¤ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Other structure extractors.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;directly learn a number of â€œhidden graphsâ€ as the â€œanchor subgraphsâ€ to represent subgraphs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;domain-specific GNNs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;non-parametric graph-kernel&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-structure-aware-transformer&quot;&gt;&lt;em&gt;2. Structure-Aware Transformer&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/69068083/231114106-a71006e8-a9e5-44cb-b353-578ec4e09a80.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;self-attentionâ†’ skipconnection â†’ normalization layer â†’ FFN â†’ normalization layer&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Augmentation on skip connection.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;$xâ€™_v = x_c +1/ \sqrt {d_v} \operatorname{SA-Attn}\left(v\right)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$d_v$ : node $v$ì˜ degree&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;degree factorë¥¼ í¬í•¨í•˜ì—¬ ì—°ê²°ì´ ë§ì€ graph componentë“¤ì´ ì••ë„ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šë„ë¡í•©ë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;*graph-level taskë¥¼ ì§„í–‰í•´ì•¼ í•  ê²½ìš° input graphì— ë‹¤ë¥¸ ë…¸ë“œì™€ì˜ connectivityì—†ì´ virtual &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[cls] &lt;/code&gt;nodeë¥¼ ì¶”ê°€í•˜ê±°ë‚˜, node-level representationì„ sum/average ë“±ìœ¼ë¡œ aggregation&lt;/p&gt;

&lt;h3 id=&quot;3-combination-with-absolute-encoding&quot;&gt;&lt;em&gt;3. Combination with Absolute Encoding&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;ìœ„ì˜ structure aware self-attentionì— ì¶”ê°€ë¡œ absolute encodingì„ ì¶”ê°€í•˜ê²Œ ë˜ë©´ postion-awareí•œ íŠ¹ì„±ì´ ì¶”ê°€ë˜ì–´ ê¸°ì¡´ì˜ ì •ë³´ë¥¼ ë³´ì™„í•˜ëŠ” ì—­í• ì„ í•˜ê²Œë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë””ìì¸ ì´ˆì´ìŠ¤ì˜ ì¡°í•©ì„ í†µí•´ ì„±ëŠ¥í–¥ìƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RandomWalk PE&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Absolute PEë§Œ ì‚¬ìš©í•  ê²½ìš° structural biasê°€ ê³¼ë„í•˜ê²Œ ë°œìƒí•˜ì§€ ì•Šì•„ì„œ ë‘ê°œì˜ ë…¸ë“œê°€ ìœ ì‚¬í•œ local structureë¥¼ ê°–ê³  ìˆë”ë¼ë„ ë¹„ìŠ·í•œ node representationì´ ìƒì„±ë˜ëŠ”ê²ƒì„ ë³´ì¥í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤!&lt;/p&gt;

&lt;p&gt;â†’ ì´ëŠ” Structural, positional signìœ¼ë¡œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” distanceë‚˜ Laplacian-based positional representationì´ ë…¸ë“œë“¤ ì‚¬ì´ì˜ structural simialrityë¥¼ í¬í•¨í•˜ì§€ ì•Šê¸°ë•Œë¬¸ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ğŸ“Œ Structural aware attenrionì€ inductive biasê°€ ë” ê°•í•˜ë”ë¼ë„ ë…¸ë“œì˜ strucutral similarityë¥¼ ì¸¡ì •í•˜ëŠ”ë° ì í•©í•˜ì—¬ ìœ ì‚¬í•œ subgraphêµ¬ì¡°ë¥¼ ê°€ì§„ ë…¸ë“œë“¤ì´ ë¹„ìŠ·í•œ embeddingì„ ê°–ê²Œí•˜ê³ , expressivityê°€ í–¥ìƒë˜ì–´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;4-expressivity-analysis&quot;&gt;&lt;em&gt;4. Expressivity Analysis&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;SATì—ì„œëŠ” ê°ë…¸ë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œí•˜ëŠ” k-subgraph GNN extractorê°€ ë„ì…ë˜ì–´ ì ì–´ë„ subgraph representationë§Œí¼ì€ expressive(More than 1WL Test)í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì¥í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h1 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h1&gt;

&lt;h3 id=&quot;experiment-setup&quot;&gt;&lt;em&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Dataset&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ZINC :
    &lt;ul&gt;
      &lt;li&gt;from &lt;a href=&quot;https://arxiv.org/abs/1610.02415&quot;&gt;Automatic chemical design using a data-driven continuous representation of molecules&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;250,000ê°œì˜ ë¶„ì ê·¸ë˜í”„êµ¬ì¡°,  with up to 38 heavy atoms&lt;/li&gt;
      &lt;li&gt;task is to regress the penalized &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;logP&lt;/code&gt; (also called constrained solubility)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CLUSTER :
    &lt;ul&gt;
      &lt;li&gt;from &lt;a href=&quot;https://arxiv.org/abs/2003.00982&quot;&gt;Benchmarking Graph Neural Networks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;task is semi-supervised graph clustering (node classification)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;PATTERN
    &lt;ul&gt;
      &lt;li&gt;from &lt;a href=&quot;https://arxiv.org/abs/2003.00982&quot;&gt;Benchmarking Graph Neural Networks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;task is semi-supervised graph pattern recognition&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;OGBG-PPA
    &lt;ul&gt;
      &lt;li&gt;from &lt;a href=&quot;https://arxiv.org/abs/2005.00687&quot;&gt;Open Graph Benchmark: Datasets for Machine Learning on Graphs&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Protein-Protein Association Network&lt;/li&gt;
      &lt;li&gt;task is to predict new association edges given the training edges&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;OGBG-CODE2
    &lt;ul&gt;
      &lt;li&gt;from &lt;a href=&quot;https://arxiv.org/abs/2005.00687&quot;&gt;Open Graph Benchmark: Datasets for Machine Learning on Graphs&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Abstract Syntax Tree of Source Code&lt;/li&gt;
      &lt;li&gt;ASTë¡œ í‘œì‹œë˜ëŠ” Python ë©”ì„œë“œ ë³¸ë¬¸ê³¼ í•´ë‹¹ ë…¸ë“œ ê¸°ëŠ¥ì´ ì£¼ì–´ì§€ë©´ ë©”ì„œë“œ ì´ë¦„ì„ í˜•ì„±í•˜ëŠ” í•˜ìœ„ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” task&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Baseline&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;&lt;strong&gt;GNNs&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GCN&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GraphSAGE&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GAT&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GIN&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;PNA&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deeper GCN&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ExpC&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;&lt;strong&gt;Transformers&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Original Transformer with RWPE&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Graph Transformer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SAN&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Graphormer&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GraphTrans&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;results&quot;&gt;&lt;em&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Table1.&lt;/strong&gt; SATì™€ graph regression, classification taskì˜ sotaëª¨ë¸ê³¼ ë¹„êµ&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ZINC datasetì˜ ê²½ìš° ì‘ì„ìˆ˜ë¡ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸í•˜ëŠ” MAE(Mean Absolute Error), CLUSTERì™€ PATTERNì˜ ê²½ìš° ë†’ì„ìˆ˜ë¡ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸í•˜ëŠ” Acurracyê°€ í‰ê°€ì§€í‘œë¡œ ì‚¬ìš©ë˜ì—ˆìŒ.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/69068083/231114155-056893f6-8d16-4a59-b43b-62c76fd482a3.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Table2.&lt;/strong&gt; SATì™€ OGBë°ì´í„°ì…‹ì—ì„œì˜ sotaëª¨ë¸ ë¹„êµ&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;OGB datasetì˜ ê²½ìš° ë†’ì„ìˆ˜ë¡ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸í•˜ëŠ” Acurracy, F1 scoreê°€ í‰ê°€ì§€í‘œë¡œ ì‚¬ìš©ë˜ì—ˆìŒ.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/69068083/231114185-23daa0d6-bc32-4838-93e8-0a6d09a17f7e.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Table3.&lt;/strong&gt; structure extractorë¡œ ì‚¬ìš©í•œ GNNê³¼ì˜ ì„±ëŠ¥ë¹„êµ. Sparse GNNì„ ëª¨ë“  ê²½ìš°ì—ì„œ outperformí•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/69068083/231114223-e6e32dfd-039b-4caa-b123-14e72e9fc867.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fig3.&lt;/strong&gt; ZINCë°ì´í„°ì…‹ì— SATì˜ ë‹¤ì–‘í•œ variantì‹¤í—˜&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;í‰ê°€ì§€í‘œ : MAE(ë” ì‘ì€ ì§€í‘œê°€ ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/69068083/231114263-2ea26465-c8b3-4df8-b7d4-4d329d41d97b.png&quot; alt=&quot;Untitled&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;structure extractorì—ì„œì˜ kì˜ ì˜í–¥ ë¹„êµ&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;k=0ì¼ë•Œ, Absolute encodingë§Œì„ í™œìš©í•˜ëŠ” vanilla transformerë‘ ê°™ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;k=3ì¼ë•Œ, optimal performanceë¥¼ ë³´ì„ì„ ì‹¤í—˜ì„ í†µí•´ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;k=4ë¥¼ ë„˜ì–´ì„œë©´ ì„±ëŠ¥ì´ ì•…í™”ë˜ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆëŠ”ë°, ì´ëŠ” GNNì—ì„œì˜ ì•Œë ¤ì§„ ì‚¬ì‹¤ì¸ ë” ì ì€ ìˆ˜ì˜ layerë¥¼ ê°€ì§€ëŠ” networkê°€ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒê³¼ ë§ˆì°¬ê°€ì§€ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.(Oversmoothing and Oversquashing)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Absolute encodingì˜ ì˜í–¥ ë¹„êµ&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;RandomWalkPE vs. Laplacian PE&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Structure-aware attentionì˜ ë„ì…ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥í–¥ìƒë³´ë‹¤ëŠ” ê·¸ ì •ë„ê°€ ë‚®ì•˜ì§€ë§Œ, RWPEë¥¼ ë„ì…í•  ê²½ìš° ì„±ëŠ¥ì´ ë” ì¢‹ì€ê²ƒìœ¼ë¡œ ë³´ì•˜ì„ ë•Œ, ë‘ê°€ì§€ encodingì´ ìƒí˜¸ë³´ì™„ì ì¸ ì—­í• ì„ í•œë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Readout methodì˜ ì˜í–¥ ë¹„êµ&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;node-level representationì„ aggregateí•  ë•Œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ readoutìœ¼ë¡œ meanê³¼ sumì„ ë¹„êµí•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ì¶”ê°€ë¡œ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt; í† í°ì„ í†µí•´ graph-level ì •ë³´ë¥¼ poolingí•˜ëŠ” ë°©ë²•ë„ ê°™ì´ ë¹„êµí•˜ì—¬ë³´ì•˜ìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GNNì—ì„œëŠ” readout methodì˜ ì˜í–¥ì´ ë§¤ìš° ì»¸ì§€ë§Œ SATì—ì„œëŠ” ë§¤ìš° ì•½í•œ ì˜í–¥ë§Œì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Strong Points.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;structural infoë¥¼ graphormerì—ì„œì²˜ëŸ¼ íœ´ë¦¬ìŠ¤í‹±í•˜ê²Œ shortest path distance(SPD)ë¥¼ í™œìš©í•˜ì§€ ì•Šê³ , ê·¸ëŸ¬í•œ local infoë¥¼ ì˜ ë°°ìš°ëŠ” GNNìœ¼ë¡œ ëŒ€ì²´í•œ ì ì´ novelí•˜ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;Transformerì˜ global receptive field íŠ¹ì„±ê³¼ GNNì˜ local structureíŠ¹ì„±ì´ ìƒí˜¸ë³´ì™„ì ì¸ë°,&lt;/p&gt;

&lt;p&gt;encodingì— ìˆì–´ì„œë„&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;RWPEë¥¼ í†µí•œ positional encoding&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;k-subtree/subgraph GNNì„ í†µí•œ structure-aware attention&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ë‘ê°€ì§€ê°€ ìƒí˜¸ë³´ì™„ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;â†’ ê°ìê°€ ì˜ ë°°ìš°ëŠ” íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ìƒí˜¸ë³´ì™„ì ì¸ ë‘ê°€ì§€ ë°©ë²•ë¡ ì„ ì˜ ì„ì–´ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ì—ˆê³ , ê·¸ ì´ìœ ê°€ ë‚©ë“í•˜ê¸° ì‰¬ìš´ ë…¼ë¬¸ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Weak Points.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ë˜í”„ë°ì´í„°ì— Transformerë¥¼ ì ìš©í•œ ë‹¤ë¥¸ ë…¼ë¬¸ì˜ architectureì¸ Graphormerì—ì„œ ì‚¬ìš©í•œ SPDë§Œì˜ ì¥ì ì€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ìˆì§€ ì•Šì€, ì•„ì£¼ ë©€ë¦¬ì— ìœ„ì¹˜í•œ ë…¸ë“œìŒì´ë”ë¼ë„ shortest pathìƒì˜ weighted edge aggregationì„ í•˜ëŠ” ë§Œí¼ ê·¸ëŸ¬í•œ íŠ¹ì„±ì´ ë°˜ì˜ë˜ë©´ ì¢‹ì€ ê·¸ë˜í”„ êµ¬ì¡°/ ë°ì´í„°ì…‹ì—ì„œëŠ” ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ì´ì—ë”°ë¼ ì‘ì€ k-hopì˜ subgraphë¥¼ ê³ ë ¤í•˜ëŠ” SATê°€ captureí•˜ì§€ ëª»í•˜ëŠ” ë¶€ë¶„ì´ ìˆì„ ê²ƒìœ¼ë¡œ ìƒê°ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Sujin Yun&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GSDS, KAIST&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Github Implementation : &lt;a href=&quot;https://github.com/BorgwardtLab/SAT&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/BorgwardtLab/SAT&quot;&gt;https://github.com/BorgwardtLab/SAT&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reference : &lt;a href=&quot;https://arxiv.org/abs/2202.03036&quot;&gt;Structure-Aware Transformer for Graph Representation Learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Thu, 20 Apr 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/Structure_Aware_Transformer_for_Graph_Representation_Learning.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/Structure_Aware_Transformer_for_Graph_Representation_Learning.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[T-ITS 2021] Spatio-Temporal Knowledge Transfer for Urban Crowd Flow Prediction via Deep Attentive Adaptation Networks</title>
            <description>&lt;h1 id=&quot;0-overview&quot;&gt;0. Overview&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Title : Spatio-Temporal Knowledge Transfer for Urban Crowd Flow Prediction via Deep Attentive Adaptation Networks&lt;/li&gt;
  &lt;li&gt;Authors : Senzhang Wang, Hao Miao, Jiyue Li, Jiannong Cao&lt;/li&gt;
  &lt;li&gt;Year : 2021&lt;/li&gt;
  &lt;li&gt;Publish : TITS (IEEE Transactions on Intelligent Transportation Systems)&lt;/li&gt;
&lt;/ul&gt;

&lt;aside&gt;
ğŸ’¡ How to transfer spatio-temporal knowledge well, between different two domains?

&lt;/aside&gt;

&lt;aside&gt;
ğŸ’¡ We propose the ST-DAAN framework : ConvLSTM + DAN + Attention

&lt;/aside&gt;

&lt;h1 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h1&gt;

&lt;h2 id=&quot;1-why-do-we-need-it&quot;&gt;1) Why do we need it?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Deep learningì´ ë‹¤ì–‘í•œ spatio-temporal(ì‹œê³µê°„) prediction taskì— ì‚¬ìš©ë˜ê³  ìˆìŒ
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://ojs.aaai.org/index.php/AAAI/article/view/10735&quot;&gt;ST-ResNet(2017, Cit. 1606)&lt;/a&gt; : forecast crowds inflow &amp;amp; outflow in each region of a city&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1803.01254&quot;&gt;STDN(2018, Cit. 521)&lt;/a&gt; : road network based traffic prediction&lt;/li&gt;
      &lt;li&gt;predict passenger pickup/demand demands (Attention+ConvLSTM)&lt;/li&gt;
      &lt;li&gt;DeepTransport : predict the traffic data within a transport network (CNN+RNN)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;aside&gt;
ğŸ¥² í•˜ì§€ë§Œ, í˜„ì‹¤ì—ì„œ ì‹œê³µê°„ ì •ë³´ëŠ” ê·¸ë¦¬ í’ë¶€í•˜ì§€ ì•ŠìŒ â†’ DL ì‰½ê²Œ ì ìš©í•  ìˆ˜ ì—†ìŒ

&lt;/aside&gt;

&lt;aside&gt;
ğŸ¥² ë”ë¶ˆì–´ ì•ì„œ ì–¸ê¸‰í•œ ëª¨ë¸ë“¤ = ë‹¤ë¥¸ ì‹œê³µê°„ ì •ë³´ì—ë„ ì ìš©í•  ë§Œí¼ General í•˜ì§€ ì•ŠìŒ

&lt;/aside&gt;

&lt;ul&gt;
  &lt;li&gt;ìµœê·¼ì—ëŠ” transfer learningì„ ì‚¬ìš©í•´ ìƒê¸° ë¬¸ì œë¥¼ í’€ì–´ë³´ê³ ì í–ˆìŒ
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.00386&quot;&gt;RegionTrans(2019, Cit. 88)&lt;/a&gt; : source, target cityì˜ ë¹„ìŠ·í•œ ì§€ì—­ì„ ë§¤ì¹­ â†’ ì´ ì‘ì—… í•˜ë ¤ë©´ other service dataê°€ ë˜ í•„ìš” (data ê´€ì  = region level)&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1901.08518&quot;&gt;MetaST(2019, Cit. 166)&lt;/a&gt; : ì—¬ëŸ¬ ë„ì‹œì˜ ì¥ê¸°ì  ì¶”ì„¸ë¥¼ ë½‘ì•„ë‚´ì„œ target cityì— ì¨ë³´ì â†’ ì´ê±¸ automatically í•´ì£¼ëŠ” í†µí•© ëª¨ë¸ì€ ì—†ìŒ&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ìš°ë¦¬ëŠ” data ê´€ì  = distribution ìˆ˜ì •í•˜ê³ , unified frameworkë¥¼ ë§Œë“¤ì–´ë³´ê² ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-related-works--core-things&quot;&gt;2) Related works &amp;amp; Core things&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Urban Crowd Flow Prediction : ë„ì‹œ/êµí†µ ë¶„ì•¼ì˜ í° ì£¼ì œ. ì „í†µì ìœ¼ë¡œëŠ” ARIMA ê°™ì€ í†µê³„ based methodsë¥¼ ì£¼ë¡œ ì‚¬ìš©í–ˆìœ¼ë‚˜, ìµœê·¼ì—ëŠ” DL methodsê°€ ë§ì´ ì“°ì´ëŠ” í¸
    &lt;ul&gt;
      &lt;li&gt;DNN, ST-ResNet, SeqST-GAN, ConvLSTM, MT-ASTN, DCRNN, RegionTrans, MetaST ë“±&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Transfer Learning : MLì˜ scarce labeled data problemì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì‹œëœ ë°©ë²•ë¡ 
    &lt;ul&gt;
      &lt;li&gt;TCA, TLDA, JAN, JMMD ë“±&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1502.02791&quot;&gt;DAN(2015, Cit. 4413)&lt;/a&gt; : CNNì„ domain adaptation taskì— ë§ê²Œ ì¼ë°˜í™”, ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì—ì„œ í° ì„±ê³µ
    &lt;ul&gt;
      &lt;li&gt;Neural Netì´ general feature ì˜ ì¡ì•„ë‚´ê³  ì„±ëŠ¥ ì¢‹ë‹¤ë§Œ, labeled data ë³„ë¡œ ì—†ëŠ” target domainì— ë°”ë¡œ CNN ì“°ë‹ˆ ë¬¸ì œê°€ ë§ìŒ&lt;/li&gt;
      &lt;li&gt;ì‹¤ì œë¡œ &lt;a href=&quot;https://arxiv.org/abs/1411.1792&quot;&gt;Yosinski et al.(2014, Cit. 8740)&lt;/a&gt; ë³´ë‹ˆ Conv 1-3ê¹Œì§„ OK, Conv 4-5ë¶€í„° ì´ìƒí•´ì§€ë”ë‹ˆ, FC 6-8ì—ì„  ì™„ì „íˆ ë©”ë¡±&lt;/li&gt;
      &lt;li&gt;DAN ì €ìë“¤ì€ Conv 1-3ì€ ê·¸ëŒ€ë¡œ ë‘ê³ (freeze), Conv 4-5 ë‹¨ê³„ì— fine-tuning ì ìš©, FC 6-8ì€ CNN parameter optimizingì— multi-kernel MMDë¥¼ regularizerë¡œ ë„£ëŠ” ì‹ìœ¼ë¡œ ê°œì„ 
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1207.6076&quot;&gt;Sejdinovic et al.(2013, Cit. 610)&lt;/a&gt; : two samplesì˜ distributionì´ ê°™ì€ì§€ í‰ê°€í•  ë§Œí•œ í†µê³„ëŸ‰ìœ¼ë¡œ MMD(Maximum Mean Discrepancies)ë¥¼ ì œì‹œí•œ ë°” ìˆìŒ&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;ìš”ì•½í•˜ë©´ CNN parameterë¥¼ ì°¾ë˜, FC-layers ë‹¨ì—ì„œ ë§Œë“¤ì–´ì§€ëŠ” sourceì™€ targetì˜ hidden representationì´ ë¹„ìŠ·í•´ì§€ë„ë¡ ì¶”ê°€ ì œí•œì„ ì„¤ì •í•œ ê²ƒ&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1506.04214&quot;&gt;ConvLSTM(2015, Cit. 6876)&lt;/a&gt; : ê¸°ì¡´ Fully Connected LSTMì€ 1ì°¨ì› time-series â†’ ê³µê°„ì •ë³´(row, column)ì„ ë„£ì–´ì„œ 3ì°¨ì› ë°ì´í„°ë¥¼ ë‹¤ë£¨ë„ë¡ í™•ì¥
    &lt;ul&gt;
      &lt;li&gt;í™ì½© ê¸°ìƒì²­ì—ì„œ radar echo imagesë¡œ ê°•ìˆ˜ ì˜ˆë³´ë¥¼ í•˜ë ¤ë‹ˆ, ê¸°ì¡´ LSTMìœ¼ë¡  ê³µê°„ì„±ì„ ë‹´ì•„ë‚¼ ìˆ˜ ì—†ì–´ì„ ì§€ ì„±ëŠ¥ì´ ì•ˆ ì¢‹ë”ë¼ â†’ imageë¥¼ LSTMì— ë„£ê¸° ì „ CNNìœ¼ë¡œ ì´ˆë²Œêµ¬ì´í•˜ëŠ” ë°©ì‹ì„ ì œì•ˆ&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-formulationss&quot;&gt;3) Formulationss&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Spatio-Temporal Data : 2ì°¨ì› ê³µê°„ ìƒì—ì„œ ê¸°ë¡ë˜ëŠ”, ì‹œê°„ì— ë”°ë¼ ë³€í•˜ëŠ” featureë¥¼ ë§í•œë‹¤. ë”°ë¼ì„œ ë‹¨ì¼ featureë¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ 3ì°¨ì› ë°ì´í„°.&lt;/li&gt;
  &lt;li&gt;ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì„œë¡œ ë‹¤ë¥¸ ì§€ì—­ì—ì„œ ë§Œë“¤ì–´ì§„ ë°ì´í„°ë¥¼ ë‹¤ë£¨ë©°, ì´ë“¤ì„ ê°™ì€ ìˆ˜ì˜ grid cellë¡œ ë‚˜ëˆ  ì‘ì—…í•œë‹¤.
    &lt;ul&gt;
      &lt;li&gt;ì„œìš¸, ëŒ€ì „, ë‰´ìš•, â€¦ ë„ì‹œì˜ í¬ê¸°/í˜•íƒœëŠ” ì œê°ê°ì´ì§€ë§Œ cell ìˆ˜ê°€ ê°™ë„ë¡ ê²©ìë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354355-c106f23c-6012-48d2-8204-c7e78d49f7cd.jpg&quot; alt=&quot;ë°ì´í„°ê°€ coverí•˜ëŠ” ê³µê°„ì„ m*nê°œì˜ grid cellë¡œ ë‚˜ëˆˆë‹¤. each cell regionì´ tì‹œì ì— ê°–ëŠ” ì •ë³´(êµí†µëŸ‰, ê°•ìˆ˜ ë“±)ê°€ ìˆì„ í…ë°, ì´ë“¤ì´ ì–´ë–¤ ê°’ì„ ê°–ëŠ”ì§€ í‘œí˜„í•œ ê²Œ spatio-temporal image (matrix)ë¼ í•œë‹¤.&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;ë°ì´í„°ê°€ coverí•˜ëŠ” ê³µê°„ì„ m*nê°œì˜ grid cellë¡œ ë‚˜ëˆˆë‹¤. each cell regionì´ tì‹œì ì— ê°–ëŠ” ì •ë³´(êµí†µëŸ‰, ê°•ìˆ˜ ë“±)ê°€ ìˆì„ í…ë°, ì´ë“¤ì´ ì–´ë–¤ ê°’ì„ ê°–ëŠ”ì§€ í‘œí˜„í•œ ê²Œ spatio-temporal image (matrix)ë¼ í•œë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;ê²©ì í˜•íƒœ matrixë¥¼ imageë¼ í•  ë•Œ, ë§¤ ì‹œì ë§ˆë‹¤ ê¸°ë¡ëœ imageë“¤ì˜ time-seriesë¥¼ ëª¨ìœ¼ë©´ 3ì°¨ì› tensorê°€ ëœë‹¤.
    &lt;ul&gt;
      &lt;li&gt;ì„œìš¸ì˜ ë”°ë¦‰ì´ í†µí–‰ëŸ‰(a feature)ì„ ì—´ë‘ ì‹œê°„ì¯¤ ê´€ì°°í–ˆë‹¤ë©´, í•´ë‹¹ ë°ì´í„°ëŠ” ì•„ë˜ì™€ ê°™ì€ spatio-temporal tensorë¡œ ë¬˜ì‚¬í•  ìˆ˜ ìˆê² ë‹¤.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354358-d21b52f2-a3bc-4403-98c5-fd7aeaa93a10.jpg&quot; alt=&quot;imageëŠ” ì‹œê°„ì— ë”°ë¼ ë³€í•˜ë©°, tì‹œì  ê¸°ì¤€ìœ¼ë¡œ ê³¼ê±° kê°œ imageë¥¼ ì¶•ì í•˜ë©´, ìœ„ì™€ ê°™ì€ 3ì°¨ì› tensorë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ì´ tensorê°€ ì•ìœ¼ë¡œ ì „ê°œí•  ë…¼ë¦¬ì˜ ê¸°ë³¸ ë‹¨ìœ„ë¡œ ìì£¼ ì“°ì¸ë‹¤.&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;imageëŠ” ì‹œê°„ì— ë”°ë¼ ë³€í•˜ë©°, tì‹œì  ê¸°ì¤€ìœ¼ë¡œ ê³¼ê±° kê°œ imageë¥¼ ì¶•ì í•˜ë©´, ìœ„ì™€ ê°™ì€ 3ì°¨ì› tensorë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ì´ tensorê°€ ì•ìœ¼ë¡œ ì „ê°œí•  ë…¼ë¦¬ì˜ ê¸°ë³¸ ë‹¨ìœ„ë¡œ ìì£¼ ì“°ì¸ë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;tensorë“¤ì€ ìµœìƒë‹¨(latest) imageë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¶”ë ¤ë‚¸ ìµœê·¼ kê°œ imagesì¸ ì…ˆì¸ë°, ì´ ê°™ì€ ë­‰ì¹˜ë¥¼ 1-step after ë§ˆë‹¤ ê³„ì† ë½‘ì•„ë‚¸ë‹¤ë©´, í•´ë‹¹ tensorsë¡œ ì–´ë–¤ 4ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆê² ë‹¤.
    &lt;ul&gt;
      &lt;li&gt;List with parameters : Row(m) * Column(n) * Accumulation(k) * Time-stamp(t)&lt;/li&gt;
      &lt;li&gt;ì´ ë¦¬ìŠ¤íŠ¸ë¥¼ tensor set, ê¸¸ì´ë¥¼ â€˜Lâ€™ì´ë¼ í•˜ì.&lt;/li&gt;
      &lt;li&gt;ë°ì´í„°ê°€ ë§ì€(ì¥ê¸°ê°„) domainì—ì„œëŠ” ì§‘í•©ì´ ê¸¸ì­‰í•˜ê²Œ, ë°˜ëŒ€ë¡œ ë°ì´í„°ê°€ ë¶€ì¡±í•œ domainì—ì„œëŠ” ì§¤ë§‰í•œ ì§‘í•©ì´ ë‚˜ì˜¨ë‹¤.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354364-0c50754c-04c4-4625-92a9-8dd41f75118b.jpg&quot; alt=&quot;tensorëŠ” ì •ë³´ë¥¼ ì˜ë¯¸í•˜ë©°, domainì— ë”°ë¼ ì •ë³´ëŸ‰ì€ ë‹¤ë¥¼ í…Œë‹¤. ì˜ˆì»¨ëŒ€ ì—¬ê¸°ì„  ì„œìš¸ì˜ íƒì‹œ ìŠ¹ê° ë°ì´í„°ëŠ” ë‚˜í˜(ìµœì¢… ì—…ë°ì´íŠ¸ ê¸°ì¤€) ì •ë„ë¡œ ê¸¸ì§€ë§Œ, ë”°ë¦‰ì´ í†µí–‰ëŸ‰ ë°ì´í„°ëŠ” ê¸°ê»í•´ì•¼ ë°˜ë‚˜ì ˆì¯¤ ë¼ì„œ, ë‹¤ë¥¸ domainì¸ íƒì‹œ ì •ë³´ë¥¼ ì–´ë–»ê²Œ ì˜ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì„ê¹Œ ê³ ë¯¼í•˜ê²Œ ëœë‹¤. ê·¸ê²Œ ì´ ë…¼ë¬¸ì˜ í•µì‹¬ ì£¼ì œ.&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;tensorëŠ” ì •ë³´ë¥¼ ì˜ë¯¸í•˜ë©°, domainì— ë”°ë¼ ì •ë³´ëŸ‰ì€ ë‹¤ë¥¼ í…Œë‹¤. ì˜ˆì»¨ëŒ€ ì—¬ê¸°ì„  ì„œìš¸ì˜ íƒì‹œ ìŠ¹ê° ë°ì´í„°ëŠ” ë‚˜í˜(ìµœì¢… ì—…ë°ì´íŠ¸ ê¸°ì¤€) ì •ë„ë¡œ ê¸¸ì§€ë§Œ, ë”°ë¦‰ì´ í†µí–‰ëŸ‰ ë°ì´í„°ëŠ” ê¸°ê»í•´ì•¼ ë°˜ë‚˜ì ˆì¯¤ ë¼ì„œ, ë‹¤ë¥¸ domainì¸ íƒì‹œ ì •ë³´ë¥¼ ì–´ë–»ê²Œ ì˜ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì„ê¹Œ ê³ ë¯¼í•˜ê²Œ ëœë‹¤. ê·¸ê²Œ ì´ ë…¼ë¬¸ì˜ í•µì‹¬ ì£¼ì œ.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;2-main-architecture&quot;&gt;2. Main Architecture&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;ê¸°ë³¸ì ì¸ íŠ¹ì§•ì€ stacked ConvLSTM ìœ¼ë¡œ ì¡ì•„ë‚´ë©°, ë§Œë“¤ì–´ì§„ hidden stateì— DAN(generalized CNN), ë§ˆì§€ë§‰ì—” Global Attention ì ìš© &amp;amp; ê¸°íƒ€ features ì¶”ê°€í•˜ëŠ” êµ¬ì„±ì´ë‹¤&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354374-0e4af3ed-40d4-4893-afe7-c0818881f20c.jpg&quot; alt=&quot;ë…¼ë¬¸ì˜ main figure. í¬ê²Œ 1) ConvLSTM, 2) CNN with MMD (DAN), 3) Global spatial attention êµ¬ê°„ìœ¼ë¡œ ë‚˜ë‰œë‹¤.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë…¼ë¬¸ì˜ main figure. í¬ê²Œ 1) ConvLSTM, 2) CNN with MMD (DAN), 3) Global spatial attention êµ¬ê°„ìœ¼ë¡œ ë‚˜ë‰œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;1-representaion-learning-convlstm&quot;&gt;1) Representaion Learning (ConvLSTM)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Input = Tensor set(4D) ì´ì§€ë§Œ, ì‘ì—…ì€ ë§¤ image(2D) ë§ˆë‹¤ ì§„í–‰ â†’ í•œ ì¥ì”© CNNì„ ê±°ì³ ìƒˆë¡œìš´ tensor setì„ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆìŒ â†’ ë‹¤ì‹œ LSTMì˜ Input gateì— íˆ¬ì… + ì´ì „ hidden state tensor setê³¼ ê²°í•© + â€¦ (ë§ˆì°¬ê°€ì§€ë¡œ 2D ë‹¨ìœ„ë¡œ ì§„í–‰) â†’ ë°˜ë³µ&lt;/li&gt;
  &lt;li&gt;ëª¨ë“  stacked LSTMì„ í†µê³¼í•´ ë§Œë“¤ì–´ì§„ ìµœì¢… ê²°ê³¼ë¬¼ì„ â€˜Hâ€™ë¼ í•˜ì&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-knowledge-transfer-dan&quot;&gt;2) Knowledge Transfer (DAN)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;two different domainsâ€™ distributionsì´ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ì§€, distanceë¡œ í‰ê°€í•œ ê²ƒì„ MMDë¼ í•œë‹¤.&lt;/li&gt;
  &lt;li&gt;ë„ë©”ì¸ ë³„ë¡œ hidden stateì— CNNì„ ì ìš©í•˜ë˜, CNN layer ë§ˆë‹¤ mmd lossë¥¼ ì‚°ì¶œí•´ í‰ê· ì„ ë‚¸ë‹¤.&lt;/li&gt;
  &lt;li&gt;Parameter set &lt;strong&gt;Î˜&lt;/strong&gt; = argmin Loss Function of (GT vs ConvLSTM &amp;amp; CNN &amp;amp; mmd_loss &amp;amp; â€¦ )&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-global-spatial-attention&quot;&gt;3) Global Spatial Attention&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;local spatial correlationsëŠ” CNN ë‹¨ê³„ì—ì„œ ì¡íˆì§€ë§Œ, ë³´ë‹¤ ë„“ì€ ë²”ìœ„ì—ì„œ geographical dependenciesëŠ” ì˜ í¬ì°©ë˜ì§€ ì•ŠëŠ”ë‹¤.
    &lt;ul&gt;
      &lt;li&gt;ì§€ë¦¬ìƒìœ¼ë¡œëŠ” ë©€ë¦¬ ë–¨ì–´ì§„ ë‘ ì§€ì—­ì´ ìœ ì‚¬í•œ Point of Interest distributionì„ ê°€ì§€ëŠ” ê²½ìš°ê°€ ë§ë‹¤&lt;/li&gt;
      &lt;li&gt;ì´ëŠ” taxi-trip, crowd flow ê°™ì€ ì‹œê³µê°„ ì •ë³´ë„ ë§ˆì°¬ê°€ì§€&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;source domain ë°ì´í„°ë¥¼ í™œìš©í•  ë•Œ, attention scoreë¥¼ ê³±í•´ì„œ ê°€ì ¸ì˜¤ë©´ global relationì„ ì²´í¬í•˜ëŠ” íš¨ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354371-07961d2f-8a3e-4941-b542-c7b4a2d25b23.jpg&quot; alt=&quot;ì•„ì¹¨ í™ëŒ€ì˜ íƒì‹œ ìŠ¹ê°(source)ì€, ê°™ì€ ì‹œê° í™ëŒ€ì™€ ë…¸ì›ì˜ ìì „ê±° í†µí–‰ëŸ‰(target)ê³¼ ë‹®ì•„ìˆë‹¤. domainì€ ë‹¤ë¥´ì§€ë§Œ, â€˜ì¶œí‡´ê·¼/í†µí•™â€™ ì´ë¼ëŠ” ìš”ì†Œê°€ ì €ë³€ì— ê¹”ë ¤ìˆìŒì„ attention mechanismì„ í†µí•´ íŒŒì•…í•˜ëŠ” ì…ˆ. ì„±ìˆ˜ëŠ” ë…¸ì›ë³´ë‹¤ í™ëŒ€ì— ê°€ê¹Œì´ ìˆì§€ë§Œ, ì£¼ê±°/ì—…ë¬´/í•™êµ° ë³´ë‹¨ â€˜ë¬¸í™”ì˜ˆìˆ â€™ ì§€ì—­ì´ë¼ ì•„ì¹¨ì— ìì „ê±° íƒ€ëŠ” ì‚¬ëŒì´ ì ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆê² ë‹¤.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì•„ì¹¨ í™ëŒ€ì˜ íƒì‹œ ìŠ¹ê°(source)ì€, ê°™ì€ ì‹œê° í™ëŒ€ì™€ ë…¸ì›ì˜ ìì „ê±° í†µí–‰ëŸ‰(target)ê³¼ ë‹®ì•„ìˆë‹¤. domainì€ ë‹¤ë¥´ì§€ë§Œ, â€˜ì¶œí‡´ê·¼/í†µí•™â€™ ì´ë¼ëŠ” ìš”ì†Œê°€ ì €ë³€ì— ê¹”ë ¤ìˆìŒì„ attention mechanismì„ í†µí•´ íŒŒì•…í•˜ëŠ” ì…ˆ. ì„±ìˆ˜ëŠ” ë…¸ì›ë³´ë‹¤ í™ëŒ€ì— ê°€ê¹Œì´ ìˆì§€ë§Œ, ì£¼ê±°/ì—…ë¬´/í•™êµ° ë³´ë‹¨ â€˜ë¬¸í™”ì˜ˆìˆ â€™ ì§€ì—­ì´ë¼ ì•„ì¹¨ì— ìì „ê±° íƒ€ëŠ” ì‚¬ëŒì´ ì ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆê² ë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;êµ¬ì²´ì ìœ¼ë¡œëŠ” source domainì˜ 2D imageì˜ íŠ¹ì • ë¶€ë¶„ Region (i, j)ê°€, target domainì˜ ëª¨ë“  m*nê°œ regionê³¼ ì–¼ë§ˆë‚˜ ë‹®ì•„ìˆëŠ”ì§€ ì²´í¬í•œë‹¤
    &lt;ul&gt;
      &lt;li&gt;ë³¸ ë…¼ë¬¸ì—ì„œ ë‹¤ë£¨ëŠ” imageëŠ” ëª¨ë‘ ê°™ì€ m*n ì‚¬ì´ì¦ˆ grid cellë¡œ ë‚˜ëˆ ì ¸ ìˆìœ¼ë‹ˆ í–‰ë ¬ ê³„ì‚°ì´ ìš©ì´í•˜ë‹¤.&lt;/li&gt;
      &lt;li&gt;dot-product, softmax ì·¨í•´ì„œ attention matrix ë§Œë“œëŠ” ë“± ë„ë¦¬ ì•Œë ¤ì§„ attention mechanismê³¼ í¬ê²Œ ë‹¤ë¥¸ ì ì€ ë³´ì´ì§€ ì•Šì•˜ë‹¤&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;3-algorithm--code&quot;&gt;3. Algorithm &amp;amp; Code&lt;/h1&gt;

&lt;h2 id=&quot;1-algorithm&quot;&gt;1) Algorithm&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354356-aaeed10f-eb7a-40fd-83df-02f213efb054.jpg&quot; alt=&quot;algo 1.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-real-code&quot;&gt;2) Real Code&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/MiaoHaoSunny/ST-DAAN&quot;&gt;https://github.com/MiaoHaoSunny/ST-DAAN&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;4-evaluation&quot;&gt;4. Evaluation&lt;/h1&gt;

&lt;aside&gt;
ğŸ¤·â€â™‚ï¸ ST-DAAN is good enough?

&lt;/aside&gt;

&lt;aside&gt;
ğŸ¤·â€â™‚ï¸ Global Spatial Attention â†’ Performance

&lt;/aside&gt;

&lt;aside&gt;
ğŸ¤·â€â™‚ï¸ Amount of available data in Target &amp;amp; Source domain â†’ Performance

&lt;/aside&gt;

&lt;aside&gt;
ğŸ¤·â€â™‚ï¸ Sensitivity to model structure &amp;amp; parameters

&lt;/aside&gt;

&lt;ul&gt;
  &lt;li&gt;ê³¼ê±° Taxi, Bike ë°ì´í„°ë¡œ Crowd flow prediction í•˜ëŠ” taskë¡œ ST-DAAN ì„±ëŠ¥ì„ í‰ê°€í•´ë³´ì&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354337-985678a7-39e6-4abb-9b23-525748e55d12.jpg&quot; alt=&quot;ì—¬ëŸ¬ ë„ì‹œì—ì„œ ìˆ˜ì§‘ëœ taxi, bike ë°ì´í„°ì…‹ìœ¼ë¡œ, ê°ê° GPS ê²½ë¡œ, ì¶œë°œ/ë„ì°©ì§€, ì‹œê°, ID ë“± ë‹¤ì–‘í•œ variablesë¡œ êµ¬ì„±ë¼ìˆë‹¤. number of trips, time spanì„ ë¹„êµí•˜ë©´ DIDIëŠ” ê°™ì€ íƒì‹œ ë°ì´í„°ì…‹ì¸ TaxiNYCë³´ë‹¤ data scarce í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì—¬ëŸ¬ ë„ì‹œì—ì„œ ìˆ˜ì§‘ëœ taxi, bike ë°ì´í„°ì…‹ìœ¼ë¡œ, ê°ê° GPS ê²½ë¡œ, ì¶œë°œ/ë„ì°©ì§€, ì‹œê°, ID ë“± ë‹¤ì–‘í•œ variablesë¡œ êµ¬ì„±ë¼ìˆë‹¤. number of trips, time spanì„ ë¹„êµí•˜ë©´ DIDIëŠ” ê°™ì€ íƒì‹œ ë°ì´í„°ì…‹ì¸ TaxiNYCë³´ë‹¤ data scarce í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Intra-city(TaxiNYC â†’ BikeNYC), Cross-city(BikeChicago â†’ BikeNYC, DIDI â†’ TaxiBJ) transfer caseë¥¼ ëª¨ë‘ ë‹¤ë¤„ë³´ì•˜ë‹¤&lt;/li&gt;
  &lt;li&gt;Baseline modelì€ non-transfer learning, ìµœê·¼ì˜ transfer leaning basedì—ì„œ ê³ ë£¨ ê³¨ëë‹¤
    &lt;ul&gt;
      &lt;li&gt;non-transfer learning based : ARIMA, ConvLSTM, DCRNN, DeepST, ST-ResNet&lt;/li&gt;
      &lt;li&gt;transfer learning based : (ìœ„ ëª¨ë¸ë“¤ì— fine-tuning), RegionTrans, MetaST&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;1-comparison-with-baselines&quot;&gt;1) Comparison With Baselines&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ARIMA &amp;lt; non-transfer &amp;lt; non-transfer with fine-tuning &amp;lt; transfer &amp;lt; ST-DAAN ìˆœìœ¼ë¡œ ì„±ëŠ¥ Good
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;ST-DAAN full versionê³¼ Attention &amp;amp; External featuresì„ ê°ê° ë¹¼ë³¸ variationì„ ë¹„êµí•´ë³´ë‹ˆ, ì´ë“¤ ì—­ì‹œ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ëìŒ&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354343-d00945bc-988a-4d10-814a-54d5daf71861.jpg&quot; alt=&quot;Intra-city, Cross-city ë¬´ê´€í•˜ê²Œ ST-DAANì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„. nonAtt, nonExtëŠ” ê°ê° global spatial attention, inserting external featureì„ ì—†ì•¤ ë²„ì „ì˜ ST-DAAN&quot; /&gt;&lt;/p&gt;

        &lt;p&gt;Intra-city, Cross-city ë¬´ê´€í•˜ê²Œ ST-DAANì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„. nonAtt, nonExtëŠ” ê°ê° global spatial attention, inserting external featureì„ ì—†ì•¤ ë²„ì „ì˜ ST-DAAN&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-effect-of-data-amount&quot;&gt;2) Effect of Data Amount&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ë°ì´í„°ê°€ ë§ì„ ìˆ˜ë¡ ì¢‹ê¸´ í•˜ë”ë¼. Source/Target ë‘˜ ë‹¤ ë°ì´í„°ê°€ ë§ìœ¼ë©´ ì„±ëŠ¥ ì¢‹ìŒ&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233356050-9f85199f-d270-4f08-a353-48a055454b34.PNG&quot; alt=&quot;ëŒ€ì²´ë¡œ ë°ì´í„° length ê¸¸ìˆ˜ë¡ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ì¢‹ì•„ì§. ì—­ì‹œ ë‹¤ë‹¤ìµì„ &quot; /&gt;&lt;/p&gt;

&lt;p&gt;ëŒ€ì²´ë¡œ ë°ì´í„° length ê¸¸ìˆ˜ë¡ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ì¢‹ì•„ì§. ì—­ì‹œ ë‹¤ë‹¤ìµì„ &lt;/p&gt;

&lt;h2 id=&quot;3-parameter-sensitivity-analysis&quot;&gt;3) Parameter Sensitivity Analysis&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Scarce data ë‹¤ë£¨ëŠ” transfer learning, ì‹ ê²½ë§ ê¹Šê²Œ ìŒ“ìœ¼ë©´ ì˜¤íˆë ¤ overfitting ë¬¸ì œê°€ ë°œìƒ&lt;/li&gt;
  &lt;li&gt;Domain discrepancyì— ì ë‹¹í•œ penalty ì¤˜ì•¼ í•¨. ì‘ê²Œ ì£¼ë©´ common knowledgeê°€ ì „ë‹¬ë˜ì§€ ì•Šê³ , ë„ˆë¬´ í¬ê²Œ ì£¼ë©´ only domain-specific featureë§Œ ì „ë‹¬ë¨&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354353-80c061bd-935e-44f6-81a1-b2835f658aa7.jpg&quot; alt=&quot;ConvLSTM, CNN ë‹¨ê³„ì—ì„œ number of layers ë„ˆë¬´ ë§ìœ¼ë©´ ë¬¸ì œ, penalty hyper-parameter gammaë„ ì ë‹¹íˆ ì„¤ì •í•  í•„ìš”&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ConvLSTM, CNN ë‹¨ê³„ì—ì„œ number of layers ë„ˆë¬´ ë§ìœ¼ë©´ ë¬¸ì œ, penalty hyper-parameter gammaë„ ì ë‹¹íˆ ì„¤ì •í•  í•„ìš”&lt;/p&gt;

&lt;h1 id=&quot;5-others&quot;&gt;5. Others&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;TaxiBJì˜ crowd flowsë¥¼ RegionTrans, ST-DAANìœ¼ë¡œ ì˜ˆì¸¡í•´ë³´ì•˜ëŠ”ë°, íƒì‹œ ë§ì´ ì¡ëŠ” Rush hourì—ì„œ ST-DAANì´ RegionTrans ëŒ€ë¹„ ìš°ìˆ˜ â†’ ë³¸ ëª¨ë¸ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ë  ë§Œí•œ ì§ê´€ì  ì˜ˆì‹œ?
    &lt;ul&gt;
      &lt;li&gt;ê¸°ì¡´ ëª¨ë¸ì€ time invariant, íŠ¹ì§ˆì„ ì œëŒ€ë¡œ êµ¬ë¶„í•˜ì§€ ëª»í•˜ì§€ë§Œ, ST-DAANì€ ì¼ì • ë¶€ë¶„ GTì— ë‹¤ê°€ì„œëŠ” ëª¨ìŠµì„ ë³´ì˜€ë‹¤ëŠ” ì‹ìœ¼ë¡œ ì´í•´í•¨&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/67723054/233354351-b35fb7c7-ded5-4a75-9e53-31e43cb7e7ea.jpg&quot; alt=&quot;íƒì‹œ ë§ì´ ì•ˆ ì¡ëŠ” ì‹¬ì•¼ ì‹œê°ì—ëŠ” RegionTrans, ST-DAAN ë‘˜ ë‹¤ ë¹„ìŠ·í•˜ì§€ë§Œ, Rush hourì—ì„  ê½¤ ë¹„ìŠ·í•˜ê²Œ capture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;íƒì‹œ ë§ì´ ì•ˆ ì¡ëŠ” ì‹¬ì•¼ ì‹œê°ì—ëŠ” RegionTrans, ST-DAAN ë‘˜ ë‹¤ ë¹„ìŠ·í•˜ì§€ë§Œ, Rush hourì—ì„  ê½¤ ë¹„ìŠ·í•˜ê²Œ capture&lt;/p&gt;

</description>
            <pubDate>Thu, 20 Apr 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/Spatio_Temporal_Knowledge_Transfer_for_Urban_Crowd_Flow_Prediction_via_Deep_Attentive_Adaptation_Networks.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/Spatio_Temporal_Knowledge_Transfer_for_Urban_Crowd_Flow_Prediction_via_Deep_Attentive_Adaptation_Networks.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[WWW 2021] SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation</title>
            <description>&lt;h1 id=&quot;simgrace-a-simple-framework-for-graph-contrastive-learning-without-data-augmentation&quot;&gt;&lt;strong&gt;SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Please write the problem definition on here&lt;/p&gt;

&lt;p&gt;Graph Contrastive learning(GCL)ì—ì„œ Graph augmentationì´ ì‚¬ìš©ë˜ëŠ”ë° Graphì˜ ë³¸ì§ˆì ì¸ ì˜ë¯¸ë¥¼ í›¼ì†í•˜ì§€ ì•Šê³  ì§„í–‰í•˜ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤. ë”°ë¼ì„œ Graph augmentaionì€ GCLì˜ ì¼ë°˜ì ì¸ ì ìš©ì˜ ê°€ëŠ¥ì„±ì´ë‚˜ íš¨ìœ¨ì„±ì„ ì œì•ˆí•œë‹¤ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Graph Contrastive IEarningì„ ìœ„í•œ Simple í”„ë ˆì„ì›Œí¬ì¸ SimGRACEë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” Graph Augmentationì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;GCLì€ ë³´í†µ augmentaionìœ¼ë¡œ 4ê°€ì§€ ë°©ë²•ì„ ì£¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤(node dropping, edge perturbation, attribute masking and subgraph). í•˜ì§€ë§Œ ì´ 4ê°€ì§€ ë°©ë²•ì€ ëª¨ë“  ê²½ìš°ì— ì‚¬ìš©ë˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ graphì— ë”°ë¼ ì°¨ì´ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì†Œì…œ ë„¤í‹°ì›Œí¬ graphì—ì„œëŠ” edge perturbationì´ ì˜ë˜ì§€ë§Œ ìƒí™”í•™ ë¶„ì êµ¬ì¡° edgeë¥¼ ë³€ê²½í•˜ëŠ”ê²Œ ë¶„ì êµ¬ì¡°ë¥¼ ë°”ê¾¸ì–´ ì„±ëŠ¥ì´ ì¢‹ì§€ì•Šë‹¤ëŠ” ê²ƒ ë“±ì´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë§¤ë‰´ì–¼ì—ë”°ë¼ augmentaionì„ ì„ íƒí•˜ëŠ” trail-and-errorë¥¼ ì´ìš©í•˜ëŠ” ë°©ë²•ë“¤ì´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ trial-and-errorë¥¼ ì´ìš©í•˜ëŠ” ë°©ì‹ë“¤ì€ ë§ì€ ì—°ì‚°ëŸ‰ì„ ìš”êµ¬í•˜ê³  ì—¬ì „íˆ GCLì˜ ì¼ë°˜ì ì¸ ì‚¬ìš©ì—ë„ í•œê³„ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. JOAOì˜ ê²½ìš°ëŠ” ìë™ì ìœ¼ë¡œ GCLì—ì„œ augmentaion pairsë¥¼ ì„ íƒí•˜ëŠ” ë°©ë²•ì„ ì œì‹œí–ˆìœ¼ë‚˜ ê³„ì‚°ì˜ ë³µì¡ë„ê°€ ì˜¬ë¼ê°”ê³  augmentaion poolì„ êµ¬ì„±í•œëŠë° ì¸ê°„ì˜ ì‚¬ì „ ì§€ì‹ì„ ì´ìš©í•œë‹¤ëŠ” í•œê³„ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” &lt;strong&gt;ì–´ë–»ê²Œí•˜ë©´ manual trial-and-errorsë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë³µì¡í•œ ê³„ì‚°ì´ë‚˜ domain ì§€ì‹ ë˜í•œ ì‚¬ìš©í•˜ëŠ” ì•Šê³  GCLì„ ì‚¬ìš©í•  ìˆ˜ìˆì„ê¹Œ&lt;/strong&gt;ë¼ëŠ” motivationì„ ì œì‹œí•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì €ìëŠ” graph augumentaionì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  semantic-preserved data augmentaionì„ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ í•´ê²°í•˜ë ¤í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;3-contribution&quot;&gt;&lt;strong&gt;3. Contribution&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Significance&lt;/em&gt;: ê¸°ì¡´ì˜ GCL ë°©ë²•ë“¤ì— ë¹„í•´ ì¼ë°˜ì ìœ¼ë¡œ ì ìš©ê°€ëŠ¥í•˜ê³  manual trail-and-errorsë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ GCL ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Framework&lt;/em&gt;: ìƒˆë¡­ê³  íš¨ìœ¨ì ì¸ frameworkë¥¼ ì œì‹œí•˜ê³  SimGRACEê°€ ì˜ ì‘ë™í•  ìˆ˜ ìˆëŠ” ì´ìœ ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Algorithm&lt;/em&gt;: GCLì˜ Robustnessë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ AT-SimGRACEë¼ëŠ” ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì„ ì œì‹œí•©ë‹ˆë‹¤. ì•½ê°„ì˜ computational overheadê°€ ì¡´ì¬í•˜ì§€ë§Œ ë” Robustnessí•œ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Experiment&lt;/em&gt;: ì—¬ëŸ¬ ì¢…ë¥˜ì˜ datasetì— ëŒ€í•´ state-of-the-art ë°©ë²•ë“¤ê³¼ ë¹„êµí•´ ë” ë›°ì–´ë‚˜ê±°ë‚˜ ê²½ìŸë ¥ìˆëŠ” ëª¨ìŠµì„ ë³´ì—¬ì¤ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-graph-contrastive-learning&quot;&gt;&lt;strong&gt;4. Graph Contrastive Learning&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;GCLì€ 2ê°€ì§€ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì²«ë²ˆì§¸ëŠ” localê³¼ global representationì„ ëŒ€ì¡°í•˜ì—¬ encodingì„ ì§„í–‰í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. DGIê³¼ InfoGraphëŠ” graph-level representaionê³¼ substructure-level representaionì˜ ì°¨ì´ë¥¼ ìµœëŒ€í™”í•˜ì—¬ graphë‚˜ nodeì˜ representaionë¥¼ encodingí•©ë‹ˆë‹¤. ë³´ë‹¤ ìµœê·¼ì— ë‚˜ì˜¨ MVGRLì€ node diffusionì„ ìˆ˜í–‰í•˜ê³  contrast learningì„ ì´ìš©í•´ graph-levelê³¼ node-levelì˜ representaionì„ ì–»ëŠ” ê²ƒì„ ì œì•ˆí•©ë‹ˆë‹¤ë‹¤. ë‘ë²ˆì§¸ëŠ” dataë¥¼ ë³€í™˜í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ”ë° augmentí•˜ê³  ì´ë¥¼ shared encoderê³¼ projection headì— ë„£ì–´ mutual informationì„ ìµœëŒ€í™”í•©ë‹ˆë‹¤. GCAëŠ” node-level taskë¥¼ ìœ„í•´ ì œì‹œë˜ì—ˆê³  DGCLì€ false negative ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. Graph-levelì—ì„œëŠ” GraphCLì´ 4ê°€ì§€ ë°©ë²•ì˜ augmentaionì„ ì‚¬ìš©í•˜ì—¬ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. JOAOëŠ” GraphCLì˜ manual trail-and-errorì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;5-method&quot;&gt;&lt;strong&gt;5. Method&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289501-42c61afb-f639-473e-b6e1-d8c9b8b5f164.png&quot; alt=&quot;SimGRACE&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(1) Encoder perturbation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$h$ ì™€ $h^\prime$ 2ê°œì˜ graph-level representaionì„ ì¶”ì¶œí•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;$h=f(G;\theta),h^\prime=f(G;\theta)$&lt;/p&gt;

&lt;p&gt;$\theta$ì™€ $\theta^\prime$ì€ GNN ì¸ì½”ë”ì˜ lë²ˆì§¸ ë ˆì´ì–´ì˜ weight tensorì™€ perturbed versionì…ë‹ˆë‹¤.
$\Delta\theta_l$ ëŠ” í‰ê· ì´ 0ì´ê³  ë¶„í¬ê°€ $\sigma^2_l$ ì¸ ê°€ìš°ì‹œì•ˆ ë¶„í¬ì—ì„œ samplingí•˜ëŠ” perturbation termì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ SimGRACEëŠ” ê¸°ì¡´ì˜ ëª¨ë¸ë“¤ê³¼ 3ê°€ì§€ ì°¨ë³„ì ì´ ìˆëŠ”ë°. (1) ëª¨ë©˜í…€ ì—…ë°ì´íŠ¸ ëŒ€ì‹  ë¬´ì‘ìœ„ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆë¡œ ì¸ì½”ë”ë¥¼ perturbation ì‹œí‚µë‹ˆë‹¤. (2) data augmentaionì„ í•„ìš”ë¡œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (3) graph-level representaionì— ì§‘ì¤‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;$\theta^\prime_l=\theta_l + \eta \cdot \Delta\theta_l$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(2) Projection head&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Projection headë¼ëŠ” non-linear transformation $g(\cdot)$ì„ ì´ìš©í•˜ì—¬ representaionì„ ë‹¤ë¥¸ latent spaceì— ë§¤í•‘ ì‹œì¼œ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. SimGRACEëŠ” two-layer perceptron(MLP)ì„ ì´ìš©í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;$z=g(h), z^\prime = g(h^\prime)$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(3) Contrastive loss&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;SimGRACEì—ì„œëŠ” normalized temperature-scaled cross entropy loss (NT-Xent)ë¥¼ ì‚¬ìš©í•˜ì—¬ postive pairsì¸ $z$ì™€ $z^\prime$ì„ negative pairsì™€ ë¹„êµí•˜ì—¬ ê·¸ ì°¨ì´ë¥¼ ì¤„ì—¬ê°‘ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œ N graphë¥¼ randomly samplingí•˜ì—¬ GNNì¸ì½”ë”ë¥¼ í†µí•´ perturbed versionê¹Œì§€ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤ ë”°ë¼ì„œ 2Nê°œì˜ representaionì´ ì¡´ì¬í•˜ëŠ”ë° ë¯¸ë‹ˆë°°ì¹˜ì—ì„œ në²ˆì§¸ graphë¥¼ $z_n$ë¼ê³  í‘œí˜„í•©ë‹ˆë‹¤. Negative pairsëŠ” ìì‹ ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ N-1ê°œì˜ pertubed representaionì„ í†µí•´ì„œ ë‚˜ì˜¤ê²Œë©ë‹ˆë‹¤. ë”°ë¼ì„œ në²ˆì§¸ graphì— ëŒ€í•œcontrasive lossëŠ” ë‹¤ìŒê°™ì´ ë‚˜ì˜µë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;$l_n = -log {exp(sim(z_n, z^\prime_n)\tau)\over \sum^N_{n^\prime=1,n^\prime\ne n} exp(sim(z_n,z_{n^\prime}))\tau)}$&lt;/p&gt;

&lt;p&gt;simì€ cosine similarityì´ê³ , final lossëŠ” ëª¨ë“  postive pairsì— ëŒ€í•´ì„œ ê³„ì‚°ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;at-simgrace&quot;&gt;&lt;strong&gt;AT-SimGRACE&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;GraphCLì€ GNN frameworkë¥¼ ì‚¬ìš©í•˜ì—¬ Robustnessë¥¼ ì–»ì„ ìˆ˜ ìˆìŒì„ ì œì‹œí•˜ì§€ë§Œ ê·¸ ì´ìœ ê¹Œì§€ ì œì‹œí•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ë˜í•œ GraphCLì€ random attackì— ëŒ€í•´ì„œëŠ” Robustí•˜ì§€ë§Œ adversrial attackì—ì„œëŠ” ì·¨ì•½í•œ ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤. AT-SimGRACEëŠ” adversarial attackì— Robustnessë¥¼ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ AT FrameworkëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289517-a039b362-723c-4517-8693-95a02562e4e0.png&quot; alt=&quot;AT Framework&quot; /&gt;&lt;/p&gt;

&lt;p&gt;í•˜ì§€ë§Œ ìœ„ì˜ frameworkëŠ” graph contrastive learningì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ lossë¥¼ ìœ„ì—ì„œ ì„¤ëª…í•œ Contrastive lossë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. ë˜í•œ íš¨ìœ¨ì„±ì„ ë†’íˆê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ì„ ë„ì…í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;$\Theta$ë¥¼ GNNì˜ weight spaceë¼ê³  ê°€ì •í•˜ë©´ $\theta$ë¥¼ L2 normì„ ì´ìš©í•´ ë‹¤ì‹œ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289522-0ec02f2f-3783-434b-a0b7-da8b33eba60b.png&quot; alt=&quot;AT Framework2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289527-23f9ed5a-23df-4bf0-a551-9c66d0b47ed9.png&quot; alt=&quot;AT Framework3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì´ì œ AT-SimGRACEëŠ” optimization problemì„ ë‹¤ì‹œ ì •ì˜í•˜ëŠ”ë° inner maximizationë¥¼ í•˜ê¸°ìœ„í•´ contrastive lossë¥¼ gradient ascent ë°©ë²•ìœ¼ë¡œ updateí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ $\theta$ë¥¼ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ SGDë¥¼ í†µí•´ updateí•©ë‹ˆë‹¤&lt;/p&gt;

&lt;h2 id=&quot;6-experiment&quot;&gt;&lt;strong&gt;6. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;research-question&quot;&gt;&lt;strong&gt;Research Question&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;RQ1.(Generalizability)&lt;/strong&gt;: SimGRACEëŠ” unsupervisedì™€ semi-supervisedì—ì„œ ë‹¤ë¥¸ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œê°€?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RQ2.(Transferabilitry)&lt;/strong&gt;: SimGRACEë¡œ pre-trainëœ GNNì´ ë‹¤ë¥¸ ëª¨ë¸ë³´ë‹¤ ë” ë‚˜ì€ transferabilityë¥¼ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ”ê°€?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RQ3.(Robustness)&lt;/strong&gt;: AT-SimGRACEëŠ” ë‹¤ì–‘í•œ adversarial attackì— ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆëŠ”ê°€?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RQ4.(Efficiency)&lt;/strong&gt;: SimGRACEì˜ íš¨ìœ¨ì„±ì€ ì–´ë–»ê³  ë‹¤ë¥¸ ëª¨ë¸ì— ë¹„í•´ íš¨ìœ¨ì ì¸ê°€?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RQ5.(Hyperparameters Sensitivity)&lt;/strong&gt;: SimGRACEê°€ hyperparameterì— ëŒ€í•´ ì–¼ë§ˆë‚˜ Sensitivityí•œê°€?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;unsupervised-and-semi-supervised-learning-rq1&quot;&gt;&lt;strong&gt;Unsupervised and semi-supervised learning (RQ1)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289536-9924cc76-f692-4988-87a3-94246c84aa89.png&quot; alt=&quot;Table2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289546-53f6a789-57c9-4a0a-8933-d8bf2ee8fac4.png&quot; alt=&quot;Table4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Table2ë¥¼ ë³´ë©´ Unsuperviesd ê²½ìš° SimGRACEê°€ ë‹¤ë¥¸ baselineë“¤ì„ ëŠ¥ê°€í•˜ë©° ëª¨ë“  datasetì—ì„œ ìƒìœ„ 3ìœ„ ì•ˆì— ë“­ë‹ˆë‹¤. ë˜í•œ Table 4ë¥¼ ë³´ë©´ semi-superviesde taskë¥¼ 1%ì™€ 10%ì™€ labelì—ì„œ ì§„í–‰í•˜ì˜€ëŠ”ë° SOTA ë°©ë²•ë¡ ë“¤ê³¼ ë¹„êµí–ˆì„ë•Œ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì´ê±°ë‚˜ ë” ëŠ¥ê°€í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤. 10% labelì—ì„œ JOAOê°€ ì¡°ê¸ˆ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠë° JOAOì˜ ë¹„íš¨ìœ¨ì„±ì„ ìƒê°í•´ë³´ë©´ SimGRACEì˜ ì„±ëŠ¥ ë˜í•œ ìš°ìˆ˜í•˜ë‹¤ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;transferability-rq2&quot;&gt;&lt;strong&gt;Transferability (RQ2)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289556-a1a9f31d-e33e-45e8-8bc3-ffde2c869d4d.png&quot; alt=&quot;Table3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pre-trainingì˜ transferabilityë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ë‹¨ë°±ì§ˆ ê¸°ëŠ¥ ì˜ˆì¸¡ì— ëŒ€í•œ transfer learningì— ëŒ€í•œ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. Table 3ì— ë‚˜ì™€ ìˆë“¯ì´ SimGRACEëŠ” PPI datasetì—ì„œ ë‹¤ë¥¸ pre-training schemeì— ë”°ë¼ ë” ë‚˜ì€ Transferabilityì— ëŒ€í•œ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;adversarial-robustness-rq3&quot;&gt;&lt;strong&gt;Adversarial robustness (RQ3)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289574-7fc89115-24ee-439b-8d43-813cc544a57f.png&quot; alt=&quot;Table5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;RandSampling, GradArgmaxì™€ RL-S2Vì— ëŒ€í•´ AT-SimGRACEì˜ Robustnessë¥¼ í‰ê°€í–ˆìŠµë‹ˆë‹¤. Structure2vecë¥¼ GNN ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. 3ê°€ì§€ evasion attackì—ì„œ AT-SimGRACEëŠ” GNNì˜ Robustnessë¥¼ ëˆˆì— ë„ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;efficiency-rq4&quot;&gt;&lt;strong&gt;Efficiency (RQ4)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289577-68964294-fe00-4165-a094-3f504437c510.png&quot; alt=&quot;Table6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;í›ˆë ¨ ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ overhaed ì¸¡ë©´ì—ì„œ ê²°ê³¼ë¥¼ ë¹„êµí•´ë³¸ ê²°ê³¼ SimGRACEëŠ” JOAOv2ë³´ë‹¤ ê±°ì˜ 40-90ë°° ë” ë¹ ë¥´ê³  GCLë³´ë‹¤ 2.5-4ë°° ë” ë¹ ë¦…ë‹ˆë‹¤. GCLì˜ traial-and-errorì˜ ì‹œê°„ê¹Œì§€ ê³ ë ¤í•˜ë©´ SimGRACEì˜ íš¨ìœ¨ì„±ì€ ë” ë›°ì–´ë‚˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤&lt;/p&gt;

&lt;h3 id=&quot;hyper-parameters-sensitivity-analysis-rq5&quot;&gt;&lt;strong&gt;Hyper-parameters sensitivity analysis (RQ5)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289581-5700dfd6-219f-4ac6-ae13-8f065ab8e54e.png&quot; alt=&quot;Figure4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Magnitude of the pertubation&lt;/strong&gt;
Figure 4ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ weight pertubationëŠ” SimGRACEì—ì„œ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. $\eta$ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ë©´ ëŠ˜ ë†’ë‹¤ê³  ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì´ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. $\eta$ê°€ 0ì¸ ê²½ìš°ëŠ” ê°€ì¥ ë‚®ì€ ì„±ëŠ¥ì„ ë‚´ëŠ”ë° ì´ëŠ” ì§ê´€ì ìœ¼ë¡œ ì˜³ì€ ê²°ê³¼ì…ë‹ˆë‹¤. ì ì˜í•œ $\eta$ë¥¼ ì„¤ì •í•˜ëŠ”ê²Œ ì¤‘ìš”í•˜ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/101261577/232289585-415c1f7a-42f9-425b-a461-72bf41cb269c.png&quot; alt=&quot;Figure5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Batch-size and traing epochs&lt;/strong&gt;
Figure 5ì€ ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ì™€ epochë¡œ í›ˆë ¨ëœ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë” í° ë°°ì¹˜ í¬ê¸°ì™€ epochì¼ë•Œ ì¢‹ì€ ì„±ëŠ¥ì´ ë³´ì—¬ì§‘ë‹ˆë‹¤. ì™œëƒí•˜ë©´ ë°°ì¹˜ í¬ê¸°ê°€ ë” í´ ìˆ˜ë¡ ë” ë§ì€ negative sampleì„ ì œê³µí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;SimGRACEëŠ” ê¸°ì¡´ Graph Contarsive Learning modelì˜ data augmentaionì˜ í•œê³„ë¥¼ ê³„ì„  ì‹œí‚¤ì˜€ê³ , Generalí•œ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ê²Œ í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ AT-simGRACEë¥¼ í†µí•´ Robustnessë„ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. í–¥í›„ì—ëŠ” (1)ì¸ì½”ë”ì˜ perubationì´ ì»´í“¨í„° ë¹„ì „ì´ë‚˜ ìì—°ì–´ ì²˜ë¦¬ ë¶€ë¶„ì—ì„œ ì˜ í™œìš©ë  ìˆ˜ ìˆëŠ”ì§€ ì—°êµ¬í•´ë³¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ë˜í•œ (2) Pre-trainëœ GNNì„ ì—¬ëŸ¬ real-world taskì— ì ìš©í•´ë³¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;6-github&quot;&gt;&lt;strong&gt;6. Github&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Github Implementation  : https://github.com/junxia97/SimGRACE&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Thu, 20 Apr 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/SimGRACE_A_Simple_Framework_for_Graph_Contrastive_Learning_without_Data_Augmentation.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/SimGRACE_A_Simple_Framework_for_Graph_Contrastive_Learning_without_Data_Augmentation.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
    </channel>
</rss>
