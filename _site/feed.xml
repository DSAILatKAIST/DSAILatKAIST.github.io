<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>DSAILatKAIST.github.io</title>
        <description>Intended as a documentation theme based on Jekyll for technical writers documenting software and other technical products, this theme has all the elements you would need to handle multiple products with both multi-level sidebar navigation, tags, and other documentation features.</description>
        <link>http://dsailatkaist.github.io/</link>
        <atom:link href="http://dsailatkaist.github.io/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Tue, 17 Oct 2023 00:21:24 +0900</pubDate>
        <lastBuildDate>Tue, 17 Oct 2023 00:21:24 +0900</lastBuildDate>
        <generator>Jekyll v3.9.2</generator>
        
        <item>
            <title>[SIGIR 2022] User-controllable Recommendation Against Filter Bubbles</title>
            <description>&lt;h1 id=&quot;sigir-22user-controllable_recommendation_against_filter_bubbles&quot;&gt;[SIGIR-22]User-controllable_Recommendation_Against_Filter_Bubbles&lt;/h1&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#1-problem-definition&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;과거 몇 년 동안 추천시스템은 ‘개인화된 정보 필터링’이라는 명목으로 정보의 과잉을 감당하기 어려운 사용자들에게 불필요한 정보를 필터링 해주어 빠른 발전을 거두었지만, ‘필터버블(Filter Bubble)’에 대한 논의는 항상 이어져 왔었다.&lt;/p&gt;

&lt;p&gt;필터버블이란, 추천시스템이 사용자-아이템 간 상호작용을 기반으로 기존 사용자의 선호도에 일치하는 아이템만 계속해서 노출시키는 현상을 가리킨다.  이런 현상이 반복되면, 유사한 아이템만 노출되는 확률이 계속해서 커지게 되고, 사용자가 다양한 카테고리의 콘텐츠를 접할 수 있는 기회가 점점 줄어지게 된다.&lt;/p&gt;

&lt;p&gt;즉, 장기적인 관점에서 필터버블은 아이템 혹은 콘텐츠의 다양성과 오리지널리티를 추천시스템에서 배제시키게 되고, 이는 필연적으로 정보의 편식으로 인해 사용자로 하여금 왜곡 효과를 낳게 된다.&lt;/p&gt;

&lt;p&gt;따라서, 필터버블을 완화하는 것 또한 추천시스템에서 중요한 과제로 자리매김하게 되었다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#2-motivation&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;필터버블을 완화하는 방안으로 기존 연구에서는 ‘다양성(Diversity)’과 공정성(Fairness)’을 높이는 방법을 제안했었다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;추천에서의 다양성:
다양성은 추천 목록에서 유사성이 다른 아이템을 생성하도록 장려하는 방안이다. 이는 후처리 및 엔드-투-엔드 방법으로 나눌 수 있다. 전자는 몇몇 모델에 의해 생성된 추천 목록을 다시 순위 지정을 통해 다양화시키며, 후자는 모델 훈련 및 예측 과정에서 정확도와 다양성의 균형을 맞추는 방향으로 진행된다. 그러나 이러한 방식들 역시 단순히 사용자에게 다양한 아이템을 추천한 후 사용자의 피드백을 통해 새로운 아이템 카테고리를 발굴해가는 것으로 많은 시간이 필요하다. 심지어 다양한 아이템을 추천하는 단계에서 사용자 선호도와 관련 없는 아이템을 많이 가져올 수 있다는 단점이 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;추천에서의 공정성:
추천시스템에서 공정성을 달성하기 위해서는 다양한 사용자 그룹 또는 아이템 카테고리 간에 균형을 맞추어야 한다. 이것은 특정 그룹에게 더 많은 추천을 하도록 조절하거나 특정 카테고리의 아이템을 다른 것보다 자주 포함시키는 것을 의미하여 필터버블을 어느 정도 완화할 수 있다. 그러나 이렇게 균형을 맞추는 과정에서, 일부 사용자 또는 아이템 그룹에 대한 추천 정확성을 희생시킬 수 있다. 예를 들어, 만약 특정 사용자 그룹에게 더 많은 공정성을 부여하려면 그 그룹에 대한 추천 목록에서 다른 사용자 그룹의 선호를 무시하고 그 그룹에 맞춰야 할 수 있기 때문에 그 그룹에 대한 정확한 추천이 희생되고 사용자 경험이 저하될 수 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇듯 기존 접근 방식은 다양성, 공정성을 고려하여 필터버블을 완화하지만 정확성과 사용자 경험을 희생해야 한다는 단점이 있다.&lt;/p&gt;

&lt;p&gt;또한, 사용자의 피드백을 통해서 추천시스템이 모델 훈련-예측의 무한 루프를 도는 과정에서, 사용자는 추천 결과를 수동적으로만 받아들이게 때문에 진정한 ‘개별맞춤’ 결과를 생성하기까진 많은 시간과 비용을 필요로 하다. 즉, 비록 추천시스템이 사용자의 선호도를 기반으로 결과를 생성하긴 하지만, 다양성과 공정성 향상 과정에서 다시 불필요한 정보까지 포함시킬 수 있기 때문에 사용자가 자신에게 필요한 정보만을 얻기 위해선 생성된 추천 결과에 대해 ‘like’ 혹은 ‘dislike’ 등 지속적인 피드백을 제공하고 학습을 시켜야 한다.&lt;/p&gt;

&lt;p&gt;따라서, 동 연구는 사용자가 직접 컨트롤을 통해 자신이 원하는 추천 결과를 생성할 수 있게끔 ‘User-Controllable Recommendation System(UCRS)’ 방안을 제시했다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/9wXYx34/rsloop.png&quot; alt=&quot;rsloop&quot; /&gt;&lt;/p&gt;

&lt;p&gt;사용자가 제어할 수 있는 추천시스템인 UCRS는 기존 추천시스템 외에 아래 3가지 기능을 추가시켰다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;필터버블의 수준을 측정하여 사용자에게 알려주는 필터버블 경고 기능&lt;/li&gt;
  &lt;li&gt;4가지 수준의 제어 명령 기능&lt;/li&gt;
  &lt;li&gt;사용자 제어에 따라 추천결과를 조정하는 응답 메커니즘&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이로써, 동 연구는 사용자가 추천시스템의 동작을 제어할 수 있는 방법을 제공하여 사용자의 참여를 촉진하고, 사용자가 더 많은 표현력과 제어권을 가지게 함으로써 사용자 경험을 향상시키는 것을 목적으로 삼았다.&lt;/p&gt;

&lt;p&gt;이와 더불어, 동 연구는 앞서 말한 응답 메거니즘 단계에서 사용자 A가 1년 전에는 액션 영화를 많이 시청했지만 현재는 코미디 영화에 더 관심이 있을 수 있는 것처럼 시간 지남에 따라 사용자의 선호도가 변할 수 있다는 점까지 인식하였다. 이에 따라, 사용자 표현의 오래된 정보가 추천에 미치는 영향을 완화하는 데 중점을 둔 ‘User-Controllable Inference(UCI)’ 프레임 워크가 제안되었다.&lt;/p&gt;

&lt;p&gt;UCI는 사용자가 제어 명령을 제공하면,  반 사실(counterfactual)인 대조적 추론을 사용하여 과거에 나온 사용자 표현의 영향을 줄이는 방안이다. 예를 들어, 여성인 사용자 B는 여성 사용자 그룹이 선호하는 영화 리스트에 질려 남성 사용자 그룹이 선호하는 영화 리스트를 추천시키는 제어 명령을 내렸다고 가정하자. 이 때, 반 사실인 대조적 추론은 ‘사용자 B가 남성이라면 추천 리스트는 어떻게 변할까?’라는 질문의 대한 예측이라고 생각할 수 있다. 즉, UCI는 오래된 사용자 표현이 폐기되는 반 사실 세계를 상상하고 이런 반 사실 조건에 맞는 새로운 추천 결과를 생성한다. 이로써 과거 사용자-아이템 간 상호작용 패턴에 극한되지 않고 사용자가 원하는 추천을 얻을 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;3-preliminary&quot;&gt;3. Preliminary&lt;/h2&gt;
&lt;p&gt;동 연구는 Method를 확립하기 전에 다양한 사용자 그룹에 대한 필터버블 결과를 분석하는 사전 실험을 수행했다:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;대표적인 추천 모델인 Factorization Machine (FM)을 DIGIX-Video, Amazon-Book 및 ML-1M과 같은 세 개의 공개 데이터셋에 훈련시킴.&lt;/li&gt;
  &lt;li&gt;각 사용자에 대해 상위 10개의 추천 아이템을 수집함.&lt;/li&gt;
  &lt;li&gt;사용자 그룹을 ID, 성별 및 연령을 고려한 사용자 특성(User Features)과 아이템 카테고리에 대한 관심도 등을 고려한 사용자 상호작용(User Interactions) 두 가지 요인으로 분류함.&lt;/li&gt;
  &lt;li&gt;FM이 생성한 추천결과와 사용자 그룹에 따른 사용자의 과거 상호작용 패턴을 비교함.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;분석 결과로는, 사용자 특성과 아이템 특성(Item Features) 2가지 측면에서 필터버블이 존재한다는 사실이 발견되었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/0c9Qt8R/fbresult.png&quot; alt=&quot;fbresult&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이미지 2(a)는 DIGIX-Video의 남성 및 여성 사용자별 상위 3개 아이템 카테고리에 대한 과거 분포를 시각화한 결과이다. 여성 사용자 그룹은 로맨스 영화를 더 선호한 반면, 남성 사용자 그룹은 액션 영화를 더 선호했다. 그 결과, 이미지 2(b)와 2(c)에서 알 수 있듯이, 추천 결과에서도 편향된 분포를 유지하게 되었다.&lt;/p&gt;

&lt;p&gt;이러하듯이, 사용자는 계속해서 유사한 아이템을 추천 받게 된다. 추천 모델은 이러한 편향을 강화하고 상위 특정 카테고리를 더 노출시키는 경향으로 이어져 결국 남성과 여성 사용자 그룹 간의 심각한 분리를 야기시키게 된다.&lt;/p&gt;

&lt;p&gt;또한, 이미지 2(d) 및 2(e)는 Amazon-Book 및 ML-1M 데이터셋에 대해 사용자 상호작용에 따라 나눈 결과이다. 동 결과에서도 과거 사용자 상호작용 패턴에 따른 카테고리 편향 증폭이 발견되었다. 즉, 사용자으로부터 가장 큰 관심을 받은 카테고리가 이후 추천 목록에서도 증가된 것이다. 이는 필터버블의 강화를 초래하고 사용자의 관심을 좁혀 사용자 그룹 분리로 이어지게 된다.&lt;/p&gt;

&lt;h2 id=&quot;4-method&quot;&gt;&lt;strong&gt;4. Method&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#3-method&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;전반적으로 동 연구는 커버리지(Coverage), 격리지수(Isolation Index), 최다 카테고리 지배도(Majority Category Domination, MCD) 등 지표를 통해 필터버블의 수준을 실시간으로 감지하고 사용자에게 알람을 보내는 경고 기능을 구현했다.&lt;/p&gt;

&lt;p&gt;또한, 제어 명령 기능과 관련해서는 앞서 사전 실험에서 사용자 특성과 아이템 특성 2가지 측면에서 필터버블이 존재한다는 사실을 발견함에 따라, UCRS를 설계할 때에도 사용자 특성과 아이템 특성 각각의 방면에서 제어시스템을 구현했다.&lt;/p&gt;

&lt;p&gt;마지막으로, 사용자 제어에 따라 추천결과를 조정하는 반 사실 대조적 추론 응답 메커니즘을 통해 필터버블을 완화하는 동시에 정확성은 유지하고 사용자가 원하는 결과를 얻을 수 있는 추천시스템을 구현했다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/7Nrkm21/ucrs.png&quot; alt=&quot;ucrs&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;41-필터버블-감지-지표&quot;&gt;4.1 필터버블 감지 지표&lt;/h3&gt;
&lt;p&gt;추천시스템에서 필터버블을 감지한다는 것은 다양성을 제한하고 특정 그룹 내에서 사용자를 고립시키는 개인화된 추천의 심각도를 측정하는 것을 의미한다. 추천 목록의 항목 카테고리 수를 계산하는 Coverage와 서로 다른 사용자 특성 그룹 간의 분리를 평가하는 Isolation Index와 같은 지표를 사용하여 필터버블의 심각도를 정량화할 수 있다. MCD는 아이템 특성과 관련된 필터버블을 감지하는 용도로 사용되어 가장 자주 추천되는 아이템 카테고리의 비율을 확인할 수 있다. 시간이 지남에 따라 MCD가 증가하면 아이템 카테고리와 관련된 필터 버블의 심각성이 커지고 있음을 나타낸다. 이러한 지표들을 통해 사용자에게 실시간으로 필터버블 경고를 보내고 이를 제어할지 여부를 결정하게 도울 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;42-제어-명령-기능&quot;&gt;4.2 제어 명령 기능&lt;/h3&gt;
&lt;p&gt;사용자의 과거 상호작용 데이터인 𝐷가 주어졌을 때, 기존의 추천 모델은 추천 𝑅을 예측하기 위해 𝑃(𝑅|𝐷)를 사용한다. 그러나 UCRS는 추가로 사용자 제어인 𝐶를 고려하며 사용자 개입(𝑑𝑜(𝐶))을 통해 𝑃(𝑅|𝐷, 𝑑𝑜(𝐶))를 추정할 것을 제시했다. 이때, 사용자 제어과 관련해서 UCRS는 사용자 및 항목별로 ‘Fine-grained controls’와 ‘Coarse-grained controls’를 2수준으로 나눠 총 4가지 유형의 사용자 제어를 제시했다.&lt;/p&gt;

&lt;h4 id=&quot;421-사용자-특성-제어user-feature-controls&quot;&gt;4.2.1 사용자 특성 제어(User-feature Controls)&lt;/h4&gt;
&lt;p&gt;N가지 사용자 특성과 사용자 𝑢가 있을 때, 사용자 𝑢는 $x &lt;em&gt;{u} = [ x^1 _{u}, \ldots, x^n _{u}, \ldots,  x^N _{u} ], \text{ where }  x^n _{u} \in {0,1 }$ 로 나타내며, 여기서 $x^n _{u} \in {0,1 }$
는 사용자 𝑢가 사용자 특성 $x^n$을 가지고 있는지 여부를 나타낸다. 예를 들어, 특성 $x&lt;/em&gt; {1}$과 $x_ {2}$가 남성과 여성을 나타낸다면, $x_ {u}$ = [0, 1]은 사용자 𝑢가 여성임을 뜻한다.&lt;/p&gt;

&lt;p&gt;사용자 특성 제어는 ‘Fine-grained controls’와 ‘Coarse-grained controls’를 2수준으로 또 나뉘게 된다.  ‘Fine-grained controls’에서는 사용자가 세분화된 사용자 특성을 활용하여 구체적인 제어를 통해 다른 사용자 그룹의 관심사에 맞는 추천을 받을 수 있게 된다(예: 30대 사용자가 10대가 선호하는 동영상을 추천 받기).&lt;/p&gt;

&lt;p&gt;반면에 ‘Coarse-grained controls’를 사용하면 사용자의 기존 특성만을 제한하는 방안으로 추천을 줄이게 된다. 예를 들어, ‘연령=30’처럼 사용자의 나이 특성을 제거함으로써 기존 자신의 사용자 그룹에 제시되었던 추천을 줄임으로써 필터버블을 완화할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;422-아이템-특성-제어item-feature-controls&quot;&gt;4.2.2 아이템 특성 제어(Item-feature Controls)&lt;/h4&gt;
&lt;p&gt;사용자 기능 제어는 사용자 특성과 관련된 필터버블을 해결하지만 사용자 상호 작용의 영향은 고려하지 않는다. 사용자 특성 제어를 보완하기 위해 아이템 특성 제어가 도입되어 아이템 특성에 따라 추천 목록을 조정할 수 있다. 이러한 제어 명령을 사용하면 액션 영화와 같은 특정 카테고리에 속하는지 여부와 같은 아이템의 특성을 고려하여 추천을 지정할 수 있게 된다.&lt;/p&gt;

&lt;p&gt;M개의 아이템 특성과 아이템 i는 $h _{i} = [ h^1 _{i}, \ldots, h^m _{i}, \ldots,  h^M _{i} ], \text{ where }  h^n _{i} \in {0,1 }$ 로 나타내며, 여기서 $h^m _{i} \in {0,1 }$ 는 아이템i가 아이템 특성 $h^m$ 을 가지고 있는지 여부를 나타낸다.&lt;/p&gt;

&lt;p&gt;‘Fine-grained controls’에서는 사용자가 특정 아이템 카테고리의 추천을 늘리도록 허용할 수 있다. 예를 들어 로맨스 영화와 같은 특정 카테고리의 아이템을 더 많이 받을 수 있게끔 구체적인 제어 명령을 내릴 수 있다.&lt;/p&gt;

&lt;p&gt;‘Coarse-grained controls’에서는 사용자의 과거 상호작용에서 가장 큰 아이템 카테고리의 추천을 줄이도록 진행된다.&lt;/p&gt;

&lt;p&gt;종합적으로 보면,  UCRS의 ‘Fine-grained controls’에서는 사용자가 세분화된 사용자 혹은 아이템 특성을 활용하여 구체적인 제어 명령을 통해 특정 추천 목표를 달성하는 방안이고,  ‘Coarse-grained controls’는 세분화된 특성에 대해서 사용자가 구체적인 제어 명령을 지시할 필요없이 간단하게 필터버블을 완화하는 방법을 구현했다.&lt;/p&gt;

&lt;h3 id=&quot;43-반-사실적counterfactual-응답-메커니즘&quot;&gt;4.3 반 사실적(Counterfactual) 응답 메커니즘&lt;/h3&gt;
&lt;p&gt;‘Fine-grained controls’에는 연령과 같이 변경된 사용자 특성을 기반으로 추천을 생성하여 다양한 사용자 그룹에서 사실과 다른 질문에 답하는 추론 과정이 포함된다.&lt;/p&gt;

&lt;p&gt;UCI는 사용자의 이전 상호작용 패턴에 반대되는 반 사실적인 조건 아래에서 새로운 추천을 생성하게 된다. 이를 통해 사용자가 과거 패턴에 제한받지 않고 원하는 추천을 받을 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;5-experiment&quot;&gt;&lt;strong&gt;5. Experiment&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#4-experiment&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;experiment-setup&quot;&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#experiment-setup&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;DIGIX-Video&lt;/li&gt;
  &lt;li&gt;ML-1M&lt;/li&gt;
  &lt;li&gt;Amazon-Book&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Baseline&lt;/strong&gt;
 Factorization Machine(FM)과  Neural Factorization Machine(NFM) 2가지 추천 모델에 대해 아래와 같은 베이스라인을 적용함&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;woUF: 사용자 특성 없이 학습된 포로토타입&lt;/li&gt;
  &lt;li&gt;maskUF:  사용자 특성을 삭제하는 포로토타입&lt;/li&gt;
  &lt;li&gt;changeUF: 사용자 특성을 변경한 포로토타입&lt;/li&gt;
  &lt;li&gt;Fairco: 공정성 기반 ranking 포로토타입&lt;/li&gt;
  &lt;li&gt;Diversity: 다양성 기반 re-ranking 포로토타입&lt;/li&gt;
  &lt;li&gt;Reranking: UCI의 한 변형으로, counterfactual 추론과 target category 예측을 제외한 포로토타입&lt;/li&gt;
  &lt;li&gt;C-UCI: ‘Coarse-grained controls’ UCI 포로토타입&lt;/li&gt;
  &lt;li&gt;F-UCI: ‘Fined-grained controls’ UCI 포로토타입&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Evaluation Metric&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Recall: 정확도 척도&lt;/li&gt;
  &lt;li&gt;NDCG: 정확도 척도&lt;/li&gt;
  &lt;li&gt;Weighted-NDCG: 카테고리 선호도 우선순위 척도&lt;/li&gt;
  &lt;li&gt;Coverage: 다양성 척도&lt;/li&gt;
  &lt;li&gt;Isolation Index: 격리지수 척도&lt;/li&gt;
  &lt;li&gt;MCD: 최다 카테고리 비율 척도&lt;/li&gt;
  &lt;li&gt;DIS-EUC: 유클리디언 거리 척도&lt;/li&gt;
  &lt;li&gt;TCD(Target Category Domination): 목표 카테고리 비율 척도&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;result&quot;&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#result&quot;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/DGLCcZ2/rs1.png&quot; alt=&quot;rs1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/kD7nSjt/rs2.png&quot; alt=&quot;rs2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/WpSs466/rs3.png&quot; alt=&quot;rs3&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;3가지 데이터 세트를 대상으로 실험한 결과, UCI 프레임워크가 사용자 제어를 기반으로 원하는 항목을 더 많이 추천하는 효과가 입증되었으며, 정확성과 다양성 측면에서 유망한 성과를 보였다.&lt;/li&gt;
  &lt;li&gt;UCI 프레임워크는 사용자 제어를 기반으로 더 많은 원하는 항목을 효과적으로 추천하여 사용자 만족도와 추천 생태계 참여도를 높일 수 있는 결론을 얻을 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-conclusion&quot;&gt;&lt;strong&gt;6. Conclusion&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#5-conclusion&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;동 연구는 사용자가 필터버블 완화를 능동적으로 제어할 수 있도록 하는 UCRS (User-Controllable Recommender System) 를 제안하여 사용자 특성 및 과거 상호작용을 기반으로 유사한 항목을 과도하게 추천하는 문제를 해결하는 시도를 보였다.&lt;/li&gt;
  &lt;li&gt;UCRS 프로토타입은 필터버블의 심각도를 감지하고 사용자에게 4가지 제어 명령을 제공하여 사용자로 하여금 추천시스템의 제어권을 능동적으로 실시할 수 있도록 추천시스템 생태계에 방향을 제시했다.&lt;/li&gt;
  &lt;li&gt;세 가지 데이터셋을 대상으로 한 실험을 통해 UCRS 프로토타입과 UCI 프레임워크는 정확성과 다양성 측면에서 유망한 성과를 보였으며 사용자 만족도와 추천 생태계에 대한 참여도를 높일 수 있을 것으로 기대된다.&lt;/li&gt;
  &lt;li&gt;단, 동 연구는 UCRS 프로토타입과 UCI 프레임워크를 평가할 때 온라인 실시간 데이터 대신 오프라인 데이터셋을 사용했고, 일부 사용자가 필터버블을 완화하고 제어 기능을 제공할 의향이 있다고 가정을 했기 때문에 현실 데이터와 비교하면 strong assumption일 것으로 판단된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#author-information&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Minkyung Choi
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Affiliation:
 &lt;a href=&quot;http://hfel.kaist.ac.kr/&quot;&gt;Human Factors and Ergonomics Lab – Human Factors and Ergonomics Lab (HFEL) (kaist.ac.kr)&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Research Topic:
Data Science, Computer Vision, VR&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference--additional-materials&quot;&gt;&lt;strong&gt;Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;a href=&quot;https://dsailatkaist.github.io/template.html#6-reference--additional-materials&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Github Implementation:
https://github.com/WenjieWWJ/UCR&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reference:
Wang, W., Feng, F., Nie, L., &amp;amp; Chua, T. S. (2022, July). User-controllable recommendation against filter bubbles. In &lt;em&gt;Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval&lt;/em&gt; (pp. 1251-1261).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-User-controllable_Recommendation_Against_Filter_Bubbles.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-User-controllable_Recommendation_Against_Filter_Bubbles.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[SIGIR 2023] Uncertainty-aware Consistency Learning for Cold-Start Item Recommendation</title>
            <description>&lt;h1 id=&quot;uncertainty-aware-consistency-learning-for-cold-start-item-recommendation&quot;&gt;&lt;strong&gt;Uncertainty-aware Consistency Learning for Cold-Start Item Recommendation&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;1-problem-definition-and-motivation&quot;&gt;&lt;strong&gt;1. Problem Definition and Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;In this paper, the central problem at hand is the Cold-Start problem in  GNN-based recommendation systems, particularly when new items with limited interaction data are introduced to a user-item graph.  The cold-start problem especially becomes tricky when the user-item graph constantly changing. This problem arises due to the scarcity of information on these “cold” items, which hinders accurate recommendations. To tackle this issue, existing models primarily rely on auxiliary user and item features which underutilize actual user-item interactions. Cold items have different embeddings due to fewer interactions comparing to warm items. This difference leads to a challenge of improving recommendations for both simultaneously which is called seesaw phenomenon.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For instance,&lt;/strong&gt; Suppose movie recommender system is using a vector of length 100 for movie embeddings:&lt;/p&gt;

&lt;p&gt;The embedding for “Spider-Man” might encompass values such as [0.2, 0.1, -0.3, 0.5, …], capturing its distinct characteristics and traits.&lt;/p&gt;

&lt;p&gt;However, when a new movie, “Kaist-Man,” is introduced, its embedding might initiate with values like [?, ?, ?, …], primarily due to the lack of interaction data.&lt;/p&gt;

&lt;p&gt;in this case, because “Spider-Man” is more likely to be recommended to users who are interested in superhero action movies than “Kaist-Man”. because the system has more information about it. The huge gap between their embeddings makes it challenging to improve recommendations for both simultaneously.&lt;/p&gt;

&lt;p&gt;To bridge this gap, in this paper, an Uncertainty-aware Consistency learning framework for Cold-start item recommendation (UCC) was introduced which relies exclusively on user-item interactions.  This framework has two key designs: a) Uncertainty-aware Interaction Generation, and b) Graph-based Teacher-Student Consistency Learning.&lt;/p&gt;

&lt;h2 id=&quot;2-problem-formulation&quot;&gt;&lt;strong&gt;2. Problem formulation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Notations.&lt;/strong&gt; In this paper $U = {u}$ is the set of users and  $I = {i}$ is set of items and  $O ={ (u, i^+) \vert u  ∈ U, i^+ ∈ I }$ is user-item interactions, where each pair represents each observed feedback.
&lt;strong&gt;Input:&lt;/strong&gt;  a bipartite graph, where $V = U∪I$ is node set and $G = (V, O^+)$ is the edge set. if $M$:= number of users, $N$:=number of items, $D$:= dimension size of embedding
Then in the training process of graph representation learning, $E_ {u}  = [e_ {u_ {1}} , … , e_ {u_ {M}} ]∈ R^{M\times D}$ is user embedding and $E_ {i}  = [e_ {i_ {1}} , … , e_ {i_ {N}}] ∈R^{N\times D}$ is item embedding.
&lt;strong&gt;Output:&lt;/strong&gt; Recommender models assessing the relationships between unobserved user-item pairs using the dot products of their embeddings. For given user $m$ and given item $n$ the score ${s_ {mn}}$ is calculated  as: $s_ {mn}  = e_ {u_ {m}} {e_ {i_ {n}} }^T$.
A larger value of ${s_ {mn}}$ indicates a stronger preference by the user for the item. The top-k items from the ranking list are recommended to the user.&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/2qjj3J0/figure1.png&quot; alt=&quot;figure1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this paper, they tackle the distribution gap between cold and warm items by employing an uncertainty-aware approach to generate interactions. Then they kept both item-level and model-level similarity with consistency.&lt;/p&gt;

&lt;h3 id=&quot;31-uncertainty-aware-interaction-generation&quot;&gt;3.1. Uncertainty-aware Interaction Generation&lt;/h3&gt;

&lt;p&gt;To determine whether generated interactions are accurate and unbiased enough they introduce the uncertainty degree of each user-item interaction which is calculated by cosine distance.
for user $u_ {m}$ and item $i_ {n}$ cosine distance is
$d_ {mn}= {\vert e_ {u_ {m}} {e_ {i_ {n}} }^T\vert \over \vert \vert e_ {u_ {m}}\vert\vert \ \vert \vert e_ {i_ {n}}\vert \vert }$
${s_ {mn}}_ {n=1}^N$ is ranking scores of item $i_ {n}$ for all users calculated with the pre-trained  recommender, then overall interaction uncertainty of the item $i_ {n}$ can be estimated by the average of all rankings scores:&lt;/p&gt;

&lt;p&gt;$\bar{s_n}= {{1\over M}}\sum_ {k=1}^M s_ {mn}$&lt;/p&gt;

&lt;p&gt;So, high $\bar{s_n}$ suggests low item uncertainty, indicating widespread user acceptance, and whole low $\bar{s_n}$ indicates higher uncertainty.
In order to bridge the gap between cold and warm items’ distribution and popularity bias all interactions with $d_ {mn}&amp;lt;\alpha \bar{s_n}$ will be regarded as uncertain interactions and filtered in the generation stage. So the selection would be as follow:
$\hat{O_ {n}}={I(d_ {mn}&amp;gt;\alpha \bar{s_n})}$,
where $\alpha$ is a pre-defined parameter and $I$ is the indicator function.
In other words, they find the average ranking score for an item for all users ($\bar{s_n}$) and then for each user if item-user similarity ($d_ {mn}$) is smaller than $\alpha \bar{s_n}$ they regard that interaction as uncertain.&lt;/p&gt;

&lt;h3 id=&quot;32-teacher-student-consistency-learning&quot;&gt;3.2. Teacher-student Consistency learning&lt;/h3&gt;

&lt;p&gt;To address seesaw phenomena, and to achieve better recommendations for both warm and cold items at the same time, cold-item with generated low-uncertainty interactions should have a similar distribution with the warm items, so in this paper, they trained the teacher model (generator) and student model (recommender) with consistency learning
trained the teacher model (generator) and student model (recommender) with consistency learning
we train the teacher model (generator) and student model (recommender) with consistency learning, to ensure the cold items with additionally generated low-uncertainty interactions can have similar distribution with the warm items.&lt;/p&gt;

&lt;h4 id=&quot;321-item-level-consistency-learning&quot;&gt;3.2.1 Item-level consistency learning&lt;/h4&gt;

&lt;p&gt;This technique employs a contrastive loss to compare item embeddings before and after a generation process.
Two types of augmentations are used:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Weak Augmentation:&lt;/strong&gt;
In this, edges in a graph are dropped out based on a dropout ratio $\rho$ to make the model more robust and less sensitive to specific data points. It can be formulated as follows:
${\mathcal G}^{w}=({\mathcal V},{\mathcal M}\cdot{\mathcal O}^{+})$ where $\mathcal{M}\in{0,1}^{\vert O^{+}}$ is a masking vector.
For example, in the movie recommendation system, if you always include the same user’s connection to a particular movie, the model might become too biased towards that user’s preferences. By using dropout, you randomly exclude some user-movie connections in each training iteration, making the model more balanced and better at recommending movies for a variety of users.
Where M is a masking vector containing binary values {0, 1} for each element in O+.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Strong Augmentation:&lt;/strong&gt;
This type involves adding more edges to the graph based on generated labels and can be formulated as follows:
${\mathcal G}^{s}=({\mathcal V},{\mathcal O}^{+} +{\widehat O})$
For example, if two movies share many common actors or are often rated similarly by users, strong augmentation would introduce more connections between those movies in the recommendation graph. This enriches the information available to the model, allowing it to make more accurate and diverse movie recommendations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These two augmentation operations create two different views for each node, denoted as $z_i^{\prime},z_i^{\prime\prime}$ 𝑖 (for weak and strong graphs, respectively).
Consistency Regularization: To encourage the similarity between the different views of the same node, a consistency regularization is implemented. This involves the use of a contrastive loss:
$\mathcal{L}_ {cr, item}=\sum_ {i\in I}-\log\frac{\exp(sim(z_i’,z_i’’)/\tau)}{\sum_ {j\in I}\exp(sim(z_i’,z_j’’)/\tau)}$,
where $\mathcal{L}_ {cr, item}$ represents the item-side consistency regularization loss for both the teacher and the student model, $sim()$ is cosine similarity function and $\tau$ is a predefined hyper-parameter.Similarly, $\mathcal{L}_ {cr, user}$ can be computed.  $\mathcal{L}_ {cr}=\mathcal{L}_ {cr, item}+\mathcal{L}_ {cr, user}$ represents the ultimate consistency loss used for consistency regularization.
Recommendation loss can be calculated as follow:&lt;/p&gt;

&lt;p&gt;$\mathcal{L}_ {\mathbf{rec}}=\sum_ {(u,i^+,i^-)\in O}-\ln\sigma(\hat{y}_ {ui^+}-\hat{y}_ {ui^-})+\lambda\vert \vert \Theta\vert \vert &lt;em&gt;2^2,$ is L2-regularization of model’s parameters.
And Finally, our total loss is $\mathcal{L}&lt;/em&gt; {total}=\mathcal{L}_ {rec}+\mu\mathcal{L}_ {cr}$ where $\mu$ is a hyper-parameter.&lt;/p&gt;

&lt;h4 id=&quot;322-model-level-consistency-learning&quot;&gt;3.2.2 Model-level consistency learning&lt;/h4&gt;

&lt;p&gt;To keep the consistency between the teacher model and student, they suggested collecting the teacher embedding into the student embedding: 
$\mathbf{E}^s\leftarrow\gamma\mathbf{E}^s+(1-\gamma)\mathbf{E}^t$
where $E^s$ and $E^t$ are the embeddings of the student and student model’s embedding respectively.&lt;/p&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;experiment-setup&quot;&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Datasets:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Experiments on Yelp and Amazon-Book benchmark datasets.&lt;/li&gt;
  &lt;li&gt;Follow a 10-core setting as in previous studies (Lightgcn and Neural collaborative filtering)&lt;/li&gt;
  &lt;li&gt;Split user-item interactions into training, validation, and testing sets (ratio 7:1:2).
&lt;strong&gt;Baselines:&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;The foundation for our GNN-based model is LightGCN&lt;/li&gt;
  &lt;li&gt;Focused on modelling user-item interactions, not item features.&lt;/li&gt;
  &lt;li&gt;They used two types of recommendation models, the Generative model and Denoising models for user-item interactions: IRBPR, ADT, and SGL.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Evaluation Metric&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Following previous studies, they evaluate performance using Recall@K and  NDCG@K where K = 20&lt;/p&gt;

&lt;h3 id=&quot;result&quot;&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;The overall results are shown in Table 1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/5F54hKF/table1.png&quot; alt=&quot;Table1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This table shows how UCC outperforms previous models.&lt;/p&gt;

&lt;p&gt;The paper conducts a comparative analysis between the proposed method and LightGCN in the context of cold-start recommendation. Items are categorized into ten groups based on popularity, ensuring equal interaction numbers for each group. The last two groups represent cold-start items, with higher GroupID values indicating warmer items. The following figures show how UCC has better performance in all groups&lt;/p&gt;

&lt;p&gt;Unlike other methods that often sacrifice warm item accuracy to improve cold items, the proposed method notably enhances the recall of LightGCN, especially for cold items. For instance, on the Yelp dataset, the proposed method achieves nearly a 7-fold increase in recall compared to LightGCN. The most significant improvement is observed for group-id 1 items in Amazon-Book, with recall improving by 400%, underscoring the method’s effectiveness in addressing cold-start recommendation challenges and highlighting the “seesaw phenomenon” problem.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/j87vzrD/figure2.png&quot; alt=&quot;figure2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In their ablation study, the result shows that the number of generated interactions is adaptive for different item groups. It notes that low-uncertainty interactions, which are more abundant for cold items, help alleviate the distribution difference between warm and cold items. Using item-side-generated interactions significantly improves performance, while user-side-generated interactions exacerbate the distribution gap. This underscores the effectiveness of the uncertainty-aware interaction generation component. Also, as shown in the following figure teacher-student learning outperforms other methods.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/HhYyCx0/figure3.png&quot; alt=&quot;figure3&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;This paper tackles the Cold-Start problem in recommendation systems by introducing the Uncertainty-aware Consistency Learning framework (UCC). UCC’s Uncertainty-aware Interaction Generation effectively bridges the gap between cold and warm items, resulting in notable improvements in recommendation performance.&lt;/p&gt;

&lt;p&gt;The Teacher-Student Consistency Learning component further enhances recommendation quality, addressing the seesaw phenomenon. Extensive ablation studies and experiments on benchmark datasets showcase the effectiveness of the UCC model, consistently outperforming existing approaches, especially in improving recall for cold items. This paper offers a promising solution to enhance recommendation systems, particularly in dynamic settings.&lt;/p&gt;

&lt;p&gt;However, it may face challenges related to complexity, scalability, and generalizability, and a broader evaluation with diverse datasets and consideration of interpretability is needed to establish its practical applicability. Additionally, a more in-depth analysis of its performance compared to a wider range of state-of-the-art approaches would provide a more comprehensive understanding of its competitiveness.&lt;/p&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Author Name:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Taichi Liu&lt;/li&gt;
      &lt;li&gt;Chen Gao&lt;/li&gt;
      &lt;li&gt;Zhenyu Wang&lt;/li&gt;
      &lt;li&gt;Dong Li&lt;/li&gt;
      &lt;li&gt;Jianye Hao&lt;/li&gt;
      &lt;li&gt;Depeng Jin&lt;/li&gt;
      &lt;li&gt;Yong Li&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Affiliation:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Tsinghua University&lt;/li&gt;
      &lt;li&gt;Huawei Noah’s Ark Lab&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Research Topic:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Uncertainty-aware Consistency Learning for Cold-Start Item Recommendation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-Uncertainty-aware_Consistency_Learning_for_Cold-Start_Item_Recommendation.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-Uncertainty-aware_Consistency_Learning_for_Cold-Start_Item_Recommendation.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[RecSys 2023] Trending Now: Modeling Trend Recommendations</title>
            <description>&lt;p&gt;&lt;strong&gt;[Recsys 2023] Trending Now: Modeling Trend Recommendations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Info&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;▢   &lt;strong&gt;Authors&lt;/strong&gt; : AWS AI Labs, Amazon USA&lt;/p&gt;

&lt;p&gt;▢   &lt;strong&gt;Research topic&lt;/strong&gt; : Trending now (현재 인기있는 상품을 추천하는 추천시스템)&lt;/p&gt;

&lt;p&gt;▢   &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3604915.3608810&quot;&gt;paper links&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Research Motivation &amp;amp; 논문 선정 이유&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;최근 추천시스템에서는 일반적으로 “현재 인기있는 상품 (trending now)” 과 같은 별도의 추천 항목을 제시해주어 해당 상품의 인기를 높여 활성유저를 유치하고 있습니다. 그러나 일반적으로 “시간 간격 내 interaction 수” 와 같은 단순한 휴리스틱 방법을 기반으로 추천해주기 때문에 rich-get-richer (인기있는 상품만 더 노출되어 더 많은 인기를 얻는) 문제 등 개선의 여지가 많이 남아있으며, 추천시스템에서 trend 를 모델링하는 연구는 제한적으로 이루어져 있습니다. 따라서 해당 논문은 &lt;strong&gt;시계열 예측&lt;/strong&gt; 이라는 새로운 관점에서 &lt;strong&gt;trend 를 반영한 추천시스템 모델을 제안&lt;/strong&gt;합니다. item trendiness 에 대한 정의를 통해 trend recommendation task 를 &lt;strong&gt;one-step time series forecasting&lt;/strong&gt; 문제로 공식화합니다. item 의 미래 trend 를 예측하고 추천 리스트를 생성하는 deep latent variable 모델인 &lt;strong&gt;TrendRec&lt;/strong&gt; 을 제안합니다.
현재 시점에서의 trend 를 파악하고 유저에게 관련 item 을 추천하는 것을 시계열 예측으로 접근한 관점이 신선했고, “acceleration” 이라는 개념을 정의하여 인기가 “빠르게 상승” 하고 있고 가까운 미래에 인기를 얻을 가능성이 있는 item 을 추천한다는 아이디어가 참신한 것 같아 해당 논문을 선정하게 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-introudction&quot;&gt;1. Introudction&lt;/h3&gt;

&lt;h4 id=&quot;1--definition&quot;&gt;1-①. Definition&lt;/h4&gt;

&lt;h5 id=&quot;-용어정의&quot;&gt;▶ 용어정의&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;용어&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Popularity&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;특정 시간 간격 내에 발생한 interaction 수&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;trend in the recommendation context&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;인기도 (popularity) 또는 가속도 (acceleration)의 &lt;strong&gt;변화율&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;trending now&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;현재 시점에서 점점 더 많은 interaction 이 발생하는 item list 이지만, 해당 item 들은 반드시 가장 인기있는 item 을 뜻하진 않는다. 아직 인기가 높지 않은 유망한 trending up item 에 대한 탐색이 가능하므로 popularity bias 없이 효과적으로 item 을 추천한다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;-trending-now-의-target-item-예시&quot;&gt;▶ trending now 의 target item 예시&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Example&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;•  최근 출시된 좋은 품질의 cold items (ex. 왕좌의 게임 새로운 에피소드) = Recently released cold items of good quality&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;•  갑작스러운 변화가 발생하는 항목 (ex. 영화가 오스카상을 수상하여 갑자기 유행하는 경우) = Items experiencing sudden changes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;•  주기적으로 유행하는 오래 지속되는 품목 (ex. 겨울의류와 같이 계절적인 영향을 받는 품목) = Long lasting items with periodic up-trend&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1--challenge&quot;&gt;1-②. Challenge&lt;/h4&gt;

&lt;p&gt;▢  &lt;strong&gt;Problem&lt;/strong&gt;: 현재 trend 를 안정적이고 신뢰성 있게 파악하기 위해서는 충분한 interaction 을 수집하는 데 일정 시간이 필요하나, trend 는 정의 특성상 역동적으로 변화하고 데이터 수집 기간 동안 변동이 있을 수 있다.&lt;/p&gt;

&lt;p&gt;▢  &lt;strong&gt;Solution&lt;/strong&gt; : trend recommendation 을 one-step forecasting problem 으로 공식화한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1--problem-setting--one-step-forecasting-problem&quot;&gt;1-③. Problem setting : One-step forecasting problem&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;▢ (왼쪽 그래프) 과거 item 의 trend 변화가 주어지면, &lt;strong&gt;다음 시간 단계에 어떤 item 이 유행할지 예측 (→ One-step forecasting)&lt;/strong&gt; 하는 것을 목표로 한다. 모델이 다음 시간 단계에서 유행하는 item 을 예측하면, 백엔드에서 데이터를 버퍼링하면서 다음 시간 단계 내 user 에게 해당 item 을 표시한다. 다음 시간 단계가 끝나면 모델은 새로 축적된 데이터를 기반으로 바로 다음 시간 단계에 대한 새로운 예측을 수행한다. 또 다른 데이터 수집의 주기를 시작하는 것으로 추천을 반복한다.&lt;/p&gt;

&lt;p&gt;▢ (오른쪽 그래프) 특정 use case 에 대한 최적화된 트렌드 추천을 설계하려면 기존의 시계열 예측 모델을 기반으로 구축할 수 있다. 더불어 시계열 예측 모델 외에도 추천 상황의 고유한 속성이 활용될 수 있다. 시계열에서 각 item 에 대한 대략적인 누적 interaction 수 외에도 더 세분화된 user-item 간 interaction 이 존재한다. 특정 item 에 대해 얼마나 많은 user 가 해당 item 과 상호작용 했는지 알 수 있을 뿐 아니라 이러한 user 가 정확히 누구인지도 알 수 있다. 이는 item 간 근본적인 상관관계를 파악하는 데 도움이 되는 추가적인 정보를 제공하며 &lt;strong&gt;user 가 많이 겹치는 item 은 공통 trend 패턴을 공유 할 수 있으므로 trend 예측의 정확도를 높일&lt;/strong&gt; 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-preliminaries&quot;&gt;2. Preliminaries&lt;/h3&gt;

&lt;h4 id=&quot;2--term-definition&quot;&gt;2-①. Term Definition&lt;/h4&gt;

&lt;h5 id=&quot;-용어정의-1&quot;&gt;▶ 용어정의&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;용어&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
      &lt;th&gt;표기&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Time Step&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;미리 정의한 시간 간격 (ex. 한시간)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Δ𝑡&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Velocity&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;item j 에 대해서, time step t 동안 수집된 interaction 수를 time step t 에서의 velocity 로 정의 (unit time Δ𝑡 당 item j 의 popularity)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;W𝑗𝑡&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Acceleration&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;time step t 에서의 item j 에 대한 acceleration. item j 의 velocity 가 단위 시간 Δ𝑡당 ΔW𝑗𝑡씩 &lt;strong&gt;변화&lt;/strong&gt;하고 있음을 나타낸다 (&lt;strong&gt;변화량&lt;/strong&gt;).&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;A𝑗𝑡&lt;/strong&gt; = &lt;strong&gt;ΔW𝑗𝑡&lt;/strong&gt; = W𝑗(𝑡) - W𝑗(𝑡-1)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;-acceleration--trend&quot;&gt;▶ &lt;strong&gt;Acceleration = Trend&lt;/strong&gt;&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;item 𝑗 의 시간 단계 𝑡 에서의  acceleration A𝑗𝑡 가 &lt;strong&gt;모든 item 의 acceleration 중 가장 높으면&lt;/strong&gt; 해당 item 은 시간 단계 𝑡에서 &lt;strong&gt;trendy 한 것으로 간주&lt;/strong&gt;한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;2--problem-definition&quot;&gt;2-②. Problem Definition&lt;/h4&gt;

&lt;h5 id=&quot;-적절한-time-interval-ex-향후-1시간-trend-item-향후-하루동안-trend-item-이-관건이다&quot;&gt;▶ 적절한 Time interval (ex. 향후 1시간 trend item, 향후 하루동안 trend item) 이 관건이다.&lt;/h5&gt;

&lt;p&gt;현재 trend 를 빠르게 감지하고 실시간으로 인기 있는 item 을 추천하는 것이 이상적이다. 이를 위해선 충분한 interaction 을 축적하는데 일정 시간이 필요하면서도, trend 는 동적으로 변화하면서 (dynamic variations) 데이터 수집 과정에서 시간적 변동 (temporal drift) 있는 것이 특징이기 때문에 적절한 time interval Δt 를 설정하는 것이 중요하다. Δt 가 너무 작다면 수집된 데이터가 불충분하여 noisy 가 발생할 수 있고, 너무 크다면 시간적 변동성이 발생해 예측 성능이 낮아질 수 있다. 따라서 데이터에 맞는 feasible 하고 short 한 적절한 time interval 을 찾는 것이 중요하다.&lt;/p&gt;

&lt;h5 id=&quot;-시간-단계-길이-time-step-length-와-작업-실행-가능성-task-feasibility-간의-상관-관계에-대한-가설&quot;&gt;▶ 시간 단계 길이 (time step length) 와 작업 실행 가능성 (task feasibility) 간의 상관 관계에 대한 가설&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;bias-variance tradeoff&lt;/strong&gt; : 시간 단계 길이가 짧으면(예: 1시간) 데이터 희소성 (data sparsity) 으로 인해 variance 가 발생하고, 시간 단계 길이가 길면(예: 하루) 시간적 드리프트 (temporal drift 시간에 따른 변동) 로 인해 편향이 발생한다. 따라서 둘 사이의 균형을 잘 맞출 수 있는 sweet spot 을 찾아야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig3.png&quot; alt=&quot;fig3&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;-one-step-time-series-forecasting-task&quot;&gt;▶ one-step time series forecasting task&lt;/h5&gt;

&lt;p&gt;trend recommendation task 를 one-step time series forecasting 문제로 정의한다. 각 item 대해 주어진 &lt;strong&gt;historical acceleration&lt;/strong&gt; [A𝑗0, A𝑗1, . . . , A𝑗𝑡] := &lt;strong&gt;A𝑗,0:𝑡&lt;/strong&gt; 과, covariates 와 같은 추가적인 &lt;strong&gt;contextual information&lt;/strong&gt; [C𝑗0, C𝑗1, . . . , C𝑗𝑡] := &lt;strong&gt;C𝑗,0:t&lt;/strong&gt; 가 주어졌을 때, 다음 step 인 (t+1) 에서의 acceleration 을 예측하기를 원한다. 그리고 trend prediction 을 기반으로 상위 k 개의 아이템을 추천한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig2.png&quot; alt=&quot;fig2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;2--baseline-model&quot;&gt;2-③. Baseline model&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;널리 채택된 두 가지 휴리스틱 모델을 설명한 다음 일반적인 형태의 딥러닝 기반 확률론적 시계열 예측 모델을 baseline model 로 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-1-markov-heuristic-model&quot;&gt;▶ (1) Markov Heuristic Model&lt;/h5&gt;

&lt;p&gt;임의의 item j 의 next time step 의 acceleration A𝑗 (𝑡+1) 는 “오직” 현재 time step 의 acceleration A𝑗t 에 의존한다고 가정한다. 실제로 acceleration 는  짧은 시간 동안 동일하게 유지되는 경향이 있으므로 마르코프 휴리스틱 모델을 다음과 같이 정의한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig4.png&quot; alt=&quot;fig4&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Aˆ𝑗 (𝑡+1) = next time step 에서 예측된 acceleration&lt;/li&gt;
  &lt;li&gt;Auto regressive model (AR) 의 special case 로도 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-2-exponential-moving-average-ema-heuristic-model&quot;&gt;▶ (2) Exponential Moving Average (EMA) Heuristic Model&lt;/h5&gt;

&lt;p&gt;마르코프 휴리스틱 모델의 가장 큰 단점은 다음 시간 단계의 item acceleration 이 현재 시간 단계의 영향을 받기 때문에 데이터 희소성 등의 문제로 인해 노이즈가 발생할 수 있다는 것이다. 따라서 여러 개의 최신 시간 단계를 고려하여 더 최근의 시간 단계에 더 많은 가중치를 할당하는 지수이동평균 휴리스틱 모델을 정의할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig5.png&quot; alt=&quot;fig5&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Aˆ𝑗 (𝑡+1) = next time step 에서 예측된 acceleration&lt;/li&gt;
  &lt;li&gt;T : 모델이 고려하고 있는 최근 시간 단계 수&lt;/li&gt;
  &lt;li&gt;wk : 현재 시간 step 에서 멀어질수록 기하급수적으로 감소하는 미리 정의된 가중치&lt;/li&gt;
  &lt;li&gt;ARIMA model 의 special case 로 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-3-deep-learning-based-time-series-forecasting-model&quot;&gt;▶ (3) Deep Learning based Time Series Forecasting Model&lt;/h5&gt;

&lt;p&gt;휴리스틱 모델은 일반적으로 다양한 시나리오에 적응할 수 있는 유연성이 부족한 일반적인 가정 (general assumptions) 을 인코딩한다. 그러나 &lt;strong&gt;acceleration 패턴은 도메인(리테일, 미디어, 뉴스 등)에 따라 다르다&lt;/strong&gt;. 예를 들어, 매주 수요일마다 TV 시리즈의 새 에피소드가 공개되는 것과 같이 리테일과 미디어 영역 모두에서 다양한 주기(일별, 주별, 계절별 등)의 주기적 acceleration  패턴이 풍부하게 존재한다. 반대로 뉴스는 시간에 민감하고 사람들은 가장 최근 뉴스를 팔로우하는 경향이 있기 때문에 뉴스 영역에서는 이러한 규칙적인 acceleration  패턴이 거의 관찰되지 않는다. 또한 같은 도메인 내에서도 다양한 acceleration  패턴이 공존할 수 있다. 예를 들어, 특정 영화 플랫폼에서 새로 개봉한 액션 영화의 acceleration 곡선은 해당 플랫폼 사용자 커뮤니티의 선호도에 따라 새로 개봉한 다큐멘터리 영화의 acceleration 곡선에 비해 지속적으로 가파른 증가세를 보일 수 있다. 따라서 &lt;strong&gt;트렌드 추천을 위한 보다 일반적인 솔루션은 다양한 시나리오에 적응할 수 있는 학습 가능한 딥러닝 기반 시계열 예측 모델을 설계&lt;/strong&gt;하는 것이다. 모델을 공식화하면 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig6.png&quot; alt=&quot;fig6&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;𝑓seq (·) : 과거 acceleration  를 집계하고 다음 시간 단계에서 acceleration  의 확률적 분포를 예측하는 순차적 모델로 DeepAR, RNN, MQCNN, TFT 등이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-model--collaborative-time-series-forecasting-model-with-user-item-interactions-trendrec&quot;&gt;3. Model : collaborative time series forecasting model with user-item interactions (TRENDREC)&lt;/h3&gt;

&lt;h4 id=&quot;3--two-phase-framework&quot;&gt;3-①. Two-phase framework&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;phase&lt;/th&gt;
      &lt;th&gt;objective&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;1. 다음 item 추천&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;보조적인 목표로 하여, TrendRec은 user-item 간 interactive signal 을 활용하여 item 간의 기본 상관관계를 감지하고 이러한 지식을 item embedding 으로 인코딩한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;2. 다음 time step 의 trend (=acceleration) 예측&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;학습된 item embedding 을 사용하여 시계열 예측 목표를 위해 각 시계열에 대한 추가 context 를 제공한다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3--model-overview&quot;&gt;3-②. Model overview&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;TrendRec : RecSys + Time series forecasting&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;추천 모델은 user-item interaction 을 통해 다음 아이템 추천 objective 를 학습한다.
    &lt;ul&gt;
      &lt;li&gt;item feature 에 대한 representation learning 을 통해 dense latent item embedding 을 생성한다. 이를 통해 item 간 correlation 을 파악하여 시계열 예측에 대한 추가적인 context 를 제공한다. Item correlation 을 인코딩하는 shared latent item embeddings 을 통해 두 objectives 가 연결된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;시계열 예측 모델은 item의 accelerations 를 사용하여 다음 단계 acceleration 예측 objective 에 대해 학습한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;probabilistic graphical model (PGM)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig7.png&quot; alt=&quot;fig7&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;-노드&quot;&gt;▸ &lt;strong&gt;노드&lt;/strong&gt;&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;표기&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;V𝑗t ∈ R(D)&lt;/td&gt;
      &lt;td&gt;∘  &lt;strong&gt;item 𝑗’s properties&lt;/strong&gt; till time step t  both static properties and dynamic properties &lt;br /&gt; ∘  𝐷 is the hidden dimension of the embedding &lt;br /&gt; ∘ &lt;strong&gt;latent item embedding&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;𝜆v&lt;/td&gt;
      &lt;td&gt;∘  &lt;strong&gt;hyperparameters&lt;/strong&gt; related to distribution variance of latent item embedding&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;A𝑗,0:t ∈ R(𝑁𝑗t)&lt;/td&gt;
      &lt;td&gt;∘  &lt;strong&gt;item 𝑗’s historical acceleration&lt;/strong&gt; till time step 𝑡 which is [A𝑗0, A𝑗1, . . . ,A𝑗𝑡]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;A𝑗(𝑡+1) ∈ R&lt;/td&gt;
      &lt;td&gt;∘  the acceleration of item 𝑗 at the next time step 𝑡 + 1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;𝑁𝑗t&lt;/td&gt;
      &lt;td&gt;∘  the number of historical time steps of item 𝑗 till time step t&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;U𝑖t ∈ R(D)&lt;/td&gt;
      &lt;td&gt;∘  &lt;strong&gt;user 𝑖’s interests&lt;/strong&gt; till time step t &lt;br /&gt; ∘  &lt;strong&gt;latent user embedding&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;𝜆u&lt;/td&gt;
      &lt;td&gt;∘  hyperparameters related to distribution variance of latent user embedding&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;S𝑖t ∈ R(N𝑖t x D)&lt;/td&gt;
      &lt;td&gt;∘  &lt;strong&gt;user 𝑖’s historical interaction sequence&lt;/strong&gt; till time step 𝑡 &lt;br /&gt; ∘  embedding matrix and each row of it represents an item embedding&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;𝑁𝑖t&lt;/td&gt;
      &lt;td&gt;∘  the number of interactions from user 𝑖 till time step t&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;R𝑖𝑗t ∈ {0, 1}&lt;/td&gt;
      &lt;td&gt;∘  &lt;strong&gt;interaction label&lt;/strong&gt; denoting whether user 𝑖 interacted with item 𝑗 at time step t&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;-엣지&quot;&gt;▸ &lt;strong&gt;엣지&lt;/strong&gt;&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;표기&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Edge S𝑖𝑡 → U𝑖t&lt;/td&gt;
      &lt;td&gt;∘  user 의 이전 interactions 는 user 의 interest 를 표현하며, 이는 user의 다음 행동에 영향을 미친다. &lt;br /&gt; ∘  ex. 휴대폰을 구매한 사용자가 다음에 휴대폰 액세서리를 구매할 수 있다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edge {U𝑖𝑡, V𝑗𝑡} → R𝑖𝑗𝑡&lt;/td&gt;
      &lt;td&gt;∘  Interaction 은 user interests U𝑖𝑡 와 item properties V𝑗t 에 따라 달라진다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edge {V𝑗𝑡, A𝑗,0:𝑡 } → A𝑗 (𝑡+1)&lt;/td&gt;
      &lt;td&gt;∘ 다음 시간 단계 𝑡 +1에서 아이템 𝑖의 acceleration 는 item feature 와 item 의 과거 acceleration 에 영향을 받는다. &lt;br /&gt; ∘ ex. 액션 영화는 특정 웹사이트의 사용자 커뮤니티에서 트렌드가 될 가능성이 높다. &lt;br /&gt; ∘ ex. 주간 trend 패턴이 주기적으로 나타나는 item&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;-generative-process&quot;&gt;▸ &lt;strong&gt;Generative process&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;평균이 𝝁 그리고 분산이 diagonal covariance λ&lt;sup&gt;-1&lt;/sup&gt;ⅠD 인 가우시안 분포에서 latent offset vector 를 설정하여 latent item embedding 과 latent user embedding 을 계산한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig8.png&quot; alt=&quot;fig8&quot; /&gt;&lt;/p&gt;

&lt;p&gt;R𝑖𝑗t 를 구하기 위해서 softmax function 을 latent user embedding 와 latent item embedding 을 내적한 값에 적용하여 recommendation score 를 계산한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Y𝑖𝑗𝑡 = 𝑓softmax(U’𝑖𝑡•V𝑗𝑡)&lt;/li&gt;
  &lt;li&gt;R𝑖∗𝑡 ~ 𝐶𝑎𝑡([Y𝑖𝑗𝑡]), j: 1,,..,J , 𝐶𝑎𝑡 is categorical distribution.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3--training&quot;&gt;3-③. Training&lt;/h4&gt;

&lt;h5 id=&quot;-maximum-a-posteriori-map-estimation&quot;&gt;▸ &lt;strong&gt;Maximum a Posteriori (MAP) Estimation&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;maximum a posteriori (MAP) estimation&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig11.png&quot; alt=&quot;fig11&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다음 item 을 추천하는 것에 있어서 interaction R𝑖𝑗t 에 대한 조건부 확률을 다음과 같이 정의한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig9.png&quot; alt=&quot;fig9&quot; /&gt;&lt;/p&gt;

&lt;p&gt;item accelerations A𝑗(𝑡+1) 에 대한 조건부 확률을 다음과 같이 정의한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig10.png&quot; alt=&quot;fig10&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;𝑓𝑡𝑠 (·) : 다음 시간 단계 𝑡에서 acceleration 의 확률적 분포를 예측하기 위해 item 의 과거 acceleration 와 latent item embedding 을 모두 사용하는 모든 유형의 확률론적 시계열 예측 모델&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-negative-log-likelihood-nll&quot;&gt;▸ &lt;strong&gt;Negative Log Likelihood (NLL)&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;posterior probability 를 최대화 하는 것은 negative log likelihood 를 최소화하는 것과 같다. NLL 은 다음과 같이 계산할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig12.png&quot; alt=&quot;fig12&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(10) : Next Item Recommendation Loss → 이를 최소화하면 학습 세트에서 다음 항목 추천 성능이 향상된다.&lt;/li&gt;
  &lt;li&gt;(11) : Time Series Forecasting Loss → 이 term 을 최소화하면 훈련 세트에서 acceleration 예측이 향상된다.&lt;/li&gt;
  &lt;li&gt;(12) : Regularizing Latent Item Embedding V𝑗t and Latent User Embedding U𝑖t  →  V𝑗t 를 zero-mean Gaussian prior 에 근접하게 정규화하고 U𝑖𝑡 를 유저의 과거이력이 유저의 흥미를 나타낸다고 가정하고, 계산된  𝑓seq (S𝑖𝑡) likelihood function adopted by the probabilistic time series forecasting model에 근접하게 정규화한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3--inference&quot;&gt;3-④. Inference&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig13.png&quot; alt=&quot;fig13&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;V*jt : the posterior of item j’s latent item embedding&lt;/li&gt;
  &lt;li&gt;𝑓∗ts (·) : the trained sequential time series forecasting model&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3--model-architecture&quot;&gt;3-⑤. Model architecture&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig14.png&quot; alt=&quot;fig14&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;왼쪽그림 : overview network structure&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;오른쪽그림 : figure visualizes the full details of the TrendRec implementation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;the model contains two principal components
    &lt;ul&gt;
      &lt;li&gt;(1) a sequential recommender :   &lt;strong&gt;R𝑖𝑗t&lt;/strong&gt; ⇨  recommendation score 는 latent user embedding U𝑖t 과 latent item embedding V𝑗t 사이의 내적 곱을 기반으로 계산된다.&lt;/li&gt;
      &lt;li&gt;(2) collaborative time series forecasting model :   &lt;strong&gt;A𝑗(𝑡+1)&lt;/strong&gt; ⇨  다음 item 추천 (1) 과정에서 pre-trained 된 latent item embedding 을 가져와 item historical acceleration 와 함께 활용하여 다음 시간 단계에서의 acceleration 를 예측한다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;→ 2가지 요소는 학습가능한 latent item embedding 을 통해 join 된다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-experiments&quot;&gt;4. Experiments&lt;/h3&gt;

&lt;p&gt;▢ &lt;strong&gt;Research question&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Research question&lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Q1&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;task feasibility 와 time step length 의 correlations 에 대해 제안한 가설 (적절한 Δ𝑡 의 존재) 이 적용되는지, 각 dataset 의 time step length 는 어떻게 선택해야 하는지&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Q2&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;TrendRec이 휴리스틱 모델과 기본적인 딥러닝 기반 시계열 예측 모델을 포함한 모든 기준 모델보다 성능이 우수한지&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4--datasets&quot;&gt;4-①. Datasets&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig15.png&quot; alt=&quot;fig15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;리테일 (TaoBao), 미디어(Netflix), 뉴스(MIND)를 포함한 다양한 도메인의 데이터를 이용
    &lt;ul&gt;
      &lt;li&gt;TaoBao 의 경우  아이템 카테고리가 크기 때문에 , 3개의 구분된 데이터셋을 구조화하기 위해 인터랙션 수를 기반으로 상위 3개의 아이템 카테고리를 선택한다 → TaoBao Cat1, TaoBao Cat2, TaoBao Cat3&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;다음 item 추천 objective 와 시계열 예측 objective 사이에 시간적 누수 (temporal leakage) 가 발생하지 않도록 엄격한 실험설정을 적용 : 모든 training interactions 이 모든 testing interactions 보다 먼저 발생하도록 데이터를 시간적으로 분할하고, training 단계에서 두 objective 에 대해 정확하게 동일한 훈련 데이터셋을 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4--evaluated-methods&quot;&gt;4-②. Evaluated methods&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Mtehods&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Oracle&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  다음시간 단계에서 실제 정답 (ground truth) 미래 acceleration 에 접근할 수 있다. &lt;br /&gt; ∘  항상 acceleration 을 정확하게 예측하고 상위 k 개의 트렌드 아이템을 추천한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Random&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  전체 아이템 카탈로그에서 replacement 없이 전체 아이템으로부터 random selection 을 하여 아이템을 추천해준다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Exponential moving average (EMA)&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  지수이동평균은 최근 m 시간 단계 (latest 𝑚 time steps) 의 acceleration 의 가중치 합을 기반으로 다음 시간 단계의 acceleration 을 예측하는 규칙기반 모델이다. (m=8) &lt;br /&gt;  ∘  가중치는 현재 시간 단계로부터 멀어지는 시간 단계수가 증가함에 따라 0.75의 계수로 기하급수적으로 감소한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;DeepAR&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  auto-regressive RNN 에 기반한 SOTA 시계열 모델 중 하나이다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;TrendRec&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;∘  본 연구에서 제안한 모델로 two-phase 로 이루어져있다. &lt;br /&gt; ∘ 다음 아이템 추천을 위해 GRU4Rec 을 채택해 latent item embedding 을 학습한다. &lt;br /&gt; ∘ 시계열 예측을 위해선 DeepAR 모델을 사용한다. 최신 시계열 예측 모델 중 하나이고, 널리 채택되고 있기 때문이다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4--evaluation-metrics&quot;&gt;4-③. Evaluation metrics&lt;/h4&gt;

&lt;p&gt;시계열 예측 설정에서 RMSE와 같은 평가 지표를 채택하는 대신, 다음 시간 단계에서 트렌드 아이템을 추천하는 트렌드 추천 집합의 목표에 밀접하게 부합하는 평가 지표를 설계한다.&lt;/p&gt;

&lt;h5 id=&quot;-1-acceleration-metric&quot;&gt;▸ (1) Acceleration metric&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig16.png&quot; alt=&quot;fig16&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델이 예측한 다음 단계 시간 t 의accelerations 에 기반하여 상위 k 개 item 을 선택&lt;/li&gt;
  &lt;li&gt;그런 다음 선택한 𝑘 아이템을 다음 시간 단계 𝑡에서 해당 ground truth acceleration 에 다음과 같이 맵핑&lt;/li&gt;
  &lt;li&gt;acceleration 이 trend 의 정량적인 측정 (quantitative measurement) 이기 때문에 item 의 다음 시간 단계의 예측한 acceleration 의 총합 (sum) 으로 계산하고 모델의 trendiness score 로 사용
    &lt;ul&gt;
      &lt;li&gt;값이 높을수록 모델은 다음 시간 단계에서의 트렌드한 아이템에 대한 예측을 더 잘한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;[0,1] 사이의 값으로 스케일링을 하기 위해 trendiness score 의 top 에 대해 min-max normalization 을 적용한다. trendiness score 의 upper bound 는 Oracle 모델에서, lower bound 는 Random 모델에서 온다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig18.png&quot; alt=&quot;fig18&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;-2-tndcg-metric&quot;&gt;▸ (2) TNDCG Metric&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig17.png&quot; alt=&quot;fig17&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trendiness-Normalized-DCG (TNDCG) metric : 아이템의 rank position 을 logarithmic reduction factor 로 고려한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig19.png&quot; alt=&quot;fig19&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;r : index the rank position&lt;/li&gt;
  &lt;li&gt;A&lt;sup&gt;p&lt;/sup&gt;&lt;sub&gt;r&lt;/sub&gt; : acceleration of item ranked at position r based on order from &lt;strong&gt;model prediction (표기 p)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;A&lt;sup&gt;O&lt;/sup&gt;&lt;sub&gt;r&lt;/sub&gt; : acceleration of item ranked at position r based on order from &lt;strong&gt;ground truth (표기 O)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-3-evaluation-protocol&quot;&gt;▸ (3) Evaluation protocol&lt;/h5&gt;

&lt;p&gt;timestamp 를 기준으로 training 과 test step 을 나눈다. 그리고 testing 을 위해 가장 최근의 20% time span 을 남긴다. (예. eight hour training window, two-hour testing window)&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4---hypothesis-validation-q1--적절한-δt-선택하기&quot;&gt;4-④.  Hypothesis validation Q1 : 적절한 Δt 선택하기&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig20.png&quot; alt=&quot;fig20&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Markov heuristic model 을 활용해 성능을 평가한다. 간단하지만 generic 한 가정에 기반한 기초적인 모델이고, 따라서 해당 모델의 성능은 task feasibility 를 반영한다. 
결과를 보면, TaoBao 와 MIND 데이터 세트의 곡선은 데이터 희소성 완화로 인해 시간 간격이 길어질수록 acc 지표가 먼저 개선된 다음 temporal drift 로 인해 감소하는 Q1 가설과 일치하는 결과를 보인다. 반면 Netflix 데이터셋의 경우 곡선이 계속 감소하고 있는데, 이는 time stamp 단위가 하루로, 충분한 데이터를 수집할 수 있을 만큼 길지만 temporal drift 가 발생하기 때문이다. 전반적으로 위의 결과는 가설을 입증하고 있다. 각 데이터셋의 시간 간격 &lt;strong&gt;Δ𝑡을 각 곡선의 peak 에 따라 선택&lt;/strong&gt;한다. 일관성을 위해 3개의 TaoBao dataset 은 모두 3시간, Netflix 는 하루, MIND 는 30분 시간간격으로 설정한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4---experimental-results-q2--trendrec-모델의-우수함-증명&quot;&gt;4-⑤.  Experimental results Q2 : TrendRec 모델의 우수함 증명&lt;/h4&gt;

&lt;p&gt;TrendRec 모델을 3개 도메인의 데이터에 대한 다양한 베이스라인모델에 대해 평가한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/hopebii/kaist_ds535/blob/main/fig21.png&quot; alt=&quot;fig21&quot; /&gt;&lt;/p&gt;

&lt;p&gt;TrendRec 이 가장 좋은 performance 를 보인다. TrendRec 의 시계열 예측 부분이 DeepAR 로 구성되어 있는데, DeepAR 대비 TrendRec 의 성능 향상은, 다음 item 추천 파트에서 얻은 pre-trained 된 latent item embedding 을 활용한 것이 효과적이었음을 보여준다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;4---findings&quot;&gt;4-⑥.  Findings&lt;/h4&gt;

&lt;h5 id=&quot;-deep-learning-based-models-significantly-outperform-heuristic-models&quot;&gt;▸ Deep learning based models significantly outperform heuristic models&lt;/h5&gt;

&lt;p&gt;딥러닝 기반의 모델은 휴리스틱 모델보다 성능이 높다. 특히 TaoBao 과 Netflix 데이터셋에 대해 DeepAR 과 TrendRec 과 같은 딥러닝 기반의 모델은 휴리스틱 모델을 큰 차이로 더 성능이 높게 나온다. 해당 결과는 trend 추천을 위해 학습가능한 모델을 채택하는 것의 중요성을 강조한다.&lt;/p&gt;

&lt;h5 id=&quot;-the-ema-model-is-worse-than-the-markov-model-in-most-cases&quot;&gt;▸ The EMA model is worse than the Markov model in most cases&lt;/h5&gt;

&lt;p&gt;EMA 모델은 대부분의 경우에서 마르코프 모델보다 성능이 더 저하되는 결과를 보였다. 이는 trend 가 동적으로 변하고  이러한 결과는, recency bias 를 가진 간단한 가중치합 (weighted sum) 보다, 다음 시간 단계에서의 트렌드와 과거 트렌드 (historical trends) 사이에 의존적인 관계가 보다 더 복잡하다는 것을 의미한다.&lt;/p&gt;

&lt;h5 id=&quot;-performance-gain-from-deep-learning-based-models-is-relatively-small-in-the-news-domain&quot;&gt;▸ Performance gain from deep learning based models is relatively small in the News domain&lt;/h5&gt;

&lt;p&gt;뉴스도메인이 리테일이나 미디어 도메인과 비교했을 때, 딥러닝 기반의 모델과 휴리스틱 모델 사이의 성능 차이는 상대적으로 미미하다. (relatively marginal) 뉴스 도메인의 item 시계열을 분석해 보면 일반적으로 아이템이 출시되면 단기간에 최대 acceleration 에 도달한 후 급격히 하락하는 것으로 나타난다.  이는 주로 시간에 민감한 뉴스의 특성 때문이며, 딥러닝 기반 모델에 큰 도전 과제이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h3&gt;

&lt;h4 id=&quot;5--summary&quot;&gt;5-①. Summary&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;이 연구에서는 추천 시스템에서 잘 다루어지지 않은 주제인 trend recommender 를 연구한다. 선행 연구가 제한적으로 이루어져 있기 때문에 trend 라는 개념을 공식적으로 정의하는 것으로 시작한다. 이후 적시에 안정적으로 trend 를 식별하는데 문제가 되는 bias-variance tradeoff 현상을 관찰하여 이를 바탕으로 trend recommendation 을 one-step time series forecasting 로 공식화한다.&lt;/li&gt;
  &lt;li&gt;방법론 측면에서 user-item interactive signal 을 활용하여 item 간 correlation 을 파악하고 이를 바탕으로 trend 예측을 용이하게 하는 TrendRec 이라는 two phase model 을 개발하였다.&lt;/li&gt;
  &lt;li&gt;Recommendation context 에서 trend 의 개념을 공식적으로 정의하고 그에 맞는 평가지표와 평가 프로세스를 수립했다.&lt;/li&gt;
  &lt;li&gt;리테일, 미디어, 뉴스 등 다양한 영역의 데이터셋에 대한 실험으로 통해 TrendRec 모델의 효과를 입증했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;5--opinion&quot;&gt;5-②. Opinion&lt;/h4&gt;

&lt;p&gt;해당 논문은 시계열 예측 모델을 적용하여 trend 한 item set 을 추천해주는 방법론을 제안하고 있습니다. user-item 간 interaction 정보를 바탕으로 item 정보를 embedding 하여, 더 효과적으로 시계열 예측이 가능하도록 모델 구조를 구성하였으며 특히 trend 라는 맥락에서 발생할 수 있는 적절한 time interval 을 설정하는 데 있어 bias-variance tradeoff 문제를 명시하고 관련된 해결책을 제시하고 있습니다. interaction 수의 변화율 (acceleration) 을 기준으로 trend 를 감지하려고 한 시도가 신선하게 다가왔으며, 수업에서 배웠던 sequence 한 정보를 기반으로 추천해주는 추천시스템 모델들과는 또 다른 맥락의 추천 방법론인 것 같아 전반적으로 인상깊었던 논문이었습니다. 또한 dataset 마다 trend 가 발생하는 상이한 특징에 따라 optimal 한 time interval 을 설정하는 접근 방식이 논문에서 뉴스나 영화 예시를 들었던 것 처럼 domain-based 한 부분이라, 추천 메커니즘에 대한 해석이 더 흥미롭게 다가왔던 것 같습니다. 그러나 TrendRec 에서 시계열 예측 모델로 DeepAR 을 선택한 것, 다음 아이템 예측 모델에 임베딩 방식으로 GRU4Rec을 채택한 것 대한 근거가 조금 부족하다고 느꼈습니다. 추가적인 다른 모델 채택 구성방식의 실험결과도 비교해주었으면 좋을 것 같다는 생각이 들었습니다. 하지만 trend recommendation 이라는 분야에서 해당 논문이 가지고 있는 가치는 매우 크다고 생각하며 앞으로 해당 분야가 발전함에 있어서 중요한 연구가 될 것이라 생각합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;-review-writer-information&quot;&gt;👩🏻 Review writer information&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;이다현 (Lee Dahyeon)
    &lt;ul&gt;
      &lt;li&gt;Master student, Department of Data science, KAIST&lt;/li&gt;
      &lt;li&gt;contact : isdawell@kaist.ac.kr&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-Trending_Now_Modeling_Trend_Recommendations.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-Trending_Now_Modeling_Trend_Recommendations.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[AAAI 2023] Simple and Efficient Heterogeneous Graph Neural Network</title>
            <description>&lt;h1 id=&quot;simple-and-efficient-heterogeneous-graph-neural-network&quot;&gt;Simple and Efficient Heterogeneous Graph Neural Network&lt;/h1&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;1. Problem Definition&lt;/h2&gt;

&lt;p&gt;Heterogeneous Graph Neural Networks(HGNN)은 기존 Graph Neural Network(GNN)에서 사용하는 attention이나 multi-layer 구조 등의 매커니즘을 그대로 사용해왔다. 하지만 homogeneous graph를 위해 디자인된 GNN에서 사용하는 매커니즘을 Heterogeneous graph에 적용했을 때, 정말 효과가 있는지에 대한 분석은 이루어지지 않았다. 본 논문에서는 이러한 매커니즘들의 효과성에 대한 분석을 바탕으로, Heterogeneous graph를 효율적으로 모델링할 수 있는 Simple and Efficient Heterogeneous Graph Neural Networks(SeHGNN)을 제안한다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;2. Motivation&lt;/h2&gt;

&lt;p&gt;이전의 Heterogeneous Graph Neural Network(HGNN)은 GNN에서 사용하는 메커니즘이 heterogeneous 그래프에 효과가 있는지에 대한 분석은 거의 하지 않은 채, 이를 그대로 사용하면서 heterogeneous 그래프의 representation learning을 수행해왔다. 본 논문에서는 attention이나 multi-layer 구조가 heterogeneous 그래프를 모델링하는데 효과적인지에 대해 분석하는 과정에서 중요한 두 가지 발견을 하였고, 이를 바탕으로 SeHGNN 아키텍처를 설계하였다. Heterogeneous 그래프에 대한 기존 매커니즘의 효과성에 대한 분석 과정과 그에 따른 발견은 아래와 같다.&lt;/p&gt;

&lt;li&gt; attention에 대한 연구 &lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/MDVHbCW/figure1.png&quot; alt=&quot;figure1&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;HGNN은 Figure 1에 나타난 것처럼 서로 다른 모듈이나 파라미터들을 사용하여 계산되는 여러 attention을 사용한다. 이러한 attention들은 두 가지 유형으로 분류할 수 있는데, 첫 번째는 같은 relation의 neighbor들 사이에서 계산되는 neighbor attention이고, 두 번째는 서로 다른 relation 사이에서 계산되는 semantic attention이다. 본 논문에서는 attention의 효과성을 살펴보기 위해 attention을 사용한 경우와 사용하지 않은 경우에 대한 비교를 수행하였다.&lt;br /&gt;
이때, attention의 사용 양상은 Heterogeneous graph를 모델링하는 유형에 따라 나뉘어 지는데, HAN과 같이 metapath 기반 방법은 neighbor aggregation 단계와 semantic fusion 단계 각각에서 두 가지 attention을 뚜렷하게 구분하여 사용한다. 반면, HGB와 같이 metapath를 사용하지 않는 방법은 relation-specific한 임베딩을 사용하여 1-hop neighbor의 attention을 계산해서, 두 가지 attention 유형을 구분하는 것이 어려울 수 있기 때문에, attention의 영향을 제거하기 위해 추가 계산을 수행해야 한다. 구체적으로 각 노드의 이웃의 attention 값을 relation별로 평균화하여 neighbor attention을 제거하거나, 각 relation 내에서 정규화하여 각 relation이 최종 결과에 동일하게 기여하도록 조정할 수 있는데 이것은 semantic attention을 제거하는 것과 같다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/Ns6wjmB/table1.png&quot; alt=&quot;table1&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이를 바탕으로 HAN과 HGB에 대해 각 요소를 제거하면서 DBLP 데이터와 ACM 데이터에 대해 node classification을 수행해 실험하였고 그 결과를 Table 1에 정리하였다. 여기서 ‘*‘는 neighbor attention를 제거하는 것을 의미하고 ‘†’는 semantic attention를 제거하는 것을 의미한다. Table 1의 결과에서, semantic attention이 없는 모델은 성능이 감소하는 것을 나타내는 반면, neighbor attention이 없는 모델은 그렇지 않음을 보여준다. 이를 통해 semantic attention은 HGNN에서도 필수적이며, neighbor attention은 필요하지 않다는 것을 발견했고, 추가적으로 neighbor attention의 경우 다양한 SGC(Stochastic Gradient Community)기반의 연구에서 단순 mean aggregtion이 attention 모듈을 사용한 aggregation과 동일한 효과를 가질 수 있다는 것을 확인하였다고 하면서, mean aggregation으로 대체할 수 있음을 언급한다.&lt;/p&gt;

&lt;li&gt; multi-layer 구조에 대한 연구 &lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;neighbor attention이 없는, metapath를 사용하지 않는 방법은 각 relation 내에서 neighbor의 feature를 먼저 평균화한 다음, 다른 relation의 결과를 fusion하는 형태를 지닌다. 따라서 이들은 multi-layer 구조를 가지고 있으며, 각 레이어에서 1-hop metapath만 사용하는 metapath 기반 방법으로 변환할 수 있다. 따라서 본 논문에서는 metapath 기반 방법에서의 레이어 수와 metapath 수의 영향에 중점을 두고 실험을 수행하였다. metapath 기반 방법인 HAN에 대한 실험을 수행하면서 각 variant의 구조를 나타내는 숫자 list를 사용하였는데, 예를 들어 ACM 데이터셋에서 (1,1,1,1)은 각 레이어에서 1-hop metapath “PA” 및 “PS”를 사용하는 네 개의 레이어 네트워크를 나타내며, (4)는 4-hop 이상의 metapath가 없는 single-layer 네트워크를 나타낸다. 이러한 list는 receptive field의 크기도 보여준다. 예를 들어 (1,1,1,1), (2,2), (4)는 동일한 receptive field의 크기를 가지며 4-hop neighbor를 포함한다. 본 논문에서는 마찬가지로 DBLP 데이터와 ACM 데이터에 대해 실험을 수행하여 Table 2에 정리하였고 이 결과를 기반으로 두 번째 발견을 도출했다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/ZJp6f07/table2.png&quot; alt=&quot;table2&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Table 2에 나타난 것처럼 single-layer 구조와 긴 metapath를 사용한 모델이, multi-layer 구조와 짧은 metapath를 사용한 모델보다 우수한 성능을 보이는 것을 볼 수 있다. single-layer와 긴 metapath를 사용한 모델은 동일한 receptive field 크기에서 더 나은 성능을 달성하는데, 이는 multi-layer 네트워크가 각 레이어마다 semantic들을 fusion하기 때문에 고수준 의미를 구별하기 어렵게 만든다는 사실로 설명할 수 있다. 예를 들어, ACM 데이터에서 network 구조로 (4)와 같은 형태를 가진 모델에서 multi-hop metapath를 사용하면, 동일한 저자로부터 쓰여진 (PAP) 또는 익숙한 저자 (PAPAP)와 같은 고수준 의미를 구별할 수 있지만, 모든 중간 벡터가 서로 다른 semantic의 혼합을 나타내므로 4개 layer 네트워크 (1,1,1,1)에서는 이러한 차이를 구분할 수 없다. 더 나아가, 최대 metapath 길이를 증가시킴으로써 모델의 성능을 향상시키는데 도움이 되며, 다양한 의미를 갖는 더 많은 metapath를 도입할 수 있다고 설명한다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위의 두 가지 발견을 바탕으로 제안된 SeHGNN에서는 각 metapath 범위에서 mean aggregation을 사용하여 모델의 성능을 희생시키지 않으면서 중복되는 neighbor attention를 피할 수 있고, single-layer 네트워크 구조를 사용하면서 단순하지만 더 긴 metapath를 사용하여 receptive field를 확장함으로써 더 나은 성능을 얻는 것을 보여준다. 더불어 attention 모듈이 없는 neighbor aggregation 부분은 linear 연산만 포함하고 학습 가능한 파라미터가 없으므로, neighbor aggregation을 매 트레이닝 에폭마다 수행하는 것이 아니라 전처리 단계에서 한 번만 실행할 수 있도록 하여 훈련 시간을 크게 줄일 수 있다. 즉, 이러한 최적화를 통해 네트워크 구조를 간소화하고 효율적으로 만드는 것이 SeHGNN의 핵심 포인트이다.&lt;/p&gt;

&lt;h2 id=&quot;methodology&quot;&gt;Methodology&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://ibb.co/cYBCPdK&quot;&gt;&lt;img src=&quot;https://i.ibb.co/PDL9R8s/figure2.png&quot; alt=&quot;figure2&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://usefulwebtool.com/&quot;&gt;writing keyboard&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;SeHGNN의 아키텍처는 Simplified Neighbor Aggregation과 Multi-layer Feature Projection, 그리고 Transformer-based Semantic Fusion의 세 가지 주요 요소로 구성된다. Figure 2에서 SeHGNN과 다른 metapath 기반 HGNN 간의 차이를 볼 수 있는데, SeHGNN은 &lt;b&gt;neighbor aggregation을 전처리 단계에서 사전 계산&lt;/b&gt;하므로, 매 트레이닝 에폭에서 반복적인 neighbor aggregation의 과도한 복잡성을 피할 수 있다는 점이 주요한 특징이다. 각 구성 요소를 세부적으로 살펴보면 다음과 같다.&lt;/p&gt;

&lt;li&gt;Simplified Neighbor Aggregation&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;간소화된 neighbor aggregation은 전처리 단계에서 단 한 번 수행되는데, 주어진 모든 metapath의 집합 $\Phi_X$에 대한 다른 semantic의 feature matrix들의 list를 아래와 같이 생성한다.&lt;/p&gt;

&lt;p&gt;$M = {X_P : P \in \Phi_X}$&lt;/p&gt;

&lt;p&gt;일반적으로 각 노드 $v_i$에 대해, 각 주어진 metapath로부터 metapath 기반 이웃의 feature를 aggregate하기 위해 mean aggregation을 사용하며 semantic feature vector들의 list를 다음과 같이 출력하는데,&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$mi = {z_P^i = \frac{1}{&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;SP&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;} \sum_{p(i,j)\in SP} x_j : P \in \Phi_X}$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;본 논문에서는 metapath 기반 neighbor collection을 간소화하기 위해 새로운 방법을 제안한다. HAN과 같은 기존의 metapath 기반 방법은 각 metapath에 대해 모든 metapath 기반 이웃을 열거하는 metapath neighbor 그래프를 구축하며, 이는 metapath의 길이에 따라 metapath 인스턴스의 수가 기하급수적으로 증가하므로 높은 부하를 초래했다. 본 논문에서는 GCN의 레이어별 전파에서 영감을 얻어 각 노드의 최종 기여 가중치를 인접 행렬의 곱셈을 사용하여 계산한다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$X_c = {x_0^{cT}; x_1^{cT}; \ldots; x_{&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;V_c&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;-1}^{cT}} \in \mathbb{R}^{&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;V_c&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\times d_c}$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;여기서 $d_c$는 feature dimension이고, $X_c$는 $c$ 유형에 속하는 모든 노드의 초기 feature matrix를 나타낸다. 그런 다음 간소화된 neighbor aggregation 과정은 다음과 같이 표현될 수 있다.&lt;/p&gt;

&lt;p&gt;$XP = \hat{A}&lt;em&gt;{c,c1}\hat{A}&lt;/em&gt;{c1,c2}\ldots \hat{A}_{cl-1,cl}X^{cl}$&lt;/p&gt;

&lt;p&gt;여기서 $P = c1c2 … cl$은 $l$-hop metapath이며, $\hat{A}&lt;em&gt;{ci,ci+1}$은 노드 유형 $c_i$와 $c&lt;/em&gt;{i+1}$ 간의 인접 행렬 $A_{ci,ci+1}$의 row-normalized된 형태이다.&lt;/p&gt;

&lt;p&gt;여기에 레이블을 추가 입력으로 통합하면 모델 성능을 향상시킬 수 있다는 것을 입증한 이전 연구(Wang and Leskovec 2020; Wang et al. 2021b; Shi et al. 2021)를 활용하기 위해, raw feature들을 aggregation하는 것과 유사하게, 레이블을 one-hot 형식으로 표현하고 다양한 metapath를 통해 전파한다. 이 과정은 일련의 행렬 ${Y_P : P \in \Phi_Y}$ 을 생성하며, 이러한 행렬은 해당 metapath neighbor 그래프의 레이블 분포를 반영한다. metapath $P \in \Phi_Y$ 의 두 끝점은 노드 분류 작업에서 대상 노드 유형 $c$여야 한다. metapath $P = cc_1c_2 \ldots c_{l-1}c \in \Phi_Y$ 가 주어지면, 레이블 전파 과정은 다음과 같이 표현될 수 있다.&lt;/p&gt;

&lt;p&gt;$Y^P = rm _ diag(\hat{A}^P)Y^c, \, \hat{A}^P = \hat{A}&lt;em&gt;{c,c1}\hat{A}&lt;/em&gt;{c1,c2}\ldots \hat{A}_{cl-1,c}\,$&lt;/p&gt;

&lt;p&gt;여기서 $Y^c$는 raw label matrix이다. $Y^c$에서 training set에 속하는 노드에 해당하는 행은 one-hot 형태의 label 값을 가지며, 다른 행은 0으로 채워진다. 레이블 유출을 방지하기 위해 각 노드가 자신의 실제 레이블 정보를 받지 않도록 하기 위해 인접 행렬의 곱셈 결과에서 대각선에 있는 값을 제거한다. 레이블 전파는 neighbor aggregation 단계에서 실행되며 나중에 학습을 위한 추가 입력으로 semantic 행렬을 생성한다.&lt;/p&gt;

&lt;li&gt;Multi-layer Feature Projection&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;feature projection 단계는 서로 다른 metapath의 semantic 벡터가 다른 차원을 가지거나 다양한 데이터 공간에 위치할 수 있기 때문에, 이러한 semantic 벡터를 동일한 데이터 공간으로 projection하는 과정이다. 일반적으로, 각 metapath $P$에 대한 semantic-specific한 transformation matrix $W^P$를 정의하고 ${H^′P = W^PX^P}$ 를 계산한다. 더 나은 representation을 위해, 각 metapath $P$에 대해 multi-layer perception 블록 $MLP_P$를 사용하며, 이 블록은 두 개의 연속적인 linear layer 사이에 normalization layer, non-linear layer 및 dropout layer를 포함한다. 이 과정을 다음과 같이 나타낸다.&lt;/p&gt;

&lt;p&gt;$H’_P = \text{MLP}_P(X_P)$&lt;/p&gt;

&lt;li&gt;Transformer-based Semantic Fusion&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;semantic fusion 단계는 semantic feature 벡터를 융합하고 각 노드에 대한 최종 임베딩 벡터를 생성한다. 단순한 weighted sum 형식 대신, 본 논문에서는 각 semantic 쌍 간의 상호 관계를 더 탐색하기 위해 트랜스포머 기반의 semantic fusion 모듈을 제안하였다. 트랜스포머 기반의 semantic fusion 모듈은 미리 정의된 metapath list $\Phi = {P_1, \ldots, P_K}$ 와 각 노드에 대한 projected된 semantic 벡터 ${h’&lt;em&gt;{P1}, \ldots, h’&lt;/em&gt;{PK}}$ 을 고려하여 semantic 벡터 쌍 간의 상호 attention를 학습하도록 설계되었다. 각 semantic 벡터 
$h^{‘Pi}$ 에 대해 이 모듈은 이 벡터를 query 벡터 $q^{Pi}$, key 벡터 $k^{Pi}$ 및 value 벡터 $v^{Pi}$로 매핑한다. 상호 attention 가중치 $\alpha(P_i, P_j)$ 는 소프트맥스 normalization 후의 query 벡터 $q^{Pi}$와 key 벡터 $k^{Pi}$의 dot product 결과이다. current semantic $P_i$의 출력 벡터 $h^{Pi}$는 모든 value 벡터 $v^{Pj}$의 weighted sum과 residual connection을 포함한다. semantic fusion 과정은 다음과 같이 표현될 수 있다.&lt;/p&gt;

&lt;p&gt;$q^{Pi} = W_Q h’^{Pi}$ , $k^{Pi} = W_K h’^{Pi}$ , $v^{Pi} = W_V h’^{Pi}$ , $P_i \in \Phi$ &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$\alpha(Pi,Pj) = \frac{exp(q^{Pi} \cdot k^{{Pj}^T})}{\sum_{Pt\in\Phi} exp(q^{Pi} \cdot k^{{Pt}^T})}$ &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$h^{Pi} = \beta \sum_{P_j\in\Phi} \alpha(P_i,P_j) v^{P_j} + h’^{P_i}$ &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;여기서 $W_Q$, $W_K$, $W_V$, β는 모든 metapath 간에 공유되는 학습 가능한 파라미터이다.&lt;/p&gt;

&lt;p&gt;각 노드의 최종 임베딩 벡터는 모든 출력 벡터의 연결로 이루어지는데, node classification과 같은 downstream 작업을 위해 또 다른 MLP가 사용되어 예측 결과를 생성하며, 이는 다음과 같이 표현될 수 있다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$Pred = \text{MLP}([h^{P1}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;h^{P2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\ldots&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;h^{P&lt;/td&gt;
      &lt;td&gt;\Phi&lt;/td&gt;
      &lt;td&gt;}])$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;experiment&quot;&gt;Experiment&lt;/h2&gt;

&lt;p&gt;본 논문에서는 DBLP, ACM, IMDB 및 Freebase와 같은 널리 사용되는 heterogeneous 그래프 4개와 OGB 챌린지에서 가져온 큰 규모의 ogbn-mag 데이터셋을 사용하여 실험을 진행했고, node classification의 성능 비교를 통해 제안한 방법의 효과성을 검증했다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ibb.co/dpyvcbK&quot;&gt;&lt;img src=&quot;https://i.ibb.co/fN7WS80/table3.png&quot; alt=&quot;table3&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;li&gt;Results on HGB Benchmark&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;
Table 3은 네 가지 데이터셋에서 SeHGNN의 성능을 HGB 벤치마크의 여러 baseline들과 비교한 결과를 제시하며, 1st 행은 네 가지 metapath 기반 방법, 2nd 행은 metapath를 사용하지 않는 네 가지 방법을 나타낸다. SeHGNN이 Freebase 데이터셋의 micro-f1을 제외하고 모든 baseline 대비 최상의 성능을 달성하였다.&lt;/p&gt;

&lt;p&gt;추가적으로 Motivation 파트에서 언급한 두 가지 발견을 검증하고, 다른 모듈의 중요성을 결정하기 위해 ablation study도 수행하였는데, Table 3의 4th 행은 SeHGNN에 네 가지 변형을 가한 각각의 경우에 대한 결과를 나타낸다. Variant#1은 neighbor aggregation 단계에서 HAN과 같이 각 metapath에 대해 GAT를 사용한 경우이다. Variant#2는 각 레이어가 독립적인 neighbor aggregation 및 semantic fusion 단계를 갖는 두 개의 레이어 구조를 사용하며, 각 레이어의 metapath의 최대 hop이 SeHGNN의 절반으로 놓고 SeHGNN과 Variant#2가 동일한 수용 영역 크기를 갖도록 한 경우이다. SeHGNN과 Variant#1과 Variant#2 사이의 성능 차이를 통해 Motivation에서 언급한 두 가지 발견에 대한 내용이 SeHGNN에도 적용된다는 것을 확인할 수 있다. Variant#3는 추가 입력으로 레이블을 포함하지 않는 경우이고, Variant#4는 HAN과 같이 weighted sum fusion으로 트랜스포머 기반의 semantic fusion을 대체한 경우이다. 특히, SeHGNN에 뒤쳐지지만, Variant#3은 Freebase 데이터셋의 micro-f1을 제외한 대부분의 baseline들보다 우수한 성능을 보여준다. 이러한 결과는 레이블 전파와 트랜스포머 기반 fusion의 활용이 모델 성능을 향상시킨다는 것을 입증하는 증거로 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/TmM0Ldh/table4.png&quot; alt=&quot;table4&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;li&gt;Results on  Ogbn-mag&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;본 논문에서는 다섯 번째 데이터셋으로 ogbn-mag을 사용하여 성능을 비교하였다. ogbn-mag 데이터셋은 일부 유형의 노드의 초기 feature가 부족하고, target type 노드가 연도에 따라 분할되어 training 노드와 test 노드가 다른 데이터 분포를 갖게 된다는 문제점을 갖고 있다. 기존의 다른 방법들은 일반적으로 이러한 어려움을 다루기 위해 ComplEx (Trouillon et al. 2016)와 같은 비지도 표현 학습 알고리즘을 사용하여 추가 임베딩을 생성하고, multi-stage learning을 활용하여 마지막 학습 단계에서 확신 있는 예측을 가진 test 노드를 선택하고 이러한 노드를 training set에 추가하여 새로운 단계에서 모델을 다시 훈련한다고 한다(Li, Han, and Wu 2018; Sun, Lin, and Zhu 2020; Yang et al. 2021). 본 논문의 저자는 이러한 방법들을 사용하거나 사용하지 않는 결과를 이용하여 비교하였다. 추가 임베딩이 없는 방법의 경우 무작위로 초기화된 초기 feature 벡터를 사용했다고 한다.&lt;/p&gt;

&lt;p&gt;Table 4는 대규모 데이터셋 ogbn-mag에 대해 baseline과 비교한 결과를 보여준다. 결과는 SeHGNN이 동일한 조건에서 다른 방법을 능가한다. 무작위로 초기화된 특징을 가진 SeHGNN이 추가 표현 학습 알고리즘에서 잘 훈련된 임베딩을 가진 다른 방법보다 우수한 성능을 보이는데, 이는 SeHGNN이 그래프 구조로부터 더 많은 정보를 학습한다는 것을 보여주는 증거이다.&lt;/p&gt;

&lt;li&gt;Time Analysis&lt;/li&gt;
&lt;p&gt;&lt;br /&gt;
본 논문에서는 또한 실행 시간에 대한 비교 분석도 수행하였다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/f8wwp0k/table5.png&quot; alt=&quot;table5&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;먼저, Table 5에서 보여지듯이 SeHGNN의 시간 복잡도를 HAN과 HGB와 비교하는 이론적 분석을 수행한다. SeHGNN과 HAN은 k개의 metapath와 single-layer 구조를 가정하고, HGB는 $l$개의 레이어 구조를 갖는 것으로 가정하여 분석한다. metapath의 최대 hop도 $l$로 설정하여 receptive field의 크기를 동일하게 유지한다. 대상 유형 노드의 수는 n이며 입력 및 hidden 벡터의 차원은 $d$이다. HAN에서 metapath neighbor 그래프의 평균 neighbor 수는 $e_1$이고, HGB에서 multi-layer aggregation 중에 관련된 neighbor 수는 $e_2$ 이다. $e_1$ 과 $e_2$는 metapath의 길이와 레이어 수인 $l$과 함께 지수적으로 증가한다. 위 다섯 개의 데이터셋에서 본 논문은 최대 metapath 수십 개를 사용하지만, 레이어 $l$ ≥ 3에 대해 각 노드는 평균 수천 개의 neighbor들로부터 정보를 aggregation한다. 일반적으로 $e_1$ ≫ $k^2$, $e_2$ ≫ $k^2$이다. 따라서 SeHGNN의 이론적 복잡성은 HAN과 HGB보다 훨씬 낮은 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgbb.com/&quot;&gt;&lt;img src=&quot;https://i.ibb.co/9GcRN9c/figure3.png&quot; alt=&quot;figure3&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://imgbb.com/&quot;&gt;image hosting without registration&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이론적 분석을 검증하기 위해 SeHGNN의 시간을 이전에 나온 HGNN들과 비교하는 실험을 수행하였고, Figure 3은 각 모델의 평균 시간 단위로 학습 시간에 따른 micro-f1 점수 달성 정도를 보여준다. 이는 SeHGNN이 학습 속도와 모델 성능 모두에서 우수함을 나타낸다.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;본 논문은 heterogeneouos 그래프 representation learning을 위한 SeHGNN이라는 새로운 방법을 제안한다. 이 방법은 attention 사용 여부와 네트워크 구조에 따른 효과성에 대한 두 가지 주요 발견을 기반으로 제안되었다. 본 논문에서는 light mean aggregation을 사용하여 neighbor aggregation을 사전에 계산함으로써 구조 정보를 효과적으로 포착하면서, neighbor attention이 과도하게 사용되는 것을 방지하고 반복적인 neighbor aggregation도 피할 수 있도록 하였다. 이와 함께 receptive field를 확장하고 semantic 정보를 더 잘 활용하기 위해 긴 metapath를 사용하는 single-layer 구조와, 트랜스포머 기반의 semantic fusion 모듈을 사용하여 모델의 효과성을 향상시켰다.&lt;/p&gt;

</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-Simple_and_Efficient_Heterogeneous_Graph_Neural_Network.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-Simple_and_Efficient_Heterogeneous_Graph_Neural_Network.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[RecSys 2023] STRec: Sparse Transformer for Sequential Recommendations</title>
            <description>&lt;h1 id=&quot;title&quot;&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;STRec: Sparse Transformer  for  Sequential Recommendations&lt;/p&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Transformer 구조가 급속도로 발전함에 따라 researcher들은 SRS(sequential recommender systems)에서 Transformer 구조를 적용하고 이전 SRS model들에 비해 SRS task에 대하여 발전된 성능을 나타내는 model을 제시하고 있다. &lt;br /&gt;
이 논문에서 user-item interaction history는 다음과 같이 정의된다. &lt;br /&gt;
 $\begin{align}S = {\left{\left(v_ 1, t_ 1 \right), \ldots, \left(v_ n, t_ n \right), \ldots, \left(v_ N, t_ N \right)  \right}} \end{align}$&lt;/p&gt;

&lt;p&gt;여기서 $v_ n \in V$는 timestamp $t_ n$에서 sequence $S$의 $n$번째 interacted item이고 $N$은 sequence의 최대 길이이다. 단순화를 위해 user 및 실제 길이에 대한 표기는 생략되었고 interacted timestamp $t_ n$을 고려한다. &lt;br /&gt;
SRS는 제공된 길이가 $N$인 interaction sequence ${\left{\left(v_ 1, t_ 1 \right), \ldots, \left(v_ N, t_ N \right)  \right}}$를 활용해서 다음 interacted item $v_ {N+1}$을 예측해야 하는 문제이다. &lt;br /&gt;
그러나 대부분의 기존 transformer 기반 SRS model들은 모든 item-item pair 간의 attention score를 계산하는 vanilla attention mechanism을 사용하고 있다.
이 경우 중복되는 item interaction으로 인해 model 성능이 저하되고 많은 계산 시간과 메모리를 필요로 할 수 있다는 문제점이 발생한다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;vanilla self-attention을 transformer 기반 SRS model에 활용하면 모든 item interaction을 scan할 수 있지만 모든 interaction을 scan할 경우 막대한 계산 시간과 메모리 비용이 발생하여 SRS 모델의 inference 효율성이 저하된다.
게다가 최적이 아닌 item interaction을 고려할 수 있어 추천 성능이 저하될 수 있다.&lt;br /&gt;
따라서 inference 효율성과 추천 성능을 높이기 위해 필요한 item interaction을 구별할 수 있는 효율적인 transformer 구조를 설계하는 것이 필요하다. &lt;br /&gt;
효율적인 Transformer 구조를 설계하기 위해 다음과 같은 노력이 이루어졌다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2004.05150&quot;&gt;Longformer&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2007.14062&quot;&gt;Big Bird&lt;/a&gt; : sparce attention 전략을 사용하여 필수적인 token pair에 대해서만 attention score를 계산&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.04768&quot;&gt;Linformer&lt;/a&gt; : low-rank approximation 방법을 사용하여 attention score 계산&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2106.13008&quot;&gt;Autoformer&lt;/a&gt; : 시계열 예측을 위해 sequence를 분해&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2202.10447&quot;&gt;FLASH&lt;/a&gt; : vanilla attention을 gated attention unit으로 대체&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2001.04451&quot;&gt;Reformer&lt;/a&gt; : locality-sensitive hashing(lsh) module 적용&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;하지만 위의 방법들은 SR(Sequential recommendation)을 위한 목적으로 설계되지 않았기 때문에(NLP나 시계열 예측을 위한 목적으로 설계됨) SR task에 직접 적용하면 추천 성능이 저하될 수 있다. &lt;br /&gt;
새로운 transformer 구조 설계가 필요한 이유를 아래 Figure 1을 통해 설명하고 있다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/da1298ed-6331-42bf-89b6-527befee79d0/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 1의 Attention weight matrix를 통해 SRS task에서의 transformer 기반 model이 높은 sparsity를 보이는 것을 알 수 있다.
논문에서는 해당 sparse attention에서 보이는 low-rank phenomenon을 두 가지 측면에서 설명하고 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;극히 일부의 interaction이 output에 차이를 만든다. (heatmap column level)&lt;/li&gt;
  &lt;li&gt;attention weight vector가 유사하고 이것이 low-rank phenomenon을 가중시킨다. (heatmap row level)&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/c910d64c-6c51-4c47-bbfc-0a11b206a0db/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;low-rank phenomenon은 attention weight matrix의 행에 대한 SVD 분해를 통해 명확히 드러난다. Figure 2를 통해 eigenvalue의 분포를 확인할 수 있다. &lt;br /&gt;
x축은 eigenvalue, y축은 value의 비율이다.
대부분의 eigenvalue는 상대적으로 작다. 이를 통해 low-rank matrix를 사용하여 original attention weight matrix를 근사화 할 수 있음을 알 수 있다. &lt;br /&gt;
이러한 현상을 바탕으로 이 논문에서는 효율성을 위해 일부 interaction 쌍만 transformer layer에서 계산하는 sparse transformer 모델(&lt;strong&gt;STRec&lt;/strong&gt;)을 제안하였다.&lt;br /&gt;
&lt;strong&gt;S&lt;/strong&gt;parse &lt;strong&gt;T&lt;/strong&gt;ransformer model for sequenctial &lt;strong&gt;Rec&lt;/strong&gt;ommendation tasks(&lt;strong&gt;STRec&lt;/strong&gt;)는 cross-attention와 학습 가능한 parameter를 활용한 sampling 전략을 기반으로 한다.&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;STRec&lt;/strong&gt;은 transformer 기반 backbone model을 기반으로 구성되었다. Figure 3를 통해 &lt;strong&gt;STRec&lt;/strong&gt; 모델 구조를 확인할 수 있다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/18dfd67a-8704-4238-b825-762bff970ac5/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Model은 Embedding layer, 여러 Transformer layer, Prediction layer로 구성되어 있다. 
Backbone model과 비교했을 때 TransformerLayer에서 차이가 있는데, 논문에서는 cross-attention과 학습 가능한 parameter를 활용한 효율적인 sampling 전략을 기반으로 하는 sparse transformer를 활용한다. &lt;br /&gt;
Model의 각 layer를 설명하되 이 논문의 핵심인 Cross Attention Transformer Layer와 Sampling 전략 부분을 좀 더 자세히 설명할 예정이다.&lt;/p&gt;

&lt;h3 id=&quot;31-embedding-layer&quot;&gt;3.1 Embedding Layer&lt;/h3&gt;
&lt;p&gt;ID embedding과 positional embedding을 통합한 input item의 초기 표현을 식으로 나타내면 다음과 같다.&lt;/p&gt;

&lt;p&gt;$ \begin{align}h_ {n}^{0} = e_ n + p_ n \end{align}$&lt;/p&gt;

&lt;p&gt;여기서 $e_ n$은 item $v_ n$에 대한 ID embedding이고, $p_ n$은 sequence의 item index $n$에 대한 positional embedding이다. $h_ {n}^{0}$의 위 첨자 index 0는 embedding layer임을 나타낸다.&lt;/p&gt;

&lt;h3 id=&quot;32-sparse-transformer-in-strec&quot;&gt;3.2 Sparse Transformer in STRec&lt;/h3&gt;

&lt;h4 id=&quot;321-cross-attention-transformer-layer&quot;&gt;3.2.1 Cross Attention Transformer Layer&lt;/h4&gt;
&lt;p&gt;Attention layer의 계산 비용을 줄이기 위해 vanilla self-attention을 cross-attention으로 대체하였다. cross-attention은 input sequence를 key, value로 샘플링된 item sequence를 query로 사용한다.
sampling된 query matrix는 기존 query matrix에 비해 크게 축소되기 때문에 계산이 더 효율적이다.
$H^ {l-1}$에 대해서 cross-attention은 다음과 같은 식으로 나타낼 수 있다. &lt;br /&gt;
$ \begin{align} \tilde{H}^ {l-1} = Add\&amp;amp;Norm\left(Attention\left(H_{I}^ {l-1}, H^ {l-1}, H^ {l-1}\right) \right)  \end{align}$
$\tilde{H}^ {l-1}$은 사전 정의된 $k_l$의 길이를 갖으며 sampling index $I_l$에 의해 $H_ {l-1}$에 있는 item representation이 sampling된 부분집합이다.
$\tilde{H}^ {l-1}$은 $H_{I}^ {l-1}$과 똑같은 shape를 갖는다.&lt;br /&gt;
FFN layer는 짧아진 $\tilde{H}^ {l-1}$를 input으로 하여 output hidden state를 만들어 낸다. &lt;br /&gt;
$ \begin{align} {H}^ {l} = Add\&amp;amp;Norm\left(FFN\left(\tilde{H}^ {l-1} \right)\right) \end{align}$
output hidden state $H^ {l}$의 길이는 여전히 $k_l$이며, $H_{I}^ {l-1}$, $\tilde{H}^ {l-1}$과 똑같은 shape를 갖는다.&lt;br /&gt;
vanila self-attention transformer layer와 비교했을 때 cross-attention layer는 attention과 feed-forward network 모두에서 sampled item에 대해서만 계산한다.&lt;br /&gt;
시간 복잡도와 공간 복잡도 모두 $O(n^ 2)$에서 $O(nk_ l)$로 감소한다.&lt;/p&gt;

&lt;h4 id=&quot;322-sampling-strategy&quot;&gt;3.2.2 Sampling strategy&lt;/h4&gt;
&lt;p&gt;Figure 1을 통해 후방 item이 SR task에서 중요할 가능성이 높음을 알 수 있다.
따라서 논문에서는 마지막 item과의 time interval을 바탕으로 학습 가능한 parameter를 사용해서 sampling 전략을 수행한다. time interval은 $T = \left{\tilde{t}_ {i}\right}_ {1 \le i \le N}$로 표현한다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} \tilde{t}_ {i} = t_ i - t_ N  \end{align}$
$t_ i, 1 \le i \le N$은 interaction $v_ i$에 대해 기록된 timestamp이다.&lt;br /&gt;
첫번째 layer의 경우 MLP(Multi-layer Perceptron)을 활용해서 time interval $T$를 sampling density로 mapping한다. 무작위 샘플링을 위해 uniform distribution을 갖는 random matrix $R$ 을 추가한다. sampling index $I$는 다음과 같이 생성된다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} I_ {1} = Top_k\left(MLP(T) + R, k_ 1\right)  \end{align}$
$ \begin{align} r_ {i} \sim Uniform\left(0, 1\right) \nonumber \end{align}$&lt;/p&gt;

&lt;p&gt;$Top_k\left(\cdot \right)$는 내림차순으로 정렬된 index들의 set을 생성한다.
$k_ 1$은 hyperparameter로서 첫번째 layer의 pre-define된 sample size이다.&lt;/p&gt;

&lt;p&gt;이후 layer들에 대해서 sampling index를 layer별로 생성하는데는 많은 시간이 걸린다. 따라서 $MLP\left(T \right) + R$ 부분은 모든 layer에 대해 fine-tuning 및 inference 과정에서 동일하게 유지된다. &lt;br /&gt;
논문에서는 정렬된 index $I_ 1$를 입력하고 첫 $k_ l$개의 index를 $I_ l$로 사용한다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} I_ {l} = I_ 1\left[1: k_ l\right]  \end{align}$
$ \begin{align} {H}_ {I}^ {l-1} = \left[{h}_ {I_ l \left[1\right]}^ {l-1}, \ldots, {h}_ {I_ l \left[k_ l\right]}^ {l-1} \right]
 ∀ 2 \le l \le L  \end{align}$
$I$는 미분 가능한 방식으로 근사된(하지만 미분 가능한 방식으로 처리하기 어려운) hard decision을 생성하는 random process를 요구하는 $Top_k$ 연산 으로 인해 미분 불가능하다. &lt;br /&gt;
이러한 문제를 해결하기 위해 pre-train 과정에서 &lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;Gumbel-Softmax&lt;/a&gt;를 적용하여 sampling 과정을 attention mask $M$으로 대체한다.
여기서 $m_ {ij} \approx 0$은 $i$번째 query와 $j$번째 key 간의 attention weight가 계산되지 않았음을 의미하고 그 반대의 경우(계산된 경우)는 $m_ {ij} \approx 1$이다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} S_ {l} = Sigmoid\left(MLP\left(T\right) + R + \alpha _ l\right)  ∀ 1 \le l \le L  \end{align}$
$ \begin{align} S_ {0} = \left[ 1, 1, \ldots, 1\right] \end{align}$
$ \begin{align} M_ {l} = S_ {l-1} \otimes S_ {l}  ∀ 1 \le l \le L  \end{align}$
$ \begin{align} r_ {i} \sim Uniform\left(0, 1\right) \nonumber \end{align}$&lt;/p&gt;

&lt;p&gt;$MLP\left(\cdot\right)$는 normalization이 포함된 multi-layer perceptron이다. &lt;br /&gt;
$\alpha$는 sampling될 interaction 수(mask matrix $S_l$의 1 개수)를 제어하는데 사용된다.
$\alpha_ {l}$이 커지면 해당 layer에서 더 많은 sample이 생성된다. &lt;br /&gt;
layer $S_ {l}$과 그 이전 layer $S_ {l-1}$을 활용하여 attention mask matrix는 outer product $\otimes$로 계산된다. 
이때 query-key pair를 뽑으면 query는 $S_ {l}$에서 나오고 key는 $S_ {l-1}$에서 나온다&lt;/p&gt;

&lt;p&gt;attention mask $M$이 있는 미분 가능한 attention layer는 다음과 같이 표현된다.&lt;/p&gt;

&lt;p&gt;$ \begin{align} \tilde{H}^ {l-1} = Add\&amp;amp;Norm\left(\sigma \left(H_{I}^ {l-1}H^ {l-1^ {T}} + \left(M - 1\right) * \infty \right)H^ {l-1} \right)  \end{align}$&lt;/p&gt;

&lt;h3 id=&quot;33-prediction-layer&quot;&gt;3.3 Prediction layer&lt;/h3&gt;
&lt;p&gt;논문에서는 마지막 item embedding에 대한 최종 output prediction score를 계산하기 위해 &lt;a href=&quot;https://ieeexplore.ieee.org/document/5197422&quot;&gt;Matrix Factorization(MF)&lt;/a&gt;를 수행한다.&lt;/p&gt;

&lt;p&gt;$\begin{align} \hat{y} = \sigma\left(h_ {N}^ {L}E^ {T} \right)  \end{align}$&lt;/p&gt;

&lt;p&gt;위 식에 나온 기호 정리를 하면 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$h_ {N}^ {L} \in R^ d$: 마지막 transformer layer에서 나온 마지막 item representation&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$E \in R^ {&lt;/td&gt;
          &lt;td&gt;V&lt;/td&gt;
          &lt;td&gt;\times d}$: candidate item $V$에 대한 embedding matrix&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;$\sigma\left(\cdot\right)$: softmax&lt;/li&gt;
  &lt;li&gt;$d$: embedding 차원&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$\hat{y} \in R^ {&lt;/td&gt;
          &lt;td&gt;V&lt;/td&gt;
          &lt;td&gt;}$: prediction 결과로서 item set $V$에 대한 다음 item의 probability distribution&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;34-optimization&quot;&gt;3.4 Optimization&lt;/h3&gt;
&lt;p&gt;논문에서는 &lt;strong&gt;STRec&lt;/strong&gt;을 pre-train과 fine-tuning의 두 단계로 나누어서 train한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;pre-train 단계에서는 식 $(9)-(12)$를 활용해 sampling을 구현하고 모든 parameter를 최적화한다.&lt;/li&gt;
  &lt;li&gt;fine-tuning 단계에서는 MLP의 fix된 근사 hash 함수를 사용하고 다른 parameter를 fine-tuning하면서 추가로 최적화를 진행하는 대신 식 $(6)$을 활용하여 sampling index $I$를 직접 생성한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;최적화 할 parameter에는 다음과 같은 2가지 종류가 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$W$: backbone model parameter&lt;/li&gt;
  &lt;li&gt;$A$: 식$(9) -(12)$에 포함된 sampling 전략 parameter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;최적화 문제를 식으로 나타내면 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pre-training stage
  $\begin{align} \min _{\boldsymbol{W}, \mathcal{A}} \mathcal{L}(\hat{\boldsymbol{y}}, \boldsymbol{y}) \nonumber \end{align}$&lt;/li&gt;
  &lt;li&gt;Fine-tuning Stage
  $\begin{align} \min _{\boldsymbol{W}} \mathcal{L}(\hat{\boldsymbol{y}}, \boldsymbol{y}) \nonumber \end{align}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;candidate item은 모든 item이고 &lt;br /&gt;
$\hat{y}$는 다음 방문하는 item에 대한 예측 확률, $y$는 ground truth인 다음 item을 의미한다. &lt;br /&gt;
item embedding과 마지막 transformer layer의 output vector 사이의 내적을 수행하여 다음 방문 item에 대한 확률을 얻는다.&lt;/p&gt;

&lt;p&gt;$\mathcal{L}(\hat{\boldsymbol{y}}, \boldsymbol{y})$ loss function은 SRS 작업에서 활용되는 binary Cross-Entropy loss이다.
 $\begin{align} \mathcal{L}(\hat{\boldsymbol{y}}, \boldsymbol{y})  = \boldsymbol{y}log(\hat{\boldsymbol{y}}) + (1 - \boldsymbol{y})log(1 - \hat{\boldsymbol{y}})  \end{align}$&lt;/p&gt;

&lt;p&gt;상세 최적화 과정은 아래 Algorithm 1에 설명되어 있다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/b18318d2-596a-48c1-ae56-ef5195ee8095/image.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(line 3) flag c 초기화, c를 활용해 train epoch 계산&lt;/li&gt;
  &lt;li&gt;(line 4-9) pretrain 단계에서 모든 parameter를 동시에 train&lt;/li&gt;
  &lt;li&gt;(line 10-14) parameter $A$를 고정하고 $W$를 train 단계에서 수렴하도록 계속 train&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;35-model-inference&quot;&gt;3.5 Model Inference&lt;/h3&gt;
&lt;p&gt;inference 과정을 순서대로 작성하였다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;식 $(2)$ 활용 각 interaction의 초기 representation을 만들고 $H^ 0$과 연결&lt;/li&gt;
  &lt;li&gt;식 $(5)$ 활용 visiting time interval $T$ 계산&lt;/li&gt;
  &lt;li&gt;식 $(6)$ 활용 첫 layer에 대한 index $I_ 1$ 생성&lt;/li&gt;
  &lt;li&gt;$H^ 0$가 $L$개의 transformer layer에 의해 식 $(3, 4)$와 같이 변환됨&lt;/li&gt;
  &lt;li&gt;식 $(7)$ 활용 각 layer $l$의 index $I_ l$이 포함된 sampling query 직접 생성&lt;/li&gt;
  &lt;li&gt;모든 candidate item과 sparse transformer의 output을 내적&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모든 candidate item similarity 점수 $\hat{y}$을 통해 next item에 대한 prediction 결과를 획득 가능하다.&lt;/p&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;experiment-setup&quot;&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Dataset
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://grouplens.org/datasets/movielens/1m/&quot;&gt;ML-20M&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://snap.stanford.edu/data/loc-gowalla.html&quot;&gt;Gowalla&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://jmcauley.ucsd.edu/data/amazon/&quot;&gt;Amazon-Electronics&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;baseline
    &lt;ul&gt;
      &lt;li&gt;classical SRS models
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06939&quot;&gt;GRU4Rec&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.04725&quot;&gt;NARM&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1808.09781&quot;&gt;SASRec&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1904.06690&quot;&gt;Bert4Rec&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://www.ijcai.org/proceedings/2019/0600.pdf&quot;&gt;FDSA&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3336191.3371786&quot;&gt;Ti-SASRec&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;transformer architecture
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.04768&quot;&gt;Linformer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2007.14062&quot;&gt;Big Bird&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2012.07436&quot;&gt;Informer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2001.04451&quot;&gt;Reformer&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2202.10447&quot;&gt;FLASH&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2106.13008&quot;&gt;Autoformer&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Evaluation Metric
    &lt;ul&gt;
      &lt;li&gt;mean reciprocal rank(MRR)&lt;/li&gt;
      &lt;li&gt;normalized discounted cumulative gain(NDCG)&lt;/li&gt;
      &lt;li&gt;hit ratio(HR)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;result&quot;&gt;&lt;strong&gt;Result&lt;/strong&gt;&lt;/h3&gt;
&lt;h3 id=&quot;rq1-how--the--proposed--strec--performs--in--accuracy--while--it-can-reduce-the-time-and-spatial--complexity&quot;&gt;RQ1: How  the  proposed  STRec  performs  in  accuracy  while  it can reduce the time and spatial  complexity?&lt;/h3&gt;

&lt;p&gt;RQ1에 대한 답변을 위해 accuracy 성능을 계산하여 비교한 Table 2를 제시하였다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/66fdeb97-55de-4231-a59d-e4bdafc217c5/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;분석 결과는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;모든 dataset에서 Transformer 기반 방법이 RNN 기반 방법보다 성능이 좋다.(긴 sequence를 더 잘 모델링하기 때문)&lt;/li&gt;
  &lt;li&gt;FDSA는 side information이 부족하기 때문에 성능이 좋지 않다.(공정한 비교를 위해 side information 제외하고 실험)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;STRec&lt;/strong&gt;은  65%의 sparsity를 가진 ML-20M 및 Gowalla dataset에서 다른 baseline보다 성능이 좋다.&lt;/li&gt;
  &lt;li&gt;TiSASRec과 &lt;strong&gt;STRec&lt;/strong&gt; 모두 SRS에 시간 information을 사용하였다. TiSASRec은 time interval에 따라 item embedding을 강화하기 때문에 성능이 좋지 않으나 &lt;strong&gt;STRec&lt;/strong&gt;은 시간 information을 사용하여 item의 potentioal importance를 학습한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rq2--compared--with--the--efficient--transformer--methods--how-strec-performs--in-the-aspect-of-efficiency&quot;&gt;RQ2:  Compared  with  the  efficient  transformer  methods,  how STRec performs  in the aspect of efficiency?&lt;/h3&gt;

&lt;p&gt;RQ2에 대한 답변을 위해 efficiency performance를 측정하여 비교한 Table 3를 제시하였다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/7b669acf-9769-40b8-be0b-4c766ddb5483/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;분석 결과는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Linformer와 Informer는 backbone model보다 효율적이고, Informer는 down-sampling setting을 적용했기 때문에 가장 좋은 memory 효율을 보인다.
   그러나 sampling에 많은 operation이 필요하기 때문에 &lt;strong&gt;STRec&lt;/strong&gt;에 비해 inference time이 훨씬 길다. 게다가 성능도 &lt;strong&gt;STRec&lt;/strong&gt;에 비해 좋지 않다.&lt;/li&gt;
  &lt;li&gt;Big bird의 결과가 N/A인 이유는 sparse pattern에 대한 높은 complexity로 인해 효율성이 떨어져 구현할 수 없었기 때문이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;STRec&lt;/strong&gt;은 시간 정보를 기반으로 중요한 query를 추출할 수 있기 때문에 accuracy와 time-space 효율성 모두에서 다른 transformer baseline들을 능가한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rq3-how-does-the-sparsity-and-pre-training-process-of-strec-affect-the--accuracy--performance&quot;&gt;RQ3: How does the sparsity and pre-training process of STRec affect the  accuracy  performance?&lt;/h3&gt;

&lt;h4 id=&quot;sparcity&quot;&gt;Sparcity&lt;/h4&gt;

&lt;p&gt;Figure 4는 sparsity 측면에서의 parameter study 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/16cc41d6-273b-4ed3-9b81-06009932aa8a/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 5는 sparsity 측면에서의 efficieny performance 비교 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/cc72f6ee-dbc8-478a-9cc8-e02ae18c8767/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;x축은 모든 layer애서의 sample size $k_ l$에 의해 계산된 sparsity를 의미한다.&lt;br /&gt;
e.g. sequence 길이가 50이고 $k_ l$이 5일 때 sparsity는 (50 - 5) / 50 = 90% &lt;br /&gt;
y축은 accuracy performance와 efficiency performance(backbone model과의 inference time과 memory cost의 persentage 비교)를 나타낸다.&lt;/p&gt;

&lt;p&gt;Figure 4와 5에 대한 분석 결과는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;optimal sparsity는 69%이다.&lt;/li&gt;
  &lt;li&gt;sparsity가 42%보다 낮을 때 sparsity와 model 성능은 비례한다. 그 이유는 중요하지 않은 period의 interaction에 대한 영향을 제거하여 transformer가 sequential user preference를 잘 학습할 수 있도록 중복되는 interaction 계산을 생략하기 때문이다.&lt;/li&gt;
  &lt;li&gt;너무 높은 sparsity는 성능을 감소시킨다. 77%보다 sparsity가 커질 때 모델 성능은 점점 감소된다. 그 이유는 sparsity가 너무 심하면 많은 key information을 잃어버리고 prediction을 충분히 학습할 수 없기 때문이다.&lt;/li&gt;
  &lt;li&gt;(42%-77%)의 sparsity 범위에서 STRec은 SASRec(가장 성능이 좋은 baseline)의 성능을 능가한다. 그 이유는 sequence에서 representative interaction을 선택하는 성공적인 sampling 전략 덕분이다.(denoising과 비슷)&lt;/li&gt;
  &lt;li&gt;100%에 가까운 sparsity에서도 inference을 위한 backbone model의 cost으로 인해 I/O 및 embedding layer에도 약 15%의 시간이 소요된다. Memory cost은 주로 transformer layer에 의해 발생하므로 sparsity이 100%에 가까워지면 memory cost가 거의 0%가 될 수 있다.
    &lt;h4 id=&quot;training-pipeline-analysis&quot;&gt;Training Pipeline Analysis&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Figure 6는 pretrain epoch $C$를 변화시켜 가며 실험을 진행한 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/c0d0e1ed-e2ec-4536-85a3-bce4a0178c80/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;x축은 epoch $C$, y축은 performance(NDCG@10)를 의미하며 &lt;br /&gt;
푸른 선은 fine-tuning 단계를 skip하고 바로 pre-training 단계만을 거친 모델로 예측을 진행한 결과이다.&lt;/p&gt;

&lt;p&gt;Figure 6를 통해 다음과 같은 결과를 얻을 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$C$가 60일 때 성능이 가장 좋다. pre-training epoch이 그 이상으로 늘어나면 overfitting이 발생하여 성능이 감소한다.&lt;/li&gt;
  &lt;li&gt;$C$를 60에서 10으로 감소시키면 성능은 크게 감소한다. 이를 통해 pre-training 단계를 생략하면 underfitting 문제가 발생함을 알 수 있다.&lt;/li&gt;
  &lt;li&gt;fine-tuning 단계를 skip하면 최적의 performance를 얻을 수 없다.(blue line 참고)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rq4-what--is--the--influence--on--the--performance--of--the--core--com--ponents-in-strecablation-study&quot;&gt;RQ4: What  is  the  influence  on  the  performance  of  the  core  com- ponents in STRec?(Ablation Study)&lt;/h3&gt;

&lt;p&gt;Figure 7은 &lt;strong&gt;STRec&lt;/strong&gt;에 대한 Ablation Study 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/1a18be99-5cce-4eba-8355-ab3835f66651/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;STRec&lt;/strong&gt;에 대한 세 가지 변형으로 실험을 진행하였다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;STRec-1 : train과 inference 둘 다에서 식 (6)의 random matrix $R$ 제거(random sampling 안함)&lt;/li&gt;
  &lt;li&gt;STRec-2 : 식 (6)에서 index $I$를 random으로 만듦(첫번째 layer에서 item을 random으로 sampling하고 sort함)&lt;/li&gt;
  &lt;li&gt;STRec-3 : visiting time interval matrix $T$를 item 방문 순서를 나타내는 position index matrix로 대체&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;분석 결과는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;STRec-1은 random sampling의 부재로 성능이 감소하였다. 모든 layer에 대한 query는 sequence의 마지막 몇개의 item으로 제한되며, 이로 인해 user interaction sequence의 초기 정보를 무시하게 되기 때문이다.&lt;/li&gt;
  &lt;li&gt;STRec-2는 interaction을 query로 random으로 sampling하며 &lt;strong&gt;STRec&lt;/strong&gt;에 비해 성능 저하를 보이는 것을 통해 sampling된 query가 interaction sequence의 random query보다 훨씬 우수하다는 것을 보여 준다.&lt;/li&gt;
  &lt;li&gt;STRec-3의 성능 저하는 SRS에서의 방문 순서가 NLP의 단어 순서만큼이나 중요하다는 논문의 주장을 입증한다. 또한 이를 통해 SRS task에서 sampling 전략이 time interval 이외에 다른 정보를 기반으로 할 수 있음을 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rq5-why-the-proposed-method-can-elevate-performance-and-shrink-computation-simultaneously-case-study&quot;&gt;RQ5: Why the proposed method can elevate performance and shrink computation simultaneously? (Case Study)&lt;/h3&gt;

&lt;p&gt;Figure 8은 식 (9)에서의 MLP에 대한 sampling density function을 시각화한 결과이다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/cb1e4f53-b5ce-4d90-872c-3ba21cf0edcb/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Time interval의 절대값이 작을수록 MLP의 output이 높으며 이는 sequence 뒤쪽에 가까운 interaction이 더 중요하다는 것을 의미한다. &lt;br /&gt;
결과적으로 현재 시점에서 가까운 interaction이 sampling될 가능성이 높으며 초기 period에서는 소수의 item만 sampling된다.&lt;/p&gt;

&lt;p&gt;Figure 9는 user의 주요 관심사와 query로 sampling된 영화로만 구성된 첫 번째 layer의 attention weight matrix의 heatmap을 시각화하였다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://velog.velcdn.com/images/yst3147/post/7e7b47d0-ddc8-4cb7-a25f-cc1aafabd5b5/image.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Figure 9의 Case Study는 논문의 모델이 서로 다른 period에 대해 대표 item을 추출할 수 있음을 나타낸다. 이를 통해 시간에 따라 달라지는 사용자의 다양한 관심을 나타낼 수 있다. 이러한 sampling된 item은 모델이 다양한 time period에 더 중요한 item에 집중하도록 하는 데 도움이 될 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;이 논문에서는 학습 가능한 sparse transformer인 &lt;strong&gt;s&lt;/strong&gt;parce &lt;strong&gt;t&lt;/strong&gt;ransformer for the seqeuntial &lt;strong&gt;rec&lt;/strong&gt;ommendation(&lt;strong&gt;STRec&lt;/strong&gt;)을 설계하였다. &lt;br /&gt;
대표 item을 선택하기 위해 모든 sequence에 대해 먼저 sampling index를 
생성하는 새로운 sampling 전략을 제시하였다. 한편으로는 Cross-attention 기반 sparse transformer를 main framework로 설계하였다.&lt;br /&gt;
Sampling 전략을 최적화하고 정확도를 높이기 위해 &lt;strong&gt;STRec&lt;/strong&gt;을 pre-train과 fine-tuning의 두 단계로 train한다. &lt;br /&gt;
그 결과 &lt;strong&gt;STRec&lt;/strong&gt;은 inference time을 54% 단축하고 GPU memory 비용을 70%를 줄이면서도 다른 state-of-the-art 방법들보다 더 나은 accuracy 성능을 보인다. &lt;br /&gt;
추천시스템에서 발생하는 sparsity 특성을 활용하여 더 빠르고 memory를 적게 차지하면서도 성능이 좋은 transformer 기반 추천 모델을 제시하였다는 점이 인상깊었다.&lt;/p&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Github Implementation
    &lt;ul&gt;
      &lt;li&gt;https://github.com/ChengxiLi5/STRec&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reference
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://grouplens.org/datasets/movielens/1m/&quot;&gt;ML-20M&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://snap.stanford.edu/data/loc-gowalla.html&quot;&gt;Gowalla&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://jmcauley.ucsd.edu/data/amazon/&quot;&gt;Amazon-Electronics&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06939&quot;&gt;GRU4Rec&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.04725&quot;&gt;NARM&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1808.09781&quot;&gt;SASRec&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1904.06690&quot;&gt;Bert4Rec&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.ijcai.org/proceedings/2019/0600.pdf&quot;&gt;FDSA&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3336191.3371786&quot;&gt;Ti-SASRec&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2004.05150&quot;&gt;Longformer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.04768&quot;&gt;Linformer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2007.14062&quot;&gt;Big Bird&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2012.07436&quot;&gt;Informer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2001.04451&quot;&gt;Reformer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2202.10447&quot;&gt;FLASH&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2106.13008&quot;&gt;Autoformer&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;Gumbel-Softmax&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/document/5197422&quot;&gt;Matrix Factorization(MF)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-STRec_Sparse_Transformer_for_Sequential_Recommendations.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-STRec_Sparse_Transformer_for_Sequential_Recommendations.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[NIPS 2021] Robustness of Graph Neural Networks at Scale</title>
            <description>&lt;h1 id=&quot;robustness-of-gnn-at-scale&quot;&gt;Robustness of GNN at Scale&lt;/h1&gt;

&lt;h1 id=&quot;0-background&quot;&gt;0. Background&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Adversarial Attack on GNN?&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Adversarial Pertubation을 적용해 기존 분류기 또는 GNN 모델의 성능을 낮추는 것을 말함.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;이는 현실에 존재할 수 있는 이미지에 대해서는 정상적으로 동작하도록 설계되었지만 사람이 일부 변화를 취한 Adversarial Examples(Perturbed된 결과물들)에 대해서는 취약할 수 있음.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Testing Phase Attack : 분류 모델에 대해서 간섭을 주진 않지만 모델이 정확하게 동작하지 않도록 오동작을 유발하는 공격. 공격을 수행할 시 사용 가능한 지식의 양에 따라 공격을 분류&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;White Box Attacks : 분류에 사용되는 model에 대한 모든 지식을 가지고 있는 공격&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Black Box Attacks : model에 대한 정보 모르는 공격자가 행하는 공격. 조작된 input과 이것이 주는 output 관찰함으로써 이용될 수 있음.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Graph Neural Networks가 Adversarial Perturbations에 Robust하지 않다는 점은 발견이 되나, 이를 실험하고 해결하고자 한 연구들은 거의 없다. 예를 들어 PubMed라는 GNN Dataset의 경우, 인접 행렬을 기반으로 한 공격에 있어서 20GB의 메모리가 필요하며 이러한 경우 공격을 실행하기 어렵다. 이는 GNN의 Robustness를 확인해보고자 하는 연구가 진전되는 것을 어렵게 한다.&lt;/p&gt;

&lt;h1 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;해당 논문은 GNN의 Adversarial robustness에 대한 기존 연구의 한계점들을 다음과 같이 명시했다.: (1) 기존의 Loss는 Global Attack에 적합하지 않다는 점과 (2) GNN Attack에 소요되는 비용이 $O(n^2)$이상으로 매우 큰 점 그리고 (3) 기존의 Robust GNN은 scalable하지 않다는 점이다.&lt;/p&gt;

&lt;p&gt;따라서, 위의 한계점들을 (1) &lt;strong&gt;Surrogate loss&lt;/strong&gt;를 제시함으로써, (2) R-BCD를 기반으로 하여 &lt;strong&gt;시간복잡도를 $O(\Delta)$로 줄이는 방법을 제시함&lt;/strong&gt;으로써, 마지막으로 (3) &lt;strong&gt;Soft Median으로 효과적으로 GNN을 방어하는 방법을 관찰함&lt;/strong&gt;으로써 해결하고자 했다.&lt;/p&gt;

&lt;h1 id=&quot;3-method-and-experiment&quot;&gt;&lt;strong&gt;3. Method and Experiment&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;31-surrogate-losses&quot;&gt;3.1 Surrogate Losses&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Why previous loss invalid?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;많은 GNN의 Global Attacks들은 평균 Cross Entropy Loss를 증가시킨다. 그러나 node가 많은 Large Graph들의 경우 위의 loss는 효율적이지 않다.&lt;/p&gt;

&lt;h3 id=&quot;surrogate-loss&quot;&gt;Surrogate loss&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;(정의 1)&lt;/strong&gt; Global Attack에 대한 Surrogate Loss $L^\prime$은&lt;/p&gt;

&lt;p&gt;(1) 옳게 분류된 pertubing node들에 대해서만 incentive를 주고,&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$\frac{\partial L^\prime}{\partial z_c^*}&lt;/td&gt;
      &lt;td&gt;\psi_0 = 0$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;(2) Decision Boundary 근처에 있는 node들을 선호하는 방식으로 Loss를 구성한다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$\frac{\partial L^\prime}{\partial z_c^*}&lt;/td&gt;
      &lt;td&gt;\psi_1 &amp;lt; \frac{\partial L^\prime}{\partial z_c^*}&lt;/td&gt;
      &lt;td&gt;\psi_2 \; for \, any \,0&amp;lt;\psi_1&amp;lt;\psi_2$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;위 정의에서 도출된 명제에 따르면, Cross Entropy Loss는 (1)을 위반하여 Global Optimum을 가질 수 없기에 Surrogate loss가 될 수 없다. 또한, Carlini-Wagner(CW) Loss는 Decision boundary에 있는 node들을 고려하지 못하기에 (2)을 위반한다.&lt;/p&gt;

&lt;p&gt;논문은 Surrogate loss에 맞는 loss로써 Masked Cross Entropy(MCE)를 제안한다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$MCE = \frac{1}{&lt;/td&gt;
      &lt;td&gt;V^+&lt;/td&gt;
      &lt;td&gt;}  \sum_{i \in V^+}  -\log(p^{(i)}_{c^*})$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;MCE는 Projected Gradient Descent attack(PR-BCD)에 대해서는 Cross Entropy와 큰 차이를 보이지 않지만, Greedy Gradient-Based attack에 있어서는 강점을 보이는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/gJFYDfd/2023-10-15-17-52-14.png&quot; alt=&quot;2023-10-15-17-52-14.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(정의 2)&lt;/strong&gt; 정의 1을 더 확장하여 Surrogate Loss $L^\prime$는&lt;/p&gt;

&lt;p&gt;(1) 확실하게 잘못 분류된 노드($\psi$가 -1에 가까운 노드)들에 대해서 확실하게 구분하고,&lt;/p&gt;

&lt;p&gt;$\lim_{\psi  \to  -1^+} L^\prime &amp;lt; \infty$&lt;/p&gt;

&lt;p&gt;(2) 정의 1과 마찬가지로 Decision Boundary 근처에 있는 point들을 선호하는 방식으로 Loss를 구성한다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$\frac{\partial L^\prime}{\partial z_c^*}&lt;/td&gt;
      &lt;td&gt;\psi_1 &amp;lt; \frac{\partial L^\prime}{\partial z_c^*}&lt;/td&gt;
      &lt;td&gt;\psi_2&amp;lt;0 \; \ for \, any \; 0&amp;lt;\psi_1&amp;lt;\psi_2&amp;lt;1 \; \ or \; -1&amp;lt;\psi_2&amp;lt;\psi_1&amp;lt;0$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;32-scalable-attacks&quot;&gt;3.2 Scalable Attacks&lt;/h2&gt;

&lt;p&gt;Gradient-based attacks들은 인접행렬 $A$에 대해서 모두 최적화하기에 $\Theta(n^2)$의 시간 복잡도를 보여 Large Graph에 대한 robustness는 대개 측정하기 어려웠다.&lt;/p&gt;

&lt;p&gt;Large-scale Optimization을 위해 R-BCD(Randomized Block Coordinate Descent)를 사용함으로써 변수들의 부분집합에 대해서만 gradients를 구하기 때문에 사용되는 메모리와 수행 시간을 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;Perturbation $P\in{0,1}^{n*n}$ 는 아래와 같이 모델되었다.&lt;/p&gt;

&lt;p&gt;$\max_{P\; \text{s.t.}\; P \in {0, 1}^{n \times n},\; \sum P \leq  \Delta} L(f_\theta(A \otimes P, X)) \ \Delta = \text{edge budget}$&lt;/p&gt;

&lt;p&gt;그러나 $O(n^2)$ 만큼의 공간복잡도이기에 논문은 Projected Randomized Block Coordinate Descent(PR-BCD)를 제안한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/XsZ1v5K/img2.png&quot; alt=&quot;img2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;P는 이산 Edge 행렬로, 각 element(p)는 edge를 뒤집을 확률을 나타낸다. 우선, epoch마다 P에서 무작위로 추출된 Block을 바탕으로 특정 부분의 edge들만을 변경한다. 업데이트 후 p에 대한 확률 질량함수를 수정하여 베르누이 분포에 대한 기댓값이 Budget을 넘지 않도록 한다. 그리고 논문은 PR-BCD에 대한 또 다른 대안으로 &lt;strong&gt;GR-BCD&lt;/strong&gt;를 함께 제안한다. PR-BCD에서 Block 추출 시 가장 큰 gradient를 가진 entry만 &lt;strong&gt;greedy&lt;/strong&gt;하게 변경하는 것으로 E번의 epoch 후에 budget이 충족되도록 하는 방법이다. 그러나 위 방법들은 실제 최적화 문제를 얼마나 효과적으로 근사하는지에 대한 보장은 제공하지 않고, 공격의 효과의 Upper bound만 보여준다는 점에서 한계가 있다.&lt;/p&gt;

&lt;p&gt;위 방법론에서 확장하여 더 큰 그래프들을 사용하기 위해, PPRGo를 사용했다. 이는 Personalized Page Rank(PPR) Matrix($\Pi$)를 사용함으로써 explicit message passing steps 수를 1로 줄여 constant complexity를 가질 수 있게 한다.&lt;/p&gt;

&lt;p&gt;$p = softmax \big[\text{AGG}{\Pi_{uv}(A_{uv}, f_\text{enc}(x_u)\big), \;  \forall u \in  \mathbb{N}^\prime(v)}\big]$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/s6chCC0/img3.png&quot; alt=&quot;img3.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;33-scalable-defense&quot;&gt;3.3 Scalable Defense&lt;/h2&gt;

&lt;p&gt;GNN의 메세지 패싱 프레임워크를 다음과 같이 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;$h^{(l)}&lt;em&gt;v = \phi^{(l)}  \big[(  \text{AGG}^{(l)}{\big(A&lt;/em&gt;{uv}, h^{(l-1)}_uW^{(l)}\big), \quad  \forall u \in  \mathbb{N}^\prime(v)}\big] \ \ \text{where} \; \text{neighborhood} \; \mathbb{N}^\prime(v) = \mathbb{N}(v)  \cup v \\\text{and} \; AGG = \text{l-th layer message passing aggregation} \ \text{and} \; h^{(l)}_v = \text{embedding}, \sigma^{(l)}  \text{activation function}$&lt;/p&gt;

&lt;p&gt;Geisler et al. (2020)에서는 Aggregate Function으로 Soft Medoid를 제안했다. Soft Medoid는 이웃 노드들의 embedding에 대한 distance matrix에 대해 행/열 summation을 요구하기에 neighborhood size에 대해 이차 복잡도를 지닌다.&lt;/p&gt;

&lt;p&gt;이를 개선하기 위해 논문은 Soft Median을 제시한다.&lt;/p&gt;

&lt;p&gt;$\mu_\text{SoftMedian}(X) = \text{softmax}(\frac{-c}{T\sqrt{d}}  )^\intercal  \cdot  \mathbf{X} = \mathbf{s}^\intercal  \cdot  \mathbf{X}  \approx  \arg  \min_{x^\prime  \in  \mathbf{X}} |x_{\bar{}}  - x^\prime|$&lt;/p&gt;

&lt;p&gt;이로써 Dimension($d$)에만 의존함으로써 계산을 효율적으로 할 수 있다. $d$를 충분히 작게 한다면 Soft Median 스케일은 $\mathbb{N}$에 linear한 scale을 보인다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/5vY3Fdk/img4.png&quot; alt=&quot;img4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 왼편의 그래프는 원본 그래프와 Pertubed된 그래프를 첫 번째 message passing을 한 후의 latent space의 $L_2$ Distance를 나타낸 그래프이다. Soft Median이 Weighted Sum보다 20% 가까이 낮은 error를 보인다. 반면, 그래프에는 Soft Medoid가 Soft Median보다 Robust한 결과를 가지는 것으로 보인다. 그러나 오른쪽 표가 나타내듯 Adversarial accuracy에서는 Soft Medoid가 Soft Median보다 좋은 성능을 보이지 못했다.&lt;/p&gt;

&lt;p&gt;이처럼 Soft Median은 (1)차원에 대한 고려 없이 단순히 Summation 한다면 computation 비용이 많이 든다는 점과 (2)Soft Median에 비해 robust하지 않은 결과와 마찬가지로 잘못된 robustness의 결과를 가져올 수 있다는 점을 한계점으로 삼을 수 있다. 그러나 PPRGo와 결합하여 사용한다면 위 한계를 완화할 수 있다고 설명한다.&lt;/p&gt;

&lt;h2 id=&quot;34-empirical-evaluation&quot;&gt;3.4 Empirical Evaluation&lt;/h2&gt;

&lt;h3 id=&quot;robustness-wrt-global-attacks&quot;&gt;Robustness w.r.t global attacks.&lt;/h3&gt;

&lt;p&gt;아래 실험 결과는 Pubmed, arXiv, Products Dataset 각각에 대해 $\text{budget} = \Delta$만큼의 공격 후에 adversarial accuracy를 측정한 결과이다. 약 2%가량 Pertubation을 가했을 때, 대략 60%의 정확도로 떨어지는 모습을 확인할 수 있었다고 밝혔다. 각 경우에서 Soft Median GDC, Soft Median PPRGo, PPRGo Defense가 타 모델보다 비교적 좋은 결과가 보임을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/x18qbsH/img5.png&quot; alt=&quot;img5.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;robustness-wrt-local-attacks&quot;&gt;Robustness w.r.t local attacks.&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/Y2pV6Lp/img6.png&quot; alt=&quot;img6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cora ML, Citeseer, arXiv에서 PR-BCD가 SGA보다 효과적으로 공격을 하는 것을 볼 수 있었다. 그리고 아래 그래프가 보이듯 Soft Median PPRGo가 위 공격에 대해서 Vanila PPRGo와 Vanila GCN보다 대체로 잘 견디는 것을 확인할 수 있었다. (b)의 Papers100M에서 $\Delta_i = 0.25$일 때, Soft Median PPRGo는 공격자의 성공률을 90%에서 30%로 줄인 것을 그래프에서 볼 수 있다.&lt;/p&gt;

&lt;h1 id=&quot;4-conclusion&quot;&gt;4. Conclusion&lt;/h1&gt;

&lt;p&gt;규모가 있는 GNN에서의 Adversarial Robustness를 살펴보았다. 논문은 이전까지 데이터셋의 규모로 인해 잘 다뤄지지 않았던 문제를 확인하기 위해 Attack과 Defense에 대해 직접 방법을 제시하고 실험한 결과를 보였다.&lt;/p&gt;

&lt;p&gt;따라서, Complexity를 줄이기 위해 PPRGo와 Soft Median이라는 방법을 도입하고 Attack과 Defense에 반영하여 실제로 큰 데이터셋에 대한 실험결과를 낸 것을 보며 문제상황에 대한 해결 의지를 느낄 수 있었다. 공격자가 Model을 다 안다는 가정(White-box attack)을 하고 Budget($\Delta$)를 중점으로 Complexity를 해결했던 것이 현실에서 어떻게 적용이 될 수 있을지를 찾아보고 싶어졌다.&lt;/p&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Geisler, Simon, et al. “Robustness of graph neural networks at scale.” &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; 34 (2021): 7637-7649.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bojchevski, Aleksandar, et al. “Scaling graph neural networks with approximate pagerank.” &lt;em&gt;Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp;amp; Data Mining&lt;/em&gt;. 2020.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-Robustness_of_Graph_Neural_Networks_at_Scale.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-Robustness_of_Graph_Neural_Networks_at_Scale.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[ICML 2022] Rethinking Graph Neural Networks for Anomaly Detection</title>
            <description>&lt;h1 id=&quot;icml-22-rethinking-graph-neural-networks-for-anomaly-detection&quot;&gt;[ICML-22] Rethinking Graph Neural Networks for Anomaly Detection&lt;/h1&gt;

&lt;h1 id=&quot;title&quot;&gt;Title&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Rethinking Graph Neural Networks for Anomaly Detection&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Author&lt;/th&gt;
      &lt;th&gt;Booktitle&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Tang, Jianheng and Li, Jiajin and Gao, Ziqi and Li, Jia&lt;/td&gt;
      &lt;td&gt;International Conference on Machine Learning&lt;/td&gt;
      &lt;td&gt;2022&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;1-problem-definition&quot;&gt;&lt;strong&gt;1. Problem Definition&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;11-background&quot;&gt;1.1 Background&lt;/h3&gt;

&lt;p&gt;이상치 (An anomaly or an outlier) 는 대부분의 개체에서 크게 벗어난 데이터 객체를 뜻하며, 이상치 탐지 (Anomaly Detection) 문제로는 사이버 보안, 사기 탐지, 장치 오류 탐지 등이 있습니다. 기술의 발전으로 인하여 그래프 데이터가 보편화되면서 structural data에 대한 분석으로 Graph Neural Networks (이하 “GNN”)이 각광받았고 자연스럽게 그래프 이상 탐지 작업 (Graph Anomaly Detection Task)에 적용되었습니다. 하지만, vanilla GNN은 지나친 확일화 문제로 인하여 이상치 탐지에 적합하지 않았고 이를 개선하기 위하여 attention 매커니즘을 적용하는 방법, resampling 전략을 사용하는 방법, 그리고 보조의 losses를 설계하는 방법이 제안되었습니다. 이 세 가지 방법은 모두 spatial domain에서의 분석이며, spectral domain에서의 분석은 거의 이루어지지 않았습니다. GNN을 설계할 때 알맞는 spectral filter을 적용하는 것 또한 중요하기에 해당 논문에서는 ‘이상치 탐지를 위한 GNN에서 적절한 spectral filter을 어떻게 고를 것인가?’ 에 대해 답변하고자 합니다.&lt;/p&gt;

&lt;h3 id=&quot;12-overview&quot;&gt;1.2 Overview&lt;/h3&gt;

&lt;p&gt;‘이상치 탐지를 위한 GNN에서 적절한 spectral filter을 어떻게 고를 것인가?’에 대해 답변하기 위해 두 가지 과정을 거칩니다. 첫 번째로, 그래프 이상 탐지에서 spectral localized band-pass filters의 중요성을 확인하는 과정입니다. 논문의 저자는 이상의 정도(degree)가 커질수록, 저주파 에너지가 점진적으로 고주파 에너지로 전환됨을 확인하였고 이를 spectral 에너지 분포의 ‘오른쪽 편이 (right-shift)’ 현상으로 정의하였습니다. ‘오른쪽 편이’ 현상에 대한 수리적 증명 및 데이터를 통한 검증으로 적절한 spectral filter의 필요성을 보입니다. 두 번째로, 그래프 이상치에서의 ‘오른쪽 편이’ 현상을 잘 다루는 새로운 알고리즘, Beta Wavelet Graph Neural Network (이하 “BWGNN”)을 제안합니다. Hammond’s graph wavelet theory에서 착안하여 Heat kernal이 아닌 Beta kernal을 사용함으로써, 매우 유동적이고 spatial/spectral-localized 하며 band-pass한 filter을 통해 고주파 이상 현상을 해결합니다.&lt;/p&gt;

&lt;h3 id=&quot;13-preliminaries&quot;&gt;1.3 Preliminaries&lt;/h3&gt;

&lt;p&gt;속성 그래프 (Attributed graph)는  $G = { V,E,X }$ 로 정의되며, $V$ 는 node, $E$는 edge, $X$는 node features을 의미합니다. $A$를 adjacency matrix, $D$를 degree matrix로 표현합니다. $V_ {a}$ 와 $V_ {n}$을 두 개의 분리된 하위집합이라 할때, $V_ {a}$ 는 모든 이상 노드를 나타내고, $V_ {n}$ 은 모든 정상 노드를 나타냅니다. 그래프 기반 이상 탐지는 주어진 그래프 구조 $E$, node features $X$, 그리고 부분적인 노드 라벨 ${V_ {a}, V_ {n}}$ 정보를 활용하여 $G$ 내의 라벨링 되지 않은 노드를 이상 또는 정상으로 분류하는 것입니다. 해당 논문은 node 이상치에 집중하며, 모든 edge는 신뢰된다고 가정합니다. 보통, 정상 노드가 이상 노드보다 훨씬 많기에 그래프 기반 이상 탐지는 불균형한 이진 노드 분류 문제로 여겨집니다.&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;&lt;strong&gt;2. Motivation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;그래프 이상 탐지에서 spatial domain에 대한 분석은 이루어졌으나 spectral domain에 대한 분석이 거의 이루어지지 않았음이 해당 논문의 동기입니다. 그래프 이상 탐지를 위한 spectral domain 분석이 유효한지를 확인하기 위하여 ‘오른쪽 편이’ 현상을 정의하고 Gaussian anomaly model로 증명하며 인조적인 데이터와 실제 데이터에서 유효한지 확인하였습니다.&lt;/p&gt;

&lt;h3 id=&quot;21-theoretical-insights-of-the-right-shift-phenomenon&quot;&gt;2.1 Theoretical insights of the ‘right-shift’ phenomenon&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$G$ 에서 $x= (x_1, x_2, … , x_N)^T \in R^N$ 을 signal, $\hat{x}= (\hat{x}&lt;em&gt;1, \hat{x}_2, … , \hat{x}_N)^T = U^T$ 를 $x$ 의 graph Fourier transform 이라 가정해봅시다. 이때 $\hat{x}^2_k / \sum&lt;/em&gt; {i=1}^N \hat{x}^2_i$ 를 $\lambda_k (1 \leq k \leq N)$ 에서의 spectral energy distribution 이라 합니다. 논문의 저자는 이상치의 존재가 존재하면 spectral energy 에서의 ‘오른쪽 편이’ 현상이 나타남을 확인하였으며, 이는 spectral energy distribution이 낮은 주파수에는 적게 집중되어 있고 높은 주파수에는 많이 집중되어 있음을 의미합니다. 본문은 증명을 위해 $x$가 Gaussian distribution을 따른다고 가정합니다. (i.e. $x \sim N(\mu e_N,\sigma^2 I_N)$ 이때, $x$의 이상치 정도는 $\sigma /&lt;/td&gt;
      &lt;td&gt;\mu&lt;/td&gt;
      &lt;td&gt;$로 표현할 수 있습니다. $x$의 이상치 정도에 따라 spectral energy distribution이 얼마나 바뀌는지를 energy ratio라 할때, 어떠한 $1 \leq k \leq N-1$에 대하여 k번째 낮은 주파수 energy ratio 를 $\eta_k(x,L) = \frac{\sum_ {i=1}^k \hat{x}^2&lt;em&gt;i } {\sum&lt;/em&gt; {i=1}^N \hat{x}^2&lt;em&gt;i}$ 로 정의합니다. x의 이상치 정도가 바뀜에 따라 $\eta_k(x,L)$ 가 어떻게 바뀌는지를 알기 위하여 eigen-decomposition을 수행하면 시간이 많이 소요됩니다. 따라서 본문은 high-frequency area $S&lt;/em&gt; {high} = \frac{\sum_ {i=1}^k \lambda_k \hat{x}^2&lt;em&gt;i } {\sum&lt;/em&gt; {i=1}^N \hat{x}^2_i} = \frac {x^T Lx} {x^Tx}$ 를 정의내려 설명합니다. 이를 통해 모든 스펙트럼에서의 ‘오른쪽 편이’ 현상을 증명할 수 있습니다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;22-validation-on-datasets&quot;&gt;2.2 Validation on Datasets&lt;/h3&gt;

&lt;p&gt;해당 논문에서는 $x$가 Gaussian distribution을 따르는 데이터셋과 따르지 않은 데이터셋 각각에 대하여 ‘오른쪽 편이’ 현상을 검증합니다. 첫 번째로, 인조적인 데이터셋인 Barabasi-Albert graph (Figure 1 (a)-(b))와 Minnesota road graph (Figure 1 (c)-(d)) 에서 이상치의 효과를 보입니다. 아래 그림에서 파란색 원은 spatial domain에서의 이상 노드를 나타내며 원의 크기가 클수록 이상치의 정도가 심함을 의미합니다. 그래프를 해석하면, 이상치의 정도, 즉, $\sigma$ 와 $\alpha$ 가$\alpha\(\lambda$ $\lambda\)\alpha$가 큼을 확인할 수 있으며 이는 2.1에서 설명한 ‘오른쪽 편이’ 현상이 보임을 의미합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ibb.co/fXmJ8Gf&quot; alt=&quot;Figure1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;두 번째로, node feature가 Gaussian distribution을 엄격하게는 따르지 않는 현실의 데이터셋에서의 ‘오른쪽 편이’ 현상을 입증합니다. 아래는 해당 4가지 데이터셋, Amazon, YelpChi, T-Finance, T-Social 의 특징과 이상치 효과에 대하여 정리한 도표입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;%5BICML-22%5D%20Rethinking%20Graph%20Neural%20Networks%20for%20Ano%2021e4e1d2410f4095b1a56d4b069a2342/Table1.png&quot; alt=&quot;Table1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아래의 표는 Amazon dataset에서 (1) 기존 그래프, (2) 모든 이상치를 없앤 그래프, (3) 임의의 같은 노드의 수를 없앤 그래프의 spectral energy를 비교한 표입니다. Figure 3의 왼쪽 그래프에서, 낮은 주파수일때, 즉, $\lambda$ 값이 작을 때, Drop-Anomaly 가 Drop-Random 보다 큰 spectral energy distribution을 가짐을 확인할 수 있으며 이는  ‘오른쪽 편이’ 현상이 있음을 나타냅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ibb.co/nrYcYtq&quot; alt=&quot;Figure3.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;대부분의 해당 논문 이전의 GNN은 low-pass filter 또는 adaptive filter을 사용하였으며 이는 band-pass 와 spectral-localized 를 보장하지 못합니다. 이러한 단점을 극복하기 위하여 해당 논문에서는 Hammond’s graph wavelet theory를 기반으로 한 새로운 GNN architecture인 BWGNN를 제안합니다. Hammond’s Graph Wavelet 은 graph signal $x \in R^N$ 에 wavelets $W = (W_ {\psi_1}, W_ {\psi_2},…)$ 를 적용하여 변형시키는 것이며 이때, $\psi$ 는 “mother” wavelet 입니다.&lt;/p&gt;

&lt;p&gt;Beta distribution은 종종 wavelet basis의 역할을 합니다. 이전에 Beta distribution을 사용한 기록이 없어 해당 논문에서는 Graph kernal function로 Beta distribution을 선택하여 Beta graph wavelet를 만들었고 특징을 분석하였습니다. Heat Wavelet과 Beta Wavelet 를 비교해보면, Figure 4의 왼쪽에서 볼 수 있듯이 Beta Wavelet은 low-pass filter만 있는 Heat Wavelet 과 달리 low-pass 와 band-pass를 포함한 다양한 filter type을 포함합니다. Figure 4의 오른쪽에서는 Beta Wavelet은 긍정의 반응만 보이는 Heat Wavelet 과 달리 서로 다른 채널에 대해 긍정과 부정의 효과를 둘다 보임을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;%5BICML-22%5D%20Rethinking%20Graph%20Neural%20Networks%20for%20Ano%2021e4e1d2410f4095b1a56d4b069a2342/Figure4.png&quot; alt=&quot;Figure4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위에서 설명한 Beta graph wavelet을 활용하여 BWGNN은 병렬적으로 서로 다른 wavelet kernel을 사용한 후 해당 filtering의 결과를 병합합니다. 구체적으로 BWGNN은 아래의 propagation 과정을 채택합니다.&lt;/p&gt;

\[Z_i = W_ {i,C-i} (MLP(X))\]

\[H = AGG([Z_0, Z_1, ..., Z_C])\]

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;41-experiment-setup&quot;&gt;4.1 &lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;4 Dataset : T-Finance, T-Social , YelpChi, Amazon
    &lt;ul&gt;
      &lt;li&gt;T-Finance : 거래 네트워크에서의 이상 계좌를 찾는 것을 목적으로 하는 데이터셋&lt;/li&gt;
      &lt;li&gt;T-Social : 소셜 네트워크에서 이상 계정을 찾는 것을 목적으로 하는 데이터셋&lt;/li&gt;
      &lt;li&gt;YelpChi : &lt;a href=&quot;http://Yelp.com&quot;&gt;Yelp.com&lt;/a&gt; 에 올라온 악성 리뷰를 찾는 것을 목적으로 하는 데이터셋&lt;/li&gt;
      &lt;li&gt;Amazon : &lt;a href=&quot;http://Amazon.com&quot;&gt;Amazon.com&lt;/a&gt; 의 음악 악기 카테고리에 올라온 가짜 제품 리뷰를 찾는 것을 목적으로 하는 데이터셋&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Evaluation Metric : F1-macro, AUC&lt;/li&gt;
  &lt;li&gt;Baselines
    &lt;ul&gt;
      &lt;li&gt;First group : MLP, SVM&lt;/li&gt;
      &lt;li&gt;Second group : GCN, ChebyNet, GAT, GIN, GraphSAGE, GWNN&lt;/li&gt;
      &lt;li&gt;Third group : GraphConsis, CAREGNN, PC-GNN&lt;/li&gt;
      &lt;li&gt;Fourth group : BWGNN (hetero), BWGNN (homo)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;42-result&quot;&gt;4.2 &lt;strong&gt;Result&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;아래의 표에서 확인할 수 있듯이 BWGNN은 Amazon을 제외한 dataset 에서의 최고의 성능을 보여줌을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;%5BICML-22%5D%20Rethinking%20Graph%20Neural%20Networks%20for%20Ano%2021e4e1d2410f4095b1a56d4b069a2342/Table2.png&quot; alt=&quot;Table2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;%5BICML-22%5D%20Rethinking%20Graph%20Neural%20Networks%20for%20Ano%2021e4e1d2410f4095b1a56d4b069a2342/Table3.png&quot; alt=&quot;Table3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;민감도 분석을 진행한 결과는 아래와 같습니다. 중요한 hyperparameter인 order C와 이상치 정도의 영향에 대하여 민감도 분석을 진행하였고 각각 왼쪽과 오른쪽의 결과를 보였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;%5BICML-22%5D%20Rethinking%20Graph%20Neural%20Networks%20for%20Ano%2021e4e1d2410f4095b1a56d4b069a2342/Figure5.png&quot; alt=&quot;Figure5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;%5BICML-22%5D%20Rethinking%20Graph%20Neural%20Networks%20for%20Ano%2021e4e1d2410f4095b1a56d4b069a2342/Figure6.png&quot; alt=&quot;Figure6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;해당 논문은 그래프 이상 탐지에 대하여 설명한 후 ‘이상치 탐지를 위한 GNN에서 적절한 spectral filter을 어떻게 고를 것인가?’에 대해 답변합니다. 이를 위하여 핵심 특징인 ‘오른쪽 편이’에 대해 그래프로 증명하여 알고리즘의 필요성을 이야기한 후 Beta Wavelet Graph를 활용한 새로운 알고리즘인 BWGNN를 수식적으로 보여줍니다. 실험에서는 4가지 datasets을 활용하여 알고리즘 비교 실험을 진행하였고 BWGNN은 우수한 성능을 보였습니다. Future work로 noe anomalies에서 더 나아간 edge anomalies를 분석해볼 수 있다고 생각합니다. 수리적으로 energy distribution 을 표현한 것이 인상깊었습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;심윤주 (Yoonju Sim)
    &lt;ul&gt;
      &lt;li&gt;Master Student, Department of Industrial &amp;amp; Systems Engineering, KAIST&lt;/li&gt;
      &lt;li&gt;Computational Optimization, Reinforcement Learning, Transportation system&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-reference--additional-materials&quot;&gt;&lt;strong&gt;6. Reference &amp;amp; Additional materials&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Github : https://github.com/squareRoot3/Rethinking-Anomaly-Detection&lt;/li&gt;
  &lt;li&gt;Datasets :  &lt;a href=&quot;https://drive.google.com/drive/folders/1PpNwvZx_YRSCDiHaBUmRIS3x1rZR7fMr?usp=sharing&quot;&gt;google drive&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-Rethinking_Graph_Neural_Networks_for_Anomaly_Detection.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-Rethinking_Graph_Neural_Networks_for_Anomaly_Detection.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[WSDM 2020] RecVAE: a New Variational Autoencoder for Top-N Recommendations with Implicit Feedback</title>
            <description>&lt;h1 id=&quot;recvae-a-new-variational-autoencoder-for-top-n-recommendations-with-implicit-feedback&quot;&gt;&lt;strong&gt;RecVAE: a New Variational Autoencoder for Top-N Recommendations with Implicit Feedback&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;&lt;strong&gt;1. Introduction&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;행렬 분해 (Matrix Factorization)은 협업 필터링 (Collaborative Filtering)을 기반으로 한 추천시스템의 기본적인 방법 중 하나이다. 하지만 이는 다음과 같은 문제점을 가지고 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;행렬의 크기가 사용자 (User)와 항목 (Item)의 수에 선형적으로 비례하기 때문에 매우 많은 파라미터를 필요로 한다.&lt;/li&gt;
  &lt;li&gt;콜드 스타트 (Cold Start) 문제가 발생한다. 즉, 새로운 사용자나 항목이 추가될 때, 정확한 추천을 하기가 어렵다.&lt;/li&gt;
  &lt;li&gt;몇몇 사용자나 항목에 대해서 주어진 데이터가 매우 적을 수 있다. 이는 과적합을 초래할 수 있으며 일반적으로 강력한 정규화가 필요하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;최근에 이러한 극복하기 위해 오토인코더 기반의 접근이 지속적으로 연구되고 있다. Collaborative Denoising Autoencoder (CDAE)&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;는 사용자 피드백을 임베딩 (Embedding)하여 콜드 스타트 문제를 해결하였다. Variational Autoencoder (Mult-VAE)&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;는 적절한 우도 (Likelihood)를 도입하여 향상된 결과를 보여주었다. 이 연구에서는 Mult-VAE의 확장으로서 암시적 피드백 (Implicit Feedback)을 활용하는 Recommender VAE (RecVAE) 를 제안하고 이것의 기여는 아래와 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;사용자 임베딩을 향상시키는 인코더 네트워크 설계 제안&lt;/li&gt;
    &lt;li&gt;추천 시스템에 알맞는 적절한 사전분포 제안&lt;/li&gt;
    &lt;li&gt;암시적 피드백으로 인한 새로운 $\beta$-VAE 제안&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;2-preliminary&quot;&gt;&lt;strong&gt;2. Preliminary&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;21-variational-autoencoders-and-their-extensions&quot;&gt;&lt;strong&gt;2.1 Variational autoencoders and their extensions&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;변분 오토인코더는 복잡한 분포를 학습할 수 있는 잠재 변수 모델이다. 이에 대한 간략한 요약으로 시작하자. 주어진 데이터가 $p_ {true}(x)$를 따르고 모델을 $p_ {\theta}(x)$라고 하자. 잠재변수 $z$를 통해서 모델을 다시 표현 할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$p_ {\theta}(x) = \int p_ {\theta}(x \vert z)p(z)dz$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 적분을 계산하는 것은 어려우므로 이것의 하계 (Lower Bound)를 최대화 하는 방법으로 모델이 훈련된다. 이를 ELBO (Evidence Lower Bound)라고 부르며 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$p_ {\theta}(x) \geq \mathcal{L}_ {\text{VAE}} = \mathbb{E}_ {q_ {\phi}(z \vert x)} \left[ \log p_ {\theta}(x \vert z) - \text{KL}({q_ {\phi}(z \vert x)} \parallel p(z) )\right],$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 $\text{KL}$은 KL-divergence를 의미하고 $p(z), q_ {\phi}(z \vert x)$는 각각 사전분포와 변분 분포를 의미한다. $p_ {\theta}(z,x)$를 학습함으로써 변분 오토인코더는 생성모델로서 활용될 수 있다. 또한, $q_ {\phi}(z \vert x)$를 이용한다면 임베딩을 통한 재표현 (Representation)을 얻을 수 있다. $\beta$-VAE&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;는 더욱 향상된 재표현을 얻기 위해 다음과 같이 변형된 손실 함수를 제안 하였다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\mathcal{L}_ {\beta\text{-VAE}} = \mathbb{E}_ {q_ {\phi}(z \vert x)} \left[ \log p_ {\theta}(x \vert z) - \beta \text{KL}({q_ {\phi}(z \vert x)} \parallel p(z) )\right]$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Denoising variational autoencoders (DVAE)&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;는 데이터에 노이즈를 강제로 주입하여 재표현을 학습하기 위한 방법이다. 노이즈 분포 $p(\tilde{x} \vert x)$에 대하여 (예를 들어, 가우시안 혹은 베르누이 분포) 변형된 손실 함수를 정의한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\mathcal{L}_ {\text{DVAE}} = \mathbb{E}_ {q_ {\phi}(z \vert x)} \mathbb{E}_ {p(\tilde{x} \vert x)} \left[ \log p_ {\theta}(x \vert z) - \text{KL}({q_ {\phi}(z \vert \tilde{x})} \parallel p(z) )\right]$,&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그 결과로서 노이즈가 있는 데이터에 대해서도 의미있는 재표현을 얻을 수 있다. Conditional Variational Autoencoder (CVAE)&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;는 변분 오토인코더의 또 다른 확장이다. 주어진 데이터가 $x$ 뿐만 아니라 $y$라는 레이블이 있다면 이것에 따른 조건부 확률 분포를 학습 할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\mathcal{L}_ {\text{CVAE}} = \mathbb{E}_ {q_ {\phi}(z \vert x, y)}\left[ \log p_ {\theta}(x \vert z, y) - \text{KL}({q_ {\phi}(z \vert x, y)} \parallel p(z \vert y) )\right]$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;마지막으로, VAE with Arbitrary Conditioning (VAEAC)&lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;는 결측값 예측을 위해 사용하는 모델이며 협업 필터링 문제와 상당히 비슷하다. 주어진 데이터 $x$에 대해서 결측된 특성을 $x_ {b}$ 나머지를 $x_ {1-b}$ 라고 하자. CVAE에서 $y$ 대신 $(x_ {1-b}, b)$를 사용하면 VAEAC의 손실 함수를 정의할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\mathcal{L}_ {\text{VAEAC}} = \mathbb{E}_ {q_ {\phi}(z \vert x, b)}\left[ \log p_ {\theta}(x_ {b} \vert z, x_ {1-b}, b) - \text{KL}({q_ {\phi}(z \vert x, b)} \parallel p(z \vert x_ {1-b}, b) )\right],$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 $b$는 이진 마스킹 (Binary Masking)을 의미한다.&lt;/p&gt;

&lt;h3 id=&quot;22-autoencoders-and-regularization-for-collaborative-filtering&quot;&gt;&lt;strong&gt;2.2 Autoencoders and Regularization for Collaborative Filtering&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;$U$, $I$를 유저와 항목의 집합으로 표기하고 $X$를 암시적 피드백 행렬이라고 하자. 즉, $x_ {ui} = 1$ 인 필요충분조건은 유저 $u$가 항목 $i$를 긍정적으로 작용했다는 것이다. $x_ {u}$를 피드백 벡터라고 하자. CDAE&lt;sup id=&quot;fnref:1:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;는 $x_ {u}$에 마스킹을 적용해서 복구하는 모델이므로 2.1 섹션의 DVAE를 협업 필터링에 적용한 것으로 볼 수 있다.&lt;/p&gt;

&lt;p&gt;Mult-VAE&lt;sup id=&quot;fnref:2:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;는 협업 필터링에 적용하기 위해서 우도를 다항 분포로 가정한 변분 오토인코더 모델이다. $n_ {u}:= \sum_{j} (x_ {u})_ {j}$ 라고 하면 모델은 다음과 같이 정의된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;$z_ {u} \sim N(0,I_ {k \times k})$&lt;/li&gt;
    &lt;li&gt;$f_ {\theta}: \mathbb{R}^{k} \rightarrow \mathbb{R}^{\vert I \vert}$ is a neural network.&lt;/li&gt;
    &lt;li&gt;$\pi(z_ {u}) \sim \text{softmax}(f_ {\theta}(z_{u}))$&lt;/li&gt;
    &lt;li&gt;$x_ {u} \sim \text{Multinomial}(n_ {u}, \pi(z_ {u}))$&lt;/li&gt;
    &lt;li&gt;(Objective) $\mathcal{L}_ {\text{Mult-VAE}} = \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u})} \left[ \log p_ {\theta}(x_ {u} \vert z_ {u}) - \beta \text{KL}({q_ {\phi}(z_{u} \vert x_ {u})} \parallel p(z_ {u}) )\right]$&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;3-method&quot;&gt;&lt;strong&gt;3. Method&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;기본적으로, 제안된 모델 RecVAE는 Mult-VAE의 확장이다. DAE 방법을 추가하여 생성모델을 정의한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;$p_ {\theta}(x_ {u} \vert z_ {u}) = \text{Multinomial}(x \vert n_ {u}, \pi(z_ {u}))$&lt;/li&gt;
    &lt;li&gt;$\pi(z_ {u}) = \text{softmax}(f_ {\theta}(z_ {u}))$&lt;/li&gt;
    &lt;li&gt;$f_{\theta}(z_ {u})$ is a neural network.&lt;/li&gt;
    &lt;li&gt;$q_ {\phi}(z_ {u} \vert x_ {u}) = N(z_ {u} \vert \psi_ {\phi}(x_ {u}))$&lt;/li&gt;
    &lt;li&gt;(Objective) $\mathcal{L} = \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u})} \mathbb{E}_ {p(\tilde{x}_ {u} \vert x_ {u})}\left[ \log p_ {\theta}(x_ {u} \vert z_ {u}) - \beta \text{KL}({q_ {\phi}(z_ {u} \vert \tilde{x}_ {u})} \parallel p(z_ {u}) )\right]$&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;31-model-architecture&quot;&gt;&lt;strong&gt;3.1 Model Architecture&lt;/strong&gt;&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://i.ibb.co/xJQrsLz/2023-10-14-164239.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;첫번째 변화는 dense CNNs&lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;, swish activation functions&lt;sup id=&quot;fnref:8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;, layer normalization&lt;sup id=&quot;fnref:9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;과 같은 아이디어를 결합해 협업 필터링에 알맞는 추론 네트워크를 제안하며 위 그림과 같은 구조를 가지고 있다.&lt;/p&gt;

&lt;h3 id=&quot;32-composite-prior&quot;&gt;&lt;strong&gt;3.2 Composite prior&lt;/strong&gt;&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://i.ibb.co/tJDwC9P/2023-10-14-205240.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Mult-VAE 구조에서 데이터의 희소성 (Sparsity) 때문에 변분 분포의 파라미터 최적화가 어려움을 겪을 수 있다. 이는 강화학습에서 forgetting 효과라고 알려져 있으며 정책 기반 강화학습 논문에 많은 논의가 있었다&lt;sup id=&quot;fnref:10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;. 이를 해결 하기 위한 방법중 하나는 학습된 파라미터를 기억해두는 방법이다. 즉, 새로운 파라미터를 찾는 학습은 좋은 결과를 주는 파라미터로 부터 크게 벗어나지 않게 정규화를 주어야 한다.&lt;/p&gt;

&lt;p&gt;이는 오토인코더에 구조에서 $q_ {\phi}(z \vert x)$를 업데이트 할 때, 이전에 얻었던 $q_ {\phi_ {\text{old}}}(z \vert x)$을 적당히 유지하고 싶은 것과 같다 . 이를 수행할 수 있는 한 방법은 본래의 사전분포와 $q_ {\phi_ {\text{old}}}(z \vert x)$의 컨벡스 결합을 새로운 사전분포로 사용하는 것이다. 즉,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$p(z \vert \phi_ {\text{old}},x) = \alpha N(z \vert 0,I) + (1-\alpha)q_ {\phi_ \text{old}}(z \vert x)$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;최종적인 모델 설계는 위 사진과 같다.&lt;/p&gt;

&lt;h3 id=&quot;33-rescaling-kl-divergence&quot;&gt;&lt;strong&gt;3.3 Rescaling KL divergence&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;$\beta$-VAE&lt;sup id=&quot;fnref:3:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;은 재표현을 학습하기 위한 좋은 방법이지만 파라미터를 선택하는 방법이 학습에 큰 영향을 미친다. 기존의 연구&lt;sup id=&quot;fnref:11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;와는 다르게 협업 필터링 변분 오토인코더 모델에 알맞는 $\beta$ 선택 방법에 대한 연구가 필요하다.&lt;/p&gt;

&lt;p&gt;유저 피드백이 부분적으로 주어졌다고 하자. 부분적인 데이터에 대해서 $X_ {u}^{0}$를 유저 $u$가 긍정적으로 평가한 항목의 집합이라 하고 $X_ {u}^{f}$ 긍정적으로 평가한 모든 항목의 집합이라고 하자. 항목들이 원 핫 인코딩으로 주어졌다고 하고, 다음과 같이 기호를 적자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$x_ {u} = \sum_ {a \in X_ {u}^{0}}1_ {a}$&lt;/li&gt;
  &lt;li&gt;$x_ {u}^{f} = \sum_ {a \in X_ {u}^{f}}1_ {a}$&lt;/li&gt;
  &lt;li&gt;$\text{KL}_ {u} = \text{KL}(q_ {\phi}(z_ {u} \vert x_ {u}) \parallel p(z_ {u}))$&lt;/li&gt;
  &lt;li&gt;$\text{KL}_ {u}^{f} = \text{KL}(q_ {\phi}(z_ {u} \vert x_ {u}^{f}) \parallel p(z_ {u}))$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기서 $1_ {a}$는 항목 $a$에 대응되는 원 핫 인코딩된 벡터이다. 기존의 ELBO를 다음과 같이 정리 할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\mathcal{L} = \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u}^{f})}\left[ \log \text{Multinomial}(x_ {u}^{f} \vert \pi(z_ {u})) - \text{KL}_ {u}^{f}\right]$
$= \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u}^{f})} \left[ \sum_ {a \in X_ {u}^{f}} \log \text{Cat}(1_ {a} \vert \pi(z_ {u})) - \text{KL}_ {u}^{f}\right] + C$
$= \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u}^{f})}  \sum_ {a \in X_ {u}^{f}} \left[  \log \text{Cat}(1_ {a} \vert \pi(z_ {u})) - \frac{1}{\vert X_ {u}^{f}\vert} \text{KL}_ {u}^{f}\right] + C$,&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 $\text{Cat}$는 카테고리 분포이고 $C$는 최적화에 영향을 주지 않는 상수이다. (실제로 $\text{Multinomial}$의 정규화 상수이다.) 부분적 피드백에 대해 주어진 ELBO를 근사시키기 위해서 $q_ {\phi}(z_ {u} \vert x_{u}) \approx q_ {\phi}(z_ {u} \vert x_ {u}^{f})$ 그리고 $\text{KL}_ {u} \approx \text{KL} &lt;em&gt;{u}^{f}$를 가정하자. 위 마지막 식에서 급수의 범위 $X&lt;/em&gt; {u}^{f}$를 $X_ {u}^{0}$로 대체하고 추가적인 가정을 이용하면,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\approx \frac{X_ {u}^{f}}{X_ {u}^{o}} \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u}^{f})}  \sum_ {a \in X_ {u}^{0}} \left[  \log \text{Cat}(1_ {a} \vert \pi(z_ {u})) - \frac{1}{\vert X_ {u}^{f}\vert} \text{KL}_ {u}^{f}\right] + C$
$\approx \frac{X_ {u}^{f}}{X_ {u}^{o}} \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u})}  \sum_ {a \in X_ {u}^{0}} \left[  \log \text{Cat}(1_ {a} \vert \pi(z_ {u})) - \frac{1}{\vert X_ {u}^{f}\vert} \text{KL}_ {u}\right] + C$
$= \frac{X_ {u}^{f}}{X_ {u}^{o}} \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u})} \left[  \sum_ {a \in X_ {u}^{0}} \log \text{Cat}(1_ {a} \vert \pi(z_ {u})) - \frac{\vert X_ {u}^{0}\vert}{\vert X_ {u}^{f}\vert} \text{KL}_ {u}\right] + C$
$= \frac{X_ {u}^{f}}{X_ {u}^{o}} \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u})} \left[  \log \text{Multinomial}(x_ {u} \vert \pi(z_ {u})) - \frac{\vert X_ {u}^{0}\vert}{\vert X_ {u}^{f}\vert} \text{KL}_ {u}\right] + C$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;만약 $u$ 마다 $\vert X_ {u}^{f} \vert$가 일정하다면 새로운 상수 $\gamma = \frac{1}{\vert X_ {u}^{f} \vert}$를 정의하여 최종적으로 다음을 얻는다. (기댓값의 계수는 제거 할 수 있다.)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\mathcal{L} \approx \mathbb{E}_ {q_ {\phi}(z_ {u} \vert x_ {u})} \left[  \log \text{Multinomial}(x_ {u} \vert \pi(z_ {u})) - \gamma \vert X_ {u}^{0}\vert \text{KL}_ {u}\right]$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이와 같은 방법으로 암시적인 피드백이 주어졌을 때 $\beta = \beta(x)$를 $\gamma \vert X_ {u}^{0}\vert$로 선택 할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;34-summary&quot;&gt;&lt;strong&gt;3.4 Summary&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;섹션 3.1, 3.2, 3.3의 결과를 종합하여 개선 손실 함수를 제안한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\mathcal{L} &lt;em&gt;{\text{RecVAE}} = \mathbb{E}&lt;/em&gt; {q_ {\phi}(z \vert x)} \mathbb{E}_ {p(\tilde{x} \vert x)}\left[ \log p_ {\theta}(x \vert z) - \beta(x) \text{KL}({q_ {\phi}(z \vert \tilde{x})} \parallel p(z \vert \phi_ {\text{old}}, x) )\right]$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;모델 훈련을 마친 뒤, 새로운 사용자에 $x$에 대해서 $p_ {\theta}( x \vert q_ {\phi}(z \vert x))$은 항목 별 긍정적으로 평가할 확률을 준다. 이를 이용하여 상위 항목을 추천 해줄 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;4-experiment&quot;&gt;&lt;strong&gt;4. Experiment&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;RecVAE는 Adam&lt;sup id=&quot;fnref:12&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;옵티마이저로 최적화 됐으며 $\text{lr} = 5*10^{-4}$와 $500$의 배치 크기가 사용되었다. 노이즈는 평균이 $0.5$인 베르누이 분포로 주입됐고 성능을 향상시키위해 $N(0,10I)$을 복합 사전분포에 추가했다. 즉, $p(z)$, $q_ {\phi_ {\text{old}}}$, $N(0,10I)$가 복합 사전분포로 사용됐고 각각의 비율은 3:15:2가 적합했다. $\gamma$는 교차검증 (Cross-validation)을 통해 데이터마다 다른 값을 선택했다.&lt;/p&gt;

&lt;h3 id=&quot;41-datasets&quot;&gt;&lt;strong&gt;4.1 Datasets&lt;/strong&gt;&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;데이터 차원&lt;/th&gt;
      &lt;th&gt;평가된 항목 수&lt;/th&gt;
      &lt;th&gt;$\gamma$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;MovieLens-20M&lt;/td&gt;
      &lt;td&gt;(136677, 20720)&lt;/td&gt;
      &lt;td&gt;9,990,682&lt;/td&gt;
      &lt;td&gt;0.005&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Netflix Prize Dataset&lt;/td&gt;
      &lt;td&gt;(463435, 17769)&lt;/td&gt;
      &lt;td&gt;56,880,037&lt;/td&gt;
      &lt;td&gt;0.0035&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Million Songs Dataset&lt;/td&gt;
      &lt;td&gt;(571355, 41140)&lt;/td&gt;
      &lt;td&gt;33,633,450&lt;/td&gt;
      &lt;td&gt;0.01&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;RecVAE는 MovieLens-20M&lt;sup id=&quot;fnref:13&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:13&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;, Netflix Prize Dataset&lt;sup id=&quot;fnref:14&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:14&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt;, Million Songs Dataset&lt;sup id=&quot;fnref:15&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:15&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;15&lt;/a&gt;&lt;/sup&gt;에서 평가되었으며 위 표는 각 데이터의 정보와 사용된 $\gamma$를 나타낸다. 각 데이터는 8:2의 비율로 훈련데이터와 평가데이터로 분리됐다.&lt;/p&gt;

&lt;h3 id=&quot;42-baselines&quot;&gt;&lt;strong&gt;4.2 Baselines&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;모델을 비교하기 위해서 3가지 유형의 모델들을 비교할 것이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Linear models from classical collaborative filtering
    &lt;ul&gt;
      &lt;li&gt;Weighted Matrix Factorization (WMF)&lt;sup id=&quot;fnref:16&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:16&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;16&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
      &lt;li&gt;Sparse LInear Method (SLIM)&lt;sup id=&quot;fnref:17&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:17&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;17&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
      &lt;li&gt;Embarrassingly Shallow Autoencoder (EASE)&lt;sup id=&quot;fnref:18&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:18&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;18&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Rank method
    &lt;ul&gt;
      &lt;li&gt;WARP&lt;sup id=&quot;fnref:19&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:19&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;19&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
      &lt;li&gt;LambdaNet&lt;sup id=&quot;fnref:20&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:20&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;20&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Autoencoder-based method
    &lt;ul&gt;
      &lt;li&gt;CDAE&lt;sup id=&quot;fnref:1:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
      &lt;li&gt;Mult-DAE &amp;amp; Mult-VAE&lt;sup id=&quot;fnref:2:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
      &lt;li&gt;Ranking-Critical Training (RaCT)&lt;sup id=&quot;fnref:21&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:21&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;21&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;43-evaluation-metrics&quot;&gt;&lt;strong&gt;4.3 Evaluation Metrics&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;테스트 유저 $u$의 항목 $X_ {u}^{t}$와 모델의 (내림차순) 결과 $R_ {u}^{(n)}$에 대해서 $\text{Recall@}k(u)$와 $\text{NDCG@}(k(u)$가 평가 지표로서 사용될 것이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\text{Recall@}k(u) = \frac{1}{\min(\vert R_ {u}^{(n)} \vert, \vert X_ {u}^{t} \vert)} \sum_{n=1}^{k} 1\left[R_ {u}^{(n)} \in  X_ {u}^{t} \right]$ 
$\text{DGG@}k(u) = \sum_{n=1}^{k}\frac{2^{1\left[R_ {u}^{(n)} \in  X_ {u}^{t} \right]}-1}{\log(n+1)}$
$\text{NDCG@}(k(u) = \text{DCG@}k(u) / \left( \sum_{n=1}^{\vert X_ {u}^{t} \vert } \frac{1}{\log(n+1)} \right)$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;44-results&quot;&gt;&lt;strong&gt;4.4 Results&lt;/strong&gt;&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://i.ibb.co/ZdpKqMG/2023-10-15-001248.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;RecVAE을 각 경쟁 모델과 비교한 결과이다. 볼드체는 가장 좋은 결과이며 밑줄은 두번째로 좋은 결과이다. Million Songs Dataset에서는 EASE가 좋은 성능을 보이지만 나머지 결과에선 RecVAE가 좋은 모습을 보여준다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://i.ibb.co/yWsMDnT/2023-10-15-001902.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;인코더 설계, 복합 사전분포, $\beta$ 조정, 교대훈련, 노이즈 주입에 대한 제거 연구 (Ablation Study)에 대한 결과이다. 교대훈련이란 인코더와 디코더를 동시에 훈련하지 않고 각각 훈련하는 것을 의미한다. 위 표에 따르면 각각의 기능은 성능 향상에 도움이 된다. 일부 기능은 개별적으로 적용되는 것보다 함께 사용되는 것이 효과적이다. (예를 들어, $\beta$ 조정과 교대훈련)&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://i.ibb.co/VJqBBFt/2023-10-15-002402.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;위 그래프는 복합 사전분포의 용이함을 증명하기 위해 임의로 선택된 사용자의 에폭 (epoch)에 따른 NDCG@100의 변화량을 그린 것이다. 기존의 가우시안 사전분포 보다 복합 사전분포의 변동량이 더욱 안정적인 것을 확인 할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;&lt;strong&gt;5. Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이 논문에서는 Mult-VAE의 개선된 버전인 RecVAE를 제안한다. 이는 새로운 인코더 구조, 복합 사전분포, 협업필터링에 알맞은 $\beta$ 조정 방식을 포함하고 있으며, 여러가지 데이터에서 다른 모델의 성능을 능가했다. 향후 연구 방향으로서 주목되는 점은 (1) 이 방법을 유저와 항목을 뒤바꾸어 실험하면 어떻게 될지, (2) 사전분포를 더욱 복잡하게 만들면 어떻게 될지, (3) 컨벡스 결합이 아닌 다른 방법의 정규화를 이용하여 forgetting problem을 해결할 수 있는지와 같은 것이 고려된다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;additional-materials--references&quot;&gt;&lt;strong&gt;Additional materials &amp;amp; References&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Code Availability&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;https://github.com/ilya-shenbin/RecVAE&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Author information&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ilya Shenbin
    &lt;ul&gt;
      &lt;li&gt;Samsung-PDMI Joint AI Center&lt;/li&gt;
      &lt;li&gt;ilya.shenbin@gmail.com&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Anton Alekseev
    &lt;ul&gt;
      &lt;li&gt;Samsung-PDMI Joint AI Center&lt;/li&gt;
      &lt;li&gt;anton.m.alexeyev@gmail.com&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Elena Tutubalina
    &lt;ul&gt;
      &lt;li&gt;Samsung-PDMI Joint AI Center&lt;/li&gt;
      &lt;li&gt;tutubalinaev@gmail.com&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Valentin Malykh
    &lt;ul&gt;
      &lt;li&gt;Neural Systems and Deep Learning Laboratory&lt;/li&gt;
      &lt;li&gt;valentin.malykh@phystech.edu&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Sergey I. Nikolenko
    &lt;ul&gt;
      &lt;li&gt;Samsung-PDMI Joint AI Center&lt;/li&gt;
      &lt;li&gt;sergey@logic.pdmi.ras.ru&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Yao Wu, Christopher DuBois, Alice X Zheng, and Martin Ester. 2016. Collaborative denoising auto-encoders for top-n recommender systems. In Proceedings of the Ninth ACM International Conference on Web Search and Data Mining. ACM, 153–162. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:1:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;a href=&quot;#fnref:1:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. 2018. Variational autoencoders for collaborative filtering. In Proceedings of the 2018 World Wide Web Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 689–698. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:2:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;a href=&quot;#fnref:2:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2017. BetaVAE: Learning basic visual concepts with a constrained variational framework. In International Conference on Learning Representations, Vol. 3. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:3:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Daniel Im Jiwoong Im, Sungjin Ahn, Roland Memisevic, and Yoshua Bengio. 2017. Denoising criterion for variational auto-encoding framework. In Thirty-First AAAI Conference on Artificial Intelligence. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Kihyuk Sohn, Honglak Lee, and Xinchen Yan. 2015. Learning structured output representation using deep conditional generative models. In Advances in neural information processing systems. 3483–3491. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Oleg Ivanov, Michael Figurnov, and Dmitry P. Vetrov. 2019. Variational Autoencoder with Arbitrary Conditioning. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net. https://openreview.net/forum?id=SyxtJh0qYm. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Gao Huang, Zhuang Liu, and Kilian Q. Weinberger. 2016. Densely Connected Convolutional Networks. CoRR abs/1608.06993 (2016). arXiv:1608.06993 http: //arxiv.org/abs/1608.06993. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Prajit Ramachandran, Barret Zoph, and Quoc V. Le. 2018. Searching for Activation Functions. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings. OpenReview.net. https://openreview.net/forum?id=Hkuq2EkPf. &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. 2016. Layer Normalization. arXiv e-prints, Article arXiv:1607.06450 (Jul 2016), arXiv:1607.06450 pages. arXiv:stat.ML/1607.06450. &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Rein Houthooft, Xi Chen, Yan Duan, John Schulman, Filip De Turck, and Pieter Abbeel. 2016. Vime: Variational information maximizing exploration. In Advances in Neural Information Processing Systems. 1109–1117. &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy Bengio. 2016. Generating Sentences from a Continuous Space. In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning. 10–21. &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, Yoshua Bengio and Yann LeCun (Eds.). http://arxiv.org/abs/1412.6980 &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:13&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst. 5, 4, Article 19 (Dec. 2015), 19 pages. https://doi.org/10.1145/2827872. &lt;a href=&quot;#fnref:13&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:14&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;James Bennett, Stan Lanning, et al. 2007. The netflix prize. In Proceedings of KDD cup and workshop, Vol. 2007. New York, NY, USA., 35. &lt;a href=&quot;#fnref:14&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:15&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere. 2011. The Million Song Dataset. In Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR 2011). &lt;a href=&quot;#fnref:15&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:16&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for implicit feedback datasets. In 2008 Eighth IEEE International Conference on Data Mining. Ieee, 263–272. &lt;a href=&quot;#fnref:16&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:17&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Xia Ning and George Karypis. 2011. Slim: Sparse linear methods for top-n recommender systems. In 2011 IEEE 11th International Conference on Data Mining. IEEE, 497–506. &lt;a href=&quot;#fnref:17&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:18&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Harald Steck. 2019. Embarrassingly Shallow Autoencoders for Sparse Data. In The World Wide Web Conference. ACM, 3251–3257. &lt;a href=&quot;#fnref:18&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:19&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Jason Weston, Samy Bengio, and Nicolas Usunier. 2011. Wsabie: Scaling up to large vocabulary image annotation. In Twenty-Second International Joint Conference on Artificial Intelligence. &lt;a href=&quot;#fnref:19&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:20&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Christopher J Burges, Robert Ragno, and Quoc V Le. 2007. Learning to rank with nonsmooth cost functions. In Advances in neural information processing systems. 193–200. &lt;a href=&quot;#fnref:20&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:21&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Sam Lobel, Chunyuan Li, Jianfeng Gao, and Lawrence Carin. 2019. Towards Amortized Ranking-Critical Training for Collaborative Filtering. arXiv preprint arXiv:1906.04281 (2019). &lt;a href=&quot;#fnref:21&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-RecVAE_a_New_Variational_Autoencoder_for_Top-N_Recommendations_with_Implicit_Feedback.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-RecVAE_a_New_Variational_Autoencoder_for_Top-N_Recommendations_with_Implicit_Feedback.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[KDD 2022] ROLAND: Graph Learning Framework for Dynamic Graphs</title>
            <description>&lt;!-- ---
title: ROLAND Reivew
sidebar: Introduction_sidebar
keywords: introduction
permalink: template.html
toc: true
folder: introduction
--- --&gt;

&lt;h1 id=&quot;roland-graph-learning-framework-for-dynamic-graphs&quot;&gt;&lt;strong&gt;ROLAND: Graph Learning Framework for Dynamic Graphs&lt;/strong&gt;&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2208.07239&quot;&gt;Paper Link&lt;/a&gt;
&lt;a href=&quot;https://github.com/snap-stanford/roland&quot;&gt;Github Implementation&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 논문은 기존 연구들에서 제시한 dynamic graph에서의 graph representation learning의 한계점을 제시하고, static GNN에서 사용하던 테크닉들을 dynamic graph에서 활용할 수 있는 새로운 방법론인 ROLAND를 제시하였다.&lt;/p&gt;

&lt;h3 id=&quot;before-we-start&quot;&gt;&lt;strong&gt;Before We Start&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Static Graph&lt;/strong&gt;: 시간에 따라 변하지 않는 graph를 의미한다.
    &lt;ul&gt;
      &lt;li&gt;$G = {V, E, X}$
        &lt;ul&gt;
          &lt;li&gt;$V$: node set&lt;/li&gt;
          &lt;li&gt;$E$: edge set&lt;/li&gt;
          &lt;li&gt;$X$: attribute matrix&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dynamic Graph&lt;/strong&gt;: 시간에 따라 node, edge, attribute 등이 변화하는 graph를 의미한다.
    &lt;ul&gt;
      &lt;li&gt;$G(t) = {V(t), E(t), X_ {v}(t), X_ {e}(t)}$
        &lt;ul&gt;
          &lt;li&gt;$V(t)$: node set in timestep $t$&lt;/li&gt;
          &lt;li&gt;$E(t)$: edge set in timestep $t$&lt;/li&gt;
          &lt;li&gt;$X_v(t)$: node attribute matrix in timestep $t$&lt;/li&gt;
          &lt;li&gt;$X_e(t)$: edge attribute matrix in timestep $t$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Graph Nerual Network (GNN)&lt;/strong&gt;: GNN의 목적은 local network neighborhood로 부터 반복적인 message aggregation을 통해 node embedding을 learn하는 것이다.
    &lt;ul&gt;
      &lt;li&gt;&lt;img src=&quot;https://i.ibb.co/vV6W0th/2023-10-15-03-43-26.png&quot; alt=&quot;img_gnn&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;$h^{(l)}$: $l$-th layer GNN을 apply 한 모든 node들의 embedding&lt;/li&gt;
          &lt;li&gt;$m^{(l)}$: $l$-th layer에서의 message embedding&lt;/li&gt;
          &lt;li&gt;$MSG^{(l)}()$: $l$-th layer message-passing function, 다양한 종류의 function이 있음&lt;/li&gt;
          &lt;li&gt;
            &lt;h2 id=&quot;aggl-l-th-layer-aggregation-function-다양한-종류의-function이-있음&quot;&gt;$AGG^{(l)}()$: $l$-th layer aggregation function, 다양한 종류의 function이 있음&lt;/h2&gt;
            &lt;h2 id=&quot;introduction&quot;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dynamic graph를 training 하는 것은 fraud detection, anti-money laundering, recommender systems 등 다양한 도메인에서 활용될 수 있다. 그렇기에 다양한 연구들을 통해 dynamic graph를 위한 GNN들이 개발되었지만 크게 다음과 같은 한계점들이 존재했다.&lt;/p&gt;

&lt;h4 id=&quot;limitations&quot;&gt;Limitations&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:red&quot;&gt; Model Design &lt;/span&gt;
    &lt;ul&gt;
      &lt;li&gt;기존 dynamic graph 모델들은 성능이 좋은 static GNN 아키텍쳐를 응용하는 것에 실패했다.
        &lt;ul&gt;
          &lt;li&gt;GNN을 feature encoder로 사용한 후 sequence 모델 얹기&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Skip-connection, batch normalization, edge embedding과 같은 테크닉들은 static graph GNN message passing에 효과적인 성능을 보여줬지만, dynamic graph에서는 응용되지 못하고 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:green&quot;&gt; Evaluation &lt;/span&gt;
    &lt;ul&gt;
      &lt;li&gt;기존 연구들에서는 dynamic graph를 training 시키기 위해 dataset을 training, validation, test dataset으로 나눌 때 단순히 앞에서 부터 6:2:2로 자르는 등의 방법을 사용하였다.&lt;/li&gt;
      &lt;li&gt;이는 dynamic graph가 가지는 시간에 따른 dataset distribution이 변화할 수 있다는 특성을 고려하지 않은 dataset 분리 방법이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:blue&quot;&gt; Training &lt;/span&gt;
    &lt;ul&gt;
      &lt;li&gt;대부분의 dynamic GNN에서는 모든 timestep $t$에 대한 그래프 정보 $G(t)$를 GPU 메모리에 저장해야 하기 때문에 scalability issue가 있다.&lt;/li&gt;
      &lt;li&gt;그렇기에 edge 개수 200만개 이하의 작은 graph들로 실험을 진행하는 등의 문제가 있었다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ROLAND는 dynamic graph의 snapshot-based representation을 바탕으로 위의 limitation들을 타개하여 static GNN의 state-of-the-art 아키텍쳐들을 활용할 수 있도록 만들어졌다.&lt;/p&gt;

&lt;!-- &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;[http://some_place.com/image.png](https://i.ibb.co/RbLYk5J/2023-10-15-03-18-58.png)&quot; /&gt;
&lt;/p&gt; --&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/RbLYk5J/2023-10-15-03-18-58.png&quot; alt=&quot;img_fig1&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;tackling-the-limitations&quot;&gt;Tackling the Limitations&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:red&quot;&gt; Model Design &lt;/span&gt;
    &lt;ul&gt;
      &lt;li&gt;Static GNN에서 다른 GNN layer에 있는 node embedding들을 &lt;em&gt;hierarchical node state&lt;/em&gt;들로 보는 새로운 관점을 제시하였다.&lt;/li&gt;
      &lt;li&gt;Static GNN을 dynamic하게 generalize하기 위해서는 &lt;em&gt;hierarchical node state&lt;/em&gt;들을 새롭게 관찰되는 node와 edge들을 어떻게 이용하여 update할 지 정해야 한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:green&quot;&gt; Evaluation &lt;/span&gt;
    &lt;ul&gt;
      &lt;li&gt;Dynamic graph에서 live-update를 할 수 있는 evaluation setting을 제시하였다.
        &lt;ul&gt;
          &lt;li&gt;일별이나 주별로 batch를 만들어 evaluation을 진행하고 update를 할 수 있도록 하였다.&lt;/li&gt;
          &lt;li&gt;Data distribution이 timestep $t$에 따라 변화하는 dynamic graph의 특성을 고려하여 model update를 할 수 있다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:blue&quot;&gt; Training &lt;/span&gt;
    &lt;ul&gt;
      &lt;li&gt;시간에 따른 모든 graph를 저장하는 것이 아닌 training 할 때 새로운 graph snapshot과 과거의 node state 정보들만 GPU 메모리에 저장하였다.
        &lt;ul&gt;
          &lt;li&gt;이로 인해 5600만개의 edge들을 가지는 큰 graph를 train 시킬 수 있었다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Dynamic graph에서의 timestep $t$가 다른 prediction 문제들을 다른 task로 생각함으로써 문제를 meta-learning problem으로 formulation하였다.
        &lt;ul&gt;
          &lt;li&gt;위의 Figure 1 참고&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;proposed-roland-framework&quot;&gt;&lt;strong&gt;Proposed ROLAND Framework&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이제 위의 Tackling the Limitations를 조금 더 자세히 살펴보고자 한다. 해당 논문에서 다루는 자세한 notation들은 &lt;a href=&quot;https://arxiv.org/abs/2208.07239&quot;&gt;paper&lt;/a&gt;을 직접 참고하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;model_design&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;-model-design-&quot;&gt;&lt;span style=&quot;color:red&quot;&gt; Model Design &lt;/span&gt;&lt;/h4&gt;

&lt;p&gt;먼저 작가들은 Figure 2에 기존의 static GNN과 이를 어떻게 dynamic GNN에 응용할지를 그림으로 나타내었다. 아래 Figure 2-(b)에서 볼 수 있듯이, embedding update 라는 블록을 통해 &lt;em&gt;hierarchical node state&lt;/em&gt; $H$를 update 시켜줌으로써 static GNN을 쉽게 dynamic GNN으로 확장시켰다. 이 방법론대로라면 skip connection, batch normalization 등 static GNN에서 사용되던 효과적인 테크닉들을 dynamic GNN에서도 그대로 활용할 수 있다는 장점이 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/C6cjxnN/2023-10-15-13-39-08.png&quot; alt=&quot;img_fig2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결국 이 모델의 핵심은 &lt;em&gt;hierarchical node state&lt;/em&gt; $H$를 어떻게 update할 지인데, 이는 algorithm 1에 자세히 소개되어 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/t4VbsPV/2023-10-15-13-40-33.png&quot; alt=&quot;img_algo1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 논문에서 $GNN^ {(l)}$ 내부에 message embedding의 정보를 합치는 $AGG$ 함수로 sum, max, mean을 제안하였고, node embedding을 update하는 $UPDATE^ {(l)}$ 함수로 기존에 사용되던 간단하지만 효과적인 Moving Average, MLP, GRU를 제안하였다. 이는 기존 static GNN에서 사용하던 테크닉을 그대로 가져온 것으로 보인다.
모든 update가 끝나면 node $u$에서 $v$로 edge가 생길 확률을 $y_ {t}$를 MLP prediction head 블록을 통해 예측한다. 여기서 예측한 값은 다음에 설명될 live-update evaluation에 사용되어 모델을 update하는 것에 사용된다.&lt;/p&gt;

&lt;h4 id=&quot;-evaluation-&quot;&gt;&lt;span style=&quot;color:green&quot;&gt; Evaluation &lt;/span&gt;&lt;/h4&gt;

&lt;p&gt;기존 GNN 연구들에서는 통상적으로 train, test, validation dataset을 단순히 timestep 앞에서부터 6:2:2로 나누는 방식을 사용해왔다. 하지만, 이는 앞서 언급했듯이 변화하는 data distribution을 고려하지 못하게 되는 치명적인 단점이 있다. 이 paper에서는 해당 문제를 live-update evaluation을 제안함으로써 해결한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/c8B4z0C/2023-10-15-15-03-03.png&quot; alt=&quot;img_fig3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 Figure 3에서 볼 수 있듯이, 이전 시점의 node embedding과 현재 시점의 새로운 graph snapshot을 input으로 GNN에 넣어 prediction $\hat{y}_ {t}$를 얻은 후, 실제  $y_ {t}$와 비교하여 mean reciprocal rank (MRR)을 통해 평가하게 된다. 자세한 training 과정은 아래 algorithm 2에 소개되어 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/jrSF50V/2023-10-15-15-02-46.png&quot; alt=&quot;img_algo2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Update에 앞서서 먼저 live-update를 위한 link predicion label들을 각 timestep에 모아준 후, training set과 validation set으로 나누어준다. Training set $y^ {(train)}$은 GNN을 fine-tuning하는 것에 사용되고, validation set $y^ {(val)}$은 early stopping criterion으로써 활용된다 (Algorithm 2의 3, 5 ,6번째 줄). 이는 $y^ {(val)}$으로 계산된 $MRR^ {(val)}$이 증가하는 것이 멈출 때까지 반복된다 (Algorithm 2의 4, 7번째 줄).
$MRR$은 propose 된 결과들 중 실제 값이 몇 번째 rank에 있는지에 관련된 metric이다. 예를 들어, 단수형 단어가 주어졌을 때 복수형 단어를 맞춰야하는 task가 있다고 생각해보자. 이 때, apple을 input으로 주고 모델이 appl, apples, applet 를 뱉었다면 Rank는 $2$, Reciprocal Rank ($RR$)는 그의 역수인 $\frac{1}{2}$로 정의된다. $MRR$은 모든 $RR$의 평균으로 input query를 $Q$라 할 때 다음과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;$ MRR=\frac{1}{\vert Q \vert} \sum_ {i=1}^ {\vert Q \vert} \frac{1}{rank_ {i}} $&lt;/p&gt;

&lt;p&gt;Training이 모두 끝나면 각 timestep $t$에 계산된 $MRR_ {t}$의 평균을 performance metric으로 사용하여 모델을 평가한다.&lt;/p&gt;

&lt;h4 id=&quot;-training-&quot;&gt;&lt;span style=&quot;color:blue&quot;&gt; Training &lt;/span&gt;&lt;/h4&gt;

&lt;p&gt;위 Figure 3에 제시된 ROLAND의 아키텍처를 살펴보면, 각 시점에서 GNN을 update하는 것에 필요한 input은 이전 시점 node embedding $H_ {t-1}$과 새롭게 들어오는 graph snapshot $G_ {t}$임을 알 수 있다. 때문에, ROLAND의 memory complexity는 graph snapshot의 개수에 agnostic하고 scalable함을 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/42gtLdr/2023-10-15-16-19-14.png&quot; alt=&quot;img_algo3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ROLAND에서 제안된 또 다른 방법론 한 가지는 dynamic graph에서의 prediction task를 meta-learning 문제로 formulation하는 것이다. 예를 들어, daily graph snapshot이 input이라고 생각했을 때, 금요일의 모델과 토요일의 모델은 크게 다를 것이다. 때문에 금요일 모델을 단순히 fine-tuning 후 토요일 모델이라고 하는 것은 모델 성능에 좋지 않은 영향을 끼칠 수 있다. 이에 대해 작가들은 meta-model $GNN^ {(meta)}$를 찾는 Algorithm 3을 위와 같이 제시하였다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;experiments&quot;&gt;&lt;strong&gt;Experiments&lt;/strong&gt;&lt;/h2&gt;

&lt;h4 id=&quot;experiment-setup&quot;&gt;&lt;strong&gt;Experiment setup&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Datasets&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;아래 표는 이 paper에서 사용된 dataset의 종류와 각 dataset의 특성을 정리해 둔 표이다.&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;https://i.ibb.co/3hZv9MX/2023-10-15-17-18-24.png&quot; alt=&quot;img_table1&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Baselines&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;EvolveGCN-H&lt;/li&gt;
      &lt;li&gt;EvolveGCN-O&lt;/li&gt;
      &lt;li&gt;T-GCN&lt;/li&gt;
      &lt;li&gt;GCRN-GRU&lt;/li&gt;
      &lt;li&gt;GCRN-LSTM&lt;/li&gt;
      &lt;li&gt;GCRN-Baseline&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Evaluation Metric&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Mean Reciprocal Rank (MRR)
        &lt;ul&gt;
          &lt;li&gt;$ MRR=\frac{1}{\vert Q \vert} \sum_ {i=1}^ {\vert Q \vert} \frac{1}{rank_ {i}} $&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;results&quot;&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;실험은 크게 기존 dataset splitting 방법과 논문에서 제시한 live-update를 적용한 방법 두 가지로 진행되었다. 먼저 아래 Table 2는 기존의 dataset splitting 방법을 사용하여 dataset을 나눴을 때 각 baseline들과 ROLAND의 결과이다. ROALND는 앞에 &lt;a href=&quot;#model_design&quot;&gt;Model Design&lt;/a&gt;에서 제시한 것과 같이 $UPDATE$ 함수를 Moving Average, MLP, GRU 3가지를 사용하여 결과를 비교했다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/8b3P8q6/2023-10-15-17-19-54.png&quot; alt=&quot;img_table2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;모든 dataset에서 ROLAND GRU가 가장 좋은 baseline 대비 $MRR$이 적게는 43.33%에서 많게는 73.74% 향상된 결과를 보여주었다.
Table 3에는 이 paper에서 제시한 live-update 방법을 활용하여 train 시켰을 때의 결과를 기재하였다. 마찬가지로, 한가지 dataset을 제외한 모든 dataset에서 baseline들 대비 큰 $MRR$ 향상을 보여주었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.ibb.co/nPTtyWx/2023-10-15-17-53-45.png&quot; alt=&quot;img_table3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ROLAND에서 제시한 meta-model $GNN^ {(meta)}$를 사용하면 평균 performance가 적게는 2.84%에서 많게는 13.19% 증가하는 결과를 보여주었다. 더하여, $GNN^ {(meta)}$를 사용했을 때 $MRR$의 standard deviation이 줄어듦으로써 stability가 높아짐을 보였다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;이 논문은 기존 static GNN에서 사용하던 테크닉과 아키텍처들을 dynamic graph에 어떻게 적용할 수 있을지 제안하였다. Paper은 크게 model design, evaluation, training 3가지 부분으로 나누어 기존 연구들의 한계점과 ROLAND의 contribution을 정리하였다.
새로운 dynamic GNN 모델을 scratch부터 만들지 않고 static GNN과 dynamic GNN을 연결하는 다리를 제안했다는 점, 그리고 live-update를 통해 scalability issue를 해결했다는 점에서 이 논문의 contribution이 큰 것 같다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;author-information&quot;&gt;&lt;strong&gt;Author Information&lt;/strong&gt;&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Author name: Haeun Jeon&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Contact: haeun39@kaist.ac.kr&lt;/li&gt;
    &lt;li&gt;Affiliation: Financial Engineering Lab., KAIST&lt;/li&gt;
    &lt;li&gt;Research Topic: Stochastic Optimization, End-to-end learning, Portfolio Optimization&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;!-- ## **6. Reference &amp; Additional materials**  

Please write the reference. If paper provides the public code or other materials, refer them.  

&gt; [Github Implementation](https://github.com/snap-stanford/roland)
* Reference   --&gt;
</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-ROLAND_Graph_Learning_Framework_for_Dynamic_Graphs.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-ROLAND_Graph_Learning_Framework_for_Dynamic_Graphs.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
        <item>
            <title>[TSRML 2022] Private Data Leakage via Exploiting Access Patterns of Sparse Features in Deep Learning-based Recommendation Systems</title>
            <description>&lt;h1 id=&quot;private-data-leakage-via-exploiting-access-patterns-of-sparse-features-in-deep-learning-recommendation-systems&quot;&gt;Private Data Leakage via Exploiting Access Patterns of Sparse Features in Deep Learning Recommendation Systems&lt;/h1&gt;
&lt;h5 id=&quot;2022-trustworthy-and-socially-responsible-machine-learning-tsrml-2022-co-located-with-neurips-2022&quot;&gt;[2022 Trustworthy and socially responsible Machine learning (TSRML 2022) co-located with NeurIPS 2022]&lt;/h5&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Sparse and dense features are used in the deep learning-based recommendation models to carry user’s private information and this private data is often protected by the service providers using methods like memory encryption or hashing. In this paper, it is shown that irrespective of the protection used, the attacker would still be able to &lt;em&gt;learn information about which entry of the sparse feature is non-zero through the concept of embedding table access pattern&lt;/em&gt; posing a big threat to the security of customer’s sensitive data.&lt;/p&gt;

&lt;h2 id=&quot;problem-definition&quot;&gt;Problem Definition&lt;/h2&gt;

&lt;p&gt;Deep learning-based recommendation system models exploit different types of information related to the user including user attributes, user preferences, user behavior, social interaction and other contextual information to help the customers with better recommendations and companies with increased revenues. Now, there are two types of features as inputs to a deep neural network to make predictions of items a user may like, namely sparse and dense features.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The sparse sparce features contain only a few non-zero features whereas the dense features contain a large number of non-zero attributes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;These features store the information of a user as well the items in different forms. Sparse features are the discrete and categorical attributes associated with users and items whereas the dense features are the continuous and numerical ones. These features contain information which is personal to the user and is protected by the service provider with the help of memory encryption with hardware such as Intel’s SGX. However, we will look into some of the attacks an attacker may proceed with, with the purpose of stealing user’s personal information where methods like encryption or hash functions may not be useful and information like &lt;em&gt;which entries of the sparse features may be non-zero&lt;/em&gt; can be leaked.
This is because sparse features have to be projected into the lower dimensional space through an embedding table where the index of the non-zero entries are used as an index for an embedding table lookup. It is shown in this paper, how this leakage could be enough threat to the sensitive information of the users.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Embedding table is a data structure used to represent and store embeddings of these sparse features, and access patterns means to study how the users interact with the items. So, embedding table access patterns means accessing the patterns of the sparse features embedded into an embedding table.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It is demonstrated in the paper how it is possible to identify or extract sensitive information of a user with the help of embedding table access patterns under 4 different types of attacks:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Identification Attack&lt;/strong&gt;: identifying a user by with the help of combinations of unidentifiable features&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sensitive Attribute Attack&lt;/strong&gt;: identifying a user by analyzing the user-item interaction behavior&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Re-Identification Attack&lt;/strong&gt;: identifying a user by tracking the same user by analyzing their interaction history.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hash Inversion with Frequency-based Attack&lt;/strong&gt;: showing how hashing the sensitive information may not be able to protect it against the attacks, by demonstrating a hash inversion attack based on access frequency.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;working-of-the-dlrm-model-and-threat-model&quot;&gt;Working of the DLRM Model and Threat Model&lt;/h2&gt;

&lt;p&gt;The figure above shows the operation of the representative recommendation model, DLRM. In DLRM, the dense features go through a bottom MLP (multi-layer perceptron) layer whereas the sparse features go through an embedding table layer and get converted into lower-dimensional dense features. Then, these two outputs go through a feature interaction layer and then through a top MLP layer to predict the likelihood of an interaction.
Embedding tables play a pivotal role in transforming the sparse categorical feature into a dense numerical representation. Let’s consider an example to understand this. Consider a scenario where users and movies are represented by categorical features such as user IDs and movie genres, respectively. To effectively utilize these features within a deep learning model, embedding tables are employed. These tables act as large lookup tables, with each row corresponding to a unique category or ID. To convert sparse features into dense representations, a lookup operation is performed using the non-zero entries in the sparse feature as an index. For instance, to convert a specific user’s ID into a dense representation, the corresponding row in the user embedding table is accessed, and similarly, for movie genres, the relevant row in the genre embedding table is retrieved. The outcome of these operations is a dense vector, a numerical representation of the user or genre in a multi-dimensional space. These dense representations are subsequently utilized in the recommendation system’s deep learning model, enabling accurate and personalized movie recommendations based on user preferences and movie genres. This process highlights the critical role of embedding tables.&lt;/p&gt;
&lt;h4 id=&quot;threat-model&quot;&gt;Threat Model&lt;/h4&gt;
&lt;p&gt;Now, even when the entire dense and sparse features are fully encrypted and are processed under a secure environment, there is a possibility to learn which index holds a non-zero entry by looking at the table access patterns, resulting in compromising with the sensitive user data.
To understand the threat model, let’s assume the scenario. Let’s say a user shared their sensitive information with the service provider to get accurate recommendations from the system. Now, this sensitive information is fully protected with the Intel SGX team, but the access pattern of the embedding table is revealed, more specifically revealing which entries of the table are non-zero. The figure below, demonstrates our threat model.
Like this, even when the information is kept safe with the honest-but-curious service provider, the access pattern of the embedding table can help reveal that sensitive information.&lt;/p&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;p&gt;As also mentioned earlier, we will test out our theory of being able to extract sensitive information with the help of embedding table access patterns, with the help of four different types of attacks.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Attack&lt;/th&gt;
      &lt;th&gt;Goal&lt;/th&gt;
      &lt;th&gt;Assumptions&lt;/th&gt;
      &lt;th&gt;Evaluation Metric&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Identification&lt;/td&gt;
      &lt;td&gt;Finding the identity of the users&lt;/td&gt;
      &lt;td&gt;Attacker observes accesses, Has prior knowledge about distribution of accesses&lt;/td&gt;
      &lt;td&gt;K-anonymity&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sensitive Attribute&lt;/td&gt;
      &lt;td&gt;Extracting the sensitive user attributes&lt;/td&gt;
      &lt;td&gt;Attacker observes accesses, Has prior knowledge about distribution of accesses&lt;/td&gt;
      &lt;td&gt;Ambiguity&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Re-Identification&lt;/td&gt;
      &lt;td&gt;Tracking users over time based on interaction history&lt;/td&gt;
      &lt;td&gt;Attacker observes accesses&lt;/td&gt;
      &lt;td&gt;Precision and Recall&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hash Inversion with Frequency-based Attack&lt;/td&gt;
      &lt;td&gt;Finding users raw feature values&lt;/td&gt;
      &lt;td&gt;Attacker observes accesses, Has prior knowledge about distribution of accesses&lt;/td&gt;
      &lt;td&gt;Inversion Accuracy&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This table shows a summary of all the attacks, their goals and basic assumptions which have been used to prove the point of the sensitive information not being safe. Each of these attacks are discussed in detail.&lt;/p&gt;

&lt;h2 id=&quot;identification-attack-with-static-user-feature&quot;&gt;Identification Attack with Static User Feature&lt;/h2&gt;

&lt;p&gt;User profile attributes, such as gender, city, etc. are usually static in nature i.e., they don’t change with time. or the frequency of change is very low. We can categorize such features into two parts - identifiable and unidentifiable features.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Identifiable features are the features that are capable of directly or indirectly revealing the identity if the user. For example, name, city of residence, userID, etc.&lt;/li&gt;
    &lt;li&gt;Unidentifiable features are the features that can’t directly expose the identity of the user but can still provide valuable information. For example, gender, education level, search keywords, etc.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now due to strict regulations, most of the recommendation systems don’t usually collect and use the identifiable features. So, the question arises that are the unidentifiable features enough to make an accurate assumption of who the user might be?&lt;/p&gt;

&lt;h4 id=&quot;evaluation-setup&quot;&gt;Evaluation setup&lt;/h4&gt;
&lt;p&gt;To find out whether the unidentifiable features are enough to find out about the user, an open-source dataset by Alibaba has been used, containing static user features, such as userID, groupID, gender, age group, shopping depth, occupation, city level, etc. of around 11.4M users.&lt;/p&gt;

&lt;h4 id=&quot;attack-method&quot;&gt;Attack Method&lt;/h4&gt;
&lt;p&gt;After removing all the identifiable features from the dataset, we will be left with 2.1M possible combinations of the unidentifiable features, which would make any user believe that their identity is anonymous or that revealing any of the remaining unidentifiable features, won’t reveal their identity. However, in contrast to the user’s belief, it is observed that in the real world only 1120 combinations of these static feature values are possible based on the real open-source data. We refer to these 1120 combinations as user buckets.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;In simple words, user buckets are unique combinations of the feature values. The motto of the attacker can now be said to be able to recognize the users based on their unique combinations of features.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Taking the user bucket number as the x-axis and the percentage of the users per bucket as the y-axis, we plot the histogram to represent how the user distributions follow the long-tail pattern.
I can be seen from the histogram that there are only a few users in the bucket 600-1120 and in fact there are only 989 users on average across all these buckets and the last 56 buckets have only 1 user. So, these seemingly unidentifiable features may give away the user’s identity by allowing the attacker to launch an identification attack to extract the unique userID and identify the user with a high certainty.&lt;/p&gt;

&lt;h4 id=&quot;evaluation-metric&quot;&gt;Evaluation Metric&lt;/h4&gt;
&lt;p&gt;The evaluation metric we have used for this analysis is the &lt;em&gt;K-anonymity&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;K-anonymity is a privacy property that measure how well the user privacy is preserved.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If a user’s bucket number is revealed and there are K users in the same bucket then the probability of finding the user is 1/K.
The table given below summarizes the number of users with anonymity level below K in the identification attacks.
1-anonymity user means that this is the only user having this particular set of feature values.&lt;/p&gt;

&lt;h4 id=&quot;evaluation-results&quot;&gt;Evaluation Results&lt;/h4&gt;
&lt;p&gt;As shown in the above table, among 56 of the bucket users, there is only 1 user with the specific combination of static features which implies that an attacker can identify these users with 1-anonymity if they can observe this combination of feature values.&lt;/p&gt;

&lt;h2 id=&quot;sensitive-attribute-attack-by-dynamic-user-features&quot;&gt;Sensitive Attribute attack by Dynamic User Features&lt;/h2&gt;

&lt;p&gt;In this type of attack, we would see that even when the user’s hide, how the sensitive attributes such as age, gender, interest, etc. can be inferred by analyzing their user-item interaction behavior and how these sensitive features leak through other non-sensitive features through the concept of cross-correlations.&lt;/p&gt;

&lt;h4 id=&quot;evaluation-setup-1&quot;&gt;Evaluation setup&lt;/h4&gt;
&lt;p&gt;For the purpose of evaluation, we have used the Alibaba Ads Display dataset, which contains user-item interactions. This dataset contains around 723,268,134 tuples and each tuple contains information about the userID, categoryID, brand and btag (browse, cart, favour, buy)&lt;/p&gt;

&lt;h4 id=&quot;attack-method-1&quot;&gt;Attack Method&lt;/h4&gt;
&lt;p&gt;Let’s understand the attack method with the help of an example, say in the data, there are 7 age groups and 5 different brands. The user-item interaction based on the age-group and the brand is given below in the connection graph.
Now, from the above graph a basic idea of the people belonging to a particular age group can be made. The user may not want to reveal their age, but the adversary may deduce their age with a high probability based on the type of brand the user has interacted with.
In general, we can say that the attacker uses their prior knowledge o popularity of the items between different demographic groups. Then, based on this prior information, they link the query to the demographic who formed most of the accesses to that item. The task of knowing the prior information is not that big of a deal.&lt;/p&gt;

&lt;h4 id=&quot;evaluation-metric-1&quot;&gt;Evaluation Metric&lt;/h4&gt;
&lt;p&gt;The evaluation metric we have used for this analysis is called &lt;em&gt;ambiguity&lt;/em&gt;. It helps in determining the likelihood with which an adversary fails to predict a user’s static sparse feature by just viewing their interactions with items. The ambiguity for each item is defined as follows:
&lt;em&gt;ambiguity(i) = 100% - max(frequency(i))&lt;/em&gt;
where, frequency = distribution vector of all accesses to brand i by different user groups.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;An ambiguity(i) = 0 indicates if a user has interacted with item i, the attacker can successfully determine the user’s sparse features.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;evaluation-results-1&quot;&gt;Evaluation Results&lt;/h4&gt;
&lt;p&gt;In the graphs shown below, the x-axis shows the percentage of ambiguity where a value of 0 indicates that there is no ambiguity and this brand is always accessed by only one user bucket, whereas a higher ambiguity value depicts that brands are more popular across multiple user buckets.
In figure 5(A), it ca be seen that the more than 17% of brands are only accessed by 1 user bucket represented by the leftmost tall bar of PDF, meaning that the attacker can determine the user bucket using those brand interactions. On the other hand, in the CDF curve, for 38% of the brands, the attacker can predict the user bucket with a success rate of greater than 50%.
Similarly, the age and gender group versus the ambiguity are shown by graph 5(B) and 5(&lt;em&gt;C&lt;/em&gt;) respectively.&lt;/p&gt;

&lt;h2 id=&quot;re-identification-attack&quot;&gt;Re-Identification Attack&lt;/h2&gt;

&lt;p&gt;In the re-identification attack, the attacker focuses on tracking the same user over time by just analyzing their interaction history.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Re-identification attack is different from the identity resolution attack, as in the identity resolution attack the aim is to link the users across different system, potentially involving cross-referencing user’s information.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Under this attack, we study two important things:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;if the history of the purchases of a user can be used as a tracking identifier for the user.&lt;/li&gt;
  &lt;li&gt;if an attacker can re-identify the same user who sent queries over time by only tracking the history of their purchases, with no access to the static sparse features.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;evaluation-setup-2&quot;&gt;Evaluation setup&lt;/h4&gt;
&lt;p&gt;For the evaluation, we have used the Taobao dataset, and have separated about 9M purchase interactions among more than 723M user-item interactions. Then they have formatted the data into a time-series data structure, as shown below:
&lt;em&gt;user1 = (time1,item1), (time4,item10), (time500,item20)&lt;/em&gt;
&lt;em&gt;user2 = (time3,item100), (time20,item100)&lt;/em&gt; 
.
.
.
.
&lt;em&gt;user_X = (time5,item75), (time20,item50), (time100,item75), (time400,item1), (time420,item10)&lt;/em&gt;
Now for each set of consecutive items purchased by an user, we create a list of users who have the same set of consecutive purchases in exactly that order. We refer to these sets of consecutive recent purchases as &lt;em&gt;keys&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Multiple users may have the same key.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The goal of this attack is to use &lt;em&gt;m&lt;/em&gt; most recent purchases mad by a user to track them across different interactions sessions. To evaluation setup of this attack can be carried out as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;randomly select a timestamp and a user&lt;/li&gt;
  &lt;li&gt;for that selected user, we check &lt;em&gt;m&lt;/em&gt; most recent purchases at that selected timestamp and form a key&lt;/li&gt;
  &lt;li&gt;we then look up this key in the recent item purchase history dataset
    &lt;ul&gt;
      &lt;li&gt;if the same sequence of m most recent items appear on another user at the same timestamp, this means those recent purchases are not unique or that specific user at that time and hence, doesn’t represent a single user.&lt;/li&gt;
      &lt;li&gt;if the m items purchase history only belongs to that specific user, the duration of the time in which this key forms the most recent purchases of the user is extracted.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the same is repeated for many random time stamps and users to obtain 200,000 samples.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By plotting the data, we may notice that the 3, 4 and 5 most recent purchases uniquely identify users with 99% probability.&lt;/p&gt;

&lt;h4 id=&quot;attack-method-2&quot;&gt;Attack Method&lt;/h4&gt;
&lt;p&gt;For the period of time the recent purchases remain the same, every query sent by the user has the same list of recent purchases, i.e., most recent items purchased by a user usually do not change with a very high frequency. The attacker uses this knowledge to launch the attack. So, the attacker first selects a time threshold. This time threshold is chosen to help the attacker to decide if the queries come from the same&lt;/p&gt;

</description>
            <pubDate>Mon, 16 Oct 2023 00:00:00 +0900</pubDate>
            <link>http://dsailatkaist.github.io/2023-10-16-Private_Data_Leakage_via_Exploiting_Access_Patterns_of_Sparse_Features_in_Deep_Learning-based_Recommendation_Systems.html</link>
            <guid isPermaLink="true">http://dsailatkaist.github.io/2023-10-16-Private_Data_Leakage_via_Exploiting_Access_Patterns_of_Sparse_Features_in_Deep_Learning-based_Recommendation_Systems.html</guid>
            
            <category>reviews</category>
            
            
        </item>
        
    </channel>
</rss>
