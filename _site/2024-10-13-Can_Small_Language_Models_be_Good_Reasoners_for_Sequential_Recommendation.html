<!DOCTYPE html>
<html>
<head>
    <meta name="google-site-verification" content="1tAPTdgw0-t8G2Bya463OpBtYUbj9Um93gfnsowYKLw" />
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CV4PTXQSTW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-CV4PTXQSTW');
</script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="keywords" content="reviews,  ">
<title>[WWW 2024] Can Small Language Models be Good Reasoners for Sequential Recommendation? | Awesome Reviews</title>
<link rel="stylesheet" href="css/syntax.css">

<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="css/modern-business.css">
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="css/customstyles.css">
<link rel="stylesheet" href="css/boxshadowproperties.css">
<!-- most color styles are extracted out to here -->
<link rel="stylesheet" href="css/theme-blue.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="js/jquery.navgoco.min.js"></script>


<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<!-- Anchor.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script>
<script src="js/toc.js"></script>
<script src="js/customscripts.js"></script>

<link rel="shortcut icon" href="images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="DSAILatKAIST.github.io" href="http://localhost:4000/feed.xml">


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>




    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    <script>
        $(document).ready(function() {
            $("#tg-sb-link").click(function() {
                $("#tg-sb-sidebar").toggle();
                $("#tg-sb-content").toggleClass('col-md-9');
                $("#tg-sb-content").toggleClass('col-md-12');
                $("#tg-sb-icon").toggleClass('fa-toggle-on');
                $("#tg-sb-icon").toggleClass('fa-toggle-off');
            });
        });
    </script>
    


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-static-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fa fa-home fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle"> Awesome Reviews</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- toggle sidebar button -->
                <li><a id="tg-sb-link" href="#"><i id="tg-sb-icon" class="fa fa-toggle-on"></i> Nav</a></li>
                <!-- entries without drop-downs appear here -->




                
                
                
                <li><a href="introduction">Introduction</a></li>
                
                
                
                <li><a href="https://statistics.kaist.ac.kr/" target="_blank" rel="noopener">KAIST ISysE</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Reviews<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="reviews_kse801_2022.html">KSE801 (2022)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2023.html">DS503 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS535_2023.html">DS535 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2024.html">DS503 (2024)</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
			<li>



  <a class="email" title="Submit feedback" href="#" onclick="javascript:window.location='mailto:swkim@kaist.ac.kr?subject=Question about reviews feedback&body=I have some feedback about the [WWW 2024] Can Small Language Models be Good Reasoners for Sequential Recommendation? page: ' + window.location.href;"><i class="fa fa-envelope-o"></i> Feedback</a>

</li>



		
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">
                        <input type="text" id="search-input" placeholder="search...">
                        <ul id="results-container"></ul>
                    </div>
                    <script src="js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: 'search.json',
                                searchResultTemplate: '<li><a href="{url}" title="[WWW 2024] Can Small Language Models be Good Reasoners for Sequential Recommendation?">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>



<!-- Page Content -->
<div class="container">
  <div id="main">
    <!-- Content Row -->
    <div class="row">
        
        
            <!-- Sidebar Column -->
            <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
  <li class="sidebarTitle"> </li>
  
  
  
  <li>
      <a title="How to contribute" href="#">How to contribute</a>
      <ul>
          
          
          
          <li><a title="How to contribute?" href="how_to_contribute.html">How to contribute?</a></li>
          
          
          
          
          
          
          <li><a title="Review template (Example)" href="template.html">Review template (Example)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Reviews" href="#">Reviews</a>
      <ul>
          
          
          
          <li><a title="KSE801 (2022F)" href="reviews_kse801_2022.html">KSE801 (2022F)</a></li>
          
          
          
          
          
          
          <li><a title="DS503 (2023S)" href="reviews_DS503_2023.html">DS503 (2023S)</a></li>
          
          
          
          
          
          
          <li><a title="DS535 (2023F)" href="reviews_DS535_2023.html">DS535 (2023F)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
      
      <!-- if you aren't using the accordion, uncomment this block:
         <p class="external">
             <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
         </p>
         -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>



            </div>
            
        

        <!-- Content Column -->
        <div class="col-md-9" id="tg-sb-content">
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/math...">
</script>
<article class="post" itemscope itemtype="https://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[WWW 2024] Can Small Language Models be Good Reasoners for Sequential Recommendation?</h1>
        <p class="post-meta"><time datetime="2024-10-13T00:00:00+09:00" itemprop="datePublished">Oct 13, 2024</time> /
            
            
            
            
            

        </p>


    </header>

    <div class="post-content" itemprop="articleBody">

        

        <h2 id="1-motivation"><strong>1. Motivation</strong></h2>

<p>LLM이 NLP task 뿐만 아니라 다양한 task에 대해 좋은 성능을 보여주면서 sequential recommendation에서도 LLM을 활용한 방법들이 나타났다. 지금까지 LLM을 recommendation에 적용하는 방법은 크게 2가지로 나눌 수 있다. 1) LLM을 Item Ranker로 사용하는 방법론들은 zero-shot 또는 few-shot learning을 한 상태에서만 recommendation을 해왔고 이런 상황에서는 기존의 LLM이 traditional recommendation system보다 낮은 성능을 보여주었다. 두 번째로는 LLM을 Knowledge Enhancer로 사용하는 경우인데, 이 경우에 CoT [2]를 활용하면 LLM의 Reasoning Capability를 충분히 활용하면서 좋은 성능을 얻을 가능성이 많다. 하지만 real world 세팅에서 Chat-GPT 규모의 LLM을 recommendation 목적으로 활용하는 것은 매우 많은 resource가 필요하다. 그렇기 때문에 이 논문에서는 Step-by-step Knowledge distillation Framework (SLIM)을 제안한다. 이 방법론에서는 Chat-GPT를 Teacher, 더 작은 사이즈의 LLM을 Student로 하여 Teacher의 Reasoning Capability를 Student로 Distillation 한다. 그리고 최종적으로는 Distilled Student 모델을 deploy하여 real world setting에서 recommendation 할 수 있도록 하는 것이 최종적인 목표이다.</p>

<h2 id="2-method"><strong>2. Method</strong></h2>

<p>이 논문에서 제시하는 Framework인 SLIM은 크게 3단계로 이뤄져있습니다.</p>

<ol>
  <li>
    <p>Knowledge Distillation for Recommendation</p>
  </li>
  <li>
    <p>Recommendation Knowledge Encoding</p>
  </li>
  <li>
    <p>Rationale Enhanced Recommendation</p>
  </li>
</ol>

<p><img src="https://i.postimg.cc/zf5zYHBq/image.png" alt="image_sample" /></p>

<h3 id="1-knowledge-distillation-for-recommendation">1. Knowledge Distillation for Recommendation</h3>

<p>첫 번째 과정에서는 User의 Behavior Sequence를 CoT Prompt에 담아서 Chat-GPT를 사용해 Rationale을 얻습니다. 이 때 CoT의 Prompt는 아래와 같은 논리의 순서로 이뤄져 있습니다.</p>

<p>Step1. User historical sequence를 통해 user의 preference 추론.</p>

<p>Step2. User의 preference를 기반으로 brand와 category 추천.</p>

<p>Step3. brand와 category에 일치하는 item 추천.</p>

<p>위와 같은 Prompt를 통해 Chat-GPT로부터 1. User의 Preference, 2. Recommending Brand and Category, 3. Recommending Item을 최종적으로 얻게되고 해당 논문에서는 전체 결과를 Rationale 이라고 칭합니다. 구체적인 prompt와 그에 대한 Teacher model의 응답 예시는 Figure2를 보시면 됩니다.</p>

<p>Rationale을 사용하여 LLaMA 7B 모델을 Instruction Tuning을 하도록 합니다. Instruction Tuning은 language modeling을 할 때 사용하는 negative log-likelihood loss term을 사용하게 되 식은 아래와 같습니다.</p>

<p>$\mathcal{L}<em>{\text{distill}} = \sum</em> {u \in \mathcal{U}’} \sum_ {t=1}^{\vert r’ <em>u\vert} \log \left( P</em> {\theta} \left( r’_ {u,t} \mid p’_ {u}, r’_ {u,&lt;t} \right) \right)$</p>

<p>위 식에서 $\mathcal{U}’$ user 전체의 subset, $\mathcal{r’_ u}$는 Teacher에게서 얻은 user $u$에 대한 rationale 결과, $r’_ {u,t}$는 rationale 에서의 t 번째 token. 그리고 $r’_ {u,&lt;t}$ 는 $r’_ {u,t}$ 이전의 token들을 의미합니다.</p>

<p>이 식에서 SLIM은 student model의 parameter인 $\theta$를 학습하게 됩니다.</p>

<p>추가적으로 Instruction Tuning을 할 때 Efficiency를 위해서 LLM 전체를 fine-tuning 하지 않고 PEFT(Parameter Efficient Fine-Tuning method) 중의 하나인 LoRA [3]를 사용합니다.</p>

<p><img src="https://i.postimg.cc/Y90wt6wB/image.png" alt="image_sample" /></p>

<h3 id="2-recommendation-knowledge-encoding">2. Recommendation Knowledge Encoding</h3>

<p>두 번째 과정에서는 첫 번째 과정에서 Distillation 과정을 거친 student 모델을 사용합니다. 이 과정에서는 CoT Prompt를 student 모델에게 주어서 똑같이 User에 대한 rationale을 생성 하도록 합니다. 그리고 Rationale을 Pre-trained Bert 모델을 통해서 Encoding하여 Rationale Embedding으로 표현합니다. 그리고 이와 별개로 추천 대상에 있는 Item들의 Description(e.g., title, category, brand)을 같은 Text Encoder를 통해 Encoding하여 Item Description Embedding을 얻습니다.</p>

<p>$z_ i^{text}= TextEncoder(f_ i)$</p>

<p>$s_ u^{text} = TextEncoder(r_ u)$</p>

<p>$f_ i$ 는 Item i의 description을 의미합니다. $z_ i^{text}$와 $s_ u^{text}$는 각각 Item Description, Rationale의 text embedding을 의미합니다.</p>

<h3 id="3-rationale-enhanced-recommendation">3. Rationale Enhanced Recommendation</h3>

<p>세 번째 과정에서는 이전에 얻은 Rationale Embedding과 Item Description Embedding을 활용하여 Recommender System을 학습합니다. 이 때 해당 논문에서는 두 가지 구조의 Recommendation Model을 제안합니다. Item의 ID-based 모델과, ID를 사용하지 않는 ID-Agnostic인데, ID-based 경우에는 GRU4Rec, SASRec과 같은 기존 Recommendation System을 backbone으로 두어서 backbone 모델의 Item Embedding과 Item Description Embedding을 결합하고, User Embedding과 Rationale Embedding을 결합합니다. ID-Agnostic 같은 경우는 backbone 모델을 따로 사용하지는 않고 Item Description Embedding과 Rationale Embedding만을 가지고 Recommendation을 하는 형태입니다.</p>

<p>ID-based의 방법론은 아래의 식처럼 text embedding을 Backbone 모델의 Embedding과 결합하는 방법입니다. 결합하여 LInear Layer를 거쳐서 최종적으로 나온 $z_i$와 $s_u$를 활용하여 binary cross-entropy loss로 모델을 학습합니다.</p>

<p>$z_ i = g_ f([g_ l(z^{text}_ i);z^{id}_ i])$</p>

<p>$s_ u = g_ f([g_ l(s^{text}_ u);s^{SeqEnc}_ u])$</p>

<p>[;]는 concatenation operation, $z^{id}_i$는 backbone 모델에서의 Item Embedding, $s_u^{SeqEnc}는 backbone 모델에서의 얻은 User Embedding, $ $g_l$과 $g_f$ 는 LInear Layer를 의미합니다.</p>

<p>ID-agnostic은 Item description, rationale Embedding을 Transformer Layer에 같이 넣어서 모델을 학습합니다. 이 때도 binary cross-entropy loss로 모델을 학습하게 됩니다. ID-agnositc 모델의 경우는 Cold start와 같은 상황에서 더 잘 작동되기 때문에 추가적으로 제안하는 방법론이라고 말하고 있습니다.</p>

<p>$z_ i = g_ t(z_i^{text})$</p>

<p>$s_ u = g_ t(s_ u^{text})$ㅇ</p>

<p>위 식에서 $g_ t$ 는 transformer layer를 의미합니다.</p>

<h2 id="4-experiment"><strong>4. Experiment</strong></h2>

<h3 id="experiment-setup"><strong>Experiment setup</strong></h3>

<ul>
  <li>Dataset
    <ul>
      <li>Amazon Review Dataset (Video Games, Grocery and Gourmet Food, Home and Kichen)</li>
    </ul>
  </li>
  <li>baseline
    <ul>
      <li>$GRU4Rec$, $SASRec$, $SRGNN$ (이 모델들의 item feature extension 형태로 Item ID vector에 item description text vector를 concattenating 하는 모델들도 baseline으로 추가한다. $GRU4Rec^+$, $SASRec^+$, $SRGNN^+$)</li>
      <li>Ablation Study의 일종으로 $SLIM^-$는 distillation 과정을 거치지 않고 Chat-GPT의 결과를 그대로 사용한 모델이다.</li>
    </ul>
  </li>
  <li>Evaluation Metric
    <ul>
      <li>NDCG@10, Hit Rate@10, Hit Rate@20</li>
      <li>Evaulation을 할 때는 Random Negative Sample 100개를 주었고, 5번 실험을 하여 평균값과 표준편차 값을 측정하였다.</li>
    </ul>
  </li>
</ul>

<h3 id="result"><strong>Result</strong></h3>

<p>이 논문에서의 실험은 SLIM의 추천 성능 관련 실험과 해당 Framework의 여러 장점들에 대해 설명하는 실험으로 구성되어 있습니다.</p>

<p>ID-based SLIM의 성능 실험에서는 각 Backbone recommendation system과 각 backbone 모델을 사용한 SLIM의 성능을 비교하여 얼마만큼의 Improvement가 있는지를 비교한다. 실험 결과를 보면 SLIM의 방법론이 효과적이라는 것을 알 수 있습니다. item feature extension을 포함한 backbone 모델과 비교했을 때 consistent한 성능 향상이 있습니다. 그리고 대부분의 실험 결과에서 $SLIM^-$보다 $SLIM$ 모델의 성능이 높게 나왔다. 이러한 실험 결과에 대해 논문의 저자들은 distillation 과정에서 student model이 recommendation에 관련이 높은 결과를 주도록 학습되었다고 설명합니다.</p>

<p><img src="https://i.postimg.cc/DZxygf7n/image.png" alt="image_sample" /></p>

<p>ID-agnostic SLIM의 성능 실험에서는 앞서 설명했던 것 처럼 backbone recommendation system을 사용하지 않습니다. 이 실험에서는 직접적인 baseline과의 비교는 없지만 SLIM에서 사용하는 CoT 방법에 대한 이해도를 높이기 위해 ablation model을 만들었습니다. 해당 논문에서 사용한 CoT prompt에는 3 단계의 reasoning을 거쳐 추천을 하는데 각 단계의 결과만 사용을 해서 추천하는 $SLIM-Step$ 모델과 성능을 비교하게 됩니다. 실험 결과 테이블을 보면 SLIM이 대부분의 결과에서 outperform을 하는 것을 알 수 있고 SLIM-Step 모델들은 살짝 낮은 결과를 보여줍니다. 특히 SLIM-Step1, 2 는 성능 차이가 많이 나는데 각 단계에서의 macroscopic information를 활용해서 추천 아이템을 특정하는 것은 어렵기 때문이라고 설명합니다.</p>

<p><img src="https://i.postimg.cc/sf0gG2nJ/image.png" alt="image_sample" /></p>

<p>위 2가지의 메인 실험 외에도 논문에서는 SLIM의 장점에 대해 explore하는 Ablation 및 추가 실험들을 제시하고 있습니다. 크게 3가지로 1) CoT 결과로 인한 Recommendation의 Interpretability, 2)Dataset Sparsity에 대한 robustness, 3) Popularity Bias Mitigation 에 대해서 SLIM이 기존 모델들보다 좋다는 것을 뒷받침 하는 실험과 결과 해석이 포함되어있습니다.</p>

<h2 id="5-conclusion"><strong>5. Conclusion</strong></h2>

<p>이 논문에서는 LLM에 CoT Prompting 방법을 사용해서 추천에 관련성이 높은 정보를 뽑아냈고 이를 distillation 과정을 통해서 real world 에서도 affordable한 방법론을 제시했다. 그리고 CoT로 뽑은 정보를 Recommendation System과 잘 결합하여 Sequential Recommendation 성능이 올라가는 것을 실험으로 잘 보여주었고 SLIM이 가지는 여러 장점들을 보여주는 실험 또한 제시하였다.</p>

<p>개인적인 의견으로는 저자들이 LLM Recommendation 방법론들의 실제 활용에서 생기는 문제점, 기존 LLM Recommenadtion 방법론이 성능이 좋아도 성능과 비용 문제로 인하여 적용하기는 어렵다 라는 것은 산업 분야에서도 중요하기 때문에 중요한 문제를 잘 잡아냈다고 생각합니다. 그리고 해당 문제를 distillation이라는 방법으로 효과적으로 해결할 수 있다는 것을 보여주어 좋은 방법론을 제시했다고 생각한다. 한 가지 조금 더 develope을 해볼 수 있는 부분도 있을 것이라고 생각한다. LLM과 CoT로 user preference, recommend category, item 등 복잡한 형태의 문장을 뽑아내고 해당 문장은 Bert를 통해 encoding을 한다. 이 과정에서 단순히 한 개의 Token Embedding으로 뽑아 압축시켜버리면 information loss가 크고 Reasoning된 결과가 효율적으로 반영되기 어려울 것 같다는 예상이다. Reasoning된 결과를 통해 단계적으로 Recommendation System과 결합하거나, Long Sentence의 Semantic 보존에 대한 추가적인 고민과 방안이 있으면 좋지 않을까 하는 생각이 있다.</p>

<h2 id="author-information"><strong>Author Information</strong></h2>

<ul>
  <li>
    <p>Author - 강홍석 (HongSeok Kang)</p>
  </li>
  <li>
    <p>Affiliation - KAIST DSAIL</p>
  </li>
  <li>
    <p>Research Interest - Recommendation System, Tabular Learning</p>
  </li>
</ul>

<h2 id="6-reference--additional-materials"><strong>6. Reference &amp; Additional materials</strong></h2>

<p>[1] Wang, Y., Tian, C., Hu, B., Yu, Y., Liu, Z., Zhang, Z., … &amp; Wang, X. (2024, May). Can Small Language Models be Good Reasoners for Sequential Recommendation?. In <em>Proceedings of the ACM on Web Conference 2024</em> (pp. 3876-3887).</p>

<p>[2] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., … &amp; Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in large language models. <em>Advances in neural information processing systems</em>, <em>35</em>, 24824-24837.</p>

<p>[3] Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., … &amp; Chen, W. (2021). Lora: Low-rank adaptation of large language models. <em>arXiv preprint arXiv:2106.09685</em>.</p>

    </div>



</article>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>







<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy;2024 Copyright 2021 Google LLC. All rights reserved. <br />
 Site last generated: Oct 14, 2024 <br />
<p><img src="images/company_logo.png" alt="Company logo"/></p>
                </div>
            </div>
</footer>






        </div>
    <!-- /.row -->
</div>
<!-- /.container -->
</div>
<!-- /#main -->
    </div>

</body>

<!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-66296557-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>





</html>


