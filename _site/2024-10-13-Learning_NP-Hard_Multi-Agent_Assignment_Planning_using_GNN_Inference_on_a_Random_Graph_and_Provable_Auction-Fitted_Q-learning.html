<!DOCTYPE html>
<html>
<head>
    <meta name="google-site-verification" content="1tAPTdgw0-t8G2Bya463OpBtYUbj9Um93gfnsowYKLw" />
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CV4PTXQSTW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-CV4PTXQSTW');
</script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="keywords" content="reviews,  ">
<title>[NeurIPS 2022] Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on a Random Graph and Provable Auction-Fitted Q-learning | Awesome Reviews</title>
<link rel="stylesheet" href="css/syntax.css">

<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="css/modern-business.css">
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="css/customstyles.css">
<link rel="stylesheet" href="css/boxshadowproperties.css">
<!-- most color styles are extracted out to here -->
<link rel="stylesheet" href="css/theme-blue.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="js/jquery.navgoco.min.js"></script>


<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<!-- Anchor.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script>
<script src="js/toc.js"></script>
<script src="js/customscripts.js"></script>

<link rel="shortcut icon" href="images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="DSAILatKAIST.github.io" href="http://localhost:4000/feed.xml">


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>




    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    <script>
        $(document).ready(function() {
            $("#tg-sb-link").click(function() {
                $("#tg-sb-sidebar").toggle();
                $("#tg-sb-content").toggleClass('col-md-9');
                $("#tg-sb-content").toggleClass('col-md-12');
                $("#tg-sb-icon").toggleClass('fa-toggle-on');
                $("#tg-sb-icon").toggleClass('fa-toggle-off');
            });
        });
    </script>
    


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-static-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fa fa-home fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle"> Awesome Reviews</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- toggle sidebar button -->
                <li><a id="tg-sb-link" href="#"><i id="tg-sb-icon" class="fa fa-toggle-on"></i> Nav</a></li>
                <!-- entries without drop-downs appear here -->




                
                
                
                <li><a href="introduction">Introduction</a></li>
                
                
                
                <li><a href="https://statistics.kaist.ac.kr/" target="_blank" rel="noopener">KAIST ISysE</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Reviews<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="reviews_kse801_2022.html">KSE801 (2022)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2023.html">DS503 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS535_2023.html">DS535 (2023)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2024.html">DS503 (2024)</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
			<li>



  <a class="email" title="Submit feedback" href="#" onclick="javascript:window.location='mailto:swkim@kaist.ac.kr?subject=Question about reviews feedback&body=I have some feedback about the [NeurIPS 2022] Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on a Random Graph and Provable Auction-Fitted Q-learning page: ' + window.location.href;"><i class="fa fa-envelope-o"></i> Feedback</a>

</li>



		
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">
                        <input type="text" id="search-input" placeholder="search...">
                        <ul id="results-container"></ul>
                    </div>
                    <script src="js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: 'search.json',
                                searchResultTemplate: '<li><a href="{url}" title="[NeurIPS 2022] Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on a Random Graph and Provable Auction-Fitted Q-learning">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>



<!-- Page Content -->
<div class="container">
  <div id="main">
    <!-- Content Row -->
    <div class="row">
        
        
            <!-- Sidebar Column -->
            <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
  <li class="sidebarTitle"> </li>
  
  
  
  <li>
      <a title="How to contribute" href="#">How to contribute</a>
      <ul>
          
          
          
          <li><a title="How to contribute?" href="how_to_contribute.html">How to contribute?</a></li>
          
          
          
          
          
          
          <li><a title="Review template (Example)" href="template.html">Review template (Example)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Reviews" href="#">Reviews</a>
      <ul>
          
          
          
          <li><a title="KSE801 (2022F)" href="reviews_kse801_2022.html">KSE801 (2022F)</a></li>
          
          
          
          
          
          
          <li><a title="DS503 (2023S)" href="reviews_DS503_2023.html">DS503 (2023S)</a></li>
          
          
          
          
          
          
          <li><a title="DS535 (2023F)" href="reviews_DS535_2023.html">DS535 (2023F)</a></li>
          
          
          
          
          
          
          <li><a title="DS503 (2024S)" href="reviews_DS503_2024.html">DS503 (2024S)</a></li>
          
          
          
          
          
          
          <li><a title="DS535 (2024F)" href="reviews_DS535_2024.html">DS535 (2024F)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
      
      <!-- if you aren't using the accordion, uncomment this block:
         <p class="external">
             <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
         </p>
         -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>



            </div>
            
        

        <!-- Content Column -->
        <div class="col-md-9" id="tg-sb-content">
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/math...">
</script>
<article class="post" itemscope itemtype="https://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[NeurIPS 2022] Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on a Random Graph and Provable Auction-Fitted Q-learning</h1>
        <p class="post-meta"><time datetime="2024-10-13T00:00:00+09:00" itemprop="datePublished">Oct 13, 2024</time> /
            
            
            
            
            

        </p>


    </header>

    <div class="post-content" itemprop="articleBody">

        

        <h2 id="1-introduction">1. Introduction</h2>
<h3 id="11-ë¬¸ì œ-ì •ì˜">1.1 ë¬¸ì œ ì •ì˜</h3>
<p><strong>ë©€í‹° ë¡œë´‡ ë³´ìƒ ìˆ˜ì§‘ ë¬¸ì œ (MRRC):</strong></p>
<ul>
  <li>ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ë³´ìƒì„ ê³ ë ¤í•œ ë©€í‹° ì—ì´ì „íŠ¸, ë©€í‹° íƒœìŠ¤í¬ NP-ë‚œí•´ ê³„íš ë¬¸ì œ.</li>
  <li>ë™ì¼í•œ ë¡œë´‡ë“¤ì´ ê³µê°„ì ìœ¼ë¡œ ë¶„í¬ëœ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë ¤ê³  í•¨.</li>
  <li>ë¯¸ë¦¬ ì •í•´ì§„ ë³´ìƒ ê·œì¹™ì— ë”°ë¼, ë” ë¹¨ë¦¬ ì‘ì—…ì„ ì™„ë£Œí•  ë•Œ ë” ë†’ì€ ë³´ìƒì„ ë¶€ì—¬.</li>
  <li>MRRC ë¬¸ì œëŠ” ë¼ì´ë“œ ì‰ì–´ë§, í”½ì—…-ë”œë¦¬ë²„ë¦¬ì™€ ê°™ì€ ë¬¸ì œë¥¼ ì˜ ëª¨ë¸ë§í•¨.</li>
  <li>ì‘ìš© ë¶„ì•¼: ê³ ê°ì„ ìš´ì†¡í•˜ê¸° ìœ„í•œ ìš´ì „ ê¸°ì‚¬ ë°°ì°¨, ë˜ëŠ” ê³µì¥ì—ì„œì˜ ê¸°ê³„ ìŠ¤ì¼€ì¤„ë§.</li>
</ul>

<h3 id="12-ë¬¸ì œì ">1.2 ë¬¸ì œì </h3>
<ul>
  <li><strong>ë¹„ì‹¼ ê³„ì‚° ë¹„ìš©</strong>, íŠ¹íˆ ë¬¸ì œì˜ ê·œëª¨ê°€ ì»¤ì§ˆ ë•Œ.</li>
  <li>ë©€í‹° ì—ì´ì „íŠ¸ ëª¨ë¸ë§ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ë¶„ì‚° ì ‘ê·¼ë²•ì˜ ì–´ë ¤ì›€:
    <ul>
      <li>í†µì‹  ì—†ì´ <strong>ì—ì´ì „íŠ¸ ê°„ì— í•©ì˜</strong>ë¥¼ ìœ ë„í•´ ê¸€ë¡œë²Œ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ëŠ” ê²ƒì´ ë¶ˆê°€ëŠ¥.</li>
    </ul>
  </li>
</ul>

<p>ë”°ë¼ì„œ, ì´ ì—°êµ¬ëŠ” <strong>ì¤‘ì•™ ì§‘ì¤‘ì‹ ë°©ë²•</strong>ì„ ì‚¬ìš©í•˜ì—¬ MRRC ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì§‘ì¤‘í•¨.</p>

<h3 id="13-ì—°êµ¬-ì§ˆë¬¸">1.3 ì—°êµ¬ ì§ˆë¬¸</h3>
<p>ëŒ€ê·œëª¨ NP-ë‚œí•´ ìŠ¤ì¼€ì¤„ë§ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ <strong>í•™ìŠµ ê¸°ë°˜ ì¤‘ì•™ ì§‘ì¤‘ì‹ ì˜ì‚¬ê²°ì • ë°©ì‹</strong>ì„ ì„¤ê³„í•  ë•Œ, í•™ìŠµê³¼ ì˜ì‚¬ê²°ì • ì¸¡ë©´ì—ì„œ <strong>íš¨ìœ¨ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ</strong> ë°©ë²•ì„ ì–´ë–»ê²Œ ì„¤ê³„í•  ìˆ˜ ìˆì„ê¹Œ?</p>

<h3 id="14-ì—°êµ¬-ê¸°ì—¬">1.4 ì—°êµ¬ ê¸°ì—¬</h3>
<ul>
  <li>state-joint action ìŒì„ <strong>random PGM(Probabilistic Graphical Model)</strong> ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŒì„ ê´€ì°°. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ <strong>random PGM ê¸°ë°˜ Mean-field inference</strong> ì´ë¡ ì„ ê°œë°œí•˜ê³ , <strong>structure2vec</strong> (Dai et al., 2016)ì˜ í™•ì¥íŒì¸ <strong>random structure2vec</strong>ì„ ì œì•ˆ.</li>
  <li>Q-functionì„ ëœë¤ structure2vec ê³„ì¸µì„ ì‚¬ìš©í•´ ì¶”ì •. structure2vecì˜ ê³„ì¸µì„ <strong>Weisfeiler-Lehman ì»¤ë„</strong>ë¡œ í•´ì„í•˜ì—¬, <strong>order-transferability</strong>(ìˆœì„œ ì „ë‹¬ì„±)ë¼ëŠ” ì†ì„±ì„ ê°–ë„ë¡ ì„¤ê³„. ì´ëŠ” ë¬¸ì œ ê·œëª¨ì— ë”°ë¼ <strong>ì „ì´ ê°€ëŠ¥í•œ</strong> ì„±ì§ˆì„ ì œê³µí•¨.</li>
  <li><strong>OTAP (Order-Transferability-Enabled Auction Policy)</strong> ë¼ëŠ” í• ë‹¹ ê·œì¹™ì„ ì œì•ˆí•˜ì—¬, í• ë‹¹ ê³µê°„ì˜ ì§€ìˆ˜ì  ì„±ì¥ì„ í•´ê²°í•¨.</li>
  <li><strong>AFQI (Auction-Fitted Q-Iteration)</strong> ëŠ” ê¸°ì¡´ Fitted Q-Iterationì˜ argmax ì—°ì‚°ì„ OTAPìœ¼ë¡œ ëŒ€ì²´í•´ Q-functionë¥¼ <strong>íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµ</strong>í•˜ë„ë¡ ì œì•ˆë¨.</li>
  <li><strong>AFQIëŠ” ë‹¤í•­ ì‹œê°„ ë‚´ì—</strong> ê³„ì‚° ê°€ëŠ¥í•˜ë©°, ìµœì  ì •ì±…ì˜ ìµœì†Œ (1 - 1/e) ì„±ëŠ¥ì„ ë‹¬ì„±í•¨ì´ ì…ì¦ë¨.</li>
</ul>

<h2 id="2-multi-robot-reward-collection-problem-mrrc">2. Multi-Robot Reward Collection Problem (MRRC)</h2>

<p>ë³¸ë¬¸ì—ì„œëŠ” MRRC problemì„ disctrete-time, discrete-state (DTDS) sequential decision-making problemìœ¼ë¡œ ì •ì˜í•¨.</p>
<ul>
  <li>ì‹œê°„ ì¦ë¶„ì´ $\triangle$ ì¦‰, $t_ k = t_ 0 + \triangle \times k$ ($t_ k$: $k$ë²ˆì§¸ ê²°ì •ì˜ ì‹¤ì œ ì‹œê°„).</li>
  <li>ì´ í”„ë ˆì„ì›Œí¬ì—ì„œ $s_ k$ëŠ” ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ê³ , $a_ k$ëŠ” $k$ë²ˆì§¸ ì—í¬í¬(epoch)ì—ì„œ ë¡œë´‡/ê¸°ê³„ë¥¼ ë¯¸ì™„ë£Œ ì‘ì—…ì— í• ë‹¹í•˜ëŠ” ì¡°ì¸íŠ¸ í• ë‹¹ì„ ì˜ë¯¸í•¨.</li>
  <li>ì´ ë¬¸ì œì˜ ëª©í‘œëŠ” ìµœì ì˜ ìŠ¤ì¼€ì¤„ë§ ì •ì±… $\pi_\theta : s_ k \rightarrow a_ k$ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ë©°, ì´ëŠ” ìˆ˜ì§‘ëœ ë³´ìƒì„ ê·¹ëŒ€í™”í•˜ê±°ë‚˜ ì´ ì‘ì—… ì™„ë£Œ ì‹œê°„ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì„ ëª©ì .</li>
</ul>

<h3 id="21-state">2.1 State</h3>
<p>State $s_ k = (g_ k, D_ k)$ë¡œ ë‚˜íƒ€ë‚´ë©° ê·¸ë˜í”„ $g_ k= ((R,T_ k),(E_k^{TT},E_ k^{RT}))$ì™€ ê´€ë ¨ íŠ¹ì„± $D_ k = (D_ k^R,D_ k^T,D_ k^{TT},D_ k^{RT})$ë¡œ ì •ì˜ë¨.</p>

<p>$g_k$ ì •ì˜:</p>
<ul>
  <li>$R=\lbrace 1,â€¦,M\rbrace$: ëª¨ë“  ë¡œë´‡ set, $i$ì™€ $j$ ì¸ëŒìŠ¤ë¡œ ë‚˜íƒ€ëƒ„.</li>
  <li>$T_ =\lbrace 1,â€¦,N\rbrace$: $k$ë²ˆì§¸ ì—í¬í¬ë•Œ ë‚¨ì•„ìˆëŠ” unserved task set, $p$ì™€ $q$ ì¸ëŒìŠ¤ë¡œ ë‚˜íƒ€ëƒ„.</li>
  <li>$E_ k^{TT} = \lbrace \epsilon_ {pq}^{TT} \vert p \in T_ k, q \in T_ k\rbrace$:
    <ul>
      <li>ëª¨ë“  ì‘ì—…ì—ì„œ ë‹¤ë¥¸ ì‘ì—…ìœ¼ë¡œ í–¥í•˜ëŠ” ëª¨ë“  ë°©í–¥ì„± ìˆëŠ” ê°„ì„ ë“¤ì˜ ì§‘í•©.</li>
      <li>ê° ê°„ì„ ì€ í™•ë¥  ë³€ìˆ˜ë¡œ ê°„ì£¼.</li>
      <li>ì‘ì—…-ì‘ì—… ê°„ì„  $\epsilon_ {pq}^{TT} = 1$ì€ ì‘ì—… $p$ë¥¼ ì™„ë£Œí•œ ë¡œë´‡ì´ ì´í›„ì— ì‘ì—… $q$ ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì´ë²¤íŠ¸ë¥¼ ì˜ë¯¸í•¨.</li>
      <li>ê°„ì„  $\epsilon_ {pq}^{TT}$ì˜ ì¡´ì¬ í™•ë¥ ì„ $p(\epsilon_ {pq}^{TT} = 1) \in [0, 1] $ë¡œ ë‚˜íƒ€ëƒ„.</li>
    </ul>
  </li>
  <li>$E_ k^{RT} = \lbrace \epsilon_ {iq}^{RT} \vert i \in R, q \in T_k \rbrace$:
    <ul>
      <li>ë¡œë´‡ $R$ì—ì„œ ì‘ì—… $T_ k$ë¡œ í–¥í•˜ëŠ” ëª¨ë“  ë°©í–¥ì„± ìˆëŠ” ê°„ì„ ë“¤ì˜ ì§‘í•©</li>
      <li>ë¡œë´‡-ì‘ì—… ê°„ì„  $\epsilon_ {ip}^{RT} = 1$ì€ ë¡œë´‡ $i$ê°€ ì‘ì—… $p$ì— í• ë‹¹ëœ ì´ë²¤íŠ¸ë¥¼ ì˜ë¯¸</li>
      <li>ì´ ê°„ì„ ì€ ê³µë™ í• ë‹¹ ì•¡ì…˜ì— ë”°ë¼ deterministic.</li>
      <li>ë§Œì•½ ë¡œë´‡ $i$ê°€ ì‘ì—… $p$ì— í• ë‹¹ë˜ë©´ $p(\epsilon_ {ip}^{RT}) = 1$ì´ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0ì…ë‹ˆë‹¤.</li>
    </ul>
  </li>
</ul>

<p>$D_ k$ ì •ì˜:</p>
<ul>
  <li>$D_ k^R=\lbrace d_ i^R \vert i\in R\rbrace$:
    <ul>
      <li>ì—í¬í¬ $k$ë•Œ ë¡œë´‡ ë…¸ë“œ $R$ì˜ ë…¸ë“œ íŠ¹ì§•ë“¤ì˜ ì§‘í•©.</li>
      <li>MRRCì—ì„œëŠ” $d^R_ i$ë¥¼ ì—í¬í¬ $k$ì—ì„œ ë¡œë´‡ $i$ì˜ ìœ„ì¹˜ë¡œ ì •ì˜ (ì—í¬í¬ ì¸ë±ìŠ¤ $k$ëŠ” ìƒëµë  ìˆ˜ ìˆìŒ).</li>
    </ul>
  </li>
  <li>$D_ k^T=\lbrace d_ p^T \vert p \in T_ k\rbrace$
    <ul>
      <li>ì—í¬í¬ $k$ë•Œ ì‘ì—… ë…¸ë“œ $T_ k$ì˜ ë…¸ë“œ íŠ¹ì§•ë“¤ì˜ ì§‘í•©</li>
      <li>MRRCì—ì„œëŠ” $d_ p^T$ë¥¼ ì—í¬í¬ $k$ì—ì„œ ì‘ì—… $p$ì˜ ë‚˜ì´ë¡œ ì •ì˜ (ì—í¬í¬ ì¸ë±ìŠ¤ $k$ëŠ” ìƒëµë  ìˆ˜ ìˆìŒ).</li>
    </ul>
  </li>
  <li>$D_ k^{TT}=\lbrace d_ {pq}^{TT} \vert p \in T_ k, q \in T_ k \rbrace $
    <ul>
      <li>ì—í¬í¬ $k$ë•Œ ì‘ì—… ê°„ì˜ ê°„ì„  featureë“¤ì˜ ì§‘í•©</li>
      <li>$d_ {pq}^{TT}$ëŠ” ì‘ì—… $p$ë¥¼ ì™„ë£Œí•œ ë¡œë´‡ì´ ì‘ì—… $q$ë¥¼ ì™„ë£Œí•˜ëŠ” ë° ê±¸ë¦¬ëŠ” ì‹œê°„ì„ ë‚˜íƒ€ëƒ„. ì´ ì‹œê°„ì„ <strong>ì‘ì—… ì™„ë£Œ ì‹œê°„</strong>ì´ë¼í•¨.</li>
      <li>MRRCì—ì„œëŠ” ì‘ì—… ì™„ë£Œ ì‹œê°„ì´ í™•ë¥  ë³€ìˆ˜ë¡œ ì£¼ì–´ì§€ë©°, ì‹¤ì œë¡œëŠ” ì´ í™•ë¥  ë³€ìˆ˜ì˜ ìƒ˜í”Œ ì§‘í•©ë§Œ í•„ìš”í•¨.</li>
    </ul>
  </li>
  <li>$D_ k^{RT}=\lbrace d_ {ip}^{RT} \vert i \in R, p\ in T_ k\rbrace $
    <ul>
      <li>ì—í¬í¬ $k$ë•Œ ë¡œë´‡-ì‘ì—… ê°„ì˜ ê°„ì„  íŠ¹ì§•ë“¤ì˜ ì§‘í•©.</li>
      <li>$d_ {ip}^{RT}$ëŠ” ë¡œë´‡ $i$ê°€ ì‘ì—… $p$ì— ë„ë‹¬í•˜ëŠ” ë° ê±¸ë¦¬ëŠ” ì‹œê°„ì„ ë‚˜íƒ€ëƒ„.</li>
    </ul>
  </li>
</ul>

<h3 id="22-action">2.2 Action</h3>
<ul>
  <li>ì—í¬í¬ $k$ë•Œ ì•¡ì…˜ $a_k$ëŠ” ì™„ì „ ì´ë¶„ ê·¸ë˜í”„ $(R, T_ k, E_ k^{RT})$ ì˜ ìµœëŒ€ ì´ë¶„ ë§¤ì¹­(maximal bipartite matching)ìœ¼ë¡œ ì •ì˜ë¨.</li>
  <li>ì¦‰, í˜„ì¬ ìƒíƒœ $s_ k = (g_ k, D_ k)$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, $a_ k$ëŠ” ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” $E_ k^{RT}$ ì˜ ë¶€ë¶„ ì§‘í•©ì…ë‹ˆë‹¤:
    <ol>
      <li>ë‘ ë¡œë´‡ì´ ë™ì¼í•œ ì‘ì—…ì— í• ë‹¹ë  ìˆ˜ ì—†ìŒ.</li>
      <li>ë‚¨ì•„ ìˆëŠ” ì‘ì—… ìˆ˜ë³´ë‹¤ ë¡œë´‡ ìˆ˜ê°€ ë” ë§ì€ ê²½ìš°ì—ë§Œ ì¼ë¶€ ë¡œë´‡ì´ í• ë‹¹ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ.</li>
    </ol>
  </li>
  <li>ë§Œì•½ $\epsilon^{RT}_ {ip} \in a_ k$ ì´ë©´, ì´ëŠ” ì—í¬í¬ $k$ ì—ì„œ ë¡œë´‡ $i$ê°€ ì‘ì—… $p$ì— í• ë‹¹ëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•¨.</li>
  <li>ëª¨ë“  ë¡œë´‡ì— í• ë‹¹ëœ ê²ƒì€ ë§¤ ì• í¬í¬ ë§ˆë‹¤ ë°”ë€” ìˆ˜ ìˆìŒ.</li>
</ul>

<h3 id="23-state-transition">2.3 State transition</h3>
<ul>
  <li>Graph update: ì‘ì—… $p$ê°€ ì™„ë£Œë˜ëŠ” ì‹œì ì´ ë˜ë©´, í•´ë‹¹ ì‘ì—… ë…¸ë“œëŠ” ì—…ë°ì´íŠ¸ëœ ì‘ì—… ë…¸ë“œì—ì„œ ì œê±°ë¨. ì¦‰, $T_ {k+1} = T_ k \setminus \lbrace p\rbrace$. ë˜í•œ, ì‘ì—…-ì‘ì—… ê°„ì„  $E_ {k+1}^{TT}$ê³¼ ë¡œë´‡-ì‘ì—… ê°„ì„  $E_ {k+1}^{RT}$ë„ ì´ì— ë§ê²Œ ì—…ë°ì´íŠ¸ë¨.</li>
  <li>Feature update: $D_ k+1= (D_ {k+1}^R,D_ {k+1}^T,D_ {k+1}^{TT},D_ {k+1}^{RT})$ì€ determined.</li>
</ul>

<h3 id="24-reward-and-objective">2.4 Reward and objective</h3>
<ul>
  <li>ì‹œê°„ 0ì—ì„œ, ê° ì‘ì—…ì—ëŠ” ì´ˆê¸° ë‚˜ì´ê°€ ì£¼ì–´ì§€ë©°, ì´ ë‚˜ì´ëŠ” ì‹œê°„ì— ë”°ë¼ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€í•¨.</li>
  <li>ì—í¬í¬ $k$ì—ì„œ ë‚˜ì´ê°€ $d_p^T$ ì¸ ì‘ì—… $p \in T_ k$ ê°€ ìˆ˜í–‰ë  ë•Œ ì£¼ì–´ì§€ëŠ” ë³´ìƒ $r_ k$ëŠ” $r_ k = r - d_ p^T$ë¡œ ì •ì˜</li>
  <li>MRRCì—ì„œëŠ” ì„ í˜• ë° ë¹„ì„ í˜• ë³´ìƒ í•¨ìˆ˜ $r$ë¥¼ ê³ ë ¤í•¨.</li>
  <li>ëª©í‘œëŠ” ì •ì±… $\pi$ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒ: ì •ì±… $\pi$ ëŠ” í˜„ì¬ ìƒíƒœ $s$ë¥¼ í˜„ì¬ ì•¡ì…˜ $a$ë¡œ ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜ë¡œ, ì£¼ì–´ì§„ ì •ì±…ì— ë”°ë¼ ì´ ê¸°ëŒ€ ë³´ìƒì„ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨.</li>
</ul>

<p>$Q^\pi (s, a):=E_ {P,\pi} \left[ \sum_ {k=0}^{\infty} R(s_ {t_ k}, a_ {t_ k}, s_ {t_ {k+1}}) \mid s_ {t_0} = s, a_ {t_0} = a \right]$</p>

<h2 id="3-random-graph-embedding-randstructure2vec">3. Random graph embedding: RandStructure2Vec</h2>
<p><img src="../../images/DS535_24F/Learning_NP-Hard_Multi-Agent_Assignment_Planning_using_GNN_Inference_on_a_Random_Graph_and_Provable_Auction-Fitted_Q-learning/fig_1.png" alt="ex_screenshot" /></p>
<h3 id="31-random-pgm-for-representing-a-state-of-mrrc">3.1 Random PGM for representing a state of MRRC</h3>
<ul>
  <li>
    <p>Random probabilistic graphical model (PGM) $\chi=\lbrace X_ p\rbrace$ (random variable)</p>

    <p>$p(\chi) = \frac{1}{Z}\prod_ i \phi_ i(D_ i)$</p>
    <ul>
      <li>$Z$: normalizing constant</li>
      <li>$\phi_ i(D_ i)$: clique potnetial for $D_ i$</li>
      <li>$D_ i$: clique (scope of $\phi_ i$)</li>
    </ul>
  </li>
  <li>
    <p>Scenarios:</p>
    <ul>
      <li>ì£¼ì–´ì§„ ìƒíƒœ $s_ k$ì™€ í–‰ë™ $a_ k$ ì—ì„œ ì‹œì‘í•˜ì—¬, â€œì •ì±… $\pi$ë¥¼ ì‚¬ìš©í•œ ìˆœì°¨ì  ì˜ì‚¬ê²°ì •â€ì´ë¼ëŠ” ëœë¤ ì‹¤í—˜ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ.</li>
      <li>random experimentì—ì„œ â€˜ë¡œë´‡ë“¤ì€ ë‚¨ì•„ ìˆëŠ” ëª¨ë“  ì‘ì—…ì„ ì–´ë–¤ ìˆœì„œë¡œ ìˆ˜í–‰í•˜ëŠ”ê°€?â€™ë¥¼ ë‚˜íƒ€ëƒ„.</li>
      <li>1ê°œì˜ scenarioëŠ” 1ê°œì˜ Bayesian Networkë¡œ ë‚˜íƒ€ëƒ„.</li>
      <li>scenario realizationì€ randomí•˜ê¸° ë•Œë¬¸ì—, random node $X_ k=(s_ k,a_ k)$ì™€ clique potential $\phi$ë¡œ ì´ë£¨ì–´ì§„ <strong>random</strong> Bayesian Networkë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŒ.</li>
    </ul>
  </li>
</ul>

<h3 id="32-mean-field-inference-with-random-pgm">3.2 Mean-field inference with random PGM</h3>
<ul>
  <li>random variableì¸ $\chi =\lbrace X_p \rbrace $ë¥¼ ì¶”ë¡ í•˜ëŠ” ë¬¸ì œì—ì„œ $G_ \chi$ë¥¼ ê°€ëŠ¥í•œ ëª¨ë“  PGM set, $P: G_ \chi \to [0,1]$ probability measureë¼ í•˜ë©´ $\vert G_ \chi \vert$ê°€ ë„ˆë¬´ ì»¤ì„œ Monte-Carlo sampling ë°©ë²•ìœ¼ë¡œëŠ” { $G_\chi,P$ } ì¶”ë¡ ì´ ì–´ë ¤ì›€.</li>
  <li>semi-cliques $D_m$ë¥¼ ì‚¬ìš©í•´ì„œ approximationí•  ê²ƒ:
    <ul>
      <li>$C_ \chi$ë¥¼ ê°€ëŠ¥í•œ ëª¨ë“  cliqueë“¤ì˜ ì§‘í•©ì´ë¼ í• ë•Œ $P$ì— ë”°ë¥´ë©´ ì‹¤ì œ realizationë˜ëŠ” cliqueëŠ” ì¼ë¶€ë¿ì¸ë° ê·¸ ì ì¬ì  cliqueë“¤ semi-cliqueë¼ í•¨.</li>
      <li>semi-clique $D_ m$ì— ëŒ€í•œ í™•ë¥  $p_ m = \sum_ {G\in G_ \chi} P(G)1_ {D_ m\in G} $</li>
    </ul>
  </li>
</ul>

<h4 id="mean-field-inference-with-random-pgm">Mean-field inference with random PGM</h4>
<ul>
  <li>Random PGM on $\chi =(\lbrace H_ i \rbrace, \lbrace X_ j\rbrace)$ ($H_ K$: ê´€ì¸¡ë³€ìˆ˜ $X_ k$ì— ëŒ€ì‘ë˜ëŠ” ì ì¬ë³€ìˆ˜)</li>
  <li>ëª©í‘œ: $p(\lbrace H_ i \rbrace \vert \lbrace x_ j\rbrace)$ë¥¼ ì°¾ì•„ { $X_ j$ }ê°€ ì£¼ì–´ì¡Œì„ë•Œ { $H_ i$ }ë¥¼ ì¶”ë¡ </li>
  <li>
    <p>Mean-field inferenceì—ì„œëŠ” { $H_i$ }ë“¤ì´ independentí•œ surrogate distribution  $q^{ \lbrace x_j \rbrace }(H_i)$ì˜ setì„ ì°¾ëŠ” ê²ƒì´ ëª©í‘œ ($q^{ \lbrace x_j \rbrace }$ëŠ” $q$ê°€ { $x_j$ } ë¡œ ì´ë£¨ì–´ì§ì„ ëœ»í•¨.)</p>

    <p><img src="../../images/DS535_24F/Learning_NP-Hard_Multi-Agent_Assignment_Planning_using_GNN_Inference_on_a_Random_Graph_and_Provable_Auction-Fitted_Q-learning/thm_1.png" alt="ex_screenshot" /></p>
  </li>
  <li>Theorem 1ì€  ê° semi-cliqueì˜ í™•ë¥  $p_m$ì„ ì¶”ë¡  í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ mean-field inferenceë¥¼ í•˜ëŠ”ë° ì¶©ë¶„í•˜ë©°, { $G_ \chi,P$ } ì¶”ë¡ ì´ í•„ìš” ì—†ìŒì„ ì˜ë¯¸í•¨.</li>
</ul>

<h4 id="radstructure2vec">RadStructure2Vec</h4>
<ul>
  <li><strong>structure2vec</strong>: Dai et al.(2016)ì—ì„œ mean-field inferenceì™€ PGMë¥¼ í†µí•´ vector space embeddingì„ ë„ì¶œí•¨.
    <ul>
      <li>PGMì´ realizationë  ê²½ìš° PGMì˜ joint distributionì€ ë‹¤ìŒê³¼ ê°™ì´ factorization ëœë‹¤ê³  ê°€ì •</li>
    </ul>

    <p>$\prod_ p \phi(H_ p \vert I_ p) \prod_ {p,q} \phi(H_ p \vert H_ q) $</p>
    <ul>
      <li>ìœ„ ê°€ì • í•˜ì—ì„œ { $q^{ \lbrace x_j \rbrace }(H_ i)$ } ë¥¼  { $q^{ x_ j  }(H_ i)$ } ë¡œ ì“¸ ìˆ˜ ìˆìŒ.</li>
      <li>
        <p>Fixed point iteration</p>

        <p>$\tilde{\mu_ p} \gets \sigma ( W_ 1 x_ p +W_ 2 \sum_ {q \neq p} \tilde{\mu_ q} ) $</p>
      </li>
      <li>$\tilde{\mu_ p}$ëŠ” ë…¸ë“œ $p$ì˜ ì ì¬ ë²¡í„°ì´ê³ , $x_ p$ëŠ” ë…¸ë“œ $p$ì˜ input</li>
      <li>$\tilde{\mu_ p}$ë¥¼ injective embeddingìœ¼ë¡œ í•´ì„í•  ì‹œ structure2vecì˜ fixed point iteration == Mean-field inferenceì˜ fiexed point inferenceì„ì„ ë³´ì„</li>
    </ul>
  </li>
</ul>

<p>$\tilde{\mu_ i} = \int_ H \phi(h_ i) q^{x_ i}(h_ i) dh_ i $</p>
<ul>
  <li>Random structure2vec
    <ul>
      <li>
        <p>Theorem 1ì— ë”°ë¼ random structure2vecì€ mean-field inferenceì™€ random PGMë¥¼ í†µí•´ vector space embeddingì„ ë„ì¶œí•¨.</p>

        <p><img src="../../images/DS535_24F/Learning_NP-Hard_Multi-Agent_Assignment_Planning_using_GNN_Inference_on_a_Random_Graph_and_Provable_Auction-Fitted_Q-learning/lem_1.png" alt="ex_screenshot" /></p>
      </li>
      <li>Lemma 1ì€ GNNì„ ì‚¬ìš©í•´ ë¬´ì‘ìœ„ ê·¸ë˜í”„ë¥¼ ì„ë² ë”©í•  ë•Œ, ê°„ì„  ì¡´ì¬ ì—¬ë¶€ ê°„ì˜ ìƒí˜¸ ì˜ì¡´ì„±ì„ ë¬´ì‹œí•´ë„ ëœë‹¤ëŠ” ì´ë¡ ì  ê·¼ê±°ë¥¼ ì œê³µí•¨.</li>
      <li>ê·¸ë˜í”„ì˜ ê°„ì„ ì´ ëª…ì‹œì ìœ¼ë¡œ ì£¼ì–´ì§€ì§€ ì•Šê±°ë‚˜ ë¬´ì‘ìœ„ë¡œ ì•Œë ¤ì§„ ê²½ìš°, ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±ì€ ëª¨ë“  ê°„ì„ ì˜ ì¡´ì¬ í™•ë¥ ì„ ê°œë³„ì ìœ¼ë¡œ ì¶”ë¡ í•˜ê³ , GNNì˜ message propagation ê³¼ì •ì—ì„œ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ëŠ” ê²ƒ.</li>
      <li>Lemma 1ì— ë”°ë¥´ë©´, ê°„ì„  ê°„ì˜ ìƒí˜¸ ì˜ì¡´ì„±ì€ ì´ëŸ¬í•œ íœ´ë¦¬ìŠ¤í‹± ì¶”ë¡ ì˜ í’ˆì§ˆì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŒ.</li>
    </ul>
  </li>
</ul>

<h2 id="4-solving-mrrc-with-randstructure2vec">4. Solving MRRC with RandStructure2Vec</h2>
<p><img src="../../images/DS535_24F/Learning_NP-Hard_Multi-Agent_Assignment_Planning_using_GNN_Inference_on_a_Random_Graph_and_Provable_Auction-Fitted_Q-learning/fig_2.png" alt="ex_screenshot" /></p>
<ul>
  <li>random structure2vecì„ ì´ìš©í•´ MRRC ë¬¸ì œë¥¼ í‘¸ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…</li>
  <li>state $s_ k=(g_ k,D_ k)$ ê°€ ì£¼ì–´ì¡Œì„ë•Œ $a_ k$ë¥¼ ì–´ë–»ê²Œ í• ì§€ ì„¤ëª…:
    <ol>
      <li>random Bayesian Networkë¥¼ í†µí•´ state í‘œí˜„</li>
      <li>random graph embeddingì„ í†µí•´ Q-value ì¶”ì •</li>
      <li>joint assignment ì„ íƒ</li>
    </ol>
  </li>
</ul>

<h3 id="41-representing-a-state-using-a-random-pgm">4.1 Representing a state using a random PGM</h3>
<ul>
  <li>í•˜ë‚˜ì˜ $s_ k$ì™€ $a_ k$ë¥¼ bayesian networkë¡œ í‘œí˜„</li>
  <li>$H_ p$: ì‘ì—… $p$ì— ëŒ€í•œ hidden random variable - ì‘ì—… $p$ì˜ ì´ìµì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹´ìŒ.</li>
  <li>ì‹œë‚˜ë¦¬ì˜¤ê°€ ì£¼ì–´ì¡Œì„ë•Œ, $H_ p$ëŠ” ì‘ì—… $p$ì˜ feature $X_ p$ì— dependentí•˜ê³  ë§Œì•½ ê°™ì€ ë¡œë´‡ì´ ì‘ì—… $p$ì´í›„ $q$ë¥¼ í•œë‹¤ë©´ $H_ q$ì—ë„ dependentí•¨.</li>
  <li>
    <p>Bayesian NetworkëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë˜ë©° ì´ëŠ” í•˜ë‚˜ì˜ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€ì‘ë¨.</p>

    <p>$p(\lbrace H_ p \rbrace \vert \lbrace X_ p \rbrace) = \prod_p \phi(H_ p \vert X_ p) \prod_ {p,q} \phi(H_ p \vert H_ q) $</p>
  </li>
  <li>Lemma 1ì— ë”°ë¥´ë©´ random PGMì´ ì´ëŸ¬í•œ íŠ¹ì„±ì„ ëª¨ë¸ë§í•˜ê¸° ë•Œë¬¸ì— edge(semi-clique)ì— ëŒ€í•œ í™•ë¥  { $p(\epsilon_ {pq}^{TT}$) }ì„ ì‚¬ìš©í•œ random structure2vecì„ ì ìš©</li>
  <li>ì‘ì—… $p$ì—ëŒ€í•œ embedding $\tilde{ \mu_ p } $ëŠ” ë‹¤ìŒê³¼ ê°™ìŒ.</li>
</ul>

<p>$\tilde{\mu_ p} \gets \sigma \left( W_ 1 x_ p +W_ 2 \sum_ {p \neq q} p_ {qp} \tilde{\mu_ q} \right) $</p>

<h3 id="42-estimating-state-action-value-using-order-trainability-enabled-q-function">4.2 Estimating state-action value using Order trainability-enabled Q-function</h3>
<ul>
  <li>MRRC ë¬¸ì œì—ì„œ ì£¼ì–´ì§€ëŠ” $X_ p$ëŠ” $d_ {ip}^{RT}$ (ë¡œë´‡ $i$ê³¼ ì‘ì—… $p$ì™€ì˜ ê±°ë¦¬)ì™€ $d_p^T$ (ì‘ì—… $p$ì˜ ë‚˜ì´)ë¡œ ë‘ ì¢…ë¥˜ ì´ë‹¤.</li>
  <li>ì´ë¥¼ í•˜ë‚˜ì˜ embeddingìœ¼ë¡œ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ action embeddingê³¼ value embeddingë¡œ êµ¬ë¶„ë˜ëŠ” two-stepì˜ sequntial random structure2vec network êµ¬ì¡°ë¥¼ ì œì•ˆí•¨.</li>
  <li>ë‘ step ëª¨ë‘ random structure2vecì„ ì‚¬ìš©í•˜ë©° ê·¸ë•Œ ë“¤ì–´ê°€ëŠ” feature ì¢…ë¥˜ë§Œ ë‹¤ë¦„
    <ul>
      <li>Action embedding: ë¡œë´‡ê³¼ í• ë‹¹ëœ ì‘ì—… ê°„ì˜ ìƒëŒ€ì ì¸ ìœ„ì¹˜ ì •ë³´ë¥¼ ì¶©ë¶„íˆ ì œê³µ</li>
    </ul>
  </li>
</ul>

<p>$ \tilde{\mu_ p}^A = \sigma \left( W_ 1^A x_ p^A +W_ 2^A \sum_ {p \neq q} p_ {qp} \tilde{\mu_ q}^A \right)  \text{, where } x_ p^A =d_ {ip}^{RT} $</p>

<ul>
  <li>Value embedding: ì£¼ì–´ì§„ ê³µë™ í• ë‹¹ì— ë”°ë¼ ê° ì‘ì—… ì£¼ë³€ì˜ ë¡œì»¬ ê·¸ë˜í”„ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ê°€ì¹˜ë¥¼ ì¶©ë¶„íˆ í‘œí˜„</li>
</ul>

<p>$ \tilde{\mu_ p}^V = \sigma \left( W_ 1^V x_ p^V +W_ 2^A \sum_ {p \neq q} p_ {qp} \tilde{\mu_ q}^V \right)  \text{, where } x_p^V =(\tilde{\mu_ p}^A,d_ p^T) $</p>

<ul>
  <li>ìµœì¢…ì ìœ¼ë¡œëŠ” ëª¨ë“  nodeì˜ embedding vectorë¥¼ ë”í•´ aggregationí•œ graphì˜ embeddingì„ $(s_ k,a_ k)$ì˜ represnetationìœ¼ë¡œ ì‚¬ìš©í•˜ë©° $Q_ \theta(s_ k,a_ k)$ ì— input</li>
</ul>

<p>$ \tilde{\mu}^V  = \sum_ p \tilde{\mu_ p}^V $</p>

<ul>
  <li><strong>Order-Transferability</strong>: ë¬¸ì œ í¬ê¸°(ê·¸ë˜í”„ í¬ê¸°) ì™€ ë¬´ê´€í•˜ê²Œ Q-valueë¥¼ estimateí•  ìˆ˜ ìˆìŒ
    <ul>
      <li>action embedding: ê° ë…¸ë“œ ì£¼ë³€ì—ì„œ ì§€ì—­ì ìœ¼ë¡œ ê·œëª¨ì™€ ë¬´ê´€í•œ ì‘ì—…ì´ê¸° ë•Œë¬¸ì— ì „ì´ ê°€ëŠ¥ì„±ì´ ìëª….</li>
      <li>value embedding: ë¡œë´‡ê³¼ ì‘ì—…ì˜ ë¹„ìœ¨ì´ ì¤‘ìš”. ë§Œì•½ í›ˆë ¨ í™˜ê²½ì˜ ë¡œë´‡-ì‘ì—… ë¹„ìœ¨ì´ í…ŒìŠ¤íŠ¸ í™˜ê²½ë³´ë‹¤ ì‘ìœ¼ë©´ ì „ì²´ ì„ë² ë”© ê°’ì´ ê³¼ì†Œ ì¶”ì •ë  ìˆ˜ ìˆê³ , ê·¸ ë°˜ëŒ€ì˜ ê²½ìš° ê³¼ëŒ€ ì¶”ì •ë  ìˆ˜ ìˆë‹¤.</li>
      <li>í•˜ì§€ë§Œ, Q-function ê¸°ë°˜ì˜ policyì—ì„œ Q-functionì˜ ê°’ ìˆœì„œë§Œ ë™ì¼í•˜ë©´ ê³¼ëŒ€/ê³¼ì†Œ ì¶”ì •ì€ ë¬¸ì œë˜ì§€ ì•ŠìŒ</li>
    </ul>
  </li>
</ul>

<h3 id="43-selecting-a-joint-assignment-using-otap">4.3 Selecting a joint assignment using OTAP</h3>
<ul>
  <li>ìƒíƒœ â€‹$s_ k$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ê³µë™ í• ë‹¹(action) $ğ‘_ k$ = a maximal bipartite matching in the bipartite graph $(R,T_ k,E_ k^{RT})$</li>
  <li>Order Trasferability-enabled Aution Policy(OTAP): Bidding phaseì™€ Consensus phase ë§ˆë‹¤ í•˜ë‚˜ì˜ ë¡œë´‡-ì‘ì—… í• ë‹¹ì„ ì¶”ê°€í•´ê°€ë©° $N=\max(\vert R \vert, \vert k \vert)$ë²ˆ ë°˜ë³µí•˜ë©° ëª¨ë“  ì‘ì—…í• ë‹¹ì´ ëë‚ ë–„ê¹Œì§€ ë°˜ë³µí•¨.
    <ul>
      <li>Bidding-phase:
        <ul>
          <li>ì•„ì§ í• ë‹¹ë˜ì§€ì•Šì€ ë¡œë´‡ë³„ë¡œ ì´ì „ iterationë“¤ì—ì„œ ì´ë¯¸ í• ë‹¹ëœ ë¡œë´‡-ì‘ì—…ì€ ê³ ì •í•˜ê³  ìê¸°ìì‹ ê³¼ ë‹¤ë¥¸ ì‘ì—… pairë¥¼ ì¶”ê°€í–ˆì„ë•Œì˜ Q-valueë¥¼ ê³„ì‚°í•˜ê³  ê·¸ ì¤‘ ê°€ì¥ í° ì‘ì—…ê³¼ Q-value bidding</li>
        </ul>
      </li>
      <li>Consensus-phase:
        <ul>
          <li>ì•„ì§ í• ë‹¹ë˜ì§€ì•Šì€ ë¡œë´‡ë“¤ì˜ biddingê°’ ì¤‘ ê°€ì¥ í° biddingê°’ì„ ì œì‹œí•œ ë¡œë´‡ì—ê²Œ í•´ë‹¹ ì‘ì—…ì„ í• ë‹¹</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="44-training-q-function-using-afqi">4.4 Training Q-function using AFQI</h3>
<ul>
  <li>ì¼ë°˜ì ì¸ fitted Q-learning (FQI):</li>
</ul>

<p>$ minimize_ \theta \quad E_ {(s_ k,a_ k,r_ k,s_ {k+1}) \sim D} [Q_ \theta(s_ k,a_ k) - [r(s_ k,a_ k) + \gamma \max_ a Q_ \theta (s_ {k+1},a) ]]$</p>

<ul>
  <li>Auction fitted Q-learning (AFQI):</li>
</ul>

<p>$ minimize_ \theta \quad E_ {(s_ k,a_ k,r_ k,s_ {k+1}) \sim D} [Q_ \theta(s_ k,a_ k) - [r(s_ k,a_ k) + \gamma Q_ \theta (s_ {k+1},\pi_ {Q_ \theta} (s_ {k+1})) ]]$</p>

<h2 id="5-theoretical-analysis">5. Theoretical analysis</h2>
<h3 id="51-performance-bound-of-otap">5.1 Performance bound of OTAP</h3>

<p><img src="../../images/DS535_24F/Learning_NP-Hard_Multi-Agent_Assignment_Planning_using_GNN_Inference_on_a_Random_Graph_and_Provable_Auction-Fitted_Q-learning/thm_2.png" alt="ex_screenshot" /></p>

<ul>
  <li>Theorem 2ë¥¼ í†µí•´ OTAP ì•Œê³ ë¦¬ì¦˜ì´ $1-1/e$ optimalityë¥¼ ê°€ì§</li>
</ul>

<h3 id="52-performance-bound-of-afqi">5.2 Performance bound of AFQI</h3>

<p><img src="../../images/DS535_24F/Learning_NP-Hard_Multi-Agent_Assignment_Planning_using_GNN_Inference_on_a_Random_Graph_and_Provable_Auction-Fitted_Q-learning/lem_3.png" alt="ex_screenshot" /></p>

<ul>
  <li>Lemma 3ì— ë”°ë¥´ë©´ FQIì˜ max operatorë¥¼ ì •ì±… $1-1/r$ì˜ ê·¼ì‚¬ ì •ì±…ìœ¼ë¡œ ëŒ€ì²´í•˜ë©´ FQIì—­ì‹œë„ $1-1/r$ optimalityë¥¼ ê°€ì§.</li>
  <li>AFQIì˜ ê²½ìš° $1-1/e$ì˜ ê·¼ì‚¬ ì •ì±… OTAPë¡œ max operatorë¥¼ ëŒ€ì²´í•˜ì˜€ê¸° ë•Œë¬¸ì— AFQI ì•Œê³ ë¦¬ì¦˜ì—­ì‹œ $1-1/e$ optimalityë¥¼ ê°€ì§</li>
</ul>

<h2 id="6-experiment">6. Experiment</h2>
<h3 id="61-experiment-setting">6.1 Experiment setting</h3>
<ul>
  <li>ì‘ì—… ì™„ë£Œ ì‹œê°„ì€ deterministic í™˜ê²½ì—ì„œëŠ” ë‹¤ìµìŠ¤íŠ¸ë¼ ì•Œê³ ë¦¬ì¦˜, stochastic í™˜ê²½ì—ì„œëŠ” ë™ì  í”„ë¡œê·¸ë˜ë°ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë¨</li>
  <li>í™•ë¥ ì  í™˜ê²½ì—ì„œëŠ” ë¡œë´‡ì´ íŠ¹ì • í™•ë¥ ë¡œ ì˜ë„í•œ ëŒ€ë¡œ ì›€ì§ì„.
    <ul>
      <li>ì ì´ ìˆëŠ” ì…€: ì„±ê³µ í™•ë¥  55%, ë‚˜ë¨¸ì§€ ë°©í–¥ ê°ê° 15%.</li>
      <li>ì ì´ ì—†ëŠ” ì…€: ì„±ê³µ í™•ë¥  70%, ë‚˜ë¨¸ì§€ ë°©í–¥ ê°ê° 10%.</li>
    </ul>
  </li>
  <li>ë¡œë´‡ì´ ì‘ì—… ì§€ì ì— ë„ë‹¬í•˜ë©´ í•´ë‹¹ ì‘ì—…ì€ ì™„ë£Œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼. ë³´ìƒ ê·œì¹™ìœ¼ë¡œëŠ” ë‘ ê°€ì§€ë¥¼ ì‚¬ìš©:
    <ul>
      <li>Linear : $f(age) = \max\lbrace 200 - age,0 \rbrace$</li>
      <li>Nonlinear : $f(age) = \lambda^{age} $ ($\lambda = 0.99$)</li>
    </ul>
  </li>
  <li>Baselines:
    <ul>
      <li>deterministic: MILP ê³µì‹í™” í›„ 2ê°€ì§€ ì•Œê³ ë¦¬ì¦˜
        <ul>
          <li>Optimal: Gurobi Optimization(2019)ì˜ MILP ìµœì í™” ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬, 60ë¶„ ì œí•œ ì‹œê°„ ë‚´ì— ë¬¸ì œë¥¼ í•´ê²°</li>
          <li>Ekici et al. (2013): Operations Research ë¶„ì•¼ì—ì„œ ìµœì‹  íœ´ë¦¬ìŠ¤í‹± ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©</li>
        </ul>
      </li>
      <li>stochastic or Nonlinear: ì´ì „ ì—°êµ¬ê°€ ì—†ê¸° ë•Œë¬¸ì— ê°„ì ‘ì ì¸ benchmarkì‚¬ìš©
        <ul>
          <li>Sequential Greedy Algorithm (SGA) :ì¼ë°˜ì ì¸ ë‹¤ì¤‘ ë¡œë´‡ ì‘ì—… í• ë‹¹ ì•Œê³ ë¦¬ì¦˜(SGA; Han-Lim Choi et al., 2009)ì„ ì‚¬ìš©í•˜ì˜€ë‹¤.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Performance measure:</li>
</ul>

<p>$ \rho = \frac{\text{Rewards collected by the proposed method}}{\text{Reward collected by the baseline}} $</p>

<h3 id="62-performance-test">6.2 Performance test</h3>

<p><img src="../../images/DS535_24F/Learning_NP-Hard_Multi-Agent_Assignment_Planning_using_GNN_Inference_on_a_Random_Graph_and_Provable_Auction-Fitted_Q-learning/tab_1.png" alt="ex_screenshot" /></p>

<p>-ì œì•ˆëœ ë°©ë²•ì€ ê²°ì •ë¡ ì /ì„ í˜• ë³´ìƒ í™˜ê²½ì—ì„œ ìµœì  í•´ë³´ë‹¤ í‰ê·  3% ë‚®ì€ ë³´ìƒì„ ë‹¬ì„±í•˜ë©°, ê±°ì˜ ìµœì ì˜ ì„±ëŠ¥ì„ ë³´ì„.</p>
<ul>
  <li>ë‹¤ë¥¸ í™˜ê²½ì—ì„œë„ SGA ë¹„ìœ¨ì´ ì˜ ìœ ì§€ë¨.</li>
</ul>

<h3 id="63-transferability-test">6.3 Transferability test</h3>

<p><img src="../../images/DS535_24F/Learning_NP-Hard_Multi-Agent_Assignment_Planning_using_GNN_Inference_on_a_Random_Graph_and_Provable_Auction-Fitted_Q-learning/tab_2.png" alt="ex_screenshot" /></p>

<ul>
  <li>í–‰ì€ í›ˆë ¨ ì¡°ê±´ì„ ë‚˜íƒ€ë‚´ê³ , ì—´ì€ í…ŒìŠ¤íŠ¸ ì¡°ê±´ì„ ë‚˜íƒ€ëƒ„.</li>
  <li>ëŒ€ê°ì„  ì…€(ë¹¨ê°„ìƒ‰)ì€ ë™ì¼í•œ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ í¬ê¸°ì—ì„œì˜ ì§ì ‘ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ë©°, baseline ì„±ëŠ¥ìœ¼ë¡œ ì‚¬ìš©.</li>
  <li>ë¹„ëŒ€ê°ì„  ì…€ì€ ì „ì´ ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ë©°, ë‹¤ë¥¸ ë¬¸ì œ í¬ê¸°ì—ì„œ í›ˆë ¨ëœ ì•Œê³ ë¦¬ì¦˜ì´ í…ŒìŠ¤íŠ¸ ë¬¸ì œì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰ë˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„.
    <ul>
      <li>í•˜í–¥ ì „ì´ í…ŒìŠ¤íŠ¸(í° ë¬¸ì œë¡œ í›ˆë ¨í•˜ê³  ì‘ì€ ë¬¸ì œì—ì„œ í…ŒìŠ¤íŠ¸)ëŠ” ì„±ëŠ¥ ì†ì‹¤ì´ ê±°ì˜ ì—†ìŒ.</li>
      <li>ìƒí–¥ ì „ì´ í…ŒìŠ¤íŠ¸(ì‘ì€ ë¬¸ì œë¡œ í›ˆë ¨í•˜ê³  í° ë¬¸ì œì—ì„œ í…ŒìŠ¤íŠ¸)ëŠ” ìµœëŒ€ 4%ì˜ ì„±ëŠ¥ ì†ì‹¤ì´ ë°œìƒí•¨.</li>
    </ul>
  </li>
</ul>

<h3 id="64-scalability-analysis">6.4 Scalability analysis</h3>

<p><img src="../../images/DS535_24F/Learning_NP-Hard_Multi-Agent_Assignment_Planning_using_GNN_Inference_on_a_Random_Graph_and_Provable_Auction-Fitted_Q-learning/tab_3.png" alt="ex_screenshot" /></p>

<ul>
  <li>í›ˆë ¨ ë³µì¡ì„±
    <ul>
      <li>deterministicì—ì„œ linear ë³´ìƒì„ ê³ ë ¤í•  ë•Œ 93% ìµœì  ì„±ëŠ¥ì— ë„ë‹¬í•˜ëŠ” ë° í•„ìš”í•œ í›ˆë ¨ ì‹œê°„ì„ ì¸¡ì •í•¨.</li>
      <li>í‘œ 4ì— ë”°ë¥´ë©´, ë¬¸ì œ í¬ê¸°ê°€ ì»¤ì§€ë”ë¼ë„ í›ˆë ¨ ì‹œê°„ì´ ë°˜ë“œì‹œ ì¦ê°€í•˜ì§€ëŠ” ì•Šìœ¼ë©°, ì„±ëŠ¥ì´ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë¨</li>
    </ul>
  </li>
  <li>MRRC ë¬¸ì œ ë³µì¡ì„±:
    <ul>
      <li>MRRC ë¬¸ì œëŠ” semi-MDP ê¸°ë°˜ì˜ ë‹¤ì¤‘ ë¡œë´‡ ê³„íš ë¬¸ì œë¡œ ê³µì‹í™”í•  ìˆ˜ ìˆìŒ</li>
      <li>$R$ëŒ€ ë¡œë´‡, $T$ê°œ ì‘ì—…, ìµœëŒ€ì‹œê°„ $H$ì¼ë•Œ, ë¬¸ì œ ë³µì¡ë„ëŠ” $O((R!/T!(R-T)!)^H)$.</li>
      <li>ì œì•ˆëœ ë°©ë²•ì€ ì´ê±¸ ê³„ì‚°ë³µì¡ë„ì™€ í›ˆë ¨ ë³µì¡ë„ë¡œ ë¶„ë¦¬í•˜ì—¬ í•´ê²°.</li>
      <li>ê° ì‹œê°„ ë‹¨ê³„ì—ì„œ actionì„ ìœ„í•œ ê³„ì‚°ë³µì¡ë„ëŠ” $O(\vert R\vert \vert T\vert^3)$.</li>
    </ul>
  </li>
</ul>

<h2 id="7-conclusion">7. Conclusion</h2>
<p>ë³¸ ë…¼ë¬¸ì—ì„œëŠ” NP-ë‚œí•´í•œ ë‹¤ì¤‘ ë¡œë´‡/ê¸°ê³„ ìŠ¤ì¼€ì¤„ë§ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê·¼ì‚¬ ìµœì ì˜ í•™ìŠµ ê¸°ë°˜ ë°©ë²•ì„ ê°œë°œí•˜ëŠ” ë„ì „ì— ëŒ€í•´ ë‹¤ë£¨ì—ˆë‹¤. ìš°ë¦¬ëŠ” ìŠ¤ì¼€ì¤„ë§ ë¬¸ì œë¥¼ ìœ„í•œ mean-field inference ì´ë¡ ì„ ê°œë°œí•˜ê³ , ì´ì— ê¸°ë°˜í•œ Q-í•¨ìˆ˜ë¥¼ ì •í™•í•˜ê²Œ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” ì´ë¡ ì ìœ¼ë¡œ ì •ë‹¹í™”ëœ GNN ë°©ë²•ì„ ì œì•ˆí•˜ì˜€ë‹¤. ë˜í•œ, ë‹¤ì¤‘ ë¡œë´‡/ê¸°ê³„ ìŠ¤ì¼€ì¤„ë§ ë¬¸ì œì—ì„œ Fitted Q-Iteration ë°©ë²•ì˜ í™•ì¥ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤í•­ ì‹œê°„ ë‚´ì— ê³„ì‚° ê°€ëŠ¥í•œ ì•Œê³ ë¦¬ì¦˜ê³¼ ì„±ëŠ¥ ë³´ì¥ì„ ì œê³µí•˜ì˜€ë‹¤. ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ í†µí•´ ì œì•ˆëœ ë°©ë²•ì˜ íš¨ìœ¨ì„±ì„ ì…ì¦í•˜ì˜€ë‹¤.</p>
<h2 id="references">References</h2>
<ul>
  <li>Dai, H., Dai, B., and Song, L. Discriminative Embeddings of Latent Variable Models for Structured Data. 48:1â€“23, 2016. doi: 1603.05629.</li>
  <li>Gurobi Optimization, L. Gurobi optimizer reference manual, 2019. URL http://www.gurobi.com.</li>
  <li>Ekici, A. and Retharekar, A. Multiple agents maximum collection problem with time dependent rewards. Computers and Industrial Engineering, 64(4):1009â€“1018, 2013. ISSN 03608352. doi: 10.1016/j.cie.2013.01.010. URL http://dx.doi.org/10.1016/j.cie.2013.01.010.</li>
  <li>Han-Lim Choi, Brunet, L., and How, J. Consensus-Based Decentralized Auctions for Robust Task Allocation. IEEE Transactions on Robotics, 25(4):912â€“926, aug 2009. ISSN 1552-3098. doi: 10.1109/TRO.2009.2022423.</li>
</ul>

    </div>



</article>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>







<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy;2024 Copyright 2021 Google LLC. All rights reserved. <br />
 Site last generated: Oct 18, 2024 <br />
<p><img src="images/company_logo.png" alt="Company logo"/></p>
                </div>
            </div>
</footer>






        </div>
    <!-- /.row -->
</div>
<!-- /.container -->
</div>
<!-- /#main -->
    </div>

</body>

<!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-66296557-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>





</html>


