<!DOCTYPE html>
<html>
<head>
    <meta name="google-site-verification" content="1tAPTdgw0-t8G2Bya463OpBtYUbj9Um93gfnsowYKLw" />
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CV4PTXQSTW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-CV4PTXQSTW');
</script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="keywords" content="reviews,  ">
<title>[KDD 2021] MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems | Awesome Reviews</title>
<link rel="stylesheet" href="css/syntax.css">

<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="css/modern-business.css">
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="css/customstyles.css">
<link rel="stylesheet" href="css/boxshadowproperties.css">
<!-- most color styles are extracted out to here -->
<link rel="stylesheet" href="css/theme-blue.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="js/jquery.navgoco.min.js"></script>


<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<!-- Anchor.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js"></script>
<script src="js/toc.js"></script>
<script src="js/customscripts.js"></script>

<link rel="shortcut icon" href="images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="DSAILatKAIST.github.io" href="http://dsailatkaist.github.io/feed.xml">


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>




    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    <script>
        $(document).ready(function() {
            $("#tg-sb-link").click(function() {
                $("#tg-sb-sidebar").toggle();
                $("#tg-sb-content").toggleClass('col-md-9');
                $("#tg-sb-content").toggleClass('col-md-12');
                $("#tg-sb-icon").toggleClass('fa-toggle-on');
                $("#tg-sb-icon").toggleClass('fa-toggle-off');
            });
        });
    </script>
    


	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
	},
	tex2jax: {
		inlineMath: [ ['$', '$'] ],
		displayMath: [ ['$$', '$$'] ],
		processEscapes: true,
		}
	});
	MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
	MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
		alert("Math Processing Error: "+message[1]);
	});
</script>

<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="text/javascript" async
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-static-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="fa fa-home fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle"> Awesome Reviews</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- toggle sidebar button -->
                <li><a id="tg-sb-link" href="#"><i id="tg-sb-icon" class="fa fa-toggle-on"></i> Nav</a></li>
                <!-- entries without drop-downs appear here -->




                
                
                
                <li><a href="introduction">Introduction</a></li>
                
                
                
                <li><a href="https://statistics.kaist.ac.kr/" target="_blank" rel="noopener">KAIST ISysE</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Reviews<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="reviews_kse801_2022.html">KSE801 (2022)</a></li>
                        
                        
                        
                        <li><a href="reviews_DS503_2023.html">DS503 (2023)</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
			<li>



  <a class="email" title="Submit feedback" href="#" onclick="javascript:window.location='mailto:swkim@kaist.ac.kr?subject=Question about reviews feedback&body=I have some feedback about the [KDD 2021] MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems page: ' + window.location.href;"><i class="fa fa-envelope-o"></i> Feedback</a>

</li>



		
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">
                        <input type="text" id="search-input" placeholder="search...">
                        <ul id="results-container"></ul>
                    </div>
                    <script src="js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: 'search.json',
                                searchResultTemplate: '<li><a href="{url}" title="[KDD 2021] MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>



<!-- Page Content -->
<div class="container">
  <div id="main">
    <!-- Content Row -->
    <div class="row">
        
        
            <!-- Sidebar Column -->
            <div class="col-md-3" id="tg-sb-sidebar">
                

<ul id="mysidebar" class="nav">
  <li class="sidebarTitle"> </li>
  
  
  
  <li>
      <a title="How to contribute" href="#">How to contribute</a>
      <ul>
          
          
          
          <li><a title="How to contribute?" href="how_to_contribute.html">How to contribute?</a></li>
          
          
          
          
          
          
          <li><a title="Review template (Example)" href="template.html">Review template (Example)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
  
  <li>
      <a title="Reviews" href="#">Reviews</a>
      <ul>
          
          
          
          <li><a title="KSE801 (2022F)" href="reviews_kse801_2022.html">KSE801 (2022F)</a></li>
          
          
          
          
          
          
          <li><a title="DS503 (2023S)" href="reviews_DS503_2023.html">DS503 (2023S)</a></li>
          
          
          
          
      </ul>
   </li>
     
      
      
      <!-- if you aren't using the accordion, uncomment this block:
         <p class="external">
             <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
         </p>
         -->
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>



            </div>
            
        

        <!-- Content Column -->
        <div class="col-md-9" id="tg-sb-content">
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/math...">
</script>
<article class="post" itemscope itemtype="https://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[KDD 2021] MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems</h1>
        <p class="post-meta"><time datetime="2023-04-20T00:00:00+09:00" itemprop="datePublished">Apr 20, 2023</time> /
            
            
            
            
            

        </p>


    </header>

    <div class="post-content" itemprop="articleBody">

        

        <h1 id="title"><strong>Title</strong></h1>

<p><strong>MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems</strong></p>

<h2 id="1-problem-definition"><strong>1. Problem Definition</strong></h2>

<p>Graph Neural Networks (GNNs)은 논문 작성 당시 state-of-the-art collaborative filtering (CF) solution으로 부상하였다.
CF의 근본적인 challenge는 implicit feedback에서 negative signal을 추출하는 것이지만 GNN 기반 CF 모델에서의 negative sampling에 대한 연구는 많이 부족하다.</p>

<h2 id="2-motivation"><strong>2. Motivation</strong></h2>

<p>일반적으로 negative sampling에는 uniform distribution이 사용된다. negative samples의 quality를 향상시키기 위해 유익한 negative sample의 우선순위를 정하기 위한 새로운 sampling distribution을 설계하려는 연구들이 있었다.
GNN에서는 Negative Sampling을 개선하기 위해 다음과 같은 연구가 진행되었다.</p>
<ul>
  <li><a href="https://arxiv.org/abs/1806.01973">PinSage</a>: PageRank 점수를 기반으로 negative sampling</li>
  <li><a href="https://arxiv.org/abs/2005.09863">MCNS</a>: structural correlation을 염두해 두고 positive와 negative sampling의 분포를 재설계</li>
</ul>

<p>하지만 GNN에서의 이러한 시도는 GNN의 embedding space에서의 고유한 neighborhood aggregation 과정을 무시하고 불연속 graph space에서의 negative sampling을 개선하는 데에만 초점을 맞춘다.
<strong>MixGCF</strong>는 데이터에서 실제 negative sample을 직접 sampling하는 대신 negative sample을 합성한다. 그리고 기존 GNN 기반 추천 모델을 연결하여 사용할 수 있는 <em>positive mixing</em>과 <em>hop mixing</em> 전략을 제시하였다.</p>

<h2 id="3-method"><strong>3. Method</strong></h2>

<p><strong>MixGCF</strong>는 GNN 기반 추천에서 negative sampling을 위한 일반적인 알고리즘으로 LightGCN 및 NGCF와 같은 기존 GNN 기반 추천 알고리즘에 연결하여 사용할 수 있다. data의 실제 item을 negative item으로 샘플링하는 대신 GNN 기반 추천 모델을 학습하기 위해 그래프 구조를 기반으로 informative하고 fake한 negative item을 합성할 것을 제안한다. 특히 서로 다른 local graph의 정보를 mixing하여 negative sample을 합성하는 <em>positive mixing</em> 및 <em>hop mixing</em> 전략을 도입하였다.</p>

<p><strong>MixGCF</strong>의 흐름은 아래 그림과 같다.</p>
<p align="center">
<img src="https://velog.velcdn.com/images/yst3147/post/a6890d21-f2e9-4cd2-b238-c97de77daa57/image.png" />
</p>

<p><em>positive mixing</em>에서 positive sample의 정보를 negative sample에 주입하여 hard negative candidates를 만드는 interpolation mixing 방법을 활용한다.
<em>hop mixing</em>에서 먼저 hard negative selection 전략을 사용하여 위에서 생성된 각 hard negative candidates에서 고유한 정보를 추출한 다음
<em>pooling</em> 작업을 하여 추출된 다양한 정보를 결합, fake지만 informative한 negative item들을 생성한다.</p>

<h3 id="31-positive-mixing">3.1 Positive Mixing</h3>
<p>$L$-layer GNN에서 각 item $v$에 대해  $L+1$ 개의 embedding을 가질 수 있으며, 각 $e_v^{(l)}$은 l layer $(0 \le l \le L)$로 aggregate 되는 embedding을 의미한다.
negative $v_i^-$를 그것의 embedding인 $e_{v^-}$과 함께 fake로 만들기 위해 $M$개의 negative item을 선택하여 $M$이 일반적으로 데이터의 아이템 수보다 훨씬 작은 candidate set <strong>M</strong> 을 만든다. 이러한 $M$개 negative 아이템은 $M * (L + 1)$ size의  cadidate negative embedding set $\varepsilon = {e_{v_m}^{(l)}}$ 를 형성할 수 있다.</p>

<p><em>Positive mixing</em>은 <a href="https://arxiv.org/abs/1710.09412"><em>mixup</em></a>의 영향을 받아 $\varepsilon$에 속한 negative embedding에 positive information $e_{v^+}$을 주입한다.
<em>mixup</em>은 interpolation 기반 data augmentation 방법으로 model이 training data 간에 선형적인 output을 갖도록 해준다.
각 candidate negative embedding ${e_{v_m}^{(l)}} \in \varepsilon$에 대하여 <em>positive mixing</em> 작업은 다음 식과 같이 이루어진다.</p>

<p>$\mathbf{e}_ {v_ m}^{(l)}=\alpha^{(l)} \mathbf{e}_ {v^{+}}^{(l)}+\left(1-\alpha^{(l)}\right) \mathbf{e}_ {v_ m}^{(l)}, \alpha^{(l)} \in(0,1)$</p>

<p>여기서 $\alpha^{(l)}$은 각 홉 $l$에 대해 균일하게 샘플링되는 mixing coefficient 이다. 이 때 <em>mixup</em>의 mixing coefficient는 model의 generalization 능력에 큰 영향을 미치는 beta distribution Beta $(\beta, \beta)$에서 sampling된다. 그 영향을 decoupling하기 위해 해당 모델에서의 postive mixing에서의 mixing coefficient $\alpha^{(l)}$는 (0,1) 범위에서 균일하게 sampling된다.</p>

<p>$\varepsilon^\prime$을 candidate negatives set <strong>M</strong>에 대해 강화된 embedding이라고 정의한다.
<em>Positive mixing</em>은 다음과 같은 방법들을 활용하여 negative를 강화시킨다.</p>
<ul>
  <li>negative sample에 positive 정보를 주입하여 decision boundary를 더 잘 활용하도록 optimization 알고리즘을 수행하게 하는 데 도움을 준다.</li>
  <li>random mixing coefficient를 사용하여 확률적 불확실성을 도입한다.</li>
</ul>

<h3 id="32-hop-mixing">3.2 Hop Mixing</h3>
<p><em>hop mixing</em>은 <em>positive mixing</em>에 의해 강화된 candidate negative items embedding 
$\varepsilon^{\prime} = \lbrace{e_{v_m}^{\prime(l)}}\rbrace$ 를 가지고 합성 negative item $v^-$ 과 그것의 embedding $e_{v^-}$를 만드는 방법이다.</p>

<p><em>hop mixing</em>의 main idea는 GNN의 layer 기반 계층적 aggregation process를 활용하는 것이다.
각 layer $l(0 \le l \le L)$로부터 <strong>M</strong>에 속한 모든 candidate negative item에 대한 $l$번째 layer embedding이 포함된 $\varepsilon^{\prime(l)}$에서 하나의 candidate negative embedding $e_{v_x}^{\prime(l)}(1 \le x \le M)$을 뽑는다.</p>

<p>만약 $L = 2$라면 $e_{v_a}^{\prime(0)}, e_{v_b}^{\prime(1)},e_{v_c}^{\prime(2)}$를 $\varepsilon^{\prime}$에서 뽑을 수 있고 $a, b, c$는 반드시 별개일 필요는 없다.
<em>hop mixing</em>은 각 layer에서 선택한 모든 $(L+1)$개의 embedding을 결합하여 fake negative $v^-$에 대한 representation $e_{v^-}$를 생성한다. representation은 pooling 작업을 통해 모든 candidate embedding을 융합함으로써 합성된다:
\(e_{v^-} = f_{pool} \left(e_{v_x}^{\prime(0)}, \cdots ,e_{v_y}^{\prime(L)}\right)\)</p>

<p>이 때 $e_{v_x}^{\prime(l)}$는 layer $l$ 에서 뽑힌 $v_x$ 의 $l$ 번째 layer embedding이고 $f_{pool}(\cdot)$은 GNN 기반 추천 모델에서 쓰이는 pooling과 동일한 연산을 적용한다.</p>

<p><em>hop mixing</em>에 대한 중요한 질문은 어떻게 각 layer $l$의 $\varepsilon^{\prime^{(l)}}$에서 candidate embedding ${e}_{v_x}^{\prime(l)}(1 \le x \le M)$를 잘 뽑는가이다.
논문에서 negative sampling에 대해 제안하는 방법은 추정된 positive distribution에 따라 negative sample을 선택하는 것이다.
내적 score를 통해 positive distribution을 근사화하고 가장 높은 점수를 가진 candidate sample을 선택한다. 이 전략을 hard negative select strategy 라고도 한다.</p>

<p>$l$번째 layer에서의 hard selection strategy는 다음과 같이 구현된다:</p>

<p>$\mathbf{e}_ {v_x}^{\prime(l)}=\underset{\mathbf{e}_ {v_m}^{\prime(l)} \in \mathcal{E}^{(l)}}{\arg \max } f_ {\mathrm{Q}}(u, l) \cdot \mathbf{e}_ {v_m}^{\prime(l)}$</p>

<p>여기서 $\cdot$은 내적 연산이고, $f_Q(u, l)$은 $l$번째 hop에 대한 target user $u$의 embedding을 반환하는 query mapping이다.
위 식의 query는 추천에 사용되는 GNN의 pooling module에 따라 다르다.
GNN 기반 추천 모델에서 target user embedding $e_u$와 합성된 negative embedding $e_{v^-}$ 사이의 내적을 구하는 방법은 2가지가 있다</p>
<ul>
  <li>Sum based pooling: $\mathbf e_u\cdot\mathbf e_{v^{-}} = \displaystyle\sum_{l=0}^{L} \lambda_l \mathbf e_u \cdot \mathbf e_{v^{-}}^{(l)}$</li>
  <li>Concat based pooling: $\mathbf e_u \cdot \mathbf e_{v^{-}} = \displaystyle\sum_{l=0}^{L} \mathbf e_u^{(l)} \cdot \mathbf e_{v^{-}}^{(l)}$</li>
</ul>

<p>GNN 기반 추천 모델에서 사용되는 pooling 과 일치하는 selection process를 만들기 위해 위의 식의 $f_{\mathrm{Q}}(u, l)$을  sum based pooling은 $e_u$, concat based pooling은 $e_u^{(l)}$로 정의한다.</p>

<h3 id="33-optimization-with-mixgcf">3.3 Optimization with MixGCF</h3>
<p><strong>MixGCF</strong>에서도 다른 gnn 기반 추천 모델의 parameter를 최적화하기 위한 <a href="https://dl.acm.org/doi/10.5555/1795114.1795167">BPRloss</a>를 사용할 수 있다.
<strong>MixGCF</strong>에서의 BPRloss는 다음과 같이 업데이트 될 수 있다:</p>

<p>$\mathcal{L}_ {\mathrm{BPR}}=\sum_ {\substack{\left(u, v^{+}\right) \in O^{+} \mathbf{e}_ {v^{-}} \sim f_ {\mathrm{MixGCF}}\left(u, v^{+}\right)}} \ln \sigma\left(\mathbf{e}_ u \cdot \mathbf{e}_ {v^{-}}-\mathbf{e}_ u \cdot \mathbf{e}_ {v^{+}}\right)$</p>

<p>$\sigma(\cdot)$은 sigmoid function이고, $O^+$는 positive feedback set를 의미한다. 
그리고 $e_ {v^{-} \sim f_ {MixGCF\left(u, v^{+}\right)}}$ 는 instance embedding $e_{v^-}$는 제안된 MixGCF 방법으로 합성된다는 것을 의미한다.</p>

<p>위 전체 학습 과정을 알고리즘으로 나타내면 아래와 같다.</p>

<p align="center">
<img src="https://velog.velcdn.com/images/yst3147/post/13e6ba17-9d25-4ea0-8fa3-0db5d62ccb63/image.png" />
</p>

<h2 id="4-experiment"><strong>4. Experiment</strong></h2>

<h3 id="experiment-setup"><strong>Experiment setup</strong></h3>
<ul>
  <li>Dataset
    <ul>
      <li>Alibaba</li>
      <li>Yelp2018</li>
      <li>Amazon</li>
    </ul>
  </li>
  <li>Recommender
    <ul>
      <li><a href="https://arxiv.org/abs/2002.02126">LightGCN</a></li>
      <li><a href="https://arxiv.org/abs/1905.08108">NGCF</a></li>
      <li><a href="https://arxiv.org/abs/1806.01973">PinSage</a></li>
    </ul>
  </li>
  <li>baseline(Negative Sampling)
    <ul>
      <li>static(<a href="https://dl.acm.org/doi/10.5555/1795114.1795167">RNS</a>)</li>
      <li>hard negative(<a href="https://dl.acm.org/doi/10.1145/2484028.2484126">DNS</a>)</li>
      <li>GAN-based(<a href="https://dl.acm.org/doi/10.1145/3077136.3080786">IRGAN</a> and <a href="https://arxiv.org/abs/1811.04155">AdvIR</a>)</li>
      <li>graph-based(<a href="https://arxiv.org/abs/2005.09863">MCNS</a>)</li>
    </ul>
  </li>
  <li>Evaluation Metric
    <ul>
      <li>Recall@20</li>
      <li>NDCG@20</li>
    </ul>
  </li>
</ul>

<h3 id="result"><strong>Result</strong></h3>

<h4 id="performance-comparison">Performance Comparison</h4>
<p align="center">
<img src="https://velog.velcdn.com/images/yst3147/post/f70ca71e-8592-4a9e-bbc7-ad968c3e85fb/image.png" />
</p>

<p>baseline 중 결과가 best인 것은 밑줄, 그리고 <strong>MixGCF</strong>는 별표로 표시하였다.</p>
<ul>
  <li>LightGCN은 NGCF와 PinSage에 비해 세가지 데이터 모두에서 높은 성능을 보인다. nonlinearity와 weight matrix가 collaborative filtering에 useless함을 확인할 수 있다.</li>
  <li><strong>MixGCF</strong>는 모든 데이터셋에서 가장 좋은 성능을 보인다. 그 이유는 다음과 같다고 주장한다.
    <ul>
      <li><em>hop mixing</em>을 통해 negative sample을 생성하여 추천 모델의 generalization 성능을 개선하였다.</li>
      <li>여러 instance의 서로 다른 information을 통합하여 합성된 hard negative는 추천 모델에 informative한 gradient를 제공한다.</li>
    </ul>
  </li>
  <li>NGCF와 PinSage는 LightGCN에 비해 <strong>MixGCF</strong>를 사용했을 때 더 큰 성능 향상을 보였다. 그 이유는 다음과 같다.
    <ul>
      <li>burdensome design은 큰 파라미터 공간을 제공하여, NGCF와 PinSage는 informative한 negative로부터 더 많은 이점을 얻는다.</li>
      <li>LightGCN은 positive와 easy negative item을 잘 구별한다.</li>
    </ul>
  </li>
  <li>DNS는 대부분의 경우에서 baseline 중 가장 좋은 성능을 보인다. 이를 통해 hard negative를 선택하는 것이 model에게 의미 있는 gradient를 제공한다는 것을 알 수 있다.</li>
</ul>

<h4 id="impact-of-presence-of-positive-mixing">Impact of Presence of Positive Mixing</h4>
<p align="center">
<img src="https://velog.velcdn.com/images/yst3147/post/08732018-5ac4-4467-a93f-95e2d8144daa/image.png" />
</p>

<p><strong>MixGCF</strong>$_{w/o \; p-m}$는 <em>positive mixing</em>이 제거된 <strong>MixGCF</strong>를 의미한다.</p>
<ul>
  <li>위의 (a)부터 (i) 시각화 결과를 통해 대부분의 경우에서 <em>positive mixing</em>을 제거했을 때 성능이 하락하는 것을 볼 수 있다. 이를 통해 <em>positive mixing</em>의 필요성을 알 수 있다.</li>
  <li><em>positive mixing</em>이 제거되어도 MixGCF는 여전히 대부분의 경우에서 DNS에 비해 성능이 높고, 이를 통해 GNN 기반 추천 모델에서 hop-wise sampling이 instance-wise sampling보다 효과적임을 보여 준다.</li>
  <li><strong>MixGCF</strong>$_{w/o \; p-m}$의 경우 성능이 초기 단계에서 급증하지만 빠르게 최고점에 도달하고 하락하는 것을 볼 수 있다. 반면 <strong>MixGCF</strong>는 <em>positive mixing</em>의 이점 덕분에 overfitting에 견고해진다.</li>
</ul>

<h4 id="impact-of-neighbor-range">Impact of Neighbor Range</h4>
<p align="center">
<img src="https://velog.velcdn.com/images/yst3147/post/d644fd95-a99d-4dc1-a26f-69bd4893abfc/image.png" />
</p>

<p>Neighbor range, 즉 layer 개수를 바꾸어 가며 실험을 진행하였다.
$L$은 $\lbrace 1, 2, 3\rbrace$ 값을 사용하였다.</p>
<ul>
  <li>layer 수를 늘리면 대부분의 경우 추천 모델의 성능을 향상시킬 수 있다.
더 큰 범위의 neighbor를 고려하면 더 많은 negative item이 negative를 합성할 때 포함될 수 있다.</li>
  <li>PinSage에서는 <strong>MixGCF</strong>-1이 <strong>MixGCF</strong>-2나 <strong>MixGCF</strong>-3와 비슷하거나 더 높은 성능을 보인다는 것을 알 수 있다. layer가 많으면 PinSage는 over-smoothing 될 위험이 있기 때문이다.</li>
</ul>

<h4 id="impact-of-candidate-set">Impact of Candidate Set</h4>

<p align="center">
<img src="https://velog.velcdn.com/images/yst3147/post/66b90542-f36c-4e8f-92df-907765e0ebaf/image.png" />
</p>

<p>candidate set <strong>M</strong>의 size를 바꾸어 가며 실험을 진행하였다.
$M$은 $\lbrace 8, 16, 32, 64\rbrace$ 값을 사용하였다.
각 데이터 및 모델 별 best result는 별표로 표시하였다.</p>
<ul>
  <li>candidate set의 크기를 늘리면 대부분의 경우 추천 모델의 성능이 향상된다. NGCF의 경우 3 dataset 모두에서 가장 높은 성능을 보인다.</li>
  <li>Amazon dataset의 경우 다른 dataset에 비해 M이 증가할 때 성능이 향상되지 않는다. dataset의 scale과 distribution이 다르기 때문이다.</li>
</ul>

<h4 id="impact-of-distribution-of-positive-mixing">Impact of Distribution of Positive Mixing</h4>
<p>random coefficient $\alpha^{(l)}$의 경우 <em>positive mixing</em>에서 핵심이기 때문에, LightGCN에서 random coefficient의 distribution을 바꾸어 가며 실험을 진행하였다.
사용된 분포는 다음과 같다</p>
<ul>
  <li>beta distribution: Beta $(\beta, \beta)$, $\beta$ in range $\lbrace 0.2, 0.4 \rbrace$</li>
  <li>gaussian distribution: Gaus $(\mu, \sigma)$, $\mu = 0.5, \sigma = 0.1$</li>
  <li>uniform distribution: Uni $(0, \alpha)$, $\alpha = 0.5, 1$</li>
</ul>

<p align="center">
<img src="https://velog.velcdn.com/images/yst3147/post/057a13c5-e380-4116-bb40-bf25fb7e2b6f/image.png" />
</p>

<ul>
  <li><em>positive mixing</em>의 원래 설정인 Uni(0, 1)의 경우 모든 경우에서 best performance를 보인다. Uni(0, 1)이 Uni(0, 0.5)보다 더 높은 성능을 보이는게 가능한 이유는 random coefficient의 범위를 제한하면 model parameter의 search space가 줄어들기 때문이다.</li>
  <li>beta distribution의 경우 모든 3개 dataset에서 좋지 못한 성능을 보인다. 그 이유는 <em>mixup</em>에서 hyperparameter $\beta$의 정교한 선택이 요구되기 때문이다.</li>
</ul>

<p>위와 같은 이유로 $\alpha^{(l)}$을 sampling할 때 Uniform (0,1) distribution을 사용한다.</p>

<h2 id="5-conclusion"><strong>5. Conclusion</strong></h2>

<p>이 논문은 GNN 기반 추천 모델의 negative sample quality 향상을 목표로 연구를 진행하였다.
simple하고 non-parametric한 방법인 <strong>MixGCF</strong>는 기존 negative item을 sampling 하는 대신 여러 negative item을 통합하여 <em>positive mixing</em>과 <em>hop mixing</em>을 통해 hard negative를 합성한다.
그 결과 <strong>MixGCF</strong>는 GNN 기반 추천 모델의 성능 향상을 이끌어 낼 수 있었다.</p>

<p>대부분의 user-item 데이터의 sparsity가 높기 때문에 negative sampling이 추천 모델 성능 향상에 중요한 역할을 한다고 볼 수 있다.
해당 논문에서는 negative sampling의 품질 향상을 위한 연구를 진행하여 gnn 기반 추천 모델의 성능을 향상시킴으로서 negative sampling의 중요성을 잘 보여 주었다.</p>

<hr />
<h2 id="author-information"><strong>Author Information</strong></h2>

<ul>
  <li>유승태 (SeungTai Yoo)
    <ul>
      <li>Master Student, Graduate School of Data Science(GSDS), KAIST</li>
    </ul>
  </li>
</ul>

<h2 id="6-reference--additional-materials"><strong>6. Reference &amp; Additional materials</strong></h2>

<ul>
  <li>Github Implementation
    <ul>
      <li>https://github.com/huangtinglin/MixGCF</li>
    </ul>
  </li>
  <li>Reference
    <ul>
      <li>https://dl.acm.org/doi/abs/10.1145/3447548.3467408</li>
      <li>https://arxiv.org/abs/1806.01973</li>
      <li>https://arxiv.org/abs/2005.09863</li>
      <li>https://arxiv.org/abs/1710.09412</li>
      <li>https://dl.acm.org/doi/10.5555/1795114.1795167</li>
      <li>https://arxiv.org/abs/2002.02126</li>
      <li>https://arxiv.org/abs/1905.08108</li>
      <li>https://dl.acm.org/doi/10.1145/2484028.2484126</li>
      <li>https://dl.acm.org/doi/10.1145/3077136.3080786</li>
      <li>https://arxiv.org/abs/1811.04155</li>
    </ul>
  </li>
</ul>


    </div>



</article>
<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>







<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy;2023 Copyright 2021 Google LLC. All rights reserved. <br />
 Site last generated: Apr 26, 2023 <br />
<p><img src="images/company_logo.png" alt="Company logo"/></p>
                </div>
            </div>
</footer>






        </div>
    <!-- /.row -->
</div>
<!-- /.container -->
</div>
<!-- /#main -->
    </div>

</body>

<!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-66296557-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>





</html>


